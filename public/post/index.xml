<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts | Bowen&#39;s Academic Home</title>
    <link>https://bowenei.gitee.io/post/</link>
      <atom:link href="https://bowenei.gitee.io/post/index.xml" rel="self" type="application/rss+xml" />
    <description>Posts</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Sun, 26 Jun 2022 13:18:55 +0800</lastBuildDate>
    <image>
      <url>https://bowenei.gitee.io/media/icon_huc813daf5dbf7d2b27f0daba22fe1e0fb_68056_512x512_fill_lanczos_center_3.png</url>
      <title>Posts</title>
      <link>https://bowenei.gitee.io/post/</link>
    </image>
    
    <item>
      <title>从精神上站立起来</title>
      <link>https://bowenei.gitee.io/post/china-now-148/</link>
      <pubDate>Sun, 26 Jun 2022 13:18:55 +0800</pubDate>
      <guid>https://bowenei.gitee.io/post/china-now-148/</guid>
      <description>&lt;p&gt;“一边是‘精神美国人’，一边是自信阳光的年轻一代。我们应该全力支持中国正能量，走向全世界。”&lt;/p&gt;
&lt;p&gt;“在这种碎片化、西方化、功利化的环境之下，不少人处处以西为师，学问只为稻粱谋。”&lt;/p&gt;
&lt;p&gt;近期，人教版小学课本插画事件引起了全社会的广泛关注，也引发了热议。&lt;/p&gt;
&lt;p&gt;在东方卫视6月20日播出的&lt;a href=&#34;https://www.bilibili.com/video/BV1fZ4y1v77Z/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;《这就是中国》第148期&lt;/a&gt;节目中，复旦大学中国研究院院长张维为教授和复旦大学中国研究院副院长范勇鹏老师，就从这一事件开始，聊中国人如何“从精神上站立起来”。&lt;/p&gt;
&lt;h2 id=&#34;张维为教授演讲&#34;&gt;张维为教授演讲&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;最近这个人教版的小学课本一些插图引起了中国社会的广泛的公愤。插图里面的人物形象痴呆、表情怪异、动作不雅，美国星条旗的服饰、倒挂的五星红旗、赤裸裸的性暗示、各组颓废的西方文化符号等等。我个人认为，有一些“精神美国人”是下了决心要毁掉我们下一代的三观，让他们从小就陷入民族自卑、人种自卑、文明自卑。&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;中国网民还顺藤摸瓜，发现许多类似的问题，涉及儿童读物、人文社科书籍内容等等。我们有太多的教训要汲取，我们一定要依法追责、严惩，务必还我们的孩子一片净土，还我们的人文、艺术、社会科学一束中国自信的阳光。&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;“精神美国人”是中国特定年代产生的一批奇葩文人，大致从上世纪80年代开始经历了国门打开时的眼花缭乱，许多人一下子被西方的所谓“发达”所震撼，接下来是西方话语的渗透、文化的渗透、标准的渗透，直至他们完全丧失自信。当然，随着中国的迅速崛起，不少人开始觉醒了，但他们中还是有相当一部分人至今未醒悟。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;西方对中国的话语渗透和文化渗透，最常用的一个方法，就是通过各种交流或各种奖项，把某种“审美标准”灌输给中国的知识精英，然后又通过被西化的知识精英来垄断中国的审美标准，乃至中国人文、艺术、社会科学方面的标准，从而实现西方对中国的某种“文化规训”和“意识形态霸权”。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;他们在中国培养了一大批“精神美国人”，这影响一度非常之大，甚至忽悠了很多西方人。不少西方人在至少2012年前，真的以为“颜色革命”就要在中国成功了。我记得2011年福山跟我辩论时，他就判断中国将出现自己的“阿拉伯之春”；2012年党的十八大召开前一个星期，BBC记者采访我，第一个问题就是中共是否还会有十九大？这些实际上都反映了西方期待中国发生“颜色革命”的迫切心情以及当时“精神美国人”在国内外产生的影响。&lt;/p&gt;
&lt;p&gt;当然，物极必反，西方和西方培养的“精神美国人”最终大失所望，中国大陆不但没有发生他们所期待的“颜色革命”，而是进入了跨越式发展的新时代，迅速地走向世界政治和经济舞台的中央。&lt;/p&gt;
&lt;p&gt;而与此形成鲜明对照的是，美国和西方国家自己总体上一路走衰，美国的情况很像诺贝尔奖获得者斯蒂格利兹教授讲的：今天的美国为1%的人所有，为1%的人治理，为1%的人享用。&lt;/p&gt;
&lt;p&gt;这还使我想起一件往事，就是2010年秋天的时候，美国的一个网站叫“全球主义者”，组织了一批美国媒体人访问中国。这个网站的总编是我的朋友，他访华之后发了一篇很有意思的文章，题目是《在中国，美国梦仍在，而且还很美好》。对于他们在中国看到的奇特现象，他这样写：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;我们生活在一个奇怪的甚至可以说是扭曲的时代。突然间我们这些最拥护美国的人都对美国的未来产生了深切的怀疑，不知道这个国家是否还能辉煌下去。然而，在最近的中国之行中，我们发现在中国这片土地上，美国梦仍在，而且还很美好。这是令我们最为吃惊的。&lt;/p&gt;
&lt;p&gt;当中国媒体人和学者听到我们美国记者和学者批评美国政治陷入僵局、批评美国社会陷入严重冲突的时候，他们会非常不高兴……他们跟我们说，你们不要再说美国怎么不好了，我们不会相信的。你们在摧毁我们对未来的梦想，相信美国有美好的未来，是令我们中国人走出黑暗日子的动力。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;这位美国总编的这番话，不经意地点出问题的要害，就是这些“精神美国人”是一批“恨国党”，他们认为中国是黑暗的，美国才代表他们的未来，才代表光明。&lt;/p&gt;
&lt;p&gt;&lt;em&gt;正是这么一批内心如此扭曲的人，才会创作出如此没有底线，如此丑陋、猥琐、低俗的画作。虽然发现得晚了，但一经发现，这些东西瞬间就会变成“过街老鼠”，人人喊打。这表明中国社会的大气候已经发生了翻天覆地的变化。&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;这些“精神美国人”以及他们所代表的知识谱系，他们所崇拜的美国模式，今天在中国都走下了“神坛”，被大多数中国人所鄙视。&lt;/p&gt;
&lt;p&gt;&lt;em&gt;但我们也要看到，在中国社会的“小气候”里，这些人还有自己的圈子和山头。他们还在阻碍中国人文、艺术和社会科学的进步，还在威胁着中国的政治安全。所以，这种“小气候”的问题，需要认真解决。&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;与这些发自内心不自信的人相反，中国人民很自信：我们的工人很自信，因为他们生产了世界上种类最多最全的工业品；我们的农民很自信，因为他们用世界7%的耕地，养活了世界上20%的人口，而且可以让中国人做到食不厌精；我们的工程师很自信，他们完成了世界最大、最难的一个又一个的工程；我们的军队很自信，因为他们和西方的军队交过手，打败过西方的军队，他们是召之即来，来之能战，战之必胜，还有“东风快递，使命必达”；我们的国防科技工作者非常自信，用他们的话说就是“美国封锁什么，我们就能生产出什么”；我们的年轻人也很自信，他们自信地在广阔的平台上施展自己的才华。&lt;/p&gt;
&lt;p&gt;中国的知识精英，特别是文科知识分子，应该向我们的人民学习，向年轻人学习，首先从精神上站立起来，也就是王阳明所说的“灭山中贼易，灭心中贼难”。我们一定要从精神上站立起来，这比什么都更重要。&lt;/p&gt;
&lt;p&gt;我个人感到特别欣慰的是，中国年轻一代的崛起。&lt;/p&gt;
&lt;p&gt;举个例子，当我们很多主流文化界人士还在讨论“中国电影为什么走不出去”，或者“即使走出去了，为什么也出不了圈”之类问题的时候，我们中国的年轻一代已经通过互联网等媒介直接冲向世界。由中国年轻人推动的网络文学、短视频、动漫艺术、科幻作品、CG（计算机动画）画作、电竞游戏、手游作品、流行音乐，已经异军突起，在世界许多地方，特别是年轻人中受到热捧。他们表现出了巨大的文化自信，在不少方面走到了世界最前沿。&lt;/p&gt;
&lt;p&gt;他们的作品大都具有浓厚的中国色彩，也很有国际范。他们来自民间，可能有些粗糙，但总体上生机勃勃，具有强大的冲击力，有点像当年文艺复兴时期意大利薄伽丘的名作《十日谈》——《十日谈》的故事情节用今天的眼光来看十分简陋，但充满了生机，结果它开创了一个时代。&lt;/p&gt;
&lt;p&gt;今天中国网上的流行艺术风格，和当年欧洲文艺复兴还真的有一点类似。《十日谈》故事经常戏弄当时占主导地位的教会话语和教会的价值观。今天我们年轻人在精神上也站立起来了，他们无情地调侃美西方的价值观，调侃美西方对中国的傲慢、偏见、虚伪，他们自信地向全世界传递中国人的文化精神、审美意境、时代潮流，乃至政治主张。&lt;/p&gt;
&lt;p&gt;我有一种预感，中国的年轻一代，以他们今天的眼界、三观和才华，有可能通过互联网等手段，开启一场源于中国文化的，震撼这个世界的“文艺复兴”。&lt;/p&gt;
&lt;p&gt;一边是心理极其阴暗的“精神美国人”，一边是自信阳光的年轻一代，我们应该激浊扬清，铲除“精神美国人”在中国的影响，并以各种形式全力支持中国正能量走向全中国、走向全世界！&lt;/p&gt;
&lt;p&gt;好，今天我就跟大家分享这些，谢谢大家！&lt;/p&gt;
&lt;h2 id=&#34;范勇鹏老师演讲&#34;&gt;范勇鹏老师演讲&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;人教版教材这个事情暴露出来我觉得是个好事。现在有网友调侃说，“人民教育出版社”，这次“教育”成了一个动词，就是“人民‘教育’了出版社”。教材这个问题不是孤立的，它背后是不是存在着其他长期性或者系统性的问题，我觉得是值得我们深思的一个问题。&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;我们的社会知识体系大体上可分为两类，一类是基础知识，一类是专业知识，这两种知识不断反馈互动，但是专业知识毫无疑问是处于主导性的。&lt;/p&gt;
&lt;p&gt;&lt;em&gt;我认为今天中小学教材暴露出的看似是基础知识层次的问题，其实源头在于专业知识领域。真正出问题的，可能是在我们的大学和整个的知识界。为什么呢？&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;因为改革开放以来，我们努力地去吸收世界上一切先进的知识，但是这个过程中不可避免也会受到西方知识和价值观的渗透影响。它对我们的整个知识界的影响有很多消极的方面。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;首先，我们的知识体系失去了整体性，走向碎片化。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;在历史上，我们中国形成了非常宏伟深厚的知识体系，这个体系最大的一个特点就是整体性，至今我们中国人的思维仍然受益于此，我们非常擅长以一种整体、宏观和辩证的方式来看问题。&lt;/p&gt;
&lt;p&gt;然后近代西方科学兴起了，&lt;strong&gt;“科学”顾名思义就是分科之学&lt;/strong&gt;，这个本身是很有价值的，对我们中国文明也是一个重要的补充修正，但是它不应该成为一种替代。后来在革命和建设的过程中，我们在马克思主义的指导之下，也形成了一种新的整体性知识体系。但是从1980年代以后，西方社会科学大举引入，导致我们的人文社会的知识也更多地陷入了这种分科来主导的状态。&lt;/p&gt;
&lt;p&gt;问题是，我们面对的社会现象不是乖乖地按照学科划分来发展的。任何一个社会问题都不可能在某个学科之内得到完全的理解和解决。但是我们今天的人文社科学者，大部分都是在这种分科化的知识体系中学习和训练出来的，所以这些年出现了很多脱离实际的奇葩理论，各种历史虚无主义的观点。除了一些人主观上的问题，客观上也是因为有知识的缺陷，就是有一部分知识分子既不真懂中国，也不真懂外国。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;第二个消极的影响，就是西方社会科学的传入让我们失去了主体性，过度西方化。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;有一些学科逐渐就失去了原有的主心骨，有一些学科几乎完全就是从西方移植而来的，有的干脆直接拿西方的原版，拿到中国大学里来当教材。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;最后是知识生产方式的功利化。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;由于受到西方思想和市场经济的影响，我们不少大学变得急功近利。比方说办学方式过于商业化，资本的影响上升，科研管理上不以产生真知识、好思想为目标，盲目地追求量化，唯生产力论，仿佛发论文是天下第一要务，比教师教好学生、医生治好病人、研究者脚踏实地做好研究都要重要百倍。&lt;/p&gt;
&lt;p&gt;在这种碎片化、西方化、功利化的环境之下，我们中国的人文社科知识界不少人失去了对世界进行整体宏观把握的能力，缺乏比较眼光和国际视野；不少人失去了主体意识，崇洋媚外，处处以西为师；不少人失去了追求真知真理的志气，学问只为稻粱谋。&lt;/p&gt;
&lt;p&gt;就像刚才张老师讲的，随着中国的发展，这个群体今天已经严重落伍了，不仅他们的圈子越来越小，而且后继乏人。中国的年轻一代更加自信，精神上完全站了起来，完全不买他们的账。&lt;/p&gt;
&lt;p&gt;但是这些特定历史时期遗留下来的问题依然存在。那么怎么解决这些问题？我想到了三段话，都是非常有启发的。&lt;/p&gt;
&lt;p&gt;第一段话是诸葛亮的。在《三国演义》里边有一个很精彩的片段，叫“舌战群儒”，诸葛亮面对东吴的那群酸儒说了一段话，非常精彩：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;儒有小人君子之别。君子之儒，忠君爱国，守正恶邪，务使泽及当时，名留后世。若夫小人之儒，惟务雕虫，专工翰墨，青春作赋，皓首穷经；笔下虽有千言，胸中实无一策。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;这段话我觉得几乎不用修改，就可以拿来描述我刚才讲到的这样一群人——攒论文下笔千言，发C刊（核心期刊）著作等身，但是对人民的关切、对国家的命运毫不关心，一辈子死抱着从西方学来的这个理论、那个范式。这就是典型的“小人儒”。&lt;/p&gt;
&lt;p&gt;第二段话是鲁迅的，他在1907年写了一篇文章叫《文化偏至论》。在这篇文章里他就批评20世纪初的中国知识界，他说这些人听了几句西方的新鲜玩意，就“言必称西方”，叫“&lt;strong&gt;言非同西方之理弗道，事非合西方之术弗行&lt;/strong&gt;”，要求我们必须走西方化的道路。&lt;/p&gt;
&lt;p&gt;在鲁迅看来，这些西方派知识分子叫“&lt;strong&gt;近不知中国之情，远复不察欧美之实&lt;/strong&gt;”。这句话同样可以用来评价今天知识界一些缺乏自信者、“精美”、“精日”派，太传神了。他们根子上的问题就是既不懂中国，也不懂西方。&lt;/p&gt;
&lt;p&gt;那么正确的做法，鲁迅给了一个答案，就是要研究、比较，权衡利弊，然后得到科学客观的规律，再用于中国，做到“&lt;strong&gt;外之既不后于世界之思潮，内之仍弗失固有之血脉&lt;/strong&gt;”。这句话我觉得相当值得我们今天文化学术界深思共勉。&lt;/p&gt;
&lt;p&gt;我想到的第三段话是毛泽东主席的，他在1947年写了一篇很重要的文章，叫《改造我们的学习》。文章批评了这样一种人，他原话是这么说的：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;对自己的东西既无知识，于是剩下了希腊和外国故事，也是可怜得很，从外国的故纸堆中零星地捡来的。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;所以他总结说：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;这种主观主义的方法是共产党的大敌，是工人阶级的大敌，是人民的大敌，是民族的大敌，是党性不纯的一种表现。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;em&gt;那么今天教材暴露出的问题，以及我们学术文化界积累的很多问题，也是我们社会主义和民族复兴事业的大敌。&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;我们今天需要的，是触及灵魂、触及利益、破除权力堡垒的一场整顿改革，让实事求是压倒理论空谈，让自信自主取代崇洋媚外，让生动活泼摆脱陈陈相因，让青年冲破既得利益群体的代际压迫，让专业知识和基础知识形成良性的反馈与循环。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;最最关键的，就是要在我们的教材、课堂，以及一切阵地上牢牢树立我们的中国自信和人民立场。&lt;/p&gt;
&lt;p&gt;好，谢谢大家！&lt;/p&gt;
&lt;h2 id=&#34;圆桌讨论&#34;&gt;圆桌讨论&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;主持人何婕&lt;/strong&gt;：谢谢两位刚才给出的演讲。我在讨论这部分我也引入一些不同的观点和声音，也请两位继续来做一些阐述。就说到插画问题，也有一些不同的声音说，这个看上去好像就是一个审美不同的问题，可能是一个艺术水平不够高的问题。是不是不是两位说到的那么严肃的问题？面对这样的一种观点，两位的观点是什么？&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;张维为教授&lt;/strong&gt;：任何国家对于小学、中学的教材，甚至大学的教材，如果有插图的话，它都是倾向于比较能够反映自己国家文化或者主流价值观的东西。所以我讲对于在这方面应该有这么一种共识的——用民族的反映多数人喜欢的、向上的这样一种作品，大家比较欢迎。如果你是小众的纯艺术家的，里边你有自己不同的创造，各种流派，这是另外一回事情。&lt;/p&gt;
&lt;p&gt;而且我们要实事求是看到，因为我自己过去学过一点美术，特别是这些画家代表的，和整个中国当代艺术的的兴起，背后是资本的理念。我在瑞士生活过，瑞士一个大资本家收集大量中国这种现代化的作品，全是解构中国革命，一个个都是麻木不仁的样子。他们就喜欢这种作品。但你看，中国这种艺术作品是没有灵魂的。最终你看现在这个价格也在一直往下走，一个重要原因就是，外国人一旦不感兴趣，它马上就一路走衰了。&lt;/p&gt;
&lt;p&gt;我记得过去1960年代1950年代的时候，现在可能不是很多，当时每年有组出的很精致的《美术日记》，傅抱石的、齐白石的、李可染的、黄永玉的。我自己就受《美术日记》的影响，一下子眼界就很高，发现美的眼睛是小时候朦朦胧胧时就发现。而且我觉得儿童作品，品味非常之重要。你初步形成这种观点，包括你阅读教材，小时候看到教材很激动的。教材发下来一叠，看里面图画。&lt;/p&gt;
&lt;p&gt;所以这个“丑化插图”教材害死人。我觉得我们一定要把这个问题的原因找出来，而不能就事论事，要把后边问题的根子找出来。我认为是“精神美国人”在祸害我们下一代。这个问题一定要解决。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;范勇鹏老师&lt;/strong&gt;：审美这个东西，确实有些人你可以在创作，在小众的范围之内，你可以去发挥自己的个性。但是作为一个社会，特别是在教材这种基础教育里边，它审美肯定是要有一些基本的标准和门槛的。那么这次暴露出来的问题确实是感觉太反常了，所以背后一定是有很深很深的问题。&lt;/p&gt;
&lt;p&gt;西方长期操纵审美标准来丑化中国人的形象，是近代以来的一个重要现象。然后这些年的文化入侵把这些种族主义、殖民主义的审美文化也给带到中国。另外就是张老师刚刚讲到的一些资本，他有意的带节奏，然后把中国的文艺界很多人给带到这个方向上来。所以商家习惯于去找一个白人来做广告，然后使用中国人形象的时候就刻意用那种眯眯眼、雀斑、很空洞的眼神、生无可恋的表情。这几年爆出了很多这样的事件，包括一些西方的时尚品牌、汽车都引起了很多争议。&lt;/p&gt;
&lt;p&gt;那么，其实关于审美，它本质的问题不在于你哪个个人长得美还是不美，或者是你这个民族长得美还是不美。这个问题本身就是一个陷阱，关键就在于谁有资格，拿什么标准来决定什么是美，谁来决定谁应该长什么样。这个教材的问题，根本也不是说美和不美的问题，而是非要以它的标准把中国孩子给刻画成这个样子，把你给刻板化，强行灌输一种审美观。所以我觉得它是一个非常深层的问题。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;主持人何婕&lt;/strong&gt;：所以，其实坚守我们自己传统的一种审美的标准，其实就是在坚持我们自己的文化。再来观察这次因为插画问题而引发的种种的讨论。有的网友也在网络上留言说，其实自己很多年前就提出过这个问题了，可是这么多年过去了，到现在才引发了大家的关注。所以接下来要请两位再给我们来做一个分析，这当中是不是还是有一些变化？&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;张维为教授&lt;/strong&gt;：我后来看了好像这个版本是2012年，就意味着它这个创作可能是2011年、2010年这个时代的作品。那就是我们当时“公知”、“精神美国人”最猖狂的时代，他们都觉得他们就可以主导中国了，西方觉得他们代表“颜色革命”的成功了。当然随着时代的发展，我们看到情况不是这样。我想过去十来年，最大变化就是互联网的崛起。这个东西到网上，然后引起注意，而且引起这么多人的反感，这是个质的变化。&lt;/p&gt;
&lt;p&gt;我觉得我们的大环境变了，中国人民自信起来了。前段时间由于疫情，所以一下子好像国内悲观情绪又比较多。我说没事儿，中国人民骨子里非常自信，对自己的制度、自己的道路、自己的国家很有信心，再次证明了这一点。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;主持人何婕&lt;/strong&gt;：张老师说到这一点，确实我们看过去这些年的发展，中国人的自信是越来越强。但是在遇到一些挑战、一些问题的时候，大家还是会有困惑。如果我们说精神上还是不够自信，生活中还有哪些表现？&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;范勇鹏老师&lt;/strong&gt;：这几年其实有很多表现。我的观察，比如像中美贸易战开始之后，有的经济学家、知识分子就讲“中国必败”。特别是还有一些媒体人说“要抓住时机妥协”，甚至有人就明讲你将来连投降的机会都没有，现在是最好的投降机会。这就是典型的不自信。&lt;/p&gt;
&lt;p&gt;另外像华为或一些中国企业受到美国的不公正打压之后，有的法学界人士或者专业人士，他不是先按照是非曲直来把这个问题讲清楚，而是急于去反省、去看中国企业身上有没有什么毛病。总是有一种观念，就是人家为什么打你，肯定是你有问题。&lt;/p&gt;
&lt;p&gt;包括像美国的长臂管辖，从国际法角度来讲，这种长臂管辖是完全没有道理的，但是有知识分子、学者会给它作论证。这次俄乌冲突其实就对这样一种观念造成了比较大的打击。这是大的方面。&lt;/p&gt;
&lt;p&gt;小的方面，其实我在工作、生活里边会遇到一些很多具体的不自信的（表现）。比如像我们文科，不管你去申请课题、做项目论证，还是写政策建议等等，一定要有什么国外前沿信息、所谓国际先进经验。本能地认为西方某种东西一定是先进的，默认西方就是一种主流，顺之则昌，逆之则亡。&lt;/p&gt;
&lt;p&gt;我们要认识到，国际化本身是一个工具性的东西，它要因时而变；我们要不要国际化、国际化多少，是要与时俱进的。但是有一些人就把它当成一种抽象的教条，甚至当成某种“政治正确”。这些现象反映的都是这种精神上的不自信，精神上没有站起来的现象。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;张维为教授&lt;/strong&gt;：主要原因来源于这些年西方话语的洗脑。我可以举个例子，我上次看到一个材料，中国这些年政治学的研究，发觉研究最多的、一度占到一半左右的课题都是什么？都和村民选举有关，也就是我们中国最基层的一人一票选举有关。为什么？因为在西方政治学里，他们觉得只有这个（基层民主）跟民主有一点点关系，协商民主、民主集中制等等都不算民主，资金也就走向这样的课题。&lt;/p&gt;
&lt;p&gt;我自己是2011年回国的，我当时非常惊讶，就是因为我1994年做完博士论文的时候，我非常明确地意识到，战后美国形成的政治学和国际关系学，坦率地讲，很大的比例是伪科学——不光是我这样说，很多西方学者也这样说。现在证明它的研究路径本身可能就是错了的。&lt;/p&gt;
&lt;p&gt;我们当时觉得，美国那几个最有名的政治学期刊是垃圾，应该丢到垃圾箱里去。我回国后才知道，你在这些刊物上发一篇文章，去评教授都可以，而且英文发表对于你的整个评价，比中文发表高很多。我对此非常不习惯，我说这个东西是要出大问题的。现在十年过去了，我们才刚开始在解决这个“五唯”的问题。&lt;/p&gt;
&lt;p&gt;这些问题都很能说明我们文科受到西方话语影响，这是我们一定要解决问题。我们中国研究院从成立的第一天就非常明确，不做西方话语的“打工仔”，而是要“解构西方话语、建构中国话语”。我们提的很多观点，现在大家开始接受了，包括“阿拉伯之冬”，最近“文明型国家”也成为一个国际热点话题。我非常高兴，我们中国人要做引领世界的事情。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;主持人何婕&lt;/strong&gt;：刚才您说您觉得受到西方话语影响的人还是非常的多，我在想他受到影响之后，有一部分人真的是相信了，还有一部分人可能处于一种惯性的思维中；还有一种声音，尤其是自俄乌冲突以来，发现美国想要去打压、制裁、围堵一个国家时，它真的可以调动许许多多的力量，所以很多人得出一个结论说，美国还是那么强大。这种畏强心理会不会也是在精神上不够独立的一个非常重要的原因？&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;张维为教授&lt;/strong&gt;：你就看《这就是中国》节目一路走来，我们对很多事情都提前作出判断了，美国就是要失败的。我对西方形成的国际关系理论总体评价不高，但是里边有一个理论，即结盟理论，它讲到一点，这个联盟里边的角色越多，联盟往往越不牢靠。你看北约，芬兰、瑞典要加入，加入不了，一个土耳其就拦住了。他们说北约要扩大到亚洲来，我说开什么国际玩笑，俄罗斯允许北约东扩了五次，我们中国一次都不允许。这就是中国的实力。我这板块放在这里的，决定性的，你根本动摇不了。&lt;/p&gt;
&lt;p&gt;美国现在是色厉内荏的不得了，处在非常弱的时候，你看民主峰会，它的王牌，点击量2万都不到，就这么一个水平。我们中国的决策者、核心智库非常有定力，根本不用担心。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;主持人何婕&lt;/strong&gt;：好，张老师的观点非常明确地指出，现在美国仿佛能够调动一些资源。所谓的这种“调动”恰恰是它无力的表现。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;张维为教授&lt;/strong&gt;：你看好了，之后很可能兵败如山倒，就是不光是输掉了乌克兰，还输掉整个北约，输掉美国主导的整个经济秩序。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;范勇鹏老师&lt;/strong&gt;：我非常同意。其实您讲的畏强心理，或者现在对美国、对西方还抱着这种不切实际的过度想象的一群人，其实真的是一个小圈子，而且越来越少。为什么？从我从事学术工作以来，我其实经历过好几代“不自信知识分子”，它背后的原因是不一样的。&lt;/p&gt;
&lt;p&gt;比如像我们年轻的时候，当时的老师一辈，确实有一部分知识分子非常不自信，对中国的看法是非常悲观的。这样一些知识分子在早期有过一些不好的经历，所以他会对西方产生了一种心理寄托，认为西方就代表着文明进步。&lt;/p&gt;
&lt;p&gt;第二波就是1980年代成长起来的一群人，当时的西方确实是太强大、太发达了，被震撼到了。所以他们一旦出去之后，形成的精神创伤很难愈合。这个是当前我们国内“精神美国人”的主流的一部分。&lt;/p&gt;
&lt;p&gt;第三波是1990年代扩大开放，大量走出去的一拨人，特别是在西方受到系统的社会科学教育的，一旦在头脑里边被植入这样一种逻辑闭环，一般人很难跳出来。&lt;/p&gt;
&lt;p&gt;第四波是21世纪初，中国人的精神开始上升，经济社会变化。人文知识分子当时所标榜的西化背景贬值了，形成心理落差，另外中国各方面的进步又打破了他们原有的认知系统，这些人很痛苦，所以形成了一种逆反思维。&lt;/p&gt;
&lt;p&gt;还有最后一波就是（党的）十八大以来，我们全国“四个自信”全面增强，我们年轻人的民族自豪感上升。同时在各个领域，我们反腐改革整顿的力度都很大，整个社会朝着非常好的方向发展。规矩多了，有一些人的利益空间、任性空间就少了。&lt;/p&gt;
&lt;p&gt;综合上面讲的这几类，我看到的是“落花流水春去也”，所以是完全不用太担心的。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;主持人何婕&lt;/strong&gt;：年轻人对整个世界的认知还在塑造过程中，对于可能在精神上还有一些困惑的人来说，到底从哪里开始可以把自信培养起来？&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;张维为教授&lt;/strong&gt;：我个人觉得自信的培养和一种健康的人格的培养是一样的，应该是人格教育的一部分。我们要鼓励孩子自信，这个是我们每个家长都应该做的。另外，我们现在注意到一个现象，从大数据看也好，我们见到的年轻人也好，总体上我们比中国任何一代人都更加自信。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;范勇鹏老师&lt;/strong&gt;：人的精神就跟打铁一样，需要不断地来回锻造，在这个过程中会遇到各种不同观点的碰撞，最后产生的那种自信，它是一种真正的自信。就像打铁叫“百炼成钢绕指柔”，这样一种有坚韧的自信。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;主持人何婕&lt;/strong&gt;：那说到精神自信这个话题，我想可能有的朋友他可能还会有这个困惑，他会觉得当我们说精神自信的时候，是不是意味着我们可以不用听西方的？我希望两位可以给我一个明确的解答，怎么平衡好这个度？&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;张维为教授&lt;/strong&gt;：实际上是这样的，我们讲自信，是平视我们的对方，平视外部世界。平视的最大好处就是能够理性地、客观地看对方，更加地实事求是，我觉得这个是特别之重要。另外还有一点，今天中国之自信它一点是不排外的，它不是虚假的自信，它是在中国高度开放之后，在非常了解互联网的运作之后，在了解各种中西方文化元素之后，它产生一种发自内心的自信。所以我们国际眼光非常重要。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;范勇鹏老师&lt;/strong&gt;：自信绝对不意味着我们不去学习别人的东西了，我们关上大门了。而且中国历史几千年，我们从来没有拒绝去学习、借鉴别人的东西，不管是技术、贸易还是思想，一直到我们当代的马克思主义，都是从别人那里好的东西我们吸收过来。但是问题在哪儿呢？就是你只有自信了，比如张老师讲的“平视”，你才能更好地去吸收它。&lt;/p&gt;
&lt;p&gt;文化，它讲的是“文以化之”。那么文化交流的最终目的是，我要“化”掉你，而不是你要把我“化”掉。所以这个自信恰恰是要求我们有一个更强健的体魄，更强健的精神，我们能够更好地去吸收别人好的东西。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;主持人何婕&lt;/strong&gt;：我们今天从教材插画问题开始说，说到精神上的一种自信和独立，真的它代表的是一种“平视”，不是“仰视”也不是“俯视”。用两位在整个节目中用过的几句话，我可以来做一个结束语：&lt;/p&gt;
&lt;p&gt;什么叫精神自信——真的懂中国，同时也真的懂外国。要有一些浩然正气，不做西方话语的“打工仔”。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>挑战 2022 年高考全国乙卷数学压轴大题</title>
      <link>https://bowenei.gitee.io/post/college-entrance-examination-2022-mathematics/</link>
      <pubDate>Wed, 15 Jun 2022 19:51:34 +0800</pubDate>
      <guid>https://bowenei.gitee.io/post/college-entrance-examination-2022-mathematics/</guid>
      <description>&lt;p&gt;2022 年高考已落下帷幕，不少考生表示今年的数学是“历史第二难”。于是，我打算尝试一下今年全国乙卷数学的最后两道大题，切身体会一下今年学子们的不易。&lt;/p&gt;
&lt;h2 id=&#34;解析几何&#34;&gt;解析几何&lt;/h2&gt;
&lt;p&gt;已知椭圆 $E$ 的中心为坐标原点，对称轴为 $x$ 轴、$y$ 轴，且过 $A(0,-2),B(\frac{3}{2},-1)$ 两点。&lt;/p&gt;
&lt;p&gt;$(1)$ 求 $E$ 的方程；&lt;/p&gt;
&lt;p&gt;$(2)$ 设过点 $P(1,-2)$ 的直线交 $E$ 于 $M,N$ 两点，过 $M$ 且平行于 $x$ 轴的直线与线段 $AB$ 交于点 $T$，点 $H$ 满足 $\vec{MT} = \vec{TH}$。证明：直线 $HN$ 过定点。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;解：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;设椭圆 $E$ 的方程为&lt;/p&gt;

$$
\frac{x^2}{a^2} + \frac{y^2}{b^2} = 1 \quad (a,b&gt;0)
$$

&lt;p&gt;将 $A(0,-2),B(\frac{3}{2},-1)$ 两点坐标代入得&lt;/p&gt;

$$
\begin{cases}
\frac{4}{b^2} = 1 \\\\
\frac{9}{4a^2} + \frac{1}{b^2} = 1
\end{cases}
$$

&lt;p&gt;解得&lt;/p&gt;

$$
\begin{cases}
a^2 = 3 \\\\
b^2 = 4
\end{cases}
$$

&lt;p&gt;因此椭圆 $E$ 的方程为&lt;/p&gt;

$$
\frac{x^2}{3} + \frac{y^2}{4} = 1
$$

&lt;p&gt;第 $(2)$ 小题给出的条件特别多，我们慢慢梳理这些条件。首先条件中提到了线段 $AB$，并且有一条直线与线段 $AB$ 有交点。因此需要给出直线 $AB$ 的方程，用两点式表示，得到&lt;/p&gt;

$$
\begin{align}
\frac{y + 2}{x} &amp;= \frac{2}{3}
\end{align}
$$

&lt;p&gt;化为一般式&lt;/p&gt;

$$
l_{AB}: 2x - 3y - 6 = 0
$$

&lt;p&gt;由于本题是证明题，我们可以通过特例得出答案，然后再证明其一般性。因此，我们考察过 $P$ 点的竖直直线这一情况。此时 $M$ 点的横坐标为 $1$，代入椭圆方程得到&lt;/p&gt;

$$
\frac{1}{3} + \frac{y^2}{4} = 1
$$

&lt;p&gt;解得&lt;/p&gt;

$$
y = \pm \frac{2\sqrt{6}}{3}
$$

&lt;p&gt;即 $M,N$ 两点的坐标分别为 $(1,-\frac{2\sqrt{6}}{3}),(1,\frac{2\sqrt{6}}{3})$。于是将 $y=-\frac{2\sqrt{6}}{3}$ 代入直线 $AB$ 的方程&lt;/p&gt;

$$
2x + 2\sqrt{6} - 6 = 0
$$

&lt;p&gt;解得&lt;/p&gt;

$$
x = 3 - \sqrt{6}
$$

&lt;p&gt;即 $T$ 点的坐标为 $(3-\sqrt{6},-\frac{2\sqrt{6}}{3})$。依题意，$\vec{MT} = \vec{TH}$，我们可以求出 $\vec{MT}$ 的坐标：&lt;/p&gt;

$$
\vec{MT} = (2-\sqrt{6},0)
$$

&lt;p&gt;于是 $H$ 点的坐标为 $(5-2\sqrt{6}, -\frac{2\sqrt{6}}{3})$。下面就可以利用两点式写出直线 $HN$ 的方程：&lt;/p&gt;

$$
\frac{y - \frac{2\sqrt{6}}{3}}{x - 1} = \frac{-\frac{2\sqrt{6}}{3} - \frac{2\sqrt{6}}{3}}{4-2\sqrt{6}}
$$

&lt;p&gt;整理之后得到&lt;/p&gt;

$$
y = (2 - \frac{2\sqrt{6}}{3})x - 2
$$

&lt;p&gt;可以看出，直线 $HN$ 过点 $(0,-2)$。那么是不是一定过定点 $(0,-2)$ 呢？目前得出的结论是无法判断的，但我们可以猜想直线 $HN$ 过定点 $(0,-2)$。为了证明这个猜想，我们还需要进行不失一般性的计算。&lt;/p&gt;
&lt;p&gt;过点 $P(1,-2)$ 的直线与椭圆 $E$ 相交与 $M,N$ 两点，我们设其点斜式方程为：&lt;/p&gt;

$$
l_{MN}: y + 2 = k(x - 1)
$$

&lt;p&gt;将其与椭圆 $E$ 的方程联立，并代入得&lt;/p&gt;

$$
\begin{align}
4x^2 + 3[k^2(x-1)^2 - 4k(x-1) + 4] - 12 &amp;= 0 \\\\
(3k^2+4)x^2 - 6k(k + 2)x + 3k(k+4) &amp;= 0
\end{align}
$$

&lt;p&gt;设 $M,N$ 两点坐标分别为 $(x_1,y_1),(x_2,y_2)$，由韦达定理得&lt;/p&gt;

$$
\begin{align}
x_1+x_2 &amp;= \frac{6k(k+2)}{3k^2+4} \tag{1} \\\\
x_1x_2 &amp;= \frac{3k(k+4)}{3k^2+4} \tag{2}
\end{align}
$$

&lt;p&gt;进一步可以得到&lt;/p&gt;

$$
\begin{align}
y_1+y_2 &amp;= k(x_1+x_2) - 2k - 4 \\\\
&amp;= \frac{6k^2(k+2)}{3k^2+4} - \frac{(2k+4)(3k^2+4)}{3k^2+4} \\\\
&amp;= -\frac{8(k+2)}{3k^2+4} \tag{3} \\\\
y_1y_2 &amp;= [k(x_1-1) - 2][k(x_2-1) - 2] \\\\
&amp;= k^2(x_1x_2 - x_1 - x_2 + 1) - 2k(x_1 - 1) - 2k(x_2 - 1) + 4 \\\\
&amp;= k^2x_1x_2 - k(k+2)(x_1+x_2) + (k+2)^2 \\\\
&amp;= \frac{3k^3(k+4)}{3k^2+4} - \frac{6k^2(k+2)^2}{3k^2+4} + \frac{(k+2)^2(3k^2+4)}{3k^2+4} \\\\
&amp;= -\frac{8(k^2 - 2k - 2)}{3k^2+4} \tag{4} \\\\
x_1y_2 + x_2y_1 &amp;= x_1(kx_2 - k - 2) + x_2(kx_1 - k - 2) \\\\
&amp;= 2kx_1x_2 - (k+2)(x_1+x_2) \\\\
&amp;= \frac{6k^2(k+4)}{3k^2+4} - \frac{6k(k+2)^2}{3k^2+4} \\\\
&amp;= -\frac{24k}{3k^2+4} \tag{5}
\end{align}
$$

&lt;p&gt;式 $(1)$-$(5)$ 是下面计算化简的依据，我们在这里提前准备好。&lt;/p&gt;
&lt;p&gt;依题意，过 $M$ 且平行于 $x$ 的直线交线段 $AB$ 于点 $T$。我们将 $y=y_1$ 代入直线 $AB$ 的方程，得到&lt;/p&gt;

$$
\begin{align}
2x - 3y_1 - 6 &amp;= 0 \\\\
x &amp;= \frac{3}{2}y_1+3
\end{align}
$$

&lt;p&gt;于是可以得到 $T$ 点的坐标为&lt;/p&gt;

$$
(\frac{3}{2}y_1+3, y_1)
$$

&lt;p&gt;依题意，$\vec{MT} = \vec{TH}$，说明 $T$ 是线段 $HM$ 的中点。并且线段 $HM$ 显然与 $x$ 轴平行，$H$ 点的纵坐标与 $T$ 点相同，横坐标可以用如下的中点坐标公式求得&lt;/p&gt;

$$
\begin{align}
x_H &amp;= 2 \times (\frac{3}{2}y_1+3) - x_1 \\\\
&amp;= 3y_1 - x_1 + 6
\end{align}
$$

&lt;p&gt;于是可以得到 $H$ 点的坐标为&lt;/p&gt;

$$
(3y_1 - x_1 + 6, y_1)
$$

&lt;p&gt;现在，可以用两点式写出直线 $HN$ 的方程&lt;/p&gt;

$$
\begin{align}
l_{HN}: \frac{y - y_2}{x - x_2} &amp;= \frac{y_1 - y_2}{3y_1 - x_1 + 6 - x_2}
\end{align}
$$

&lt;p&gt;化简以后得到&lt;/p&gt;

$$
\begin{align}
(y_1-y_2)x - (3y_1-x_1-x_2+6)y + 3y_1y_2 + 6y_2 - x_1y_2 - x_2y_1 &amp;= 0
\end{align}
$$

&lt;p&gt;我们仔细观察上式，发现有很多项已经在我们之前利用韦达定理以及由其导出的结果中出现，例如 $y_1y_2$、$x_1y_2 + x_2y_1$。但是还有个别的 $y_1$、$y_2$ 之前的系数待定，甚至还出现了 $y_1-y_2$。很巧妙的一点是，我们将点 $(0, -2)$ 代入得&lt;/p&gt;

$$
\begin{align}
6(y_1+y_2) - 2(x_1+x_2) + 12 + 3y_1y_2 - x_1y_2 - x_2y_1 &amp;= 0 \\\\
\end{align}
$$

&lt;p&gt;发现所有那些无法配对的项都可以成功配对了！我们尝试将所有的 $x_1,x_2,y_1,y_2$ 都用 $k$ 来表示，得到&lt;/p&gt;

$$
\begin{align}
6(y_1+y_2) - 2(x_1+x_2) + 12 + 3y_1y_2 - x_1y_2 - x_2y_1 &amp;= 0 \\\\
-\frac{48(k+2)}{3k^2+4} - \frac{12k(k+2)}{3k^2+4} + 12 - \frac{24(k^2 - 2k - 2)}{3k^2+4} &amp;+ \frac{24k}{3k^2+4} = 0 \\\\
48(k+2) + 12k(k+2) + 24(k^2-2k-2) - 24k &amp;= 12(3k^2 + 4) \\\\
36k^2 + 48 &amp;= 12(3k^2 + 4)
\end{align}
$$

&lt;p&gt;可以看到上述等式恒成立，与 $k$ 的取值无关。&lt;/p&gt;
&lt;p&gt;综上所述，直线 $HN$ 过定点 $(0,-2)$。&lt;/p&gt;
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /post/college-entrance-examination-2022-mathematics/ellipse_hu2cdc033a8eba5e67444b581ccefb8792_14238_ea6ae7d6efb6f8a3a600b7cd37e9e11a.webp 400w,
               /post/college-entrance-examination-2022-mathematics/ellipse_hu2cdc033a8eba5e67444b581ccefb8792_14238_807adc1edcb2b6aea2cc19b3c24dd977.webp 760w,
               /post/college-entrance-examination-2022-mathematics/ellipse_hu2cdc033a8eba5e67444b581ccefb8792_14238_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://bowenei.gitee.io/post/college-entrance-examination-2022-mathematics/ellipse_hu2cdc033a8eba5e67444b581ccefb8792_14238_ea6ae7d6efb6f8a3a600b7cd37e9e11a.webp&#34;
               width=&#34;269&#34;
               height=&#34;265&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;p&gt;&lt;strong&gt;点评&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;本题题型较为常规，是一个证明直线过定点的问题。证明直线过定点的问题一般有如下两种思路：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;直接整理出带参数的直线点斜式方程，然后直接看出直线所过定点。&lt;/li&gt;
&lt;li&gt;首先通过特例判断定点坐标，然后再加以不失一般性的证明。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;然而，本题的条件特别多，这需要我们认真捋顺各点的关系。直线 $MN$ 的过定点 $P$，$MN$ 倾斜角的变化带动 $M,N$ 两点坐标的变化。后又出现 $T,H$ 两点，且和 $M$ 点满足一定的数量关系。最后又将 $H,N$ 两点连接起来。&lt;/p&gt;
&lt;p&gt;我们经过一步步的推导，将直线 $HN$ 的方程最终表示为与 $M,N$ 两点相关的带参数的方程。但是，这个时候并不能将所有参数用某一个参数表示，因此通过因式分解等方法化简直线方程以看出直线过定点的方法行不通。&lt;/p&gt;
&lt;p&gt;但本题是证明题，我们就可以先通过特例尝试猜想直线 $HN$ 过哪个定点。特例的选取应当具有一定的特殊性，并且计算简便。平行于坐标轴的直线由于其方程仅含 $x$ 或 $y$ 而计算简便，根据本题的具体情况，我们选择和 $y$ 轴平行的竖直直线，并且很容易地得到了它的方程。&lt;/p&gt;
&lt;p&gt;我们之所以可以猜想直线 $HN$ 过定点 $(0,-2)$，是因为&lt;/p&gt;

$$
\begin{cases}
x = 0 \\\\
y = -2
\end{cases}
$$

&lt;p&gt;是二元一次方程&lt;/p&gt;

$$
y = (2 - \frac{2\sqrt{6}}{3})x - 2
$$

&lt;p&gt;唯一的一对有理数解。从 $x$ 前的系数是无理数就可以看出来这一性质。如果直线 $HN$ 所经过定点的坐标包含无理数，那么不失一般性的计算必然无法化简。换而言之，我们也只有尝试 $(0,-2)$ 这一点的可能。结果，经过我们的证明，直线 $HN$ 确实过定点 $(0,-2)$。&lt;/p&gt;
&lt;p&gt;本题巧妙之处就在于，我们所选择的特例仅过 $(0,-2)$ 唯一一个有理数点，这为我们判断直线 $HN$ 过定点 $(0,-2)$ 带来了极大的方便。如果特例的方程不含无理数，我们仍然难以判断直线 $HN$ 究竟过哪个定点。&lt;/p&gt;
&lt;p&gt;不过，本题的难点在于计算量较大。除了韦达定理本身以外，还需要导出一些其他的结果以便于将所有点的坐标用 $k$ 表示。此外，还需要对式子有敏锐的观察力，每项如何凑在一起可以“消灭”。如果不能够冷静观察式子的结构，在考场上很难有信心继续算下去。&lt;/p&gt;
&lt;h2 id=&#34;函数与导数&#34;&gt;函数与导数&lt;/h2&gt;
&lt;p&gt;已知函数 $f(x) = \ln (1+x) + axe^{-x}$。&lt;/p&gt;
&lt;p&gt;$(1)$ 当 $a = 1$ 时，求曲线 $y = f(x)$ 在点 $(0,f(0))$ 处的切线方程；&lt;/p&gt;
&lt;p&gt;$(2)$ 若 $f(x)$ 在区间 $(-1,0),(0,+\infty)$ 各恰有一个零点，求 $a$ 的取值范围。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;解：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;依题意，当 $a=1$ 时，&lt;/p&gt;

$$
f(x) = \ln (1+x) + xe^{-x}
$$

&lt;p&gt;第 $(1)$ 小题要求切线方程，因此需要利用导数。我们对 $f(x)$ 求导得&lt;/p&gt;

$$
f^{\prime}(x) = \frac{1}{1 + x} + (1-x) e^{-x}
$$

&lt;p&gt;于是点 $(0,f(0))$ 处的切线斜率为&lt;/p&gt;

$$
f^{\prime}(0) = 2
$$

&lt;p&gt;故点 $(0,f(0))$ 处的切线方程为&lt;/p&gt;

$$
y = 2x
$$

&lt;p&gt;要回答第 $(2)$ 小题，我们需要直接对 $f(x)$ 求导，得到&lt;/p&gt;

$$
\begin{align}
f^{\prime}(x) &amp;= \frac{1}{1 + x} + a(1-x) e^{-x} \\\\
&amp;= \frac{1 + a(1-x^2)e^{-x}}{1+x}
\end{align}
$$

&lt;p&gt;这个式子很难判断零点和单调性。但考虑到函数 $f(x)$ 的定义域为 $(-1,+\infty)$，因此分母恒正。下面我们单独来处理导函数的分子，令&lt;/p&gt;

$$
g(x) = 1 + a(1-x^2)e^{-x}
$$

&lt;p&gt;对 $g(x)$ 求导，得到&lt;/p&gt;

$$
\begin{align}
g^{\prime}(x) &amp;= a[-2xe^{-x} + (x^2-1)e^{-x}] \\\\
&amp;= a(x^2 - 2x - 1)e^{-x}
\end{align}
$$

&lt;p&gt;于是，我们令 $g^{\prime}(x)=0$，可以解得两根&lt;/p&gt;

$$
\begin{cases}
x_1 = 1 - \sqrt{2} \\\\
x_2 = 1 + \sqrt{2}
\end{cases}
$$

&lt;p&gt;由于 $e^{-x}&amp;gt;0$ 恒成立，$g^{\prime}(x)$ 的正负就取决于 $a$ 的正负了。因此，我们按照如下情况进行分类讨论：&lt;/p&gt;
&lt;h4 id=&#34;1-a0&#34;&gt;1. $a=0$&lt;/h4&gt;
&lt;p&gt;若 $a=0$，则 $g^{\prime}(x)=0$ 恒成立，$g(x) \equiv 1$。于是 $f^{\prime}(x) &amp;gt; 0$ 恒成立，这说明 $f(x)$ 在整个定义域 $(-1,+\infty)$ 上单调递增。这无论如何都不符合题意，因为 $f(x)$ 至多只可能有一个零点。&lt;/p&gt;
&lt;h4 id=&#34;2-a0&#34;&gt;2. $a&amp;gt;0$&lt;/h4&gt;
&lt;p&gt;若 $a&amp;gt;0$，则 $g^{\prime}(x)$ 的正负性以及 $g(x)$ 的单调性如下表：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;区间&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;$g^{\prime}(x)$&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;$g(x)$&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;$(-1,1-\sqrt{2})$&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;$+$&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;$\nearrow$&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;$(1-\sqrt{2},1+\sqrt{2})$&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;$-$&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;$\searrow$&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;$(1+\sqrt{2},+\infty)$&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;$+$&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;$\nearrow$&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;下面，我们分别计算驻点和一些关键点的函数值，并判断它们的正负。&lt;/p&gt;

$$
\begin{align}
g(-1) &amp;= 1 &gt; 0 \\\\
g(1-\sqrt{2}) &amp;= 1 + \sqrt{2}a(2-\sqrt{2})e^{\sqrt{2}-1} &gt; 0 \\\\
g(0) &amp;= a + 1 &gt; 0 \\\\
g(1) &amp;= 1 &gt; 0 \\\\
g(1+\sqrt{2}) &amp;= 1 - \sqrt{2}a(2+\sqrt{2})e^{-(\sqrt{2}+1)} \\\\
\end{align}
$$

&lt;p&gt;由于 $-1$ 不在 $f^{\prime}(x)$ 的定义域内，不过我们可以根据 $g(x)$ 的正负以及单调性判断 $f^{\prime}(x)&amp;gt;0$ 在 $(-1,0)$ 上恒成立，当然也可以利用下列极限来判断：&lt;/p&gt;

$$
\lim_{x\rightarrow-1^+} f^{\prime}(x) = \lim_{x\rightarrow-1^+}[\frac{1}{1 + x} + a(1-x) e^{-x}] = +\infty
$$

&lt;p&gt;因此 $f(x)$ 在 $(-1,0)$ 上单调递增。不过，根据对数函数的性质，我们可以判断下列极限&lt;/p&gt;

$$
\lim_{x\rightarrow-1^+} f(x) = \lim_{x\rightarrow-1^+} [\ln (1+x) + axe^{-x}] = -\infty
$$

&lt;p&gt;而 $f(0)=0$。因此可以判断，$f(x)&amp;lt;0$ 在 $(-1,0)$ 上恒成立，这并不符合题意中的 $(-1,0)$ 内恰有一个零点。&lt;/p&gt;
&lt;p&gt;下图是 $a=1$ 时函数 $f(x)$ 的图像，可以帮助我们理解。&lt;/p&gt;
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /post/college-entrance-examination-2022-mathematics/fx_1_hu5d6abf9d8e64259957dd822f36f72157_7885_9b336c2f3c47cd5ded23ed52f91406c8.webp 400w,
               /post/college-entrance-examination-2022-mathematics/fx_1_hu5d6abf9d8e64259957dd822f36f72157_7885_f78883df35a74c4ee8f6a5c73a85b4e9.webp 760w,
               /post/college-entrance-examination-2022-mathematics/fx_1_hu5d6abf9d8e64259957dd822f36f72157_7885_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://bowenei.gitee.io/post/college-entrance-examination-2022-mathematics/fx_1_hu5d6abf9d8e64259957dd822f36f72157_7885_9b336c2f3c47cd5ded23ed52f91406c8.webp&#34;
               width=&#34;391&#34;
               height=&#34;265&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;h4 id=&#34;3-a0&#34;&gt;3. $a&amp;lt;0$&lt;/h4&gt;
&lt;p&gt;若 $a&amp;lt;0$，则 $g^{\prime}(x)$ 的正负性以及 $g(x)$ 的单调性如下表：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;区间&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;$g^{\prime}(x)$&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;$g(x)$&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;$(-1,1-\sqrt{2})$&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;$-$&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;$\searrow$&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;$(1-\sqrt{2},1+\sqrt{2})$&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;$+$&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;$\nearrow$&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;$(1+\sqrt{2},+\infty)$&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;$-$&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;$\searrow$&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;同样地，我们还是分别计算驻点和一些关键点的函数值，并判断它们的正负。&lt;/p&gt;

$$
\begin{align}
g(-1) &amp;= 1 &gt; 0 \\\\
g(1-\sqrt{2}) &amp;= 1 + \sqrt{2}a(2-\sqrt{2})e^{\sqrt{2}-1} \\\\
g(0) &amp;= a + 1 \\\\
g(1) &amp;= 1 &gt; 0 \\\\
g(1+\sqrt{2}) &amp;= 1 - \sqrt{2}a(2+\sqrt{2})e^{-(\sqrt{2}+1)} &gt; 0 \\\\
\end{align}
$$

&lt;p&gt;可以看到，当 $a&amp;lt;0$ 时，情况有些变化，我们无法判断 $g(1-\sqrt{2})$ 和 $g(0)$ 的正负性。不过，$g(0)$ 是一个关于 $a$ 的函数，并且表达式简单，我们可以再分情况讨论 $g(0)$ 的正负性。&lt;/p&gt;
&lt;h4 id=&#34;-a---1&#34;&gt;① $a = -1$&lt;/h4&gt;
&lt;p&gt;此时 $g(0)=0$，$f^{\prime}(0)=0$，而 $g(x)$ 在 $(1-\sqrt{2},1+\sqrt{2})$ 上单调递增，$f^{\prime}(x)$ 也有着和 $g(x)$ 同样的增减性。虽然 $g(x)$ 在 $(1+\sqrt{2},+\infty)$ 上单调递减，但下列极限&lt;/p&gt;

$$
\lim_{x\rightarrow+\infty} g(x) = \lim_{x\rightarrow+\infty} (1 + \frac{x^2-1}{e^x}) = 1 &gt; 0
$$

&lt;p&gt;因此，可以判断 $g(x)&amp;gt;0$ 在 $(0,+\infty)$ 上恒成立，即 $f^{\prime}(x)&amp;gt;0$ 在 $(0,+\infty)$ 上恒成立。因此，$f(x)$ 在 $(0,+\infty)$ 上单调递增，$f(x)&amp;gt;f(0)=0$。这样也并不符合题意。&lt;/p&gt;
&lt;p&gt;下图是 $a=-1$ 时函数 $f(x)$ 的图像。可以看到，函数 $f(x)$ 的图像正好与 $x$ 轴相切于原点。&lt;/p&gt;
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /post/college-entrance-examination-2022-mathematics/fx_2_huf148b6a987c4e8a6d0adcdeb673d0d58_8465_1767ce6d81ffe88c402d484a1f5172f9.webp 400w,
               /post/college-entrance-examination-2022-mathematics/fx_2_huf148b6a987c4e8a6d0adcdeb673d0d58_8465_011851150c98e89cb254a9ad483f0c34.webp 760w,
               /post/college-entrance-examination-2022-mathematics/fx_2_huf148b6a987c4e8a6d0adcdeb673d0d58_8465_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://bowenei.gitee.io/post/college-entrance-examination-2022-mathematics/fx_2_huf148b6a987c4e8a6d0adcdeb673d0d58_8465_1767ce6d81ffe88c402d484a1f5172f9.webp&#34;
               width=&#34;391&#34;
               height=&#34;265&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;h4 id=&#34;--1a0&#34;&gt;② $-1&amp;lt;a&amp;lt;0$&lt;/h4&gt;
&lt;p&gt;和情况 ① 类似，此时 $g(0)&amp;gt;0$，$f^{\prime}(0) = a+1 &amp;gt; 0$。通过判断极限 $\lim_{x\rightarrow+\infty} g(x) &amp;gt; 0$，可以证明 $g(x)&amp;gt;0$ 在 $(0,+\infty)$ 上恒成立，即 $f^{\prime}(x)&amp;gt;0$ 在 $(0,+\infty)$ 上恒成立。因此，$f(x)$ 在 $(0,+\infty)$ 上单调递增，$f(x)&amp;gt;f(0)=0$。这同样也并不符合题意。&lt;/p&gt;
&lt;p&gt;下图是 $a=-\frac{1}{2}$ 时函数 $f(x)$ 的图像，和 $a&amp;gt;0$ 的情况类似。&lt;/p&gt;
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /post/college-entrance-examination-2022-mathematics/fx_3_hufbc8704c06675784b32ac59258d4078e_8363_66a3c4ac07c2351a6f4b4be7cc5bb4c1.webp 400w,
               /post/college-entrance-examination-2022-mathematics/fx_3_hufbc8704c06675784b32ac59258d4078e_8363_d2aa3dd68a7d871659dd657d93b43957.webp 760w,
               /post/college-entrance-examination-2022-mathematics/fx_3_hufbc8704c06675784b32ac59258d4078e_8363_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://bowenei.gitee.io/post/college-entrance-examination-2022-mathematics/fx_3_hufbc8704c06675784b32ac59258d4078e_8363_66a3c4ac07c2351a6f4b4be7cc5bb4c1.webp&#34;
               width=&#34;391&#34;
               height=&#34;265&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;h4 id=&#34;-a-1&#34;&gt;③ $a&amp;lt;-1$&lt;/h4&gt;
&lt;p&gt;和情况 ①、② 都不同，此时 $g(0)&amp;lt;0$，$f^{\prime}(0) = a+1 &amp;lt; 0$。又因为 $g(-1)&amp;gt;0$，且 $g(x)$ 在 $(-1,1-\sqrt{2})$ 上单调递减，在 $(1-\sqrt{2},0)$ 上单调递增。这样，虽然我们一开始不好判断 $g(1-\sqrt{2})$ 的正负性，但是我们凭借 $g(x)$ 的单调性以及 $g(0)&amp;lt;0$，我们就可以判断 $g(1-\sqrt{2})&amp;lt;0$。因此 $\exists! m \in (-1,1-\sqrt{2})$，使得 $g(m)=f^{\prime}(m)=0$，即&lt;/p&gt;

$$
\begin{align}
1 + a(1-m^2)e^{-m} &amp;= 0 \\\\
ae^{-m} &amp;= \frac{1}{m^2-1}
\end{align}
$$

&lt;p&gt;同理，$g(1)&amp;gt;0$，且 $g(x)$ 在 $(1-\sqrt{2},1+\sqrt{2})$ 上单调递增。因此 $\exists! n \in (0,1)$，使得 $g(n) = f^{\prime}(n) = 0$，即&lt;/p&gt;

$$
\begin{align}
1 + a(1-n^2)e^{-n} &amp;= 0 \\\\
ae^{-n} &amp;= \frac{1}{n^2-1}
\end{align}
$$

&lt;p&gt;综合以上，我们可以得出 $f^{\prime}(x)$ 的正负性和 $f(x)$ 的增减性，如下表所示：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;区间&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;$f^{\prime}(x)$&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;$f(x)$&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;$(-1,m)$&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;$+$&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;$\nearrow$&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;$(m,n)$&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;$-$&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;$\searrow$&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;$(n,+\infty)$&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;$+$&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;$\nearrow$&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;有了 $f(x)$ 的增减性，我们就容易判断 $f(x)$ 的零点分布了。首先计算并且判断 $f(m)$、$f(n)$ 的大小：&lt;/p&gt;

$$
\begin{align}
f(m) &amp;= \ln (1+m) + ame^{-m} \\\\
&amp;= \ln (1+m) + \frac{m}{m^2-1} \\\\
f(n) &amp;= \ln (1+n) + ane^{-n} \\\\
&amp;= \ln (1+n) + \frac{n}{n^2-1} 
\end{align}
$$

&lt;p&gt;不过，$f(m)$、$f(n)$ 的大小难以判断，需要借助导数来帮助判断。令&lt;/p&gt;

$$
h(x) = \ln (1+x) + \frac{x}{x^2-1}
$$

&lt;p&gt;对 $h(x)$ 求导，有&lt;/p&gt;

$$
\begin{align}
h^{\prime}(x) &amp;= \frac{1}{1+x} + \frac{x^2-1 - 2x^2}{(x^2-1)^2} \\\\
&amp;= \frac{(x+1)(x-1)^2 - x^2 - 1}{(x+1)^2(x-1)^2} \\\\
&amp;= \frac{x[(x-1)^2-2]}{(x+1)^2(x-1)^2}
\end{align}
$$

&lt;p&gt;分子虽然是三次多项式，但可以根据“穿根引线”法来判断 $h^{\prime}(x)$ 的零点和以及 $h(x)$ 单调性。显然，$h^{\prime}(x)$ 有三个零点：$1-\sqrt{2},0,1+\sqrt{2}$。不过要特别注意的一点是，$h^{\prime}(x)$ 有无穷间断点 $x=1$。于是，我们总结函数 $h^{\prime}(x)$ 的正负性和 $h(x)$ 的单调性如下表所示。&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;区间&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;$h^{\prime}(x)$&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;$h(x)$&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;$(-1,1-\sqrt{2})$&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;$-$&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;$\searrow$&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;$(1-\sqrt{2},0)$&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;$+$&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;$\nearrow$&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;$(0,1)$&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;$-$&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;$\searrow$&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;$(1,1+\sqrt{2})$&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;$-$&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;$\searrow$&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;$(1+\sqrt{2},+\infty)$&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;$+$&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;$\nearrow$&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;$h(x)$ 的图像如下图所示：&lt;/p&gt;
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /post/college-entrance-examination-2022-mathematics/hx_huef94ef416ea2f3b82ee86f367ae1c675_9153_113fe665b03fde315c237baf04161eab.webp 400w,
               /post/college-entrance-examination-2022-mathematics/hx_huef94ef416ea2f3b82ee86f367ae1c675_9153_887e3e655554c671ff8583ad5ed9938a.webp 760w,
               /post/college-entrance-examination-2022-mathematics/hx_huef94ef416ea2f3b82ee86f367ae1c675_9153_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://bowenei.gitee.io/post/college-entrance-examination-2022-mathematics/hx_huef94ef416ea2f3b82ee86f367ae1c675_9153_113fe665b03fde315c237baf04161eab.webp&#34;
               width=&#34;391&#34;
               height=&#34;265&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;p&gt;我们可以很容易得到 $h(0)=0$。并且我们观察到，$h(1)&amp;lt;0$，且 $h(x)$ 在 $(0,1)$ 上单调递减。因此我们可以判断 $f(n)&amp;lt;0$。又 $m \in (-1,1-\sqrt{2})$，$f(0)=0$，且 $f(x)$ 在 $(m,n)$ 上单调递减。这样我们又可以判断 $f(m)&amp;gt;0$。&lt;/p&gt;
&lt;p&gt;现在所有的结论都已经推导出来了，下面先说明零点的存在性。&lt;/p&gt;

$$
\begin{align}
\lim_{x \rightarrow -1^+} f(x) &amp;= \lim_{x \rightarrow -1^+} [\ln (1+x) + axe^{-x}] = -\infty &lt; 0 \\\\
f(m) &amp;&gt; 0
\end{align}
$$

&lt;p&gt;并且函数 $f(x)$ 连续。因此，$\exists x_1 \in (-1,m)$，使得 $f(x_1)=0$。同理可得&lt;/p&gt;

$$
\begin{align}
f(n) &amp;&lt; 0 \\\\
\lim_{x \rightarrow +\infty} f(x) &amp;= \lim_{x \rightarrow +\infty} [\ln (1+x) + axe^{-x}] = +\infty &gt; 0 \\\\
\end{align}
$$

&lt;p&gt;并且函数 $f(x)$ 连续。因此，$\exists x_2 \in (n,+\infty)$，使得 $f(x_2)=0$。存在性得证。&lt;/p&gt;
&lt;p&gt;下面说明零点的唯一性。首先，$f(0)=0$，$f(x)$ 在 $(m,n)$ 上单调递减。又因为 $f(m)&amp;gt;0$ 且 $f(n)&amp;lt;0$，所以 $f(x)&amp;gt;0$ 在 $(m,0)$ 上恒成立，$f(x)&amp;lt;0$ 在 $(0,n)$ 上恒成立。而 $f(x)$ 分别在 $(-1,m)$ 和 $(n,+\infty)$ 上都是单调的，因此刚才所证明存在的零点分别是 $(-1,0)$ 和 $(0,+\infty)$ 上的唯一零点。具体可以参考下图理解：&lt;/p&gt;
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /post/college-entrance-examination-2022-mathematics/fx_4_hu09afd9709a0d4065184aae1bdd99b985_10685_3e21e89330e8848d8cf7b8fcc267fa67.webp 400w,
               /post/college-entrance-examination-2022-mathematics/fx_4_hu09afd9709a0d4065184aae1bdd99b985_10685_1d08cedce03e4bd36573359d5684de81.webp 760w,
               /post/college-entrance-examination-2022-mathematics/fx_4_hu09afd9709a0d4065184aae1bdd99b985_10685_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://bowenei.gitee.io/post/college-entrance-examination-2022-mathematics/fx_4_hu09afd9709a0d4065184aae1bdd99b985_10685_3e21e89330e8848d8cf7b8fcc267fa67.webp&#34;
               width=&#34;391&#34;
               height=&#34;265&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;h4 id=&#34;点评&#34;&gt;点评&lt;/h4&gt;
&lt;p&gt;本题题型较为常规，是一个判断函数零点的问题。不过，本题的难度较大。一方面，本题的参数 $a$ 需要分类讨论；另一方面，题目中并没有给出不等式的条件，也没有某个其他函数，使得我们可以通过放缩法与之建立不等关系，这样我们想要通过参变分离的方法转化为求值域问题的思路就不再可行。&lt;/p&gt;
&lt;p&gt;本题对参数 $a$ 的讨论是分为两个层次的。首先，我们对 $a$ 与 $0$ 的大小关系进行讨论。这是因为一阶导数的分子 $g(x)$ 的正负与 $a$ 的正负相关，它会影响到 $f(x)$ 的单调性。&lt;/p&gt;
&lt;p&gt;其次，当 $a&amp;lt;0$ 时，$g(0)$ 的大小，即 $a+1$ 的正负，对 $g(x)$ 的正负会有很大影响，也会影响到 $f(x)$ 的单调性。所以我们又对 $a$ 和 $-1$ 的关系进行了讨论。不过，我们很容易就判断出 $-1 \leqslant a &amp;lt; 0$ 的情况不合题意，因此只有 $a&amp;lt;-1$ 有进一步讨论的空间。&lt;/p&gt;
&lt;p&gt;接下来，我们判断出 $f(x)$ 的单调区间，并且是带有参数的，这使得我们难以判断驻点的正负。为此，我们将零点的条件代入 $f(x)$，以消去参数 $a$，并且构造一个新的函数研究其性质。经过研究，我们终于判断出了 $f(x)$ 两个驻点的正负，并且证明两个开区间上零点的存在性和唯一性。&lt;/p&gt;
&lt;p&gt;虽然本题题型较为常规，但本题在零点问题中是非常难的。它不光考察了考生零点定理的理解和运用，还考察了函数与导数关系的熟练运用，以及分类讨论的思想。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>A Survey of Recent Advances in Edge-Computing-Powered Artificial Intelligence of Things</title>
      <link>https://bowenei.gitee.io/post/a-survey-of-recent-advances-in-edge-computing-powered-artificial-intelligence-of-things/</link>
      <pubDate>Mon, 06 Jun 2022 11:22:43 +0800</pubDate>
      <guid>https://bowenei.gitee.io/post/a-survey-of-recent-advances-in-edge-computing-powered-artificial-intelligence-of-things/</guid>
      <description>&lt;p&gt;本文是一篇关于边缘计算赋能人工智能物联网 AIoT 的研究综述，于 2021 年发表在 CCF A 类期刊 Internet Things of Journal (IoT-J) 上。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://ieeexplore.ieee.org/document/9453402&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;原文链接&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;The Internet of Things (IoT) has created a ubiquitously connected world powered by a multitude of wired and wireless sensors generating a variety of heterogeneous data over time in a myriad of fields and applications. To extract complete information from these data, advanced artificial intelligence (AI) technology, especially deep learning (DL), has proved successful in facilitating data analytics, future prediction and decision making. The collective integration of AI and the IoT has greatly promoted the rapid development of AI-of-Things (AIoT) systems that analyze and respond to external stimuli more intelligently without involvement by humans. However, it is challenging or infeasible to process massive amounts of data in the cloud due to the destructive impact of the volume, velocity, and veracity of data and fatal transmission latency on networking infrastructures. These critical challenges can be adequately addressed by introducing edge computing. This article conducts an extensive survey of an end-edge-cloud orchestrated architecture for flexible AIoT systems. Specifically, it begins with articulating fundamental concepts including the IoT, AI and edge computing. Guided by these concepts, it explores the general AIoT architecture, presents a practical AIoT example to illustrate how AI can be applied in real-world applications and summarizes promising AIoT applications. Then, the emerging technologies for AI models regarding inference and training at the edge of the network are reviewed. Finally, the open challenges and future directions in this promising area are outlined.&lt;/p&gt;
&lt;p&gt;作者在摘要当中首先分析了背景 AIoT，并且认为在云中处理海量的数据不可行。而引入边缘计算 Edge Computing，可以充分解决这些关键挑战。作者在本文中对端边云协同架构进行了广泛的调查。具体而言，本文首先阐述了物联网 IoT、人工智能 AI 和边缘计算 Edge Computing 等基本概念。在这些概念的基础上，本文讨论了一般的 AIoT 体系结构，给出了一个实际的 AIoT 示例，以说明如何将人工智能应用于实际应用，并总结了有前途的 AIoT 应用。然后，本文回顾了人工智能模型在网络边缘的推理和训练方面的新兴技术。最后，本文概述了这一前景广阔领域的开放挑战和未来方向。&lt;/p&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;首先是论文的 Introduction 部分。在这里我将作者的 Introduction 全文翻译，并且梳理其行文逻辑，供参考学习。另外，可以积累一些常用的英语表达。&lt;/p&gt;
&lt;p&gt;&lt;mark&gt;Benefiting from&lt;/mark&gt; the &lt;mark&gt;extensive use&lt;/mark&gt; of the Internet and the rapid development of many wired and wireless connected devices, the Internet of Things (IoT) matures promptly and &lt;mark&gt;plays an increasingly significant role in&lt;/mark&gt; every aspect of life by providing many crucial services, such as information exchange and monitoring.&lt;/p&gt;
&lt;p&gt;得益于互联网的广泛使用和许多有线和无线连接设备的快速发展，物联网 IoT 迅速成熟，并通过提供许多关键服务（如信息交换和监控）在生活的各个方面发挥着越来越重要的作用。&lt;/p&gt;
&lt;p&gt;With the extensive applications of IoTs, the total installed IoT-based devices is projected to amount to approximately 41.6 billion, and nearly 79.4 Zettabytes (ZBs) of data may be generated and consumed in 2025.&lt;/p&gt;
&lt;p&gt;随着物联网的广泛应用，预计基于物联网的设备总安装量将达到约 416 亿，2025 年可能会产生和消耗近 794 ZB 的数据。&lt;/p&gt;
&lt;p&gt;Thus, some nonnegligible challenges that the IoT faces are explosive data generation and reliable data collection between heterogeneous devices &lt;mark&gt;in a wide range of applications&lt;/mark&gt; covering various backgrounds and requests.&lt;/p&gt;
&lt;p&gt;因此，物联网面临的一些不容忽视的挑战是，在覆盖各种背景和请求的广泛应用中，异构设备之间的爆炸性数据生成和可靠数据收集。&lt;/p&gt;
&lt;p&gt;Cloud computing &lt;mark&gt;plays a crucial role in&lt;/mark&gt; IoT systems, where the vast resources available in the cloud can provide ubiquitous on-demand computing and storage capabilities to support these devices. Additionally, these data may consist of multimedia information, from images, sounds, and videos to structured data (e.g., temperature and humidity). Advanced tools are needed to glean insights from a large volume of raw data.&lt;/p&gt;
&lt;p&gt;云计算在物联网系统中扮演着至关重要的角色，在物联网系统中，云中可用的巨大资源可以提供无处不在的按需计算和存储能力来支持这些设备。此外，这些数据可能包括多媒体信息，从图像、声音和视频到结构化数据（例如温度和湿度）。需要高级工具来从大量原始数据中收集见解。&lt;/p&gt;
&lt;p&gt;Facilitated by the recent achievements of algorithms, computing capabilities and big data processing necessities, artificial intelligence (AI), especially its essential sector of deep learning (DL), has achieved unprecedented success in data analysis, future prediction and decision making.&lt;/p&gt;
&lt;p&gt;在算法、计算能力和大数据处理需求的最新成就的推动下，人工智能 AI，尤其是其重要的深度学习 DL 部门，在数据分析、未来预测和决策方面取得了前所未有的成功。&lt;/p&gt;
&lt;p&gt;Clearly, the AI of Things (AIoT), an integrative technology combining both AI and the IoT, is starting to garner its share of the spotlight with the support of cloud centers. In the AIoT era, large amounts of data generated by IoT devices provide perfect opportunities for training AI models to reliably mine valuable data from a noisy and complex environment for intelligent analysis and decision making.&lt;/p&gt;
&lt;p&gt;显然，人工智能物联网 AIoT，一种结合了人工智能和物联网的综合技术，正开始在云中心的支持下获得其聚光灯的份额。在 AIoT 时代，物联网设备生成的大量数据为训练人工智能模型提供了完美的机会，以可靠地从嘈杂复杂的环境中挖掘有价值的数据，进行智能分析和决策。&lt;/p&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    作者在这一段当中由物联网 IoT 中的海量数据引出云计算 Cloud Computing 和人工智能 AI 两大概念，并且引出人工智能物联网 AIoT 的概念。
  &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;The cloud-centric AIoT requires the massive amount of heterogeneous data collected from IoT sensors to be transmitted to the cloud center through a wide-area network (WAN) for further processing and analysis before delivering the feedback to end devices.&lt;/p&gt;
&lt;p&gt;以云为中心的 AIoT 要求从物联网传感器收集的大量异构数据通过广域网（WAN）传输到云中心，以便在向终端设备提供反馈之前进行进一步处理和分析。&lt;/p&gt;
&lt;p&gt;Although the cloud center has unlimited computational capacity, such a cloud-based AIoT architecture is ill-suited for time-critical and privacy-sensitive applications due to the great pressure on network bandwidth, the inherent latency constraints of network communication and the potential to expose private and sensitive information during data offloading and remote processing.&lt;/p&gt;
&lt;p&gt;尽管云中心具有无限的计算能力，但这种基于云的 AIoT 体系结构不适合时间关键型和隐私敏感型应用程序，因为网络带宽压力巨大，网络通信固有的延迟限制，以及在数据卸载和远程处理过程中暴露私有和敏感信息的可能性。&lt;/p&gt;
&lt;p&gt;Edge computing seems to be a promising technique to remedy these issues, which brings computational resources closer to the data source with a relatively light access burden and a low transmission delay.&lt;/p&gt;
&lt;p&gt;边缘计算似乎是解决这些问题的一种很有前途的技术，它以相对较轻的访问负担和较低的传输延迟使计算资源更接近数据源。&lt;/p&gt;
&lt;p&gt;It is extremely suitable for the AIoT because AI models, especially DL models, that depend greatly on computation and storage resources can still work fluently and cooperatively by partitioning the layers into several parts and offloading the computation-intensive tasks to edge servers.&lt;/p&gt;
&lt;p&gt;它非常适合 AIoT，因为人工智能模型，尤其是深度学习模型，在很大程度上依赖于计算和存储资源，通过将层划分为几个部分并将计算密集型任务卸载到边缘服务器，仍然可以流畅地协同工作。&lt;/p&gt;
&lt;p&gt;Such a computing paradigm &lt;mark&gt;coupled with&lt;/mark&gt; AI can assist users better and more intelligently, where AI models function as a powerful tool to mine valuable information from raw data, make real-time decisions and to dynamically manage various resources of the edge platforms.&lt;/p&gt;
&lt;p&gt;这种与人工智能相结合的计算范式可以更好、更智能地帮助用户，其中人工智能模型可以作为一种强大的工具，从原始数据中挖掘有价值的信息，做出实时决策，并动态管理边缘平台的各种资源。&lt;/p&gt;
&lt;p&gt;Rather than transmit all the raw data to the cloud for overall analysis, edge computing-assisted AIoT solutions essentially enable AI models to work in the field.&lt;/p&gt;
&lt;p&gt;边缘计算辅助的 AIoT 解决方案本质上使人工智能模型能够在本地工作，而不是将所有原始数据传输到云进行全面分析。&lt;/p&gt;
&lt;p&gt;These solutions can lighten the burden of data transmission through the network backhaul, further reduce the cost of network processing and maintenance and make timely decisions by positioning computational capabilities near end devices. Additionally, these methods protect sensitive data from being abused by illegal operators or hijacked by attackers.&lt;/p&gt;
&lt;p&gt;这些解决方案可以减轻通过网络回程传输数据的负担，进一步降低网络处理和维护的成本，并通过在终端设备附近定位计算能力及时做出决策。此外，这些方法可以保护敏感数据不被非法操作员滥用或被攻击者劫持。&lt;/p&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    作者在这一段由基于云中心的 AIoT 存在的带宽限制和隐私安全问题，引出了边缘计算辅助的 AIoT 解决方案，并且分析边缘计算范式更好的原因。
  &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;This article investigates convergence of AI and the IoT from the perspective of end-edge-cloud collaboration, where immediate and real-time responses are enabled by using AI capacities for processing raw data at end or edge devices and higher accuracy results are gained by using cloud analytics in collaboration.&lt;/p&gt;
&lt;p&gt;本文从端边云协同的角度研究了人工智能与物联网的融合，其中通过使用人工智能处理终端或边缘设备原始数据的能力实现即时和实时响应，并通过协作使用云分析获得更高精度的结果。&lt;/p&gt;
&lt;p&gt;The AIoT can bring &lt;mark&gt;numerous&lt;/mark&gt; benefits to human beings in a spectrum of domains and form a ubiquitous intelligent collaborative environment; however, significant challenges must be overcome before fully realizing the potential of AIoT. Thus, this article aims to present a comprehensive survey of recent advances, open challenges and future directions for the AIoT.&lt;/p&gt;
&lt;p&gt;AIoT 可以在多个领域为人类带来诸多利益，形成无处不在的智能协作环境；然而，在充分发挥 AIoT 的潜力之前，必须克服重大挑战。因此，本文旨在全面综述 AIoT 的最新进展、开放挑战和未来方向。&lt;/p&gt;
&lt;p&gt;至此，作者已经给出了本文的简要逻辑。在 Introduction 的剩余部分中，作者分三节总结了相关工作、本文的贡献以及本文的行文结构。&lt;/p&gt;
&lt;h3 id=&#34;related-work&#34;&gt;Related Work&lt;/h3&gt;
&lt;p&gt;Several published references present AI and machine learning (ML) or DL methods that have been used in the domain of the IoT.&lt;/p&gt;
&lt;p&gt;作者在相关工作一节主要介绍了一些已发表的综述，它们都介绍了物联网领域的人工智能和机器学习或深度学习方法。相关内容见下表：&lt;/p&gt;
&lt;style type=&#34;text/css&#34;&gt;
.tg  {border-collapse:collapse;border-spacing:0;}
.tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;
  overflow:hidden;padding:10px 5px;word-break:normal;}
.tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;
  font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}
.tg .tg-mya0{border-color:#000000;font-size:18px;text-align:center;vertical-align:top}
.tg .tg-m916{border-color:#000000;font-size:18px;text-align:left;vertical-align:top}
&lt;/style&gt;
&lt;table class=&#34;tg&#34;&gt;
&lt;thead&gt;
  &lt;tr&gt;
    &lt;th class=&#34;tg-mya0&#34;&gt;Title&lt;/th&gt;
    &lt;th class=&#34;tg-mya0&#34;&gt;Year&lt;/th&gt;
    &lt;th class=&#34;tg-mya0&#34;&gt;Topic&lt;/th&gt;
  &lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
    &lt;td class=&#34;tg-mya0&#34;&gt;&lt;a href=&#34;https://ietresearch.onlinelibrary.wiley.com/doi/full/10.1049/trit.2018.1008&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Artificial intelligence in Internet of Things&lt;/a&gt;&lt;/td&gt;
    &lt;td class=&#34;tg-m916&#34;&gt;2018&lt;/td&gt;
    &lt;td class=&#34;tg-mya0&#34;&gt;AIoT&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td class=&#34;tg-mya0&#34;&gt;&lt;a href=&#34;https://www.sciencedirect.com/science/article/pii/S0167739X19304030&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Machine learning in the Internet of Things: Designed techniques for smart cities&lt;/a&gt;&lt;/td&gt;
    &lt;td class=&#34;tg-m916&#34;&gt;2019&lt;/td&gt;
    &lt;td class=&#34;tg-mya0&#34;&gt;ML; IoT&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td class=&#34;tg-mya0&#34;&gt;&lt;a href=&#34;https://ieeexplore.ieee.org/document/9052677&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Edge intelligence: The confluence of edge computing and artificial intelligence&lt;/a&gt;&lt;/td&gt;
    &lt;td class=&#34;tg-m916&#34;&gt;2020&lt;/td&gt;
    &lt;td class=&#34;tg-mya0&#34;&gt;Edge Intelligence&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td class=&#34;tg-mya0&#34;&gt;&lt;a href=&#34;https://link.springer.com/article/10.1007/s13042-018-0834-5&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;A survey on application of machine learning for Internet of Things&lt;/a&gt;&lt;/td&gt;
    &lt;td class=&#34;tg-m916&#34;&gt;2018&lt;/td&gt;
    &lt;td class=&#34;tg-mya0&#34;&gt;ML; IoT&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td class=&#34;tg-mya0&#34;&gt;&lt;a href=&#34;https://ieeexplore.ieee.org/document/8373692&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Deep learning for IoT big data and streaming analytics: A survey&lt;/a&gt;&lt;/td&gt;
    &lt;td class=&#34;tg-m916&#34;&gt;2018&lt;/td&gt;
    &lt;td class=&#34;tg-mya0&#34;&gt;IoT; DL&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td class=&#34;tg-mya0&#34;&gt;&lt;a href=&#34;https://dl.acm.org/doi/10.1145/3398209&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Deep Learning on Mobile and Embedded Devices: State-of-the-art, Challenges, and Future Directions&lt;/a&gt;&lt;/td&gt;
    &lt;td class=&#34;tg-m916&#34;&gt;2021&lt;/td&gt;
    &lt;td class=&#34;tg-mya0&#34;&gt;DL; Mobile and Embedded Devices&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td class=&#34;tg-mya0&#34;&gt;&lt;a href=&#34;https://ieeexplore.ieee.org/document/8270639&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Learning IoT in Edge: Deep Learning for the Internet of Things with Edge Computing&lt;/a&gt;&lt;/td&gt;
    &lt;td class=&#34;tg-m916&#34;&gt;2018&lt;/td&gt;
    &lt;td class=&#34;tg-mya0&#34;&gt;IoT; Edge Computing&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td class=&#34;tg-mya0&#34;&gt;&lt;a href=&#34;https://ieeexplore.ieee.org/document/8763885&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Deep Learning With Edge Computing: A Review&lt;/a&gt;&lt;/td&gt;
    &lt;td class=&#34;tg-m916&#34;&gt;2019&lt;/td&gt;
    &lt;td class=&#34;tg-mya0&#34;&gt;DL; Edge Computing&lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;contributions-of-this-survey&#34;&gt;Contributions of This Survey&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;An overview of fundamental technologies supporting the AIoT are given in terms of the general architecture of the IoT, state-of-the-art AI methods accompanied by key characteristics, and edge computing-related paradigms along with corresponding hardware and systems.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;根据物联网的一般架构、最先进的人工智能方法以及关键特征、边缘计算相关范式以及相应的硬件和系统，概述了支持人工智能应用的基本技术。&lt;/p&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;Confluence of AI and the IoT is the core of this article. In this respect, benefits of incorporating AI into IoT systems are first illustrated. An end-edge-cloud collaborative architecture of AIoT are then proposed. A practical example of AIoT applications is additionally given to further illustrate how AI can be applied in real-world applications.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;人工智能与物联网的融合是本文的核心。在这方面，首先说明了将人工智能纳入物联网系统的好处。在此基础上，提出了一种 AIoT 的端边云协同体系结构。此外，还提供了一个 AIoT 应用的实际示例，以进一步说明人工智能如何应用于实际应用中。&lt;/p&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;Some promising applications of AIoT are surveyed in &lt;mark&gt;a variety of&lt;/mark&gt; domains, such as the IoV, smart healthcare, smart industry, smart homes, smart agriculture, smart grids and smart environment.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;AIoT 在许多领域都有着很好的应用前景，如 IoV、智能医疗、智能工业、智能家居、智能农业、智能电网和智能环境。&lt;/p&gt;
&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;The recent approaches and technologies for performing AI inference on an AIoT hierarchy from resource-hungry end devices to edge servers and the cloud are summarized.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;总结了在 AIoT 层次结构上执行人工智能推理的最新方法和技术，从资源匮乏的终端设备到边缘服务器和云。&lt;/p&gt;
&lt;ol start=&#34;5&#34;&gt;
&lt;li&gt;The enabling technologies for decentralized AI training among various end devices and edge servers of an AIoT hierarchy are discussed.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;讨论了在 AIoT 层次结构的各种终端设备和边缘服务器之间进行分散式人工智能训练的使能技术。&lt;/p&gt;
&lt;ol start=&#34;6&#34;&gt;
&lt;li&gt;The open challenges and future directions for constructively and fruitfully merging of AI and the IoT are outlined.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;概述了人工智能和物联网建设性和富有成效地融合的开放挑战和未来方向。&lt;/p&gt;
&lt;h3 id=&#34;outline-of-this-survey&#34;&gt;Outline of This Survey&lt;/h3&gt;
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34;
           src=&#34;https://bowenei.gitee.io/post/a-survey-of-recent-advances-in-edge-computing-powered-artificial-intelligence-of-things/architecture.svg&#34;
           loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;h2 id=&#34;fundamentals-of-artificial-intelligence-of-things&#34;&gt;Fundamentals of Artificial Intelligence of Things&lt;/h2&gt;
&lt;p&gt;This section reviews the general architecture of the IoT in brief, then presents basic AI models with an emphasis on ML and DL models and additionally gives an overview of edge computing in terms of related paradigms, relationship with the fifth generation (5G), hardware, and systems.&lt;/p&gt;
&lt;p&gt;作者在本节简要回顾了物联网的总体架构，然后介绍了基本的人工智能模型，重点介绍了ML和深度学习模型，并从相关范式、与 5G 的关系、硬件和系统等方面概述了边缘计算。&lt;/p&gt;
&lt;h3 id=&#34;introduction-to-the-internet-of-things&#34;&gt;Introduction to the Internet of Things&lt;/h3&gt;
&lt;p&gt;Generally, the IoT architecture is composed of three layers, namely, the perception layer, network layer and application layer.&lt;/p&gt;
&lt;p&gt;作者认为，物联网架构一般由感知层、网络层和应用层三层组成。&lt;/p&gt;
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://ieeexplore.ieee.org/mediastore_new/IEEE/content/media/6488907/9530274/9453402/liu1-3088875-large.gif&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Perception Layer&lt;/strong&gt;: The perception layer provides the core capability enabling the comprehensive awareness of the environment; this layer includes such diverse devices and technologies as sensors, actuators, radio-frequency identification (RFID), 2-D codes, and multimedia information collection devices. These devices are used mainly to sense and collect physical data, and data is generally produced in trillions of bytes with a variety of attributes, including various physical quantities, identity signs, location information, and audio and video data. Additionally, these devices can respond to the environment.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;感知层提供了能够全面感知环境的核心能力；该层包括传感器、执行器、射频识别（RFID）、二维码和多媒体信息采集设备等多种设备和技术。这些设备主要用于感知和收集物理数据，数据通常以万亿字节的形式生成，具有各种属性，包括各种物理量、身份标志、位置信息以及音频和视频数据。此外，这些设备可以响应环境。&lt;/p&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;&lt;strong&gt;Network Layer&lt;/strong&gt;: The network layer is the most standardized among the three layers of the IoT, in which the devices in the perception layer can communicate with IoT gateways, wireless-fidelity (Wi-Fi) access points (APs) and base stations (BSs) to transmit data to other parts quickly, accurately and safely. This layer enables a device to communicate at a short-range to long-range distance by using a variety of communication protocols, such as wired and wireless networks, including Bluetooth, ZigBee, Sigfox, long-range radio (LoRa), and Narrowband IoT (NB-IoT). The data generated in the perception layer need to be transmitted to the server via the network layer promptly and accurately.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;网络层是物联网三层中最标准化的一层，其中感知层的设备可以与物联网网关、无线局域网（Wi-Fi）接入点（AP）和基站（BSs）进行通信，以快速、准确、安全地向其他部分传输数据。该层通过使用各种通信协议，例如有线和无线网络，包括蓝牙、ZigBee、Sigfox、远程无线电（LoRa）和窄带物联网（NB-IoT），使设备能够在短距离到长距离之间进行通信。感知层生成的数据需要通过网络层及时准确地传输到服务器。&lt;/p&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;&lt;strong&gt;Application Layer&lt;/strong&gt;: The application layer is equivalent to the control layer and decision-making layer of the IoT, in which a mass of polymorphic and heterogeneous data with rich semantics are analyzed. The application layer can provide a myriad of applications, such as industrial control, urban management, power monitoring, and green agriculture.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;应用层相当于物联网的控制层和决策层，分析了大量语义丰富的多态异构数据。应用层可以提供多种应用，如工业控制、城市管理、电力监控和绿色农业。&lt;/p&gt;
&lt;h3 id=&#34;basics-of-artificial-intelligence&#34;&gt;Basics of Artificial Intelligence&lt;/h3&gt;
&lt;p&gt;Algorithms exert a crucial function in AI, where simple algorithms can be applicable to simple applications, while more complex ones can build strong AI.&lt;/p&gt;
&lt;p&gt;算法在人工智能中发挥着至关重要的作用，简单的算法可以应用于简单的应用程序，而更复杂的算法可以构建强大的人工智能。&lt;/p&gt;
&lt;p&gt;Typically, ML, a subset of AI, is the most mainstream method used by systems to automatically learn from the data, identify patterns and make decisions from experience without human intervention or assistance.&lt;/p&gt;
&lt;p&gt;通常，机器学习 ML 是人工智能的一个子集，是系统在无需人工干预或帮助的情况下自动从数据中学习、识别模式和根据经验做出决策的最主流方法。&lt;/p&gt;
&lt;p&gt;DL, a unique branch of ML, is quite different from classic ML algorithms, which uses a hierarchical neural network to make the model more complex and enables automatic learning by absorbing a great deal of unstructured data, such as images, sound, text and video.&lt;/p&gt;
&lt;p&gt;深度学习 DL 是 ML 的一个独特分支，与经典ML算法有很大不同，后者使用层次神经网络使模型更加复杂，并通过吸收大量非结构化数据（如图像、声音、文本和视频）实现自动学习。&lt;/p&gt;
&lt;p&gt;This section will introduce several traditional ML algorithms and present some typical neural network algorithms accompanied with the corresponding functions, including a distinctive reinforcement learning (RL) method.&lt;/p&gt;
&lt;p&gt;作者在本节将介绍几种传统的 ML 算法，并介绍一些典型的神经网络算法以及相应的函数，包括一种独特的强化学习 RL 方法。&lt;/p&gt;
&lt;p&gt;下面的内容是对作者接下来介绍 ML 算法的简要概括。&lt;/p&gt;
&lt;h4 id=&#34;traditional-machine-learning-传统机器学习&#34;&gt;Traditional Machine Learning: 传统机器学习&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Support vector machine (SVM): 支持向量机&lt;/li&gt;
&lt;li&gt;Decision tree (DT): 决策树&lt;/li&gt;
&lt;li&gt;k-means clustering: k-均值聚类&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;neural-networks-神经网络&#34;&gt;Neural Networks: 神经网络&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Multilayer perceptron (MLP): 多层感知机&lt;/li&gt;
&lt;li&gt;Convolutional neural network (CNN): 卷积神经网络&lt;/li&gt;
&lt;li&gt;Recurrent neural network (RNN): 循环神经网络&lt;/li&gt;
&lt;li&gt;Long short-term memory (LSTM): 长短期记忆网络&lt;/li&gt;
&lt;li&gt;Generative adversarial network (GAN): 生成对抗网络&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;reinforcement-learning-强化学习&#34;&gt;Reinforcement Learning: 强化学习&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Value-based deep Q-learning: 基于价值的深度 Q-学习&lt;/li&gt;
&lt;li&gt;Policy-based deep Q-learning: 基于策略的深度 Q-学习&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;可以看到，作者是按照人工智能的发展来进行介绍的，即从机器学习，到深度学习，再到强化学习。&lt;/p&gt;
&lt;h3 id=&#34;overview-of-edge-computing&#34;&gt;Overview of Edge Computing&lt;/h3&gt;
&lt;p&gt;Cloud computing refers to the concept of delivering different services on demand by using networking, virtualization, distributed computing, utility computing and software services. Cloud computing is a service-oriented architecture that provides flexible services, reduces the information technology overhead for end users, and the total cost of ownership.&lt;/p&gt;
&lt;p&gt;云计算是指通过使用网络、虚拟化、分布式计算、效用计算和软件服务按需提供不同服务的概念。云计算是一种面向服务的架构，它提供灵活的服务，减少最终用户的信息技术开销，并降低总体拥有成本。&lt;/p&gt;
&lt;p&gt;However, the cloud center is usually built in a remote area far from end users, thus possibly causing data transmission delays. With a soaring number of IoT devices, the cloud cannot satisfy the requirements of latency-sensitive and privacy-critical applications.&lt;/p&gt;
&lt;p&gt;然而，云中心通常建在远离最终用户的偏远地区，因此可能导致数据传输延迟。随着物联网设备数量的激增，云无法满足延迟敏感和隐私关键应用程序的要求。&lt;/p&gt;
&lt;p&gt;The emergence of edge computing is aimed at migrating computational tasks to edge devices near sensors and actuators, which can alleviate the pressure of data transmission, reduce end-to-end latency, and thus enable real-time services.&lt;/p&gt;
&lt;p&gt;边缘计算的出现旨在将计算任务迁移到传感器和执行器附近的边缘设备，这可以缓解数据传输的压力，减少端到端延迟，从而实现实时服务。&lt;/p&gt;
&lt;p&gt;A diversity of devices can serve as edge computing platforms: switches, cellular BSs or IoT gateways, which makes edge computing flexible and scalable deploy various services at anywhere between end users and the cloud. Typically, edge computing is considered an extension of the cloud platform and works independently and effectively in some scenarios or collaborates with the cloud platform.&lt;/p&gt;
&lt;p&gt;多种设备可以用作边缘计算平台：交换机、蜂窝基站或物联网网关，这使得边缘计算灵活且可扩展，可以在最终用户和云之间的任何位置部署各种服务。通常，边缘计算被视为云平台的扩展，在某些场景中独立有效地工作，或与云平台协作。&lt;/p&gt;
&lt;p&gt;This section reviews edge computing-related paradigms, the relationship between 5G and edge computing, and edge computing hardware and systems.&lt;/p&gt;
&lt;p&gt;本节回顾边缘计算相关范例、5G 与边缘计算之间的关系以及边缘计算硬件和系统。&lt;/p&gt;
&lt;h4 id=&#34;edge-computing-related-paradigms-边缘计算相关范式&#34;&gt;Edge Computing-Related Paradigms: 边缘计算相关范式&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Cloudlet: 由卡内基梅隆大学提出的 Cloudlet 被设想为一个移动增强型数据中心，具有一定的计算和存储能力，位于移动设备附近。Cloudlet 被认为是移动设备、微云和云三层架构的中间层。&lt;/li&gt;
&lt;li&gt;Fog computing: 最初由思科提出的雾计算被认为是对传统云计算的有效扩展和补充，它将资源和服务（计算、存储、网络和处理）放置在从终端设备到云的路径上。&lt;/li&gt;
&lt;li&gt;Mobile-edge computing: 移动边缘计算由欧洲电信标准协会 ETSI 标准化，通过在蜂窝网络边缘（如无线基站）分配计算和存储资源来提供服务。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;fifth-generation-mobile-networks-and-edge-computing-5g-移动网络与边缘计算&#34;&gt;Fifth-Generation Mobile Networks and Edge Computing: 5G 移动网络与边缘计算&lt;/h4&gt;
&lt;p&gt;5G technology standard is seen as the most promising wireless cellular network standard to cater to the requirements of next-generation networks. Many ultradense edge devices will be deployed in 5G systems, including mainly small cell BSs and wireless APs. These devices are often equipped with certain computing and storage abilities, thus enabling ubiquitous mobile computing.&lt;/p&gt;
&lt;p&gt;5G 技术标准被视为最有希望满足下一代网络需求的无线蜂窝网络标准。许多超密集边缘设备将部署在 5G 系统中，主要包括小蜂窝基站和无线接入点。这些设备通常具有一定的计算和存储能力，从而实现无处不在的移动计算。&lt;/p&gt;
&lt;h4 id=&#34;edge-computing-hardware-边缘计算硬件&#34;&gt;Edge Computing Hardware: 边缘计算硬件&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Application-Specific Integrated Circuit (ASICs) Chip: 专用集成电路芯片&lt;/li&gt;
&lt;li&gt;Graphics Processing Unit-Based (GPU-Based) Product: 基于图形处理单元的产品&lt;/li&gt;
&lt;li&gt;Field-Programmable Gate Array (FPGA)-Based Device: 基于现场可编程门阵列的设备&lt;/li&gt;
&lt;li&gt;Brain-Inspired Chip: 脑启发芯片&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;edge-computing-systems-边缘计算系统&#34;&gt;Edge Computing Systems: 边缘计算系统&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://azure.microsoft.com/zh-cn/services/iot-edge/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Azure IoT Edge&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://cn.edgexfoundry.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;EdgeX Foundry&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://incubator.apache.org/projects/edgent.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Apache Edgent&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://opennetworking.org/cord/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Central Office Rearchitected as a Datacenter (CORD)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://wiki.akraino.org/display/AK/Akraino&amp;#43;Edge&amp;#43;Stack&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Akraino Edge Stack&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;artificial-intelligence-of-things&#34;&gt;Artificial Intelligence of Things&lt;/h2&gt;
&lt;p&gt;In this section, opportunities to fuse AI and the IoT, the general AIoT architecture with the support of edge computing and the cloud, and a practical example of AIoT applications will be reviewed.&lt;/p&gt;
&lt;p&gt;在本节中，作者回顾了人工智能和物联网融合的因素、支持边缘计算和云的一般 AIoT 架构，以及 AIoT 应用的一个实际示例。&lt;/p&gt;
&lt;h3 id=&#34;opportunities-for-integrating-artificial-intelligence-with-the-internet-of-things&#34;&gt;Opportunities for Integrating Artificial Intelligence With the Internet of Things&lt;/h3&gt;
&lt;p&gt;The data generated by IoT devices have many properties, namely, polymorphism, heterogeneity, timeliness, accuracy, massive-scale and rich semantics. Real-time data for all events must be processed promptly. AI can effectively and efficiently mine valuable information from these data and make decisions. Moreover, AI models can be deployed on every layer of IoT systems with enhanced performance. The synergy of AI and IoT is named AIoT, benefits of which are illustrated as follows.&lt;/p&gt;
&lt;p&gt;作者认为，人工智能与物联网深度融合的机遇源于：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;物联网设备生成的数据具有多态性、异构性、及时性、准确性、大规模和丰富的语义等特性。&lt;/li&gt;
&lt;li&gt;物联网设备处理数据必须确保实时性。&lt;/li&gt;
&lt;li&gt;人工智能可以有效地从这些数据中挖掘有价值的信息并作出决策。&lt;/li&gt;
&lt;li&gt;人工智能可以部署在物联网系统的每一层上。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;作者认为，AIoT 的优势在于：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;High Flexibility: 高度的灵活性&lt;/li&gt;
&lt;li&gt;Enhanced Interactivity: 增强的交互性&lt;/li&gt;
&lt;li&gt;Intelligent Decisions and Accurate Predictions: 智能的决策和精准的预测&lt;/li&gt;
&lt;li&gt;Various Applications: 各种应用程序&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;general-architecture-of-artificial-intelligence-of-things&#34;&gt;General Architecture of Artificial Intelligence of Things&lt;/h3&gt;
&lt;p&gt;From bottom to top are the end layer, edge layer and cloud layer, and the cloud layer can coordinate the end layer and the edge layer. The end layer can proprocess or analyze data on premises and make early decisions. The proprocessed data from the end layer can be aggregated in the edge or cloud layer for deep disposal.&lt;/p&gt;
&lt;p&gt;作者认为，AIoT 架构具有和 IoT 类似的端边云三层架构。从下到上依次为端层、边缘层和云层，云层可以协调端层和边缘层。终端层可以在本地预处理或分析数据，并做出早期决策。来自端层的预处理数据可以聚集在边缘层或云层中进行深度处理。&lt;/p&gt;
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://ieeexplore.ieee.org/mediastore_new/IEEE/content/media/6488907/9530274/9453402/liu4-3088875-large.gif&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;h3 id=&#34;example-of-artificial-intelligence-of-things-applications&#34;&gt;Example of Artificial Intelligence of Things Applications&lt;/h3&gt;
&lt;p&gt;The following describes the corresponding system design, illustrates model training and deployment as well as inference and provides a case study using an end-to-end AI model.&lt;/p&gt;
&lt;p&gt;作者在本章介绍一个 AIoT 的应用 HydraMini，一个自动驾驶汽车系统，并以此为例，说明了模型训练和部署以及推理的过程，并提供了使用端到端人工智能模型的案例研究。&lt;/p&gt;
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://ieeexplore.ieee.org/mediastore_new/IEEE/content/media/6488907/9530274/9453402/liu5-3088875-small.gif&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;p&gt;由于篇幅有限，本文在这里不对该系统进行详细的描述，仅以上图供参考。&lt;/p&gt;
&lt;h2 id=&#34;applications-of-artificial-intelligence-of-things&#34;&gt;Applications of Artificial Intelligence of Things&lt;/h2&gt;
&lt;p&gt;In this section, several application scenarios, including smart homes, smart healthcare, smart agriculture, smart industry, smart agriculture, smart grids and smart environment, are presented to demonstrate how edge computing aided AIoT systems will make real-world more efficient, smarter and safer.&lt;/p&gt;
&lt;p&gt;作者在本章介绍了几个应用场景，包括智能家居、智能医疗、智能农业、智能工业、智能农业、智能电网和智能环境，以演示边缘计算辅助的 AIoT 系统如何使现实世界更加高效、智能和安全。&lt;/p&gt;
&lt;h3 id=&#34;internet-of-vehicles&#34;&gt;Internet of Vehicles&lt;/h3&gt;
&lt;p&gt;The IoV enabled by AIoT aims to enhance road safety, strengthen efficiency, decrease crash risks and lower traffic congestion in transportation systems. Currently, the IoV covers three major categories: 1) AD; 2) monitoring systems for safe driving; and 3) cooperative vehicle infrastructure systems (CVISs).&lt;/p&gt;
&lt;p&gt;作者总结认为，AIoT 启用的 IoV 旨在提高道路安全、提高效率、降低碰撞风险和降低交通系统中的交通拥堵。目前，IoV 涵盖三大类：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Autonomous Driving: 自动驾驶&lt;/li&gt;
&lt;li&gt;Monitoring Systems for Safe Driving: 安全驾驶监控系统&lt;/li&gt;
&lt;li&gt;Cooperative Vehicle Infrastructure Systems (CVISs): 合作车辆基础设施系统&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;smart-healthcare&#34;&gt;Smart Healthcare&lt;/h3&gt;
&lt;p&gt;The era of edge-computing-enabled AIoT opens a new line of research in the field of medical and healthcare systems, which has already provided a myriad of applications, including health monitoring systems, disease diagnosis systems, and auxiliary therapy systems.&lt;/p&gt;
&lt;p&gt;边缘计算时代开启了医疗和保健系统领域的新研究领域，该领域已经提供了无数应用，包括：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Health Monitoring Systems: 健康监测系统&lt;/li&gt;
&lt;li&gt;Disease Diagnosis Systems: 疾病诊断系统&lt;/li&gt;
&lt;li&gt;Auxiliary Therapy Systems: 辅助治疗系统&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;smart-industry&#34;&gt;Smart Industry&lt;/h3&gt;
&lt;p&gt;The fourth industrial revolution, also known as Industry 4.0, has created new opportunities for product robotization and automation, which emphasize intelligent manufacturing techniques. The edge-computing-aided AIoT caters to the requirements of smart manufacturing, where edge computing enables low-latency, secure manufacturing while AI provides more intelligent local analysis and prediction. Smart industry focuses mainly on production automation and smart data analysis.&lt;/p&gt;
&lt;p&gt;第四次工业革命，也称为工业 4.0，为强调智能制造技术的产品机器人化和自动化创造了新的机遇。边缘计算辅助的 AIoT 迎合了智能制造的需求，边缘计算实现了低延迟、安全的制造，而人工智能提供了更智能的局部分析和预测。智能产业主要专注于生产自动化和智能数据分析。&lt;/p&gt;
&lt;p&gt;作者总结了如下具体应用场景：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Smart Manufacturing: 智能制造&lt;/li&gt;
&lt;li&gt;Smart Industry Analysis: 智能行业分析&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;smart-homes&#34;&gt;Smart Homes&lt;/h3&gt;
&lt;p&gt;The rapid development of AIoT has encouraged many attractive computationally intensive applications that provide intelligent sensing and convenient control services in smart home scenarios. For home data protection, edge computing has emerged as an excellent option to execute local computation and processing, especially for some computation-intensive AI-based applications.&lt;/p&gt;
&lt;p&gt;AIoT 的快速发展鼓励了许多有吸引力的计算密集型应用，这些应用在智能家居场景中提供智能传感和方便的控制服务。对于家庭数据保护，边缘计算已经成为执行本地计算和处理的一个很好的选择，特别是对于一些计算密集型 AI 应用程序。&lt;/p&gt;
&lt;h3 id=&#34;smart-agriculture&#34;&gt;Smart Agriculture&lt;/h3&gt;
&lt;p&gt;Smart agriculture aims to improve crop yield and quality, reduce labor costs and protect the environment from the excessive use of pesticides and fertilizers by using modern technologies. The explosive employment of sensors and automated equipment will generate an abundance of data, thereby taxing the Internet and cloud center. Edge-computing-aided AIoT applications enable data to be processed locally or on nearby edge servers to seek a timely response. Generally, smart agriculture concentrates on crop production, agriculture environment monitoring and agriculture security.&lt;/p&gt;
&lt;p&gt;智能农业旨在利用现代技术提高作物产量和质量，降低劳动力成本，保护环境免受农药和肥料过度使用的影响。传感器和自动化设备的爆炸性使用将产生大量数据，从而给互联网和云中心带来负担。边缘计算辅助的 AIoT 应用程序可以在本地或附近的边缘服务器上处理数据，以寻求及时的响应。一般来说，智能农业集中于作物生产、农业环境监测和农业安全。&lt;/p&gt;
&lt;p&gt;作者例举了一些具体的在农业方面的应用：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Crop Production Analysis: 作物产量分析&lt;/li&gt;
&lt;li&gt;Agriculture Environment Monitoring: 农业环境监测&lt;/li&gt;
&lt;li&gt;Agriculture Security: 农业安全&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;smart-grids&#34;&gt;Smart Grids&lt;/h3&gt;
&lt;p&gt;Grid operators have deployed IoT sensors to monitor power grid devices in real time. Recently, there has been a rush to integrate AI with electrical grids to provide a more stable, cost-saving and secure smart grid.&lt;/p&gt;
&lt;p&gt;电网运营商已部署物联网传感器来实时监控电网设备。最近，人们纷纷将人工智能与电网集成，以提供更稳定、更节省成本和更安全的智能电网。&lt;/p&gt;
&lt;p&gt;作者在这里例举了很多文献介绍 AIoT 在智能电网重点应用，这里不再赘述。&lt;/p&gt;
&lt;h3 id=&#34;smart-environment&#34;&gt;Smart Environment&lt;/h3&gt;
&lt;p&gt;The goal of smart environment is to provide humans with a safer and more comfortable life. Environmental monitoring systems can send early warnings to humans by making accurate predictions.&lt;/p&gt;
&lt;p&gt;作者认为，AIoT 也可以应用于环境监测，这里同样也不再赘述。&lt;/p&gt;
&lt;h2 id=&#34;enabling-technologies-for-artificial-intelligence-inference-in-artificial-intelligence-of-things&#34;&gt;Enabling Technologies for Artificial Intelligence Inference in Artificial Intelligence of Things&lt;/h2&gt;
&lt;p&gt;Most AI models, especially DNN models, are designed to be much deeper, which have a larger data set to promote their accuracy. Inference in the cloud will inadvertently incur additional queuing and propagation delays from the network, which is fatal for time-critical applications. These AI models, however, are too large and computationally expensive to be directly deployed on resource-constrained end devices.&lt;/p&gt;
&lt;p&gt;大多数人工智能模型，尤其是 DNN 模型，设计得更深入，有更大的数据集来提高其准确性。云中的推理将无意中导致额外的排队和网络传播延迟，这对于时间关键型应用程序来说是致命的。然而，这些人工智能模型太大，计算成本太高，无法直接部署在资源受限的终端设备上。&lt;/p&gt;
&lt;p&gt;To overcome this challenge, one possible approach is to simplify the models with a dramatic decrease in computation. The other effective approach is to outsource complex inference tasks to edge nodes with more resources. In this regard, the methods used to optimize inference on device and coinference in the edge, and privacy-preserving techniques, are surveyed.&lt;/p&gt;
&lt;p&gt;为了克服这一挑战，一种可能的方法是简化模型，大大减少计算量。另一种有效的方法是将复杂的推理任务外包给具有更多资源的边缘节点。在这方面，综述了用于优化设备上的推理和边缘中的共指的方法，以及隐私保护技术。&lt;/p&gt;
&lt;p&gt;基于上述思路，作者将 AIoT 模型推理分为三种模式：端上推理、边缘协同推理和私密推理。&lt;/p&gt;
&lt;h3 id=&#34;on-device-inference&#34;&gt;On-Device Inference&lt;/h3&gt;
&lt;p&gt;Generally, two practical methods can be used to reduce computational costs of AI models. One is to directly design compact and efficient neural network models with a reduced number of parameters, such as SqueezeNet, Xception, and ShuffleNet. The other method is typically called model compression, which achieves a smaller memory footprint and improved operation for end devices by compressing pretrained networks.&lt;/p&gt;
&lt;p&gt;通常，可以使用两种实用方法来降低人工智能模型的计算成本。一种是直接设计紧凑、高效的神经网络模型，减少参数数量。另一种方法通常称为模型压缩，它通过压缩预训练网络来实现较小的内存占用和改进终端设备的操作。&lt;/p&gt;
&lt;h4 id=&#34;designing-compact-networks-设计紧凑高效的网络&#34;&gt;Designing Compact Networks: 设计紧凑高效的网络&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1602.07360&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;SqueezeNet&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://ieeexplore.ieee.org/document/8099678&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Xception&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://ieeexplore.ieee.org/document/8578814&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ShuffleNet&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://linkinghub.elsevier.com/retrieve/pii/S1383762118304612&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;MobileNet&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;model-compression-模型压缩&#34;&gt;Model Compression: 模型压缩&lt;/h4&gt;
&lt;h5 id=&#34;parameter-pruning-and-sharing-参数剪枝与共享&#34;&gt;Parameter pruning and sharing: 参数剪枝与共享&lt;/h5&gt;
&lt;p&gt;Parameter pruning and sharing can decrease the number of redundant parameters and address the issue of overfitting. Model pruning methods are roughly divided into structural pruning and nonstructural pruning.&lt;/p&gt;
&lt;p&gt;参数剪枝和共享可以减少冗余参数的数量，并解决过拟合问题。模型剪枝方法大致分为结构性剪枝和非结构性剪枝。&lt;/p&gt;
&lt;p&gt;Nonstructural pruning is generally a connection-level, fine-grained pruning method with relatively high accuracy; however, it depends on a specific algorithm library or hardware platform, such as deep compression or sparse-winograd.&lt;/p&gt;
&lt;p&gt;非结构性剪枝通常是一种连接级别的细粒度剪枝方法，具有较高的精度；然而，它取决于特定的算法库或硬件平台，例如 &lt;a href=&#34;https://arxiv.org/abs/1510.00149&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;deep compression&lt;/a&gt; 或 &lt;a href=&#34;https://arxiv.org/abs/1802.06367&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;sparse-winograd&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;Structural pruning is a filter-level or layer-level coarse-grained pruning method with relatively low accuracy, and the structural pruning strategy is more effective than nonstructural pruning and does not depend on a specific algorithm library or hardware platform.&lt;/p&gt;
&lt;p&gt;结构剪枝是一种精度相对较低的过滤器级或层级粗粒度剪枝方法，结构剪枝策略比非结构剪枝更有效，不依赖于特定的算法库或硬件平台。&lt;/p&gt;
&lt;h5 id=&#34;quantization-量化&#34;&gt;Quantization: 量化&lt;/h5&gt;
&lt;p&gt;Quantization uses a more compact format by adopting low-bit width numbers instead of 32-bit floating-point numbers to represent each weight, thereby reducing the computational intensity and the memory footprint and further increasing the energy efficiency.&lt;/p&gt;
&lt;p&gt;量化使用更紧凑的格式，通过采用低位宽度数字而不是 32 位浮点数字来表示每个权重，从而降低计算强度和内存占用，并进一步提高能效。&lt;/p&gt;
&lt;h5 id=&#34;knowledge-distillation-知识蒸馏&#34;&gt;Knowledge distillation: 知识蒸馏&lt;/h5&gt;
&lt;p&gt;Knowledge distillation fabricates a compact DNN model that migrates the behavior from a powerful and complex DNN model. By training the smaller DNN model by using the output predictions generated by the complicated model, the smaller DNN model should approach or exceed the function trained by the larger DNNs as well as possible.&lt;/p&gt;
&lt;p&gt;知识蒸馏构建了一个紧凑的 DNN 模型，该模型将行为从强大而复杂的 DNN 模型迁移过来。通过使用复杂模型生成的输出预测对较小的 DNN 模型进行训练，较小的 DNN 模型应尽可能接近或超过较大 DNN 训练的函数。&lt;/p&gt;
&lt;h3 id=&#34;coinference-at-the-edge&#34;&gt;Coinference at the Edge&lt;/h3&gt;
&lt;p&gt;Deploying large-size AI models, which require high computation, power and memory capacity from the end infrastructures, remains a challenge. Therefore, it is a good option to segment DNN models into multiple partitions and offload each part to heterogeneous local end devices, more powerful distributed edge servers or remote cloud servers.&lt;/p&gt;
&lt;p&gt;部署大型人工智能模型仍然是一个挑战，因为它需要终端基础设施提供高计算、高功耗和高内存容量。因此，将 DNN 模型划分为多个分区并将每个部分卸载到异构本地终端设备、更强大的分布式边缘服务器或远程云服务器是一个很好的选择。&lt;/p&gt;
&lt;p&gt;作者于是总结了实现这种协同推理的技术如下：&lt;/p&gt;
&lt;h4 id=&#34;offloading-卸载&#34;&gt;Offloading: 卸载&lt;/h4&gt;
&lt;p&gt;Computation offloading is a widely used distributed computing paradigm in fast inference, where an end device can migrate part of its computation to an edge node, the cloud, or both over a heterogeneous network. By this means, offloading can employ remote servers to increase the computation speed and save energy. However, a compromise between advantages in remote execution and sacrifices in data transmission should be reached.&lt;/p&gt;
&lt;p&gt;计算卸载是快速推理中广泛使用的分布式计算范式，终端设备可以通过异构网络将部分计算迁移到边缘节点、云或两者。通过这种方式，卸载可以使用远程服务器来提高计算速度并节省能源。不过，应该在远程执行的优势和数据传输的牺牲之间达成妥协。&lt;/p&gt;
&lt;h4 id=&#34;dnn-model-partitioning-模型切分&#34;&gt;DNN Model Partitioning: 模型切分&lt;/h4&gt;
&lt;p&gt;The idea of offloading can be extended to model partitioning, which takes advantage of the unique structure of DNNs. In this way, the layers of DNNs can be divided into several parts, where some layers are directly executed on end device and some layers are offloaded to edge server or the cloud for remote computation.&lt;/p&gt;
&lt;p&gt;卸载的思想可以扩展到模型切分，它利用了 DNN 的独特结构。这样，DNN 的层可以分为几个部分，其中一些层直接在终端设备上执行，一些层卸载到边缘服务器或云上进行远程计算。&lt;/p&gt;
&lt;h4 id=&#34;model-early-exit-模型提前退出&#34;&gt;Model Early Exit 模型提前退出&lt;/h4&gt;
&lt;p&gt;A DNN model with additional layers can generally achieve higher accuracy; however, the model requires increased computation and energy resources in feed-forward inference. Therefore, it is difficult to execute such a complicated DNN model on a resource-constrained end device.&lt;/p&gt;
&lt;p&gt;具有附加层的 DNN 模型通常可以实现更高的精度；然而，该模型需要增加前馈推理的计算量和能量资源。因此，很难在资源受限的终端设备上执行如此复杂的 DNN 模型。&lt;/p&gt;
&lt;p&gt;The idea of accelerating model inference can be further promoted by the emerging model early exit method, which leverages additional side branch layers to obtain the classification result. The inference process can be completed in advance via the early classifiers with high confidence. It is also possible for some complicated tasks to use more DNN layers to complete the classification procedure.&lt;/p&gt;
&lt;p&gt;新兴的模型提前退出方法可以进一步促进加速模型推理的思想，该方法利用额外的边分支层来获得分类结果。通过提前的分类器可以提前完成推理过程，并且具有很高的可信度。对于一些复杂的任务，也可以使用更多的 DNN 层来完成分类过程。&lt;/p&gt;
&lt;h3 id=&#34;private-inference&#34;&gt;Private Inference&lt;/h3&gt;
&lt;p&gt;… However, this kind of cooperative inference system also faces privacy concerns when the data including sensitive information is transmitted to a nearby edge server or cloud. Additionally, end devices are too energy and resource constrained to execute complex data protection methods. Intuitively, it is worth studying privacy enhancement between end devices and edge servers.&lt;/p&gt;
&lt;p&gt;当包含敏感信息的数据传输到附近的边缘服务器或云时，这种协同推理系统也面临隐私问题。此外，终端设备的能源和资源过于有限，无法执行复杂的数据保护方法。直观地说，值得研究终端设备和边缘服务器之间的隐私增强。&lt;/p&gt;
&lt;p&gt;In this section, secure computation through encryption or cryptography and data obfuscation techniques are proposed for the AIoT inference.&lt;/p&gt;
&lt;p&gt;作者在本节中，提出了 AIoT 推理的概念。具体而言，包括如下技术：&lt;/p&gt;
&lt;h4 id=&#34;secure-computation-安全计算&#34;&gt;Secure Computation: 安全计算&lt;/h4&gt;
&lt;p&gt;Cryptography-based methods can be applied to AIoT privacy inference. Edge servers perform computation by using the data preserved by cryptographic techniques while knowing nothing about the data, and end devices receive the result of inference without knowing the model.&lt;/p&gt;
&lt;p&gt;基于密码学的方法可以应用于 AIoT 隐私推断。边缘服务器使用加密技术保存的数据执行计算，而对数据一无所知，终端设备在不知道模型的情况下接收推断结果。&lt;/p&gt;
&lt;h4 id=&#34;data-obfuscation-数据混淆&#34;&gt;Data Obfuscation: 数据混淆&lt;/h4&gt;
&lt;p&gt;To avoid the heavy computation of cryptographic primitives, data obfuscation can provide a strong guarantee for sensitive data by adaptively injecting noise into data set while retaining the servers’ ability to implement AIoT inference tasks.&lt;/p&gt;
&lt;p&gt;为了避免密码原语的繁重计算，数据混淆可以通过自适应地向数据集中注入噪声，同时保持服务器执行 AIoT 推理任务的能力，为敏感数据提供强有力的保障。&lt;/p&gt;
&lt;h2 id=&#34;enabling-technologies-for-artificial-intelligence-training-in-artificial-intelligence-of-things&#34;&gt;Enabling Technologies for Artificial Intelligence Training in Artificial Intelligence of Things&lt;/h2&gt;
&lt;p&gt;Conventionally, the training mode of AIoT models relies on a centralized style, which may incur additional costs in data transmission and privacy issues. To effectively address these issues, a decentralized training mode is proposed, where the AI model is divided into several subnetworks
and each part is trained directly on end device with local data. The trained model updates can be aggregated at edge nodes in the network or be exchanged through the interconnect end devices in the network.&lt;/p&gt;
&lt;p&gt;传统上，AIoT 模型的训练模式依赖于集中式，这可能会在数据传输和隐私问题上产生额外成本。为了有效解决这些问题，提出了一种分布式的训练模式，将人工智能模型划分为若干子网络，每个部分直接在终端设备上使用本地数据进行训练。经过训练的模型更新可以在网络中的边缘节点聚合，也可以通过网络中的互连终端设备进行交换。&lt;/p&gt;
&lt;p&gt;The two kinds of decentralized training modes can be realized without the support of the cloud. In this section, enabling techniques for decentralized AI model training, communication efficiency and security enhancement in AIoT are mainly discussed.&lt;/p&gt;
&lt;p&gt;作者认为，这两种分布式的训练模式可以在没有云支持的情况下实现。作者在本节主要讨论了分布式人工智能模型训练的使能技术、AIoT 中的通信效率和安全增强。&lt;/p&gt;
&lt;h3 id=&#34;decentralized-artificial-intelligence-of-things-model-training-methods&#34;&gt;Decentralized Artificial Intelligence of Things Model Training Methods&lt;/h3&gt;
&lt;p&gt;With respect to the AIoT, it is essential to develop decentralized AI training methods that can avoid data transmission, further reducing the transition bandwidth and enhancing privacy. In this subsection, enabling techniques for decentralized AIoT model training are introduced.&lt;/p&gt;
&lt;p&gt;关于AIoT，必须开发分布式的人工智能训练方法，以避免数据传输，进一步减少过渡带宽并增强隐私。作者在本节讨论了分布式 AIoT 模型训练的使能技术。&lt;/p&gt;
&lt;h4 id=&#34;federated-learning-联邦学习&#34;&gt;Federated Learning: 联邦学习&lt;/h4&gt;
&lt;p&gt;FL is a collaborative AI setting that is originally aimed at addressing the problem of Android mobile terminal users updating models locally with unreliable and slow network connections.&lt;/p&gt;
&lt;p&gt;联邦学习是一种协作式人工智能设置，最初旨在解决 Android 移动终端用户使用不可靠且缓慢的网络连接在本地更新模型的问题。&lt;/p&gt;
&lt;p&gt;Gradually, FL has come to assist in efficient AI training by using data distributed over a large number of end devices and edge servers while ensuring information security, protecting terminal and user privacy, and adhering to legal requirements during data exchange.&lt;/p&gt;
&lt;p&gt;通过使用分布在大量终端设备和边缘服务器上的数据，同时确保信息安全，保护终端和用户隐私，并在数据交换过程中遵守法律要求，联邦学习逐渐开始辅助高效的人工智能训练。&lt;/p&gt;
&lt;p&gt;Traditionally, in the distributed configuration of FL, the AI model is built without direct access to data, while mobile devices serving as clients carry out local training.&lt;/p&gt;
&lt;p&gt;传统的联邦学习的分布式配置中，人工智能模型是在不直接访问数据的情况下构建的，而作为客户端的移动设备则执行本地训练。&lt;/p&gt;
&lt;p&gt;Additionally, these mobile devices can be extended to end devices, while edge nodes and cloud servers are equivalently considered as clients. A server coordinates a series of nodes, thereby enabling the clients to take responsibility for various levels of ML model training and share the individual trained models with the server. The server creates a federated model by using the uploaded trained models and returns the optimized model to the clients.&lt;/p&gt;
&lt;p&gt;此外，这些移动设备可以扩展到终端设备，而边缘节点和云服务器被等效地视为客户端。服务器协调一系列节点，从而使客户端能够负责不同级别的 ML 模型训练，并与服务器共享各个经过培训的模型。服务器使用上传的经过训练的模型创建一个联邦模型，并将优化后的模型返回给客户端。&lt;/p&gt;
&lt;h4 id=&#34;dnn-splitting-分裂学习&#34;&gt;DNN Splitting: 分裂学习&lt;/h4&gt;
&lt;p&gt;DNN splitting exchanges partially processed data instead of raw data between end devices and edge servers, which is an effective way to protect privacy-sensitive data.&lt;/p&gt;
&lt;p&gt;DNN 拆分在终端设备和边缘服务器之间交换部分处理的数据而不是原始数据，这是保护隐私敏感数据的有效方法。&lt;/p&gt;
&lt;p&gt;However, selecting an appropriate splitting point to meet the requirement of latency remains as a research point.&lt;/p&gt;
&lt;p&gt;然而，选择合适的分割点来满足延迟的要求仍然是一个研究点。&lt;/p&gt;
&lt;p&gt;To reduce the computational complexity with accuracy preserved and introduce a bottleneck, it is proposed in [171] to employ network distillation to distill the head portion of the split model. This approach deploys lightweight models on end side and pushes the intensive computation of DNN to the server, minimizing processing load at the mobile device as well as the amount of wirelessly transferred data.&lt;/p&gt;
&lt;p&gt;作者指出，相关工作建议使用蒸馏的方法以在终端部署轻量化模型，并将密集的 DNN 计算推送到服务器，从而最小化移动设备上的处理负载以及无线传输的数据量。&lt;/p&gt;
&lt;h4 id=&#34;transfer-learning-迁移学习&#34;&gt;Transfer Learning 迁移学习&lt;/h4&gt;
&lt;p&gt;Knowledge transfer learning, also known as TL, has emerged as a practical DNN training mechanism that enables the convolution kernels to be initialized with the weights learned from the pretrained model and solves the problem of training data drawn from different distributions. TL is closely connected with DNN splitting, the goal of which is to reduce the energy cost of DNN model training on mobile devices and suitable for general-feature image recognition.&lt;/p&gt;
&lt;p&gt;知识迁移学习（也称为 TL）已成为一种实用的 DNN 训练机制，它可以使用从预训练模型中学习的权重初始化卷积核，并解决从不同分布中提取训练数据的问题。TL 与 DNN 分裂密切相关，其目的是降低移动设备上 DNN 模型训练的能量成本，适合一般特征图像识别。&lt;/p&gt;
&lt;p&gt;FL preserves privacy by leaving raw data on local devices and trains a shared model on the server by uploading the computed updates. Rather than transmitting the raw data, DNN splitting selects a splitting point, thereby enabling distributed DNN models to be trained using the partially processed data. TL applies the general features learned from a DNN pretrained on the basic data to a specific data set or task.&lt;/p&gt;
&lt;p&gt;总而言之，联邦学习通过在本地设备上保留原始数据来保护隐私，并通过上传计算出的更新在服务器上训练共享模型。分裂学习不传输原始数据，而是选择一个分割点，从而使分布式 DNN 模型能够使用部分处理的数据进行训练。迁移学习将从对基本数据进行预训练的 DNN 中学习到的一般特性应用于特定的数据集或任务。&lt;/p&gt;
&lt;h3 id=&#34;enabling-technologies-for-aiot-model-training-updates&#34;&gt;Enabling Technologies for AIoT Model Training Updates&lt;/h3&gt;
&lt;p&gt;作者在本节介绍了 AIoT 模型训练的更新方法，主要从更新频率和更新大小两个角度切入进行阐述。&lt;/p&gt;
&lt;h4 id=&#34;frequency-of-training-updates&#34;&gt;Frequency of Training Updates&lt;/h4&gt;
&lt;p&gt;In distributed DL training, a locally trained model or preprocessed data must be uploaded to a central server. One important issue is to optimize the gradient of the shared model through the gradient updates on end devices.&lt;/p&gt;
&lt;p&gt;在分布式深度学习训练中，必须将本地训练的模型或预处理的数据上载到中央服务器。一个重要的问题是通过终端设备上的梯度更新来优化共享模型的梯度。&lt;/p&gt;
&lt;p&gt;Stochastic gradient descent (SGD) is a widely used gradient descent method that updates the minibatch gradient over the entire data set. Generally, there are two kinds of SGD: 1) synchronous and 2) asynchronous SGD.&lt;/p&gt;
&lt;p&gt;作者接下来详细介绍了随机梯度下降 SGD 这一广泛使用的梯度下降方法，它可以在整个数据集上更新小批量梯度。并且，SGD 分为同步和异步两种。它们的主要区别在于：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;同步 SGD：如果所有设备都完成了计算任务，则每个设备都会在本地训练数据上使用梯度同步更新其参数。收敛结果相对更好，但由于需要等待其他设备，因此在实践中收敛速度较慢。&lt;/li&gt;
&lt;li&gt;异步 SGD：只要有设备完成了计算任务，那么就立刻使用梯度同步更新全局的参数。异步 SGD 的收敛速度比同步更快，但代价是额外的噪声，并且可能导致较差的收敛结果。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;FL also adopts SGD. In [169], the federated averaging (FedAvg) method for FL with a DNN established based on iterative model averaging is presented, in which end devices update the DNN model with one-step SGD and the server averages the obtained models with weights. This approach can be also applied to unbalanced and non-IID distributions.&lt;/p&gt;
&lt;p&gt;作者还指出，联邦学习也采用 SGD 进行更新参数。相关工作提出了基于迭代模型平均的 DNN 联邦平均 FedAvg 方法，其中终端设备使用一次 SGD 更新 DNN 模型，服务器使用权重对获得的模型进行平均。这种方法也适用于不平衡和非独立同分布的数据。&lt;/p&gt;
&lt;h4 id=&#34;size-of-training-updates&#34;&gt;Size of Training Updates&lt;/h4&gt;
&lt;p&gt;In addition to the factor of the frequency of training updates, the size of training updates significantly influences on the transmission bandwidth. Gradient compression is usually adopted to reduce the size of model updates communicated to the central server, which aims to compress the gradient information of the updated model.&lt;/p&gt;
&lt;p&gt;除了训练更新频率的因素外，训练更新的大小对传输带宽也有显著影响。通常采用梯度压缩来减小传递给中央服务器的模型更新的大小，目的是压缩更新模型的梯度信息。&lt;/p&gt;
&lt;p&gt;具体而言，作者主要总结了如下两种方法：&lt;/p&gt;
&lt;h5 id=&#34;gradient-quantization-梯度量化&#34;&gt;Gradient quantization: 梯度量化&lt;/h5&gt;
&lt;p&gt;Gradient quantization carries out lossy compression of the gradient vectors by using a finite-bit low-width number instead of the original floating-point gradients, which is similar to parameter quantization of inference. The difference between these methods lies in whether the quantization technique is applied to the model gradients or the model parameters.&lt;/p&gt;
&lt;p&gt;梯度量化通过使用有限位低宽度数代替原始浮点梯度来对梯度向量进行有损压缩，这类似于推理的参数量化。这两种方法之间的区别在于量化技术是应用于模型梯度还是模型参数。&lt;/p&gt;
&lt;h5 id=&#34;gradient-sparsification-梯度稀疏化&#34;&gt;Gradient sparsification: 梯度稀疏化&lt;/h5&gt;
&lt;p&gt;Gradient sparsification reduces the communication costs by dropping important gradient updates and transmitting only updates that exceed a certain threshold.&lt;/p&gt;
&lt;p&gt;梯度稀疏化通过丢弃重要的梯度更新并仅传输超过某个阈值的更新来降低通信成本。&lt;/p&gt;
&lt;h3 id=&#34;security-enhancement&#34;&gt;Security Enhancement&lt;/h3&gt;
&lt;p&gt;Distributed learning has shown a strong trend toward largescale model training in AIoT, where a server coordinates the computational power of end devices by sharing the trained data or aggregating local models trained on individual devices. This kind of method can stop privacy leaks from directly sharing the raw data collected from end devices; however, the gradient information shared by end devices still inevitably divulges private information. Thus, research and development of privacy preservation for AI model training is necessary.&lt;/p&gt;
&lt;p&gt;分布式学习已显示出在 AIoT 中进行大规模模型训练的强大趋势，在 AIoT 中，服务器通过共享培训数据或聚合在单个设备上培训的本地模型来协调终端设备的计算能力。这种方法可以阻止隐私泄露，避免直接共享从终端设备收集的原始数据；然而，终端设备共享的梯度信息仍然不可避免地泄露私人信息。因此，研究和开发用于人工智能模型训练的隐私保护是必要的。&lt;/p&gt;
&lt;p&gt;Generally, there are two obstacles: the first is that attackers may infer sensitive information from aggregated data or gradients; the other obstacle is that third parties are not trusted, thus causing data or model leakage.&lt;/p&gt;
&lt;p&gt;通常，存在两个障碍：第一个障碍是攻击者可能从聚合数据或梯度推断敏感信息；另一个障碍是第三方不受信任，从而导致数据或模型泄漏。&lt;/p&gt;
&lt;p&gt;作者主要从如下两个角度展开介绍隐私安全增强：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Data Privacy and Security: 数据隐私安全性&lt;/li&gt;
&lt;li&gt;System Security: 系统安全性&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;open-challenges-and-future-directions&#34;&gt;Open Challenges and Future Directions&lt;/h2&gt;
&lt;p&gt;作者认为 AIoT 中的一些开放挑战和潜在的未来方向如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Heterogeneity and Interoperability: 异构性和互操作性&lt;/li&gt;
&lt;li&gt;Resource Management: 资源管理&lt;/li&gt;
&lt;li&gt;Model Inference and Training: 模型推理与训练&lt;/li&gt;
&lt;li&gt;Security and Privacy: 安全和隐私&lt;/li&gt;
&lt;li&gt;Artificial Intelligence Ethics in Artificial Intelligence of Things: AIoT 中的人工智能伦理&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    &lt;p&gt;本文是写得相对来说很不错的一篇综述，逻辑清晰。作者给出了人工智能、物联网、边缘计算等概念，引出边缘计算辅助 AIoT 的概念。随后作者以一个实际的 AIoT 示例介绍人工智能如何应用于实际的 IoT 场景，并且还介绍了人工智能模型在网络边缘推理和训练两方面的技术。&lt;/p&gt;
&lt;p&gt;从整篇文章来看，本文的逻辑是从概念到应用，然后再到技术。这有一个从抽象到具体，再到抽象的过程。本文没有特别侧重概念、应用或者技术的任何一方面。本文的最大贡献在于捋清了人工智能、物联网、边缘计算等概念的关系，并对边缘智能赋能 AIoT 进行了深入阐述。&lt;/p&gt;
&lt;p&gt;考虑到本文的篇幅和侧重点，在介绍 AIoT 相关技术时，训练和推理各项技术仅进行了简单的分类。特别是在介绍推理时，将各项技术按照终端本地推理和边缘协同推理分类存在一些问题。以模型提前退出这项技术为例，将它放到边缘协同推理是有些牵强的。因为模型提前退出是为了平衡推理时延和精度的优化，它既适用于终端本地推理，也适用于边缘协同推理。&lt;/p&gt;

  &lt;/div&gt;
&lt;/div&gt;

</description>
    </item>
    
    <item>
      <title>Types of Transition Words and Phrases in Academic Writing</title>
      <link>https://bowenei.gitee.io/post/types-of-transition-words-and-phrases-in-academic-writing/</link>
      <pubDate>Tue, 17 May 2022 14:15:17 +0800</pubDate>
      <guid>https://bowenei.gitee.io/post/types-of-transition-words-and-phrases-in-academic-writing/</guid>
      <description>&lt;p&gt;Transition words and phrases (also called linking words, connecting words, or transitional words) are used to link together different ideas in your text. They help the reader to follow your arguments by expressing the relationships between different sentences or parts of a sentence.&lt;/p&gt;
&lt;p&gt;过渡的单词和短语（也称为连接词）用于将文本中的不同观点连接在一起。它们通过表达不同句子或句子部分之间的关系来帮助读者理解你的论点。&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;There are four main types of transition word: additive, adversative, causal, and sequential. Within each category, words are divided into several more specific functions.&lt;/p&gt;
&lt;p&gt;过渡词有四种主要类型：递进、转折、因果和顺序。在每个类别中，过渡词则分为几个更具体的功能。&lt;/p&gt;
&lt;p&gt;Remember that transition words with similar meanings are not necessarily interchangeable. It’s important to understand the meaning of all the transition words you use. If unsure, consult a dictionary to find the precise definition.&lt;/p&gt;
&lt;p&gt;记住，意思相似的过渡词不一定可以互换。理解你使用的所有过渡词的意思很重要。如果不确定，请查阅字典以找到准确的定义。&lt;/p&gt;
&lt;h2 id=&#34;additive-transition-words&#34;&gt;Additive transition words&lt;/h2&gt;
&lt;p&gt;Additive transition words introduce new information or examples. They can be used to expand upon, compare with, or clarify the preceding text.&lt;/p&gt;
&lt;p&gt;表示递进的过渡词引入了新的信息或例子。它们可以用于扩展、比较或澄清前面的文本。&lt;/p&gt;
&lt;style type=&#34;text/css&#34;&gt;
.tg  {border-collapse:collapse;border-spacing:0;}
.tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;
  overflow:hidden;padding:10px 5px;word-break:normal;}
.tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;
  font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}
.tg .tg-td2w{border-color:inherit;font-size:20px;font-weight:bold;text-align:center;vertical-align:middle}
.tg .tg-r22t{border-color:inherit;font-size:20px;text-align:left;vertical-align:middle}
&lt;/style&gt;
&lt;table class=&#34;tg&#34;&gt;
&lt;thead&gt;
  &lt;tr&gt;
    &lt;th class=&#34;tg-td2w&#34;&gt;Function&lt;/th&gt;
    &lt;th class=&#34;tg-td2w&#34;&gt;Example sentence&lt;/th&gt;
    &lt;th class=&#34;tg-td2w&#34;&gt;Transition words and phrases&lt;/th&gt;
  &lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
    &lt;td class=&#34;tg-td2w&#34;&gt;Addition&lt;/td&gt;
    &lt;td class=&#34;tg-r22t&#34;&gt;We found that the mixture was effective. &lt;span style=&#34;font-weight:bold&#34;&gt;Moreover&lt;/span&gt;, it appeared to have additional effects we had not predicted.&lt;/td&gt;
    &lt;td class=&#34;tg-r22t&#34;&gt;
      &lt;ul&gt;
        &lt;li&gt;indeed&lt;/li&gt;
        &lt;li&gt;furthermore&lt;/li&gt;
        &lt;li&gt;moreover&lt;/li&gt;
        &lt;li&gt;additionally&lt;/li&gt;
        &lt;li&gt;and&lt;/li&gt;
        &lt;li&gt;also&lt;/li&gt;
        &lt;li&gt;both &lt;span style=&#34;font-style:italic&#34;&gt;x&lt;/span&gt; and &lt;span style=&#34;font-style:italic&#34;&gt;y&lt;/span&gt;&lt;/li&gt;
        &lt;li&gt;not only &lt;span style=&#34;font-style:italic&#34;&gt;x&lt;/span&gt; but also &lt;span style=&#34;font-style:italic&#34;&gt;y&lt;/span&gt;&lt;/li&gt;
        &lt;li&gt;besides &lt;span style=&#34;font-style:italic&#34;&gt;x&lt;/span&gt;&lt;/li&gt;
        &lt;li&gt;in fact&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td class=&#34;tg-td2w&#34;&gt;Introduction&lt;/td&gt;
    &lt;td class=&#34;tg-r22t&#34;&gt;Serveral researchers have previously explored this topic. &lt;span style=&#34;font-weight:bold&#34;&gt;For instance&lt;/span&gt;, Smith (2014) examined the effects of ...&lt;/td&gt;
    &lt;td class=&#34;tg-r22t&#34;&gt;
      &lt;ul&gt;
        &lt;li&gt;such as&lt;/li&gt;
        &lt;li&gt;like&lt;/li&gt;
        &lt;li&gt;particularly&lt;/li&gt;
        &lt;li&gt;including&lt;/li&gt;
        &lt;li&gt;as an illustration&lt;/li&gt;
        &lt;li&gt;for example&lt;/li&gt;
        &lt;li&gt;for instance&lt;/li&gt;
        &lt;li&gt;in particular&lt;/li&gt;
        &lt;li&gt;to illustrate&lt;/li&gt;
        &lt;li&gt;especially&lt;/li&gt;
        &lt;li&gt;notably&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td class=&#34;tg-td2w&#34;&gt;Reference&lt;/td&gt;
    &lt;td class=&#34;tg-r22t&#34;&gt;The solution showed a high degree of absorption. &lt;span style=&#34;font-weight:bold&#34;&gt;Considering this result&lt;/span&gt;, it is reasonable to conclude that ...&lt;/td&gt;
    &lt;td class=&#34;tg-r22t&#34;&gt;
      &lt;ul&gt;
        &lt;li&gt;considering &lt;span style=&#34;font-style:italic&#34;&gt;x&lt;/span&gt;&lt;/li&gt;
        &lt;li&gt;regarding &lt;span style=&#34;font-style:italic&#34;&gt;x&lt;/span&gt;&lt;/li&gt;
        &lt;li&gt;in regard to &lt;span style=&#34;font-style:italic&#34;&gt;x&lt;/span&gt;&lt;/li&gt;
        &lt;li&gt;as for &lt;span style=&#34;font-style:italic&#34;&gt;x&lt;/span&gt;&lt;/li&gt;
        &lt;li&gt;concerning &lt;span style=&#34;font-style:italic&#34;&gt;x&lt;/span&gt;&lt;/li&gt;
        &lt;li&gt;the fact that &lt;span style=&#34;font-style:italic&#34;&gt;x&lt;/span&gt;&lt;/li&gt;
        &lt;li&gt;on the subject of &lt;span style=&#34;font-style:italic&#34;&gt;x&lt;/span&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td class=&#34;tg-td2w&#34;&gt;Similarity&lt;/td&gt;
    &lt;td class=&#34;tg-r22t&#34;&gt;It was not possible to establish a correlation between these variables. &lt;span style=&#34;font-weight:bold&#34;&gt;Similarly&lt;/span&gt;, the connection between x and y remains unclear …&lt;/td&gt;
    &lt;td class=&#34;tg-r22t&#34;&gt;
      &lt;ul&gt;
        &lt;li&gt;similarly&lt;/li&gt;
        &lt;li&gt;in the same way&lt;/li&gt;
        &lt;li&gt;by the same token&lt;/li&gt;
        &lt;li&gt;in like manner&lt;/li&gt;
        &lt;li&gt;equally&lt;/li&gt;
        &lt;li&gt;likewise&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td class=&#34;tg-td2w&#34;&gt;Clarification&lt;/td&gt;
    &lt;td class=&#34;tg-r22t&#34;&gt;The patient suffered several side effects, &lt;span style=&#34;font-weight:bold&#34;&gt;namely&lt;/span&gt; increased appetite, decreased libido, and disordered sleep.&lt;/td&gt;
    &lt;td class=&#34;tg-r22t&#34;&gt;
      &lt;ul&gt;
        &lt;li&gt;that is (to say)&lt;/li&gt;
        &lt;li&gt;namely&lt;/li&gt;
        &lt;li&gt;specifically&lt;/li&gt;
        &lt;li&gt;more precisely&lt;/li&gt;
        &lt;li&gt;in other words&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;adversative-transition-words&#34;&gt;Adversative transition words&lt;/h2&gt;
&lt;p&gt;Adversative transition words always signal a contrast of some kind. They can be used to introduce information that disagrees or contrasts with the preceding text.&lt;/p&gt;
&lt;p&gt;表示转折的过渡词总是表示某种对比。它们可以用来介绍与前面文本不一致或相反的信息。&lt;/p&gt;
&lt;style type=&#34;text/css&#34;&gt;
.tg  {border-collapse:collapse;border-spacing:0;}
.tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;
  overflow:hidden;padding:10px 5px;word-break:normal;}
.tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;
  font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}
.tg .tg-td2w{border-color:inherit;font-size:20px;font-weight:bold;text-align:center;vertical-align:middle}
.tg .tg-r22t{border-color:inherit;font-size:20px;text-align:left;vertical-align:middle}
&lt;/style&gt;
&lt;table class=&#34;tg&#34;&gt;
&lt;thead&gt;
  &lt;tr&gt;
    &lt;th class=&#34;tg-td2w&#34;&gt;Function&lt;/th&gt;
    &lt;th class=&#34;tg-td2w&#34;&gt;Example sentence&lt;/th&gt;
    &lt;th class=&#34;tg-td2w&#34;&gt;Transition words and phrases&lt;/th&gt;
  &lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
    &lt;td class=&#34;tg-td2w&#34;&gt;Conflict&lt;/td&gt;
    &lt;td class=&#34;tg-r22t&#34;&gt;The novel does deal with the theme of family. &lt;span style=&#34;font-weight:bold&#34;&gt;However&lt;/span&gt;, its central theme is more broadly political ...&lt;/td&gt;
    &lt;td class=&#34;tg-r22t&#34;&gt;
      &lt;ul&gt;
        &lt;li&gt;but&lt;/li&gt;
        &lt;li&gt;however&lt;/li&gt;
        &lt;li&gt;although&lt;/li&gt;
        &lt;li&gt;though&lt;/li&gt;
        &lt;li&gt;equally&lt;/li&gt;
        &lt;li&gt;by way of contrast&lt;/li&gt;
        &lt;li&gt;while&lt;/li&gt;
        &lt;li&gt;on the other hand&lt;/li&gt;
        &lt;li&gt;(and) yet&lt;/li&gt;  
        &lt;li&gt;whereas&lt;/li&gt;
        &lt;li&gt;in contrast&lt;/li&gt;
        &lt;li&gt;(when) in fact&lt;/li&gt;
        &lt;li&gt;conversely&lt;/li&gt;
        &lt;li&gt;whereas&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td class=&#34;tg-td2w&#34;&gt;Concession&lt;/td&gt;
    &lt;td class=&#34;tg-r22t&#34;&gt;Jones (2011) argues that the novel reflects Russian politics of the time. &lt;span style=&#34;font-weight:bold&#34;&gt;Although&lt;/span&gt; this is correct, other aspects of the text must also be considered.&lt;/td&gt;
    &lt;td class=&#34;tg-r22t&#34;&gt;
      &lt;ul&gt; 
        &lt;li&gt;even so&lt;/li&gt;
        &lt;li&gt;nonetheless&lt;/li&gt;
        &lt;li&gt;nevertheless&lt;/li&gt;
        &lt;li&gt;even though&lt;/li&gt;
        &lt;li&gt;on the other hand&lt;/li&gt;
        &lt;li&gt;admittedly&lt;/li&gt;
        &lt;li&gt;despite &lt;span style=&#34;font-style:italic&#34;&gt;x&lt;/span&gt;&lt;/li&gt;
        &lt;li&gt;notwithstanding &lt;span style=&#34;font-style:italic&#34;&gt;x&lt;/span&gt;&lt;/li&gt;
        &lt;li&gt;(and) still&lt;/li&gt;
        &lt;li&gt;although&lt;/li&gt;
        &lt;li&gt;in spite of &lt;span style=&#34;font-style:italic&#34;&gt;x&lt;/span&gt;&lt;/li&gt;
        &lt;li&gt;regardless (of &lt;span style=&#34;font-style:italic&#34;&gt;x&lt;/span&gt;)&lt;/li&gt;
        &lt;li&gt;(and) yet&lt;/li&gt;
        &lt;li&gt;though&lt;/li&gt;
        &lt;li&gt;granted &lt;span style=&#34;font-style:italic&#34;&gt;x&lt;/span&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td class=&#34;tg-td2w&#34;&gt;Dismissal&lt;/td&gt;
    &lt;td class=&#34;tg-r22t&#34;&gt;It remains unclear which of these hypotheses is correct. &lt;span style=&#34;font-weight:bold&#34;&gt;In any case&lt;/span&gt;, it can be inferred that ...&lt;/td&gt;
    &lt;td class=&#34;tg-r22t&#34;&gt;
      &lt;ul&gt;
        &lt;li&gt;regardless&lt;/li&gt;
        &lt;li&gt;either way&lt;/li&gt;
        &lt;li&gt;whatever the case&lt;/li&gt;
        &lt;li&gt;in any/either event&lt;/li&gt;
        &lt;li&gt;in any/either case&lt;/li&gt;
        &lt;li&gt;at any rate&lt;/li&gt;
        &lt;li&gt;all the same&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td class=&#34;tg-td2w&#34;&gt;Emphasis&lt;/td&gt;
    &lt;td class=&#34;tg-r22t&#34;&gt;The chemical is generally thought to have corrosive properies. &lt;span style=&#34;font-weight:bold&#34;&gt;Indeed&lt;/span&gt;, several studies have supported this hypothesis.&lt;/td&gt;
    &lt;td class=&#34;tg-r22t&#34;&gt;
      &lt;ul&gt;
        &lt;li&gt;above all&lt;/li&gt;
        &lt;li&gt;indeed&lt;/li&gt;
        &lt;li&gt;more/most importantly&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td class=&#34;tg-td2w&#34;&gt;Replacement&lt;/td&gt;
    &lt;td class=&#34;tg-r22t&#34;&gt;The character of Godfrey is often viewed as selfish, &lt;span style=&#34;font-weight:bold&#34;&gt;or at least&lt;/span&gt; self-absorbed.&lt;/td&gt;
    &lt;td class=&#34;tg-r22t&#34;&gt;
      &lt;ul&gt;
        &lt;li&gt;(or) at least&lt;/li&gt;
        &lt;li&gt;(or) rather&lt;/li&gt;
        &lt;li&gt;instead&lt;/li&gt;
        &lt;li&gt;or (perhaps) even&lt;/li&gt;
        &lt;li&gt;if not&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;causal-transition-words&#34;&gt;Causal transition words&lt;/h2&gt;
&lt;p&gt;Causal transition words are used to describe cause and effect. They can be used to express purpose, consequence, and condition.&lt;/p&gt;
&lt;p&gt;表示因果的过渡词用来描述因果关系。它们可以用来表达目的、结果和条件。&lt;/p&gt;
&lt;style type=&#34;text/css&#34;&gt;
.tg  {border-collapse:collapse;border-spacing:0;}
.tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;
  overflow:hidden;padding:10px 5px;word-break:normal;}
.tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;
  font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}
.tg .tg-td2w{border-color:inherit;font-size:20px;font-weight:bold;text-align:center;vertical-align:middle}
.tg .tg-r22t{border-color:inherit;font-size:20px;text-align:left;vertical-align:middle}
&lt;/style&gt;
&lt;table class=&#34;tg&#34;&gt;
&lt;thead&gt;
  &lt;tr&gt;
    &lt;th class=&#34;tg-td2w&#34;&gt;Function&lt;/th&gt;
    &lt;th class=&#34;tg-td2w&#34;&gt;Example sentence&lt;/th&gt;
    &lt;th class=&#34;tg-td2w&#34;&gt;Transition words and phrases&lt;/th&gt;
  &lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
    &lt;td class=&#34;tg-td2w&#34;&gt;Consequence&lt;/td&gt;
    &lt;td class=&#34;tg-r22t&#34;&gt;&lt;span style=&#34;font-weight:bold&#34;&gt;Because&lt;/span&gt; Hitler failed to respond to the British ultimatum, France and the UK declared war on Germany.&lt;/td&gt;
    &lt;td class=&#34;tg-r22t&#34;&gt;
      &lt;ul&gt;
        &lt;li&gt;therefore&lt;/li&gt;
        &lt;li&gt;because (of &lt;span style=&#34;font-style:italic&#34;&gt;x&lt;/span&gt;)&lt;/li&gt;
        &lt;li&gt;as a result (of &lt;span style=&#34;font-style:italic&#34;&gt;x&lt;/span&gt;)&lt;/li&gt;
        &lt;li&gt;for this reason&lt;/li&gt;
        &lt;li&gt;in view of &lt;span style=&#34;font-style:italic&#34;&gt;x&lt;/span&gt;&lt;/li&gt;
        &lt;li&gt;as&lt;/li&gt;
        &lt;li&gt;owing to &lt;span style=&#34;font-style:italic&#34;&gt;x&lt;/span&gt;&lt;/li&gt;
        &lt;li&gt;due to (the fact that)&lt;/li&gt;
        &lt;li&gt;since&lt;/li&gt;
        &lt;li&gt;consequently&lt;/li&gt;
        &lt;li&gt;in consequence&lt;/li&gt;
        &lt;li&gt;as a consequence&lt;/li&gt;
        &lt;li&gt;hence&lt;/li&gt;
        &lt;li&gt;thus&lt;/li&gt;
        &lt;li&gt;so (that)&lt;/li&gt;
        &lt;li&gt;accordingly&lt;/li&gt;
        &lt;li&gt;so much (so) that&lt;/li&gt;
        &lt;li&gt;under the/such circumstances&lt;/li&gt;
        &lt;li&gt;if so&lt;/li&gt;        
      &lt;/ul&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td class=&#34;tg-td2w&#34;&gt;Condition&lt;/td&gt;
    &lt;td class=&#34;tg-r22t&#34;&gt;We qualified survey responses as positive only of the participant selected “agree” or “strongly agree.” Otherwise, results were recorded as negative.&lt;/td&gt;
    &lt;td class=&#34;tg-r22t&#34;&gt;
      &lt;ul&gt;
        &lt;li&gt;(even/only) if/when&lt;/li&gt;
        &lt;li&gt;on (the) condition that&lt;/li&gt;
        &lt;li&gt;in the case that&lt;/li&gt;
        &lt;li&gt;granted (that)&lt;/li&gt;
        &lt;li&gt;provided/providing that&lt;/li&gt;
        &lt;li&gt;in case&lt;/li&gt;
        &lt;li&gt;in the event that&lt;/li&gt;
        &lt;li&gt;as/so long as&lt;/li&gt;
        &lt;li&gt;unless&lt;/li&gt;
        &lt;li&gt;given that&lt;/li&gt;
        &lt;li&gt;being that&lt;/li&gt;
        &lt;li&gt;inasmuch/insofar as&lt;/li&gt;
        &lt;li&gt;in that case&lt;/li&gt;
        &lt;li&gt;in (all) other cases&lt;/li&gt;
        &lt;li&gt;if so/not&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td class=&#34;tg-td2w&#34;&gt;Purpose&lt;/td&gt;
    &lt;td class=&#34;tg-r22t&#34;&gt;We used accurate recording equipment so that our results would be as precise as possible.&lt;/td&gt;
    &lt;td class=&#34;tg-r22t&#34;&gt;
      &lt;ul&gt;
        &lt;li&gt;to&lt;/li&gt;
        &lt;li&gt;in order to/that&lt;/li&gt;
        &lt;li&gt;for the purpose of&lt;/li&gt;
        &lt;li&gt;in the hope that&lt;/li&gt;
        &lt;li&gt;so that&lt;/li&gt;
        &lt;li&gt;to the end that&lt;/li&gt;
        &lt;li&gt;lest&lt;/li&gt;
        &lt;li&gt;with this in mind&lt;/li&gt;
        &lt;li&gt;so as to&lt;/li&gt;
        &lt;li&gt;so that&lt;/li&gt;
        &lt;li&gt;to ensure (that)&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;sequential-transition-words&#34;&gt;Sequential transition words&lt;/h2&gt;
&lt;p&gt;Sequential transition words indicate a sequence, whether it’s the order in which events occurred chronologically or the order you’re presenting them in your text. They can be used for signposting in academic texts.&lt;/p&gt;
&lt;p&gt;表示顺序的过渡词表示一个顺序，无论是事件按时间顺序发生的顺序，还是你在文本中呈现它们的顺序。它们可用于学术论文行文的标志。&lt;/p&gt;
&lt;style type=&#34;text/css&#34;&gt;
.tg  {border-collapse:collapse;border-spacing:0;}
.tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;
  overflow:hidden;padding:10px 5px;word-break:normal;}
.tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;
  font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}
.tg .tg-td2w{border-color:inherit;font-size:20px;font-weight:bold;text-align:center;vertical-align:middle}
.tg .tg-r22t{border-color:inherit;font-size:20px;text-align:left;vertical-align:middle}
.tg .tg-2bvl{font-size:20px;font-weight:bold;text-align:center;vertical-align:middle}
.tg .tg-mgyo{font-size:20px;text-align:left;vertical-align:middle}
&lt;/style&gt;
&lt;table class=&#34;tg&#34;&gt;
&lt;thead&gt;
  &lt;tr&gt;
    &lt;th class=&#34;tg-td2w&#34;&gt;Function&lt;/th&gt;
    &lt;th class=&#34;tg-td2w&#34;&gt;Example sentence&lt;/th&gt;
    &lt;th class=&#34;tg-td2w&#34;&gt;Transition words and phrases&lt;/th&gt;
  &lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
    &lt;td class=&#34;tg-td2w&#34;&gt;Enumeration&lt;/td&gt;
    &lt;td class=&#34;tg-r22t&#34;&gt;This has historically had several consequences: &lt;span style=&#34;font-weight:bold&#34;&gt;First&lt;/span&gt;, the conflict is not given the weight of other conflicts in historical narratives. &lt;span style=&#34;font-weight:bold&#34;&gt;Second&lt;/span&gt;, its causes are inadequately understood. &lt;span style=&#34;font-weight:bold&#34;&gt;Third&lt;/span&gt;, ...&lt;/td&gt;
    &lt;td class=&#34;tg-r22t&#34;&gt;
      &lt;ul&gt;
        &lt;li&gt;first&lt;/li&gt;
        &lt;li&gt;second&lt;/li&gt;
        &lt;li&gt;third&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td class=&#34;tg-td2w&#34;&gt;Initiation&lt;/td&gt;
    &lt;td class=&#34;tg-r22t&#34;&gt;&lt;span style=&#34;font-weight:bold&#34;&gt;To begin with&lt;/span&gt;, I want to consider the role played by women in this period.&lt;/td&gt;
    &lt;td class=&#34;tg-r22t&#34;&gt;
      &lt;ul&gt;
        &lt;li&gt;in the first place&lt;/li&gt;
        &lt;li&gt;initially&lt;/li&gt;
        &lt;li&gt;first of all&lt;/li&gt;
        &lt;li&gt;to begin with&lt;/li&gt;
        &lt;li&gt;at first&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td class=&#34;tg-td2w&#34;&gt;Continuation&lt;/td&gt;
    &lt;td class=&#34;tg-r22t&#34;&gt;&lt;span style=&#34;font-weight:bold&#34;&gt;Subsequently&lt;/span&gt;, I discuss the way in which the country’s various ethnic minorities were affected by the conflict.&lt;/td&gt;
    &lt;td class=&#34;tg-r22t&#34;&gt;
      &lt;ul&gt;
        &lt;li&gt;subsequently&lt;/li&gt;
        &lt;li&gt;previously&lt;/li&gt;
        &lt;li&gt;eventually&lt;/li&gt;
        &lt;li&gt;next&lt;/li&gt;
        &lt;li&gt;before &lt;span style=&#34;font-style:italic&#34;&gt;x&lt;/span&gt;&lt;/li&gt;
        &lt;li&gt;afterwards&lt;/li&gt;
        &lt;li&gt;after &lt;span style=&#34;font-style:italic&#34;&gt;x&lt;/span&gt;&lt;/li&gt;
        &lt;li&gt;then&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td class=&#34;tg-2bvl&#34;&gt;Conclusion&lt;/td&gt;
    &lt;td class=&#34;tg-mgyo&#34;&gt;&lt;span style=&#34;font-weight:bold&#34;&gt;Finally&lt;/span&gt;, I consider these two themes in combination.&lt;/td&gt;
    &lt;td class=&#34;tg-mgyo&#34;&gt;
      &lt;ul&gt;
        &lt;li&gt;to conclude (with)&lt;/li&gt;
        &lt;li&gt;as a final point&lt;/li&gt;
        &lt;li&gt;eventually&lt;/li&gt;
        &lt;li&gt;at last&lt;/li&gt;
        &lt;li&gt;last but not least&lt;/li&gt;
        &lt;li&gt;finally&lt;/li&gt;
        &lt;li&gt;lastly&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td class=&#34;tg-2bvl&#34;&gt;Resumption&lt;/td&gt;
    &lt;td class=&#34;tg-mgyo&#34;&gt;&lt;span style=&#34;font-weight:bold&#34;&gt;To return to&lt;/span&gt; my main argument, it is clear that ...&lt;/td&gt;
    &lt;td class=&#34;tg-mgyo&#34;&gt;
      &lt;ul&gt;
        &lt;li&gt;to return/returning to &lt;span style=&#34;font-style:italic&#34;&gt;x&lt;/span&gt;&lt;/li&gt;
        &lt;li&gt;to resume&lt;/li&gt;
        &lt;li&gt;at any rate&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td class=&#34;tg-2bvl&#34;&gt;Summation&lt;/td&gt;
    &lt;td class=&#34;tg-mgyo&#34;&gt;Patel (2015) comes to a similar conclusion. &lt;span style=&#34;font-weight:bold&#34;&gt;In summary&lt;/span&gt;, the four studies considered here suggest a consensus that the solution is effective.&lt;/td&gt;
    &lt;td class=&#34;tg-mgyo&#34;&gt;
      &lt;ul&gt;
        &lt;li&gt;as previously stated/mentioned&lt;/li&gt;
        &lt;li&gt;in summary&lt;/li&gt;
        &lt;li&gt;as I have argued&lt;/li&gt;
        &lt;li&gt;overall&lt;/li&gt;
        &lt;li&gt;as has been mentioned&lt;/li&gt;
        &lt;li&gt;to summarize&lt;/li&gt;
        &lt;li&gt;briefly&lt;/li&gt;
        &lt;li&gt;given these points&lt;/li&gt;
        &lt;li&gt;in view of &lt;span style=&#34;font-style:italic&#34;&gt;x&lt;/span&gt;&lt;/li&gt;
        &lt;li&gt;as has been noted&lt;/li&gt;
        &lt;li&gt;in conclusion&lt;/li&gt;
        &lt;li&gt;in sum&lt;/li&gt;
        &lt;li&gt;altogether&lt;/li&gt;
        &lt;li&gt;in short&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;thanks--references&#34;&gt;Thanks &amp;amp; References&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.scribbr.com/academic-writing/transition-words/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Transition Words &amp;amp; Phrases&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>在服务器上部署 Overleaf</title>
      <link>https://bowenei.gitee.io/post/overleaf-server-deployment/</link>
      <pubDate>Fri, 15 Apr 2022 22:55:54 +0800</pubDate>
      <guid>https://bowenei.gitee.io/post/overleaf-server-deployment/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://cn.overleaf.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Overleaf&lt;/a&gt; 是开源的在线实时协作 $\LaTeX$ 编辑器。官方还提供了&lt;a href=&#34;https://github.com/overleaf/overleaf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;开源镜像&lt;/a&gt;，可以在服务器上部署。由于课题组需要多人在线协作撰写论文，特写此文记录 Overleaf 环境部署的说明。&lt;/p&gt;
&lt;h2 id=&#34;准备工作&#34;&gt;准备工作&lt;/h2&gt;
&lt;p&gt;官方镜像是基于 Docker 的，最好部署在 Ubuntu 系统上。因此，如果服务器上没有部署 Docker，需要先安装 Docker。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;curl -fsSL https://get.docker.com -o get-docker.sh
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;sudo sh get-docker.sh
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;安装-docker-compose&#34;&gt;安装 Docker Compose&lt;/h3&gt;
&lt;p&gt;不过，仅仅通过官方安装脚本安装的 Docker 还不够。还需要安装 Docker Compose：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;sudo curl -L &lt;span class=&#34;s2&#34;&gt;&amp;#34;https://github.com/docker/compose/releases/download/v2.2.2/docker-compose-&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;$(&lt;/span&gt;uname -s&lt;span class=&#34;k&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;$(&lt;/span&gt;uname -m&lt;span class=&#34;k&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt; -o /usr/local/bin/docker-compose
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;如果要安装其他版本的 Docker Compose，替换路径中的 &lt;code&gt;v2.2.2&lt;/code&gt;。（&lt;code&gt;v2.2.2&lt;/code&gt; 是目前的稳定版本）&lt;/p&gt;
&lt;p&gt;下面，将可执行权限应用于二进制文件 &lt;code&gt;docker-compose&lt;/code&gt;：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;sudo chmod +x /usr/local/bin/docker-compose
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;创建软链接：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;sudo ln -s /usr/local/bin/docker-compose /usr/bin/docker-compose
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;测试是否安装成功：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;docker-compose --version
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;拉取-overleaf-镜像&#34;&gt;拉取 Overleaf 镜像&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;docker pull sharelatex/sharelatex
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;我们可以新建一个空文件夹，在该文件夹下工作。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;mkdir overleaf
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;cd&lt;/span&gt; overleaf
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;官方镜像是通过 Docker Compose 启动的，因此需要一个 &lt;a href=&#34;docker-compose.yml&#34;&gt;&lt;code&gt;docker-compose.yml&lt;/code&gt;&lt;/a&gt; 配置文件。（单击文件名可以下载官方提供的 &lt;code&gt;yml&lt;/code&gt; 文件）&lt;/p&gt;
&lt;p&gt;接下来，使用下面的命令运行 Docker 容器：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;docker compose up -d
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;由于完整安装 $\LaTeX$ 环境需要安装很多包，全部打包到 Docker 镜像中的话太大，不利于网络传输。因此，Overleaf 官方仅仅在 Docker 镜像中部署了很少一部分 $\LaTeX$ 的功能。完整的 $\LaTeX$ 功能需要我们手动安装。&lt;/p&gt;
&lt;h2 id=&#34;安装完整的-latex-环境&#34;&gt;安装完整的 LaTeX 环境&lt;/h2&gt;
&lt;p&gt;在运行的容器内部，我们手动安装如下包：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;docker &lt;span class=&#34;nb&#34;&gt;exec&lt;/span&gt; sharelatex tlmgr install scheme-full
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;安装的过程很漫长，需要耐心等待。&lt;/p&gt;
&lt;div class=&#34;alert alert-warning&#34;&gt;
  &lt;div&gt;
    &lt;p&gt;我在安装过程中出现了报错如下：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;tlmgr: Local TeX Live (2021) is older than remote repository (2022).
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Cross release updates are only supported with
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  update-tlmgr-latest(.sh/.exe) --update
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;See https://tug.org/texlive/upgrade.html for details.
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;根据报错的信息，我判断是 &lt;code&gt;tlmgr&lt;/code&gt; 的版本过低需要更新。按照相应网站的提示，将一些必要命令转化为 Docker 容器可以运行的命令如下：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;docker &lt;span class=&#34;nb&#34;&gt;exec&lt;/span&gt; sharelatex wget https://mirror.ctan.org/systems/texlive/tlnet/update-tlmgr-latest.sh
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;docker &lt;span class=&#34;nb&#34;&gt;exec&lt;/span&gt; sharelatex sh update-tlmgr-latest.sh -- --upgrade
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;docker &lt;span class=&#34;nb&#34;&gt;exec&lt;/span&gt; sharelatex tlmgr update --self --all
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;然后再运行上面的安装命令，就可以成功。&lt;/p&gt;

  &lt;/div&gt;
&lt;/div&gt;

&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    &lt;p&gt;&lt;strong&gt;注意&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;docker exec&lt;/code&gt; 命令对 Docker 容器的更改是暂时的。如果用 Docker Compose 重新创建容器，之前所做的更改（安装完整的 $\LaTeX$）将会丢失。因此，可以使用 &lt;code&gt;docker commit&lt;/code&gt; 命令：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;docker commit sharelatex sharelatex/sharelatex:with-texlive-full
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;然后编辑 &lt;code&gt;docker-compose.yml&lt;/code&gt; 文件：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;vim docker-compose.yml
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;找到镜像设置，并且更改为：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yml&#34; data-lang=&#34;yml&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c&#34;&gt;# ...&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;services&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;sharelatex&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;image&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;sharelatex/sharelatex:with-texlive-full&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# ...&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;

&lt;h2 id=&#34;overleaf-配置&#34;&gt;Overleaf 配置&lt;/h2&gt;
&lt;p&gt;只要 Overleaf 容器运行起来，我们就可以访问 &lt;code&gt;/launchpad&lt;/code&gt; 页面来初始化管理员用户。我们可以使用下面的命令创建第一个管理员：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;docker &lt;span class=&#34;nb&#34;&gt;exec&lt;/span&gt; sharelatex /bin/bash -c &lt;span class=&#34;s2&#34;&gt;&amp;#34;cd /var/www/sharelatex; grunt user:create-admin --email=joe@example.com&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;我们将得到一个带有 &lt;code&gt;token&lt;/code&gt; 的网址，访问该网址就可以为管理员用户设置密码。&lt;/p&gt;
&lt;p&gt;进入 Overleaf 前端界面后，可以进行创建工程、添加用户等操作，基本具有和 Overleaf 官方相同的功能。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>八次危机：中国的真实经验</title>
      <link>https://bowenei.gitee.io/post/eight-crises-chinese-real-experience/</link>
      <pubDate>Sat, 12 Mar 2022 15:22:41 +0800</pubDate>
      <guid>https://bowenei.gitee.io/post/eight-crises-chinese-real-experience/</guid>
      <description>&lt;p&gt;温铁军教授及其团队这几十年来专注于三农问题的研究。他“用脚做学问”的精神，即政策研究必须基于与基层民众一起工作得来的实践经验，非常值得我们钦佩。&lt;/p&gt;
&lt;p&gt;温铁军教授的这本《八次危机》分析了新中国 1949 年成立以来到 2009 年这 60 年来经历的主要危机及其克服的办法，总结了中国改革和发展的路径，展示了中国如何成功实现软着陆，并利用危机进一步发展。&lt;/p&gt;
&lt;p&gt;本文为读书笔记，梳理了八次危机的产生背景、表现形式、作用机理、解决方案以及历史经验，不代表作者个人观点。&lt;/p&gt;
&lt;h2 id=&#34;发展陷阱和中国经验&#34;&gt;发展陷阱和中国经验&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;成本转嫁论&lt;/strong&gt;是温铁军教授的重要理论成果，即世界存在强势群体向弱势群体转嫁工业化现代化的代价的现象。&lt;/p&gt;
&lt;p&gt;西方特色的资本主义在不同历史阶段造成的危机代价，主要是向殖民地和发展中国家转嫁。这是导致发展中国家贫困的主要原因，是为发展陷阱。&lt;/p&gt;
&lt;p&gt;而中国之所以能够实现软着陆，得益于中国因城乡差别而客观上形成的城乡二元结构——来为弱化经济周期性波动而向农村转嫁危机成本。&lt;/p&gt;
&lt;h2 id=&#34;1958-1976工业化初期的三次危机及其外资外债背景&#34;&gt;1958-1976：工业化初期的三次危机及其外资外债背景&lt;/h2&gt;
&lt;p&gt;温铁军教授认为，客观地看，这三次危机都是直接向高度组织化的人民公社和国营、集体农场大规模转移城市过剩劳动力。&lt;/p&gt;
&lt;h3 id=&#34;第一次危机1958-1960-年苏联援华投资中断&#34;&gt;第一次危机：1958-1960 年苏联援华投资中断&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;产生背景&lt;/strong&gt;：1950 年新中国引进苏联外资，进而启动国内工业化进程中发生的第一次周期性危机。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;直接原因&lt;/strong&gt;：因中国坚持领土完整和主权独立，苏联以“五年计划”方式提供的援华投资于 1957 年突然中断。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;表现形式&lt;/strong&gt;：经由苏联专家协助制定的国家第二个“五年计划”胎死腹中。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;作用机理&lt;/strong&gt;：政府增发货币，大规模下放了财权、计划管理权和企业管理权，然而财政赤字显著增加，在 1960 年爆发了赤字危机。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;解决方案&lt;/strong&gt;：允许乡土中国的小农村社制的传统经济，从服务于国家产业化资本的高度集体化经济中部分地“退出”——改“一大二公”的人民公社全面统治经济为“队为基础”的村落经济和允许农民在生产队（自然村）内搞“三自一包”。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;历史经验&lt;/strong&gt;：以工农大众能够接受的通俗化“阶级斗争”和工具化的“继续革命”理论为意识形态和国民动员手段，发动了几乎全体官员、知识分子和广大民众参与到国家工业化原始积累进程中来。主要用劳动力的集中投入成功地替代了长期绝对稀缺的资金要素——大规模投入于政府作为所有者的国家工业化所必需的大型基本建设之中，再反过来形成对国有大型设备制造业的国家需求。&lt;/p&gt;
&lt;h3 id=&#34;第二次危机1968-1970-年三线建设中的国家战略调整与经济危机&#34;&gt;第二次危机：1968-1970 年“三线建设”中的国家战略调整与经济危机&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;产生背景&lt;/strong&gt;：当时，一方面是中国处于外部全面封锁和周边地缘环境高度紧张的压力下；另一方面，中国 20 世纪 50 年代建设的符合苏联重工业管理模式的政府部门体制，一直就难以自觉地与主要依靠劳动群众“自力更生，艰苦奋斗”的经济方针一致起来。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;直接原因&lt;/strong&gt;：外部地缘政治和内部官僚化上层建筑都在中国接受苏联投资形成的以国家工业化为主体的经济基础必须作出调整的特殊阶段，其产生原因是这一复杂矛盾演化的结果。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;表现形式&lt;/strong&gt;：偿还了巨额的对外债务之后，造成城市经济第二次遭遇“赤字+失业”形态的危机。“三五”计划在不同指导思想的争论中“夭折”。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;作用机理&lt;/strong&gt;：在当时的国内外环境下，最终形成了以毛泽东的意见为主的决策主张，以巩固国防为目的，宁可遭受损失也得把沿海容易遭受军事打击的基础工业转移到内地，形成国家工业“大三线”、地方工业“小三线”的战备经济模式。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;解决方案&lt;/strong&gt;：千万知青下乡，城市危机向农村转移。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;历史经验&lt;/strong&gt;：这种“三线建设”客观上只能是国家产业资本的空间移动，并没有“纵向”地调整原来的工业结构。因此，不仅 20 世纪 60 年代中国的国家工业发展投入的成本在基础建设上是显著增加的，而且国家在工业化空间布局调整上付出的这些巨大的代价，都会造成更高的财政赤字，政府累积赤字爆发危机，其代价还是得向农村转嫁。&lt;/p&gt;
&lt;h3 id=&#34;第三次危机1974-1976-年最后一次上山下乡&#34;&gt;第三次危机：1974-1976 年最后一次“上山下乡”&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;产生背景&lt;/strong&gt;：1972 年周恩来总理亲自主持制定的“四三方案”引进欧美日等发达国家的设备和资金，把过分偏于军重工业的经济结构转向偏重民生经济。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;直接原因&lt;/strong&gt;：引进西方更为昂贵的项目和服务来调整国内工业结构。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;表现形式&lt;/strong&gt;：财政赤字连续突破 100 亿元，而当时的财政总规模才 800 亿元左右，导致国家进行扩大再生产的投资能力再次严重不足。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;作用机理&lt;/strong&gt;：引进西方成套设备价格昂贵，引发严重的财政赤字。除了必须支付昂贵的“服务”成本之外，还得在上层建筑领域让官员们倍感痛心地洗心革面，以转变过去照搬苏联政府体制（乃至整个相关制度体系）的思路，否则就不可能自觉地适应显著照搬西方生产线的情况及其内生性的制度需求。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;解决方案&lt;/strong&gt;：不得不再次以晚年毛泽东的威望动员数百万城市过剩劳动力到农村，由农村集体所有制条件下的“大锅饭”来承担他们的基本生存保障。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;历史经验&lt;/strong&gt;：毛泽东时代国家利用农村土地产权残缺而得以强势介入促成的农村“集体经济”，虽然不是当时生产力水平之下的农业发展的客观要求，也未必能够维护农民利益，但却客观上在国家工业化原始积累时期起到了意想不到的作用。&lt;/p&gt;
&lt;h2 id=&#34;1978-1997改革以来三次内源性经济危机及其化解&#34;&gt;1978-1997：改革以来三次内源性经济危机及其化解&lt;/h2&gt;
&lt;p&gt;温铁军教授认为，在中国“工业化中期阶段”的大背景下，这三次经济危机都是以国内因素为主的周期性经济危机。&lt;/p&gt;
&lt;h3 id=&#34;第四次危机1979-1980-年改革以来的第一次经济危机及借助三农的复苏&#34;&gt;第四次危机：1979-1980 年改革以来的第一次经济危机及借助“三农”的复苏&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;产生背景&lt;/strong&gt;：毛泽东 1976 年去世以后，当时客观上处于过渡期的政府因历史原因而不可能再直接向“三农”转嫁代价。因而，危机“硬着陆”在城市里，并引发了全国范围的以“大包干”为名、“政府退出不经济的农业”为实的农村改革。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;直接原因&lt;/strong&gt;：在 1978-1989 年投资高潮之后，政府采取严厉的紧缩措施。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;表现形式&lt;/strong&gt;：20 世纪 70 年代末形成的巨大财政赤字。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;作用机理&lt;/strong&gt;：在财政收入有限的条件下，当时的政府一方面要通过加大投资来强化工业化建设，另一方面又强调要提高人民生活水平。而这两条战线的同时大手笔出击，恰恰又是互相矛盾的——一个社会在没有外部资源输入的情况下，根本不可能既是高积累，又是高消费的。任何体制下依靠财政赤字透支政府信用，最终都会造成严重地入不敷出。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;解决方案&lt;/strong&gt;：“硬着陆”在城市里——全面推行农村基本经营制度改革，实现以农村工业化和城镇化为主要形式的“农村资源自我资本化”，通过“两个严打”稳定社会治安。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;历史经验&lt;/strong&gt;：加大投入力度，促进“三农”自主发展，是能够为中国特色的化解经济危机之路奠定必要基础的。虽然科学发展观 2003 年才提出，但是早在 20 世纪 80 年代就曾经在农村发展领域有过足以支撑其理论的客观经验。&lt;/p&gt;
&lt;h3 id=&#34;第五次危机1988-1990-年改革以来的第二次经济危机及三农应对&#34;&gt;第五次危机：1988-1990 年改革以来的第二次经济危机及“三农”应对&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;产生背景&lt;/strong&gt;：产业资本扩张带动投资大幅度增加，政府大规模增发货币。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;直接原因&lt;/strong&gt;：1988 年当时领导人采纳了“物价闯关”的改革建议，引发官倒公司带动的全社会大抢购。年末政府为整治高通货膨胀而开始的紧缩性调控中，随着存款、贷款利率的相继提高，国民经济出现了被称为“三角债”的严重债务链问题。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;表现形式&lt;/strong&gt;：1988 年发生了以年度 CPI 高达 18.6%（“物价改革”提出之后月度最高上涨率为 26.7%）为标志的恶心通货膨胀。接着，1989 年发生的是以企业“连锁负债”为表象的生产停滞。此二者结合，视为典型的滞涨危机。随后的 1990 年则属于典型的萧条阶段。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;作用机理&lt;/strong&gt;：其一，“短缺经济”条件下因乡村工业化和经济快速增长带来的消费和投资需求两旺，进而促使货币发行量增多，势必引发严重的通货膨胀；其二，这又跟当时政府所激进推行的相关改革措施使大量隐含制度成本被引爆密切相关。而其中的价格双轨制改革和 1988 年所采取的一系列市场化改革措施，导致了部门与官倒公司结合产生了设租和寻租成本以及在暂时的商品短缺条件下获取投机暴利的市场化成本，进而产生了严重的三角债问题。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;解决方案&lt;/strong&gt;：经济危机与成本向“三农”转嫁。此次转嫁的对象是乡镇企业，具体则表现为以“沿海经济发展战略”为名，要求企业“两头在外”，让出国内的原材料和产品市场；另一方面是减少对地方政府和党政组织、教育和医疗等公共品的维持费用和乡村公共投入。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;历史经验&lt;/strong&gt;：由于内需不足，国民经济由内需拉动增长转向对外向型经济的依赖。将来中国沿海要以乡镇企业主要形式，依靠低工资的廉价劳动力，生产劳动密集型产品出口，占领国际市场。&lt;/p&gt;
&lt;h3 id=&#34;第六次危机1993-1994-年改革以来第三次经济危机及其外向型转化&#34;&gt;第六次危机：1993-1994 年改革以来第三次经济危机及其外向型转化&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;产生背景&lt;/strong&gt;：刚刚经历上一次经济危机，而且外部环境也很不利——彼时苏联刚刚解体，在西方封锁压力下，国际舆论盛行“中国崩溃论”。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;直接原因&lt;/strong&gt;：1992-1993 年中央政府加快货币化和放开资本市场进程，不得不同时全部承担经济过热造成的过高对外债务。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;表现形式&lt;/strong&gt;：财政、金融和外汇三大赤字同步爆发，大规模货币增发，CPI 上涨幅度达 24.1%。国企职工大规模下岗、农民土地大规模被征占、社会群体性事件大幅度增加。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;作用机理&lt;/strong&gt;：由于开放股票、期货和房地产这三个投机性较强的市场的投资，各种利益集团纷纷借“高度政治正确”的改革目标之名，行投资谋私、积累资本之实。于是，全国性固定资产投资规模扩张过猛，金融领域持续混乱，金融寻租现象普遍。与此同时，由于外债激增，贸易逆差严重，当时的外汇赤字已经严重影响了中国的外汇储备和支付体系的正常运转。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;解决方案&lt;/strong&gt;：1993 年的“铁血十六条”。1994 年的三个重大宏观措施——外汇改革（人民币贬值 57%）、信用扩张（国债和货币同步大规模增发）、分税制改革（税收中央和地方各占一半）。除此之外，还包括以卖为主的国有企业改革，使数千万国企职工“买断工龄，裸体下岗”。&lt;/p&gt;
&lt;p&gt;这场经济危机使得城市和农村共同分担危机的成本，具体而言如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;城市工人大规模下岗。“资本”理论意义上的地位在中国得以确立，资本相对于劳动取得了绝对强势的地位。&lt;/li&gt;
&lt;li&gt;社会公共服务部门市场化和私有化，尤其是医疗和教育这两个领域，具有信息绝对不对称，且具有可以被个体垄断获取暴利的特征。&lt;/li&gt;
&lt;li&gt;地方基层政府将增加的治理成本转嫁农村，“财力上收，支出下移”。&lt;/li&gt;
&lt;li&gt;金融资本异化实体产业，恶化林业及环境灾难。&lt;/li&gt;
&lt;li&gt;土地资源资本化，地方政府公司化。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;历史经验&lt;/strong&gt;：这次危机是建国以来历次危机中的内发型经济危机和输入型危机的过渡期，也是分水岭——既是一个因中国产业资本逐步走向过剩而导致金融资本大规模扩张、越来越异化于产业资本的时期，也是中国开始走向外向型经济、从而受国际经济周期的影响越来越大的时期。&lt;/p&gt;
&lt;div class=&#34;alert alert-warning&#34;&gt;
  &lt;div&gt;
    &lt;p&gt;&lt;strong&gt;信息不对称&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;“信息不对称”是指交易中每个人拥有的信息不同。在社会政治、经济等活动中，一些成员拥有其他成员无法拥有的信息。&lt;/p&gt;
&lt;p&gt;温铁军教授在书中，并且也曾在多个公开场合中指出，医疗和教育这两个领域具有信息绝对不对称。我们试想：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;我们得什么病我们自己就可以知道吗？如果可以，那么我们还需要去医院吗？&lt;/li&gt;
&lt;li&gt;我们想学的知识我们都懂吗？如果懂，那么我们还需要交学费吗？&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;因此，医院（医生）单方面垄断你的生命信息（，也就直接决定了你的生死）；学校（教师）单方面垄断你的教育信息（，也从一定程度上间接地决定了你的未来）。于是，凭借垄断地位收费那就是严重的问题了。&lt;/p&gt;

  &lt;/div&gt;
&lt;/div&gt;

&lt;h2 id=&#34;1997-和-2008-年中国两次输入型危机的发生应对和影响&#34;&gt;1997 和 2008 年中国两次“输入型”危机的发生、应对和影响&lt;/h2&gt;
&lt;p&gt;温铁军教授认为，这两次经济危机与此前的六次危机不同，应该属于全球化条件下“第四次外资”带来的“输入型”危机。而且与以往内生性危机爆发之后政府都采取紧缩方针完全相反，这两次输入型危机，政府都是以大规模推行扩张性财政政策来扩大投资、拉动内需。&lt;/p&gt;
&lt;h3 id=&#34;第七次危机1997-年东南亚金融危机的应对措施及影响&#34;&gt;第七次危机：1997 年东南亚金融危机的应对措施及影响&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;产生背景&lt;/strong&gt;：中共十五大刚刚确立了“资本”的地位，迎头就遭遇了东南亚金融风暴。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;直接原因&lt;/strong&gt;：中国对国际市场的出口大幅下滑，导致了国内萧条和通货紧缩。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;表现形式&lt;/strong&gt;：1998 年出口增长率陡降到 0.5%，外需迅速收缩。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;作用机理&lt;/strong&gt;：国内固定资产投资增速放缓，短缺经济逐步消逝。买方市场特点逐步显现，供给高于需求。东南亚金融危机导致对外出口下滑，国内需求总量增速下降，导致通货紧缩。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;解决方案&lt;/strong&gt;：国有金融市场化改革，财政金融分家，银行商业化改制；开始以中央政府为主的基础设施建设；政府直接进入经济，通过追加国债拉动实体经济和同期大规模增发货币促进经济增长。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;历史经验&lt;/strong&gt;：“政府进入”成为中国应对输入型危机的基本经验。这种政府直接介入经济、通过追加国债投资拉动实体经济和同期大规模增发货币促进经济的做法，可以被认为是政府重新“进入”。国债项目主要交由国企执行，客观上造成了“国进民退”，造成以更多投资制造更大生产过剩的“粗放增长”惯性。&lt;/p&gt;
&lt;h3 id=&#34;第八次危机2008-年金融危机的应对措施及影响&#34;&gt;第八次危机：2008 年金融危机的应对措施及影响&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;产生背景&lt;/strong&gt;：中国加入 WTO 以后，宏观经济空前高涨，GDP 在 2003 年到 2007 年的五年间连续保持了两位数的高增长率。然而，这却导致了中国宏观经济“双重过剩”——劳动力过剩和一般制造业产能过剩。再加上金融资本过剩，当时的中国应该是“三大过剩”。2008 年夏季，在上年发生的次级抵押贷款市场危机加剧的形势下，美国第四大投行雷曼兄弟宣布申请破产保护，两家最大的住房抵押贷款机构（房地美和房利美）及一家最大的保险集团（AIG）被“临时国有化”。华尔街金融海啸造成了全球经济危机。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;直接原因&lt;/strong&gt;：美国次贷危机引发的华尔街金融海啸对中国本就严重失衡的经济结构产生了影响，一方面使长期依赖国外市场的出口经济遭受重挫；另一方面，因国际资本在次贷危机发生后纷纷涌入商品期货市场而推动了初级产品的价格上涨，使中国产生了输入型通胀。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;表现形式&lt;/strong&gt;：出口对中国 GDP 的拉动从 2007 年的 2.6% 下降到 2008 年的 0.8%，生产者价格指数（PPI）由 2007 年的 5.4% 上升到 2008 年 4 月时的 8.1%，而 2008 年国内 CPI 月度最高也达到 8.7%。2008 年中国 GDP 的增长率下降到 9%。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;作用机理&lt;/strong&gt;：中国承接了大量以美国为首的西方发达国家由工业化向信息化转变过程中的产业，三大过剩（一般产能、劳动力和金融资本）和三驾马车（出口、投资和消费）失衡加剧，贫富差距扩大，国内需求薄弱。国民经济运行对外依赖度过高，外需下降后，大批企业破产，打工者失业。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;解决方案&lt;/strong&gt;：积极利用财政投资带动内需增长。对民生领域和重大基础设施大幅投资，开始新农村建设，资源回流农村；在稳定汇率的条件下，提高出口退税率以刺激出口。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;历史经验&lt;/strong&gt;：输入型危机不可能靠中国政府的国内应对政策化解，中国需要取得国际规则的制定权，否则仅依靠国内政策代价巨大。&lt;/p&gt;
&lt;h2 id=&#34;温铁军教授重要论断摘录&#34;&gt;温铁军教授重要论断摘录&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;下面的内容根据本书第二部分《关于全球危机与中国对策研究的简报和会议记录选辑》整理。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;西方资本主义文明已经实现了的现代化目标及其派生的现代化体制本身，具有内生性的不可自我化解的内在矛盾，只有大量向发展中国家和弱势群体转嫁危机代价才能维持资本主导的国家的生存。&lt;/li&gt;
&lt;li&gt;过去帝国主义国家内部的资本家阶级与劳工阶级的对立矛盾和社会冲突，随着西方产业大规模对外转移，现在已经转化为发达国家与发展中国家之间的对立矛盾。&lt;/li&gt;
&lt;li&gt;处于打工者地位的发展中国家话语权愈益弱化，主要有两个自身的原因：一是劳工群体的整体失语，二是西方主流话语培养的知识分子不自觉地被西方意识形态所控制。&lt;/li&gt;
&lt;li&gt;中产阶级要求的根本就不是过去劳动者满足扩大再生产的社会福利需要，而更多的是西方消费主义和休闲享乐。由此，西方高福利社会的发展结果，是没有经济基础支撑的整个政治体制维持成本越来越高。&lt;/li&gt;
&lt;li&gt;由于国家干部和事业单位人员这两个阶层集中在没有被改革的领域，因而占有社会资源丰富，就成了中产阶级崛起造成中国社会内部阶层分化的主要特点。&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>Cloud Computing Architecture</title>
      <link>https://bowenei.gitee.io/post/cloud-computing-architecture/</link>
      <pubDate>Mon, 07 Mar 2022 16:31:12 +0800</pubDate>
      <guid>https://bowenei.gitee.io/post/cloud-computing-architecture/</guid>
      <description>&lt;p&gt;云计算是一种计算模式，其概念最早于 2006 年由 Google 公司提出，具体核心思想是将大量用网络连接的资源进行统一管理，构成一个共享资源池（包含计算设施、存储设备、应用程序等），并以按需支付、弹性扩展的方式向用户提供服务。&lt;/p&gt;
&lt;p&gt;本文旨在生动形象地介绍云计算的体系结构，方便大家理解其中的一些抽象概念。&lt;/p&gt;
&lt;h2 id=&#34;概述&#34;&gt;概述&lt;/h2&gt;
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34;
           src=&#34;https://bowenei.gitee.io/post/cloud-computing-architecture/architecture.svg&#34;
           loading=&#34;lazy&#34; data-zoomable class=&#34; img-dark&#34; /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;p&gt;云计算体系结构由 IaaS、PaaS 和 SaaS 三大核心服务以及服务管理构成，并且提供用户访问接口。&lt;/p&gt;
&lt;p&gt;IaaS（Infrastructure as a Service）提供硬件基础设施部署服务，为用户按需提供实体或虚拟的计算、存储和网络等资源。&lt;/p&gt;
&lt;p&gt;PaaS（Platform as a Service）是一种分布式平台服务，为用户提供一个包括应用设计、应用开发、应用测试及应用托管的完整的计算机平台。&lt;/p&gt;
&lt;p&gt;SaaS（Software as a Service）是基于云计算基础平台所开发的应用程序，以软件的形式提供服务。&lt;/p&gt;
&lt;p&gt;服务管理层对核心服务层的可用性、可靠性和安全性提供保障。如服务质量保证、安全管理、计费管理等。&lt;/p&gt;
&lt;p&gt;用户访问接口实现了云计算服务的泛在访问，通常包括命令行、Web 服务、Web 门户等形式。&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;不过，直接来看这些概念太过于抽象了。下面我们用一个形象的例子，并结合一些我们身边的具体例子来解释这些概念。&lt;/p&gt;
&lt;h2 id=&#34;一个形象的例子烹饪&#34;&gt;一个形象的例子：烹饪&lt;/h2&gt;
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34;
           src=&#34;https://bowenei.gitee.io/post/cloud-computing-architecture/cooking.svg&#34;
           loading=&#34;lazy&#34; data-zoomable class=&#34; img-dark&#34; /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;p&gt;假设我们现在想要做饭，可是却一无所有，该怎么办呢？我们可以摆路边摊，就当小推车是厨房，并且装着煤气罐。这样我们就有了做饭的基本条件了。但是所有的这些基本条件和资源都需要我们自己来管理，特别麻烦，而且还不稳定。&lt;/p&gt;
&lt;p&gt;有了 IaaS 以后，我们就很像是在经营一家餐馆，需要考虑安装几个灶台、用几口锅才能满足经营需要，而并不需要太关心厨房和煤气还能不能使用的问题——只需要租用或购买一家门店，并且缴纳煤气费就可以使用了。&lt;/p&gt;
&lt;p&gt;而有了 PaaS 以后，炒锅、灶台也是现成的——家庭烹饪并不需要饭店那样对烹饪工具特别大的需求，只需要考虑今天吃什么、怎么做就可以了。&lt;/p&gt;
&lt;p&gt;那么有了 SaaS 以后，我们就彻底解放了——我们只需要考虑我们今天想吃什么，完全不需要考虑菜是怎么做出来的。&lt;/p&gt;
&lt;h2 id=&#34;云计算服务模式的层次划分&#34;&gt;云计算服务模式的层次划分&lt;/h2&gt;
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /post/cloud-computing-architecture/layer-partition_hu0515c347778e5eaad6f56836bc16fc32_87721_338441f157d42b0d3f5359b6ccf3d2b7.webp 400w,
               /post/cloud-computing-architecture/layer-partition_hu0515c347778e5eaad6f56836bc16fc32_87721_07ffe225ca4caa73375b72fc5c206b29.webp 760w,
               /post/cloud-computing-architecture/layer-partition_hu0515c347778e5eaad6f56836bc16fc32_87721_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://bowenei.gitee.io/post/cloud-computing-architecture/layer-partition_hu0515c347778e5eaad6f56836bc16fc32_87721_338441f157d42b0d3f5359b6ccf3d2b7.webp&#34;
               width=&#34;760&#34;
               height=&#34;357&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;p&gt;云计算服务模式主要分为网络、存储、服务器、虚拟化、操作系统、中间件、运行环境、数据和应用九层。&lt;/p&gt;
&lt;p&gt;如果我们在纯裸机上部署云计算服务，就需要考虑到上述九层。我们需要购买部署服务所需的服务器设备，并且从零开始搭建，这特别像我们一无所有摆路边摊的感觉。&lt;/p&gt;
&lt;p&gt;有了 IaaS 以后，诸如 Vmware 的虚拟化服务帮助我们管理底层的网络、存储、服务器等资源，使得我们不再关注底层逻辑，而专注于操作系统之上的环境部署问题。于是，我们只需要找提供商租用我们需要的服务器即可，利用 IaaS 来管理这些服务器资源。&lt;/p&gt;
&lt;p&gt;而有了 PaaS 以后，诸如 Docker 的容器技术帮助我们管理操作系统和运行环境，使得我们不再关注应用程序的运行环境，而专注于应用程序本身的开发与部署。于是，我们只需要下载相应的 Docker 镜像，并且根据需要创建相应的容器，即可进入应用程序的开发环境。&lt;/p&gt;
&lt;p&gt;那么有了 SaaS 以后，软件的开发、管理、部署完全交给第三方，我们几乎什么都不需要关心了，专注于使用应用程序带给我们的服务。于是，我们只需要通过客户端连接到应用程序的服务端，通过一些命令和请求获取我们想要的服务。&lt;/p&gt;
&lt;h2 id=&#34;iaas&#34;&gt;IaaS&lt;/h2&gt;
&lt;p&gt;IaaS 其实是云计算服务的最底层，主要提供一些基础资源。&lt;/p&gt;
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://www.openstack.org/themes/openstack/home_images/Diagram/overview-diagram-new.svg&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;p&gt;OpenStack 就是目前公认的云计算 IaaS 平台，其管理的核心目标对象是机器（虚拟机或物理机），当然也可以管理存储和网络，但那些也大都是围绕着机器所提供的配套资源。近年来容器技术火了之后，OpenStack 也开始通过各种方式增加对容器的支持，但目前 OpenStack 还不被视为管理容器的主流平台。&lt;/p&gt;
&lt;h2 id=&#34;paas&#34;&gt;PaaS&lt;/h2&gt;
&lt;p&gt;PaaS 提供软件部署平台（runtime），抽象掉了硬件和操作系统细节，可以无缝地扩展（scaling）。开发者只需要关注自己的业务逻辑，不需要关注底层。&lt;/p&gt;
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://docs.docker.com/engine/images/architecture.svg&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;p&gt;Docker 是一个开源的应用容器引擎，让开发者可以打包他们的应用以及依赖包到一个可移植的容器中，然后发布到任何流行的 Linux 机器上，也可以实现虚拟化。容器是完全使用沙箱机制，相互之间不会有任何接口（类似 iOS 的 app）。Docker 几乎没有性能开销，可以很容易地在机器和数据中心中运行。最重要的是，它不依赖于任何语言、框架包括系统。&lt;/p&gt;
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://www.upgrad.com/blog/wp-content/uploads/2020/10/Kubernetes-architecture-1536x1046.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;p&gt;Kubernetes（简称 k8s）是 Google 开源的容器集群管理系统。它构建于 Docker 技术之上，为容器化的应用提供资源调度、部署运行、服务发现、扩容缩容等整一套功能。k8s 本质上可看作是基于容器技术的 Micro-PaaS 平台，即第三代 PaaS 的代表性项目。&lt;/p&gt;
&lt;p&gt;再比如，本文依赖的博客框架 hugo 也属于 PaaS。我并不需要关注代码托管平台安装的操作系统和运行环境，我只需要将我的博客框架 hugo 推送上去，然后在远程运行环境下编译即可部署。&lt;/p&gt;
&lt;h2 id=&#34;saas&#34;&gt;SaaS&lt;/h2&gt;
&lt;p&gt;SaaS 就是软件的开发、管理、部署都交给第三方，不需要关心技术问题，可以拿来即用。普通用户接触到的互联网服务，几乎都是 SaaS。&lt;/p&gt;
&lt;p&gt;以百度网盘为例，我们将文件存储在百度网盘的服务器中。我们并不需要关心百度网盘是如何存储我们的文件的，而且我们使用的百度网盘客户端也不需要实现存储文件的逻辑，只需要将文件和请求发送给百度网盘服务器即可。&lt;/p&gt;
&lt;p&gt;再比如 Gmail，我们通过 Gmail 客户端收发电子邮件。我们并不需要关心邮件服务器是如何收发我们的邮件的，而且我们使用的 Gmail 客户端或者浏览器网页也不需要实现收发邮件的功能，只需要将请求发送给 Gmail 服务器即可。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>郑强与杨澜对话中国教育</title>
      <link>https://bowenei.gitee.io/post/zheng-qiang-and-yang-lan-talk-about-chinese-education/</link>
      <pubDate>Sat, 19 Feb 2022 14:35:49 +0800</pubDate>
      <guid>https://bowenei.gitee.io/post/zheng-qiang-and-yang-lan-talk-about-chinese-education/</guid>
      <description>&lt;p&gt;郑强教授做客杨澜主持的系列节目《毛铺和文化录》第二季，从“双减”政策的话题开始谈到中国教育的问题，给出了十分犀利的观点，非常值得我们思考。&lt;/p&gt;
&lt;p&gt;本文根据节目内容筛选和整理出郑强教授的部分观点和看法，以郑强和杨澜两人的对话的形式呈现。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.tyut.edu.cn/info/1036/5023.htm&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;郑强&lt;/a&gt;教授从事材料学及高等教育管理相关研究，先后任浙江大学副教务长、求是学院院长、校党委副书记，贵州大学校长，太原理工大学党委书记。&lt;/p&gt;
&lt;p&gt;郑强教授先后在全国 20 多个省市进行了 200 多场讲演，因其“敢说话”、犀利、幽默的风格被评为“网红教授”、“2015 年最受学生喜爱大学校长”，被誉为中国教育“郑”能量。&lt;/p&gt;
&lt;p&gt;节目的相关视频如下：&lt;/p&gt;
&lt;iframe src=&#34;//player.bilibili.com/player.html?aid=550619888&amp;bvid=BV1Tq4y1A7uV&amp;cid=479564882&amp;page=1&#34; scrolling=&#34;no&#34; border=&#34;0&#34; frameborder=&#34;no&#34; framespacing=&#34;0&#34; allowfullscreen=&#34;true&#34; width=&#34;100%&#34; height=&#34;480&#34;&gt; &lt;/iframe&gt;
&lt;h2 id=&#34;session-1&#34;&gt;Session 1&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;杨澜&lt;/strong&gt;：咱们先来谈谈最火热的话题——双减。从一个大学的教育者和大学的管理者的角度，你怎么看待双减这个话题？&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;郑强&lt;/strong&gt;：从教育的阶段来讲，我作为大学教授应该讲跟所谓的双减有一点距离，但是我觉得这些年我恰恰在谈这样的问题。&lt;strong&gt;中国的孩子不是输在起跑线上，中国的孩子实际上是累倒在起跑线上的&lt;/strong&gt;。中国全民的注意力、社会的注意力都是从幼儿园开始的，小学、中学。实际上当我们走入大学以后，中国的孩子对科学的渴望已经比较惨淡了。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;杨澜&lt;/strong&gt;：已经被累坏了，过去积压的压力一下子释放出来，他实在是没有那种学习的热情了，是吧？&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;郑强&lt;/strong&gt;：对。以前把他榨干了，那是强迫的。所以到了大学他出了什么问题呢？要知道大学的职责跟中学是完全不一样的，大学是自主学习。所以他们完了，他们现在没人看了、没人管了。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;杨澜&lt;/strong&gt;：突然就是失去了依靠。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;郑强&lt;/strong&gt;：全部的放纵。放纵自己的情绪，放纵自己的精神，放纵自己的目标。以前有目标是为了考大学，可是进了大学没目标了。最直接的体现就是学业，跟不上了。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;杨澜&lt;/strong&gt;：我的确是知道很多学生上了大学以后就放羊了。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;郑强&lt;/strong&gt;：所以昨天我在一个著名的大学跟研究生做了一个报告。我说，实际上研究生阶段也是改变人生的一个最重要的阶段。&lt;/p&gt;
&lt;h2 id=&#34;session-2&#34;&gt;Session 2&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;郑强&lt;/strong&gt;：不指望本科一定要读最拔尖的学校，人生真不是起跑决定的。不太懂教育的人很看重初速度，起跑就是初速度。我们觉得我们比较懂教育的，我们看重的是途中的加速度，我是要教他在途中持续地跑。&lt;strong&gt;跑得远、跑得久，比起跑、抢跑重要很多&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;杨澜&lt;/strong&gt;：对。最近其实有一个调查的数据，就是中国的中小学生当中，（这个数字很让我惊讶，）就是有高达 24% 左右的孩子是有某种程度的情绪和心理的问题的。那么，抑郁症也正在称为学校标准体检的一个规定项目。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;郑强&lt;/strong&gt;：对，我们现在要测试是为什么呢？读书已经不是快乐了。我经常讲一个大学校长看学生，你去看他的一年级。今后你到大学去采访了，我希望你采访一下一年级，再到四年级去看看，一下子就能看得出来这个学校怎么样。如果四年级的人读书读了四年眼睛也目呆了，这个学校教育基本失败了。它把人性最可爱的朝气，尤其是学生对未来的向往教没了，读了这么多课本把人性读没有了。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;杨澜&lt;/strong&gt;：眼睛里没有光了。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;郑强&lt;/strong&gt;：没有光了，然后对任何人都显示出冷漠。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;杨澜&lt;/strong&gt;：你很痛心吧？&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;郑强&lt;/strong&gt;：非常痛心的一件事，痛心，痛心，确实痛心！我在浙大管学生就是几十年，我在贵州又当过校长，我现在又到一个大学主政。说实话，最刺激我的是什么？是孩子失去生命的那一刻。当看到那个状况的时候，我在心里也掉泪、流血，因为我们也有孩子。你们去追求那些学区房、著名幼儿园、高档的小学，重点中学考上好不容易，一辈子把爹妈所有的热情和家当赔尽，后面失去的是生命，没有任何幸福让一家人能在一起生活更幸福的。所以我真的要说一句：要改了。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;杨澜&lt;/strong&gt;：我们知道双减的目的一个是给学生减负，同时也减少家长的焦虑，增进教育的公平。那也有人分析说，如果中考、高考的这个指挥棒没有变，也就是说需求还在那里，那么仅仅是管住了供给方，并不能直接解决大家的这个焦虑问题。您是怎么看待的？&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;郑强&lt;/strong&gt;：实际上我们中国的家长把孩子送到培训班并不知道孩子学了多少、学得怎么样，他是觉得心里踏实。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;杨澜&lt;/strong&gt;：对。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;郑强&lt;/strong&gt;：几十年前，妈妈都在下面打毛线衣，现在是在下面玩微信。她觉得只要孩子进去了，她心里也踏实。实际上孩子学了多少、多少有用，她也未必就知道。现在没有了以后她恐惧。所以现在我既理解，但是我也要说一句话：这就是全民的幸福观、生活观的一种固有的错误的观念。&lt;strong&gt;真正好的教育不是让人具有头衔，不是让人觉得有财富的富有才是幸福的人生&lt;/strong&gt;。当让一个国家所有的人都想出人头地的时候，你还能指望百姓的心态正常吗？&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;杨澜&lt;/strong&gt;：可能您说的这个出人头地，它不仅仅是让孩子优秀，而且这个优秀的标准非常的狭窄。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;郑强&lt;/strong&gt;：对。它用读书读到好学校，上了重点中学，上了所谓的重点大学，来评价一个孩子和整个民众的幸福的时候，这就已经出了问题。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;杨澜&lt;/strong&gt;：其实您点出了这种教育焦虑背后最根本的原因，实际上是社会的评价体系的一种僵化和狭窄。所以，给所有人的评判标准带来的一种压力被传导到了孩子身上，而且常常是以孩子牺牲了他们的学习热情、动力，甚至失去了对生活的兴趣为代价的。&lt;/p&gt;
&lt;h2 id=&#34;session-3&#34;&gt;Session 3&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;郑强&lt;/strong&gt;：野性铸就了我们这一代。我儿子调皮，天天告状就把我弄去谈话，写检讨。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;杨澜&lt;/strong&gt;：家长要写检讨？&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;郑强&lt;/strong&gt;：那更严厉了。你不知道写检讨的味道。到了后面，对不起，就同一个版本，重新写个日期。还有一个就是成绩的问题，我的儿子一直成绩也不好。我就相信男孩的开窍，因为他发育得晚、懂事得晚。是这样，我现在教大家，生孩子的要 hold 住，不管老师怎么批评孩子调皮，不要去批评调皮，只批评行为是不是违了规。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;杨澜&lt;/strong&gt;：在这个方面我读过一本书，叫做《园丁和木匠》。它说作为一个教育者，我们可能有两种不同的思维方式，一种叫园丁，一种叫木匠。园丁就是看到孩子他的自身优势、兴趣爱好和成长环境，努力为他营造一个有利于成长的氛围，比如说给他带来阳光、雨露、松土、施肥等等，让他长成他自己应有的模样。那木匠就是不管孩子是什么样的，到了我手里就是一块木头，我都做成规格统一的桌子、椅子。当我孩子还小的时候，我唯一送他们去的课外班就是艺术班和体育班，因为我觉得在这两个方面学校的教育都不够。比如说体育课的时间不够长，比如说艺术教育常常被主课的学习边缘化。所以，作为妈妈，我就是带孩子去学滑冰、学游泳、打球、去撒野、去爬山。与其说你教给某一方面的知识和技能，不如说你给孩子展现了一种生活的方式，人生的一种活法。&lt;/p&gt;
&lt;h2 id=&#34;session-4&#34;&gt;Session 4&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;杨澜&lt;/strong&gt;：所以您怎样来回答当年的钱学森之问呢？&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;郑强&lt;/strong&gt;：钱学森之问就问了这么个问题——花了这么多钱，怎么就出不了拔尖的人才？就出在这个问题。说句实话，不敢挑战前人，不敢挑战或者质疑权威，是现在中国学术界很重的一个病。那么这样就失去了生命力了。关键在于批判。就要欣赏哪一种孩子呢？确实班上 99 个同学答案都跟老师一样的，是对的。可是突然冒出一个孩子，说我怀疑 $1+1=2$。我们知道他的答案是错的，但是如果是遇到我，我认为他今天挑战现有答案的这个勇气、他的价值和伟大远远超过那 99 个同学答案跟老师是同样答案的。这样的独特是中国教育界现在特别需要的。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;杨澜&lt;/strong&gt;：就是孩子可能是错的，但是你要允许他提出这个挑战。对不对？&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;郑强&lt;/strong&gt;：是。生命和科学的幻想和探索，&lt;strong&gt;一定要让小孩不断地提问，这个民族的探索才能得到启发&lt;/strong&gt;。&lt;/p&gt;
&lt;h2 id=&#34;session-5&#34;&gt;Session 5&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;郑强&lt;/strong&gt;：我现在教育给孩子们最多的，就包括我本人，我很欣赏过程。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;杨澜&lt;/strong&gt;：就是你为自己的一种目标或者信念去努力的这个过程，其实就是很成功的，也是会给你带来很多快乐的。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;郑强&lt;/strong&gt;：是的。这几十年，我们太急了，我们太追求眼前的成果了，包括成才，包括大学的评价。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;杨澜&lt;/strong&gt;：包括调整的这种速度，希望一夜之间把它都改完。某种程度上也会要经历这个时间的一种调整的。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;郑强&lt;/strong&gt;：所以包括大学的科学成果。你要知道国外的大学积累都是上千年了，六七百年的大学普遍都是。我们实际上讲百年老校，中国的大学才 120 年左右，实际上已经相当快了。可是我们现在有不少观点还在想快。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;杨澜&lt;/strong&gt;：这让我想到，曾经我也跟一位耶鲁大学的教授交谈。他说我从明年开始，我不再招中国大陆的学生了。我说为什么呢？他们的成绩不是很好吗？他说，可是他们选那个专业都没有热情，那个专业是他们的家长给他们选的，他们根本就没有热情来参加这个持续的研究，他很快就会想到怎么去找个工作，怎么去挣到钱等等。他说，所以我不能够浪费我有限的学术资源。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;郑强&lt;/strong&gt;：就是我们太功利了。我们把求学、读书都当成孩子今后饭碗的一个必由之路以后，我们的社会对孩子的教育就完全成了这样。另外一点，我们的坚守不够。日本得了 25 个诺贝尔奖了，新世纪到现在平均一年一个。但是你要知道日本教授他一辈子不改变自己的方向，他闷着头走到底。说到这的时候我就要讲，就是频繁换专业，这是害孩子的。如果他形成了一个习惯，当你学任何一个学科碰到一点点困难他不愿意坚守的时候，他再换专业他都学不好。你要做一个判断，我们转得太快了，这种转就是我们做学问都出了问题。&lt;/p&gt;
&lt;h2 id=&#34;session-6&#34;&gt;Session 6&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;杨澜&lt;/strong&gt;：我想问一下比如说在贵州当校长的时候，你也成立了白酒学院？&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;郑强&lt;/strong&gt;：对。我提出的口号就像我到太原去一样，贵州大学姓贵州，贵州大学就得为贵州的工业发展做贡献，就得为贵州的工业培养人才。贵州的酒产业没有人，全都是从沿海一带过去的。我们怎么会有这个工业？这是第一。第二，我这个人嘴硬，我还说了一句话——适当地爱护中国的白酒，实际上是保护我们的民族文化。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;杨澜&lt;/strong&gt;：这怎么讲？&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;郑强&lt;/strong&gt;：你想一想，为什么江浙人一听到越剧，他们有这么深的乡愁？为什么四川人围着火锅，不分你我、兄弟？它是一定要有元素的，其中一个元素饮食文化的元素是一辈子的。臭豆腐，从化学的角度来讲，它是因为表面含 $\rm H_2S$，就是化学不好的元素渗透到表面臭味出来了。可是这一臭，小的时候奶奶在路边上给他买过的那一块影响到他一生不忘了那一个山沟。这就是饮食文化。饮食文化比符号元素更厉害，是因为它影响到了人的整个生命的记忆。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;杨澜&lt;/strong&gt;：对。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;郑强&lt;/strong&gt;：两百年以后，杨澜，如果你还活着的话，你要翻拍一下《水浒传》。107 个梁山伯好汉端着的酒杯全都是红酒杯。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;杨澜&lt;/strong&gt;：那时候可能是米酒，还不是白酒。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;郑强&lt;/strong&gt;：文化会断掉的，我就稍微夸大一点。实际上在对待酒的问题上，不要单纯把它当成一个饮品。&lt;/p&gt;
&lt;h2 id=&#34;session-7&#34;&gt;Session 7&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;杨澜&lt;/strong&gt;：对于人才的定义，或者是一种培养模式，从这个工业化时代开始，就是相当于把人分工，流水线、工具化。就是你做这个事，你就做这一件事。所以，其实对人是有一种异化的。而我们人是完整的，我们每一个理工生也有非常丰富的情感需求，他们也会理解什么是美的。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;郑强&lt;/strong&gt;：对对对。这也是这几十年来中国教育的偏差，我们太注重一个人的吃饭的本领。他把大学的教育看成是一个专业的掌握了，我只要找一份工作，我能胜任这个机床，我就是一个人了。错了，大学不是教这个的，不是仅仅教这个。没有好的文科教育，缺少文化；没有好的体育教育，缺少强壮；没有好的音乐的熏陶，缺少情感。&lt;strong&gt;大学是教一个人一生的做人的准则和内心的情操的&lt;/strong&gt;，所以这是必须的。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;杨澜&lt;/strong&gt;：所以您去了太原理工之后，三个月就设立了音乐系和舞蹈系，而且办了一个相当水准的音乐会。当你把这些艺术的氛围带到太原理工这样一个比较典型的理工院校的时候，你觉得给校园带来了什么改变呢？&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;郑强&lt;/strong&gt;：你要知道给这个学校带来的是闪亮、青春、活力、内心的滋润。人的内心是需要滋润的。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;杨澜&lt;/strong&gt;：音乐是滋润的。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;郑强&lt;/strong&gt;：你看我说了两句特别俏皮的话。您说男同学看芭蕾，他懂芭蕾吗？他不懂，他在看什么？他在看漂亮的女孩。当他在看的时候，他就在想他的幸福人生，他就渴望他的旁边今后就有一位美丽的女孩出现。你别小看，这都是对生命的向往。我再说一个，那些女孩在旁边看到男孩打篮球，在那喊啦啦队，满脸通红，你以为她看多篮球了吗？她没有。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;杨澜&lt;/strong&gt;：她欣赏一种生命状态。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;郑强&lt;/strong&gt;：她看到的男同学的肌肉，给她极大的青春的冲击。这就是教育。如果一个大学没有这些，这个就不叫学校了。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;杨澜&lt;/strong&gt;：我记得我也是看到过一个报道，就是说过去我们讲到一个老师，或者一个学校的功能，往往是你给孩子传授了什么样的知识和技能。而现在的教育更多的是在谈我们创造了一种什么样的学习和成长的氛围。学习和成长是孩子自发就有这种动力去追求的一个目标，而教育工作者实际上给他创造了这样一种氛围。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;郑强&lt;/strong&gt;：是的。&lt;/p&gt;
&lt;h2 id=&#34;session-8&#34;&gt;Session 8&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;杨澜&lt;/strong&gt;：您一直被学生和网友亲切地称为“强哥”。你喜欢这个称呼吗？&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;郑强&lt;/strong&gt;：这个称呼实际上也不太好，有点江湖。不过也没关系，反正他们觉得亲切也可以。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;杨澜&lt;/strong&gt;：其实你能够说到这些孩子心里是因为你懂得他们的。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;郑强&lt;/strong&gt;：是。那些学生因为相信我的思想，相信我的情感，相信我的演讲。他一看到强哥，他就觉得像看到亲人一样。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;杨澜&lt;/strong&gt;：这个懂得真是很珍贵的。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;郑强&lt;/strong&gt;：真的要说，为学生，为教育做点事，做出点牺牲无所谓。你知道我捐了三个奖学金。贵州省给我的 50 万现金我全捐了，捐了以后感动了身边的一帮人。现在已经 1300 万了，不算大数。但是在中国，现在在岗的高校领导当中是唯一的。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;杨澜&lt;/strong&gt;：对，这也是你做出的选择。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;郑强&lt;/strong&gt;：对，生活上我可以节俭一点。我说对孩子、对教育的爱，那是我内心的、无悔的。&lt;/p&gt;
&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;杨澜&lt;/strong&gt;：我觉得今天跟郑强教授的谈话，也是我们整个社会应该进行反思和讨论的一个问题。就是我们究竟如何界定成功？我们究竟需要什么样的人才？我们应该如何以孩子自身的生命的成长为本，去给予他们更加积极的、有利的成长环境。我觉得这些问题可能不仅仅是家长和老师们要问，我们社会当中的每一个人都应该扪心自问吧。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Nonviolent Communication</title>
      <link>https://bowenei.gitee.io/post/nonviolent-communication/</link>
      <pubDate>Tue, 15 Feb 2022 15:08:33 +0800</pubDate>
      <guid>https://bowenei.gitee.io/post/nonviolent-communication/</guid>
      <description>&lt;p&gt;著名的马歇尔·卢森堡博士发现了神奇而平和的非暴力沟通方式，通过非暴力沟通，世界各地无数的人们获得了爱、和谐和幸福！当我们褪去隐蔽的精神暴力，爱将自然流露。&lt;/p&gt;
&lt;p&gt;本文根据原书逻辑整理出思维导图，并做读书笔记。&lt;/p&gt;
&lt;details class=&#34;toc-inpage d-print-none  &#34; open&gt;
  &lt;summary class=&#34;font-weight-bold&#34;&gt;Table of Contents&lt;/summary&gt;
  &lt;nav id=&#34;TableOfContents&#34;&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;a href=&#34;#导读&#34;&gt;导读&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#引言&#34;&gt;引言&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#让爱融入生活&#34;&gt;让爱融入生活&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#异化的沟通方式&#34;&gt;异化的沟通方式&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#道德评判&#34;&gt;道德评判&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#进行比较&#34;&gt;进行比较&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#回避责任&#34;&gt;回避责任&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#强人所难&#34;&gt;强人所难&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#非暴力沟通的要素&#34;&gt;非暴力沟通的要素&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#观察&#34;&gt;观察&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#感受&#34;&gt;感受&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#需要&#34;&gt;需要&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#请求&#34;&gt;请求&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#倾听他人&#34;&gt;倾听他人&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#体会他人的感受和需要&#34;&gt;体会他人的感受和需要&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#给他人反馈&#34;&gt;给他人反馈&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#表达自己&#34;&gt;表达自己&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#爱自己&#34;&gt;爱自己&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#充分表达愤怒&#34;&gt;充分表达愤怒&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#运用强制力避免伤害&#34;&gt;运用强制力避免伤害&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#表达感激&#34;&gt;表达感激&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
  &lt;/ul&gt;
&lt;/nav&gt;
&lt;/details&gt;

&lt;h2 id=&#34;导读&#34;&gt;导读&lt;/h2&gt;
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34;
           src=&#34;https://bowenei.gitee.io/post/nonviolent-communication/%E9%9D%9E%E6%9A%B4%E5%8A%9B%E6%B2%9F%E9%80%9A.svg&#34;
           loading=&#34;lazy&#34; data-zoomable class=&#34; img-light&#34; /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;p&gt;用四个词就可以概括非暴力沟通：&lt;strong&gt;观察&lt;/strong&gt;、&lt;strong&gt;感受&lt;/strong&gt;、&lt;strong&gt;需要&lt;/strong&gt;、&lt;strong&gt;请求&lt;/strong&gt;。具体来说，就是如下四个步骤：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;什么是我的&lt;strong&gt;观察&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;我的&lt;strong&gt;感受&lt;/strong&gt;如何&lt;/li&gt;
&lt;li&gt;哪些&lt;strong&gt;需要&lt;/strong&gt;（或价值、愿望等）导致那样的感受&lt;/li&gt;
&lt;li&gt;为了改善生活，我的&lt;strong&gt;请求&lt;/strong&gt;是什么&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;这四个词也是非暴力沟通的四要素，贯穿整本书。本书的第三章至第六章深入阐述了这四个要素的内涵。&lt;/p&gt;
&lt;p&gt;而本书的第一章则为引言，告诉读者运用非暴力沟通是为了&lt;strong&gt;让爱融入生活&lt;/strong&gt;，同时也是马歇尔博士毕生的追求。本身的第二章则介绍了四种异化的沟通方式，这些都不是非暴力沟通。&lt;/p&gt;
&lt;p&gt;在使用非暴力沟通时，&lt;strong&gt;表达自己&lt;/strong&gt;或&lt;strong&gt;倾听他人&lt;/strong&gt;，都是好的开端。本书的第七章和第八章则介绍了应该如何倾听他人，而剩余的第九章至第十三章则介绍了应该如何表达自己。不论是表达自己还是倾听他人，都应该注重自己（他人）的感受和需要，而不应该批评和指责。&lt;/p&gt;
&lt;h2 id=&#34;引言&#34;&gt;引言&lt;/h2&gt;
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34;
           src=&#34;https://bowenei.gitee.io/post/nonviolent-communication/%E5%BC%95%E8%A8%80.svg&#34;
           loading=&#34;lazy&#34; data-zoomable class=&#34; img-light&#34; /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;h3 id=&#34;让爱融入生活&#34;&gt;让爱融入生活&lt;/h3&gt;
&lt;p&gt;马歇尔博士认为，一旦专注于彼此的观察、感受及需要，而不反驳他人，我们便能发现内心的柔情，对自己和他人产生全新的体会。这将最大限度地避免暴力。&lt;/p&gt;
&lt;p&gt;让爱融入生活是作者毕生的追求。当我们真诚助人时，我们丰富他人生命的愿望得到了满足。我们的行为，是出于由衷的喜悦。这样的给予让施者和受者同时受益。由于施者的给予既不是出于恐惧、内疚或羞愧，也不是为了得到什么；受着获得馈赠，却不会有心理负担。与此同时，施者会因自己行为的价值更加欣赏自己。&lt;/p&gt;
&lt;h2 id=&#34;异化的沟通方式&#34;&gt;异化的沟通方式&lt;/h2&gt;
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34;
           src=&#34;https://bowenei.gitee.io/post/nonviolent-communication/%E5%BC%82%E5%8C%96%E7%9A%84%E6%B2%9F%E9%80%9A%E6%96%B9%E5%BC%8F.svg&#34;
           loading=&#34;lazy&#34; data-zoomable class=&#34; img-light&#34; /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;h3 id=&#34;道德评判&#34;&gt;道德评判&lt;/h3&gt;
&lt;p&gt;道德评判，实际上就是我们所熟知的用自己的价值观给别人贴标签。每个人的价值观都不完全相同，将自己的价值观强加给别人实际上是将问题归咎于对方，而忽略了自己的感受和需要。&lt;/p&gt;
&lt;p&gt;例如，妻子回到家中发现家里的卫生特别脏乱，于是责备一直在家的丈夫懒。实际上，妻子只是因为家里卫生的脏乱而没有得到满足，但她却把责任推给了自己的丈夫。被责备的丈夫自然心情并不会太好。妻子正确的做法应当是充分表达自己因为家里脏而尚未满足的需要，希望自己的丈夫可以多承担一些家务劳动。&lt;/p&gt;
&lt;p&gt;要注意不能将价值判断和道德评判混为一谈。价值判断反映了我们的信念——生命的需要怎样才能得到满足。如果看到了不符合我们价值观的行为，应该直接说出我们的价值观，而不是指责他人。&lt;/p&gt;
&lt;h3 id=&#34;进行比较&#34;&gt;进行比较&lt;/h3&gt;
&lt;p&gt;有些人总是喜欢和别人攀比，总是不能以心平气和的态度看待别人。例如，中国式家长会经常说别人家的孩子怎么怎么好，自己的孩子仿佛一无是处。这其实是一种暴力，它蒙蔽了父母对孩子的爱意，孩子往往会越来越自卑。&lt;/p&gt;
&lt;p&gt;如果经常觉得自己和谁都难以交流的话，那就要试着反省一下自己，看看是不是因为你总是喜欢拿自己和别人进行比较。&lt;/p&gt;
&lt;h3 id=&#34;回避责任&#34;&gt;回避责任&lt;/h3&gt;
&lt;p&gt;我们的表达方式，经常会忽略掉内心的情感根源。一旦把表达方式换成“不得不”的时候，就淡化了个人责任，不自觉地忽略掉了自己原本的出发点。&lt;/p&gt;
&lt;p&gt;例如，妻子总是跟自己的孩子、丈夫抱怨做家务辛苦、劳累。这种抱怨实际上就是逃避责任。这位妈妈本来就是出于对家庭的责任心、对丈夫和孩子的爱才去做家务的，结果一旦表达方式换成“不得不做”的时候，仿佛丈夫不是自己的丈夫，孩子不是自己的孩子，打扫的也不是自己的家一样。经常抱怨就是对孩子及家人的一种暴力伤害。&lt;/p&gt;
&lt;p&gt;由于几千年来封建传统对女性思想的影响，女性往往会将生育、家务劳动内化成她们不得不做的任务。一方面她们觉得这些理所应当，是自己的义务；另一方面，她们从内心出发似乎并不情愿去做这些她们不喜欢做的事，却又刻意压抑自己内心的想法。&lt;/p&gt;
&lt;h3 id=&#34;强人所难&#34;&gt;强人所难&lt;/h3&gt;
&lt;p&gt;众所周知，中国式家长最喜欢把自己的意愿强加给孩子。作者认为，我们可以提出各种要求，但无法强迫孩子们按照我们的期待生活。显然，强迫孩子做他不愿意，或者没有能力做到的事情也是一种暴力。&lt;/p&gt;
&lt;p&gt;异化的沟通方式来源于等级社会或专制社会。人们越是习惯于评定是非，他们也就越倾向于追随权威，来获得正确和错误的标准。这样一来，就忽略了自身的感受和需要。&lt;/p&gt;
&lt;h2 id=&#34;非暴力沟通的要素&#34;&gt;非暴力沟通的要素&lt;/h2&gt;
&lt;h3 id=&#34;观察&#34;&gt;观察&lt;/h3&gt;
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34;
           src=&#34;https://bowenei.gitee.io/post/nonviolent-communication/%E8%A7%82%E5%AF%9F.svg&#34;
           loading=&#34;lazy&#34; data-zoomable class=&#34; img-light&#34; /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;p&gt;非暴力沟通并不要求我们保持完全的客观而不作任何评论，它只是强调区分观察和评论的重要性。将观察和评论混为一谈，人们将更容易听到批评。例如：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;我儿子睡觉前经常不刷牙。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;在这句话中，“不刷牙”是观察，但是“经常”一词就暗含了你的评论。如果我们只是陈述客观事实的话，可以说：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;我儿子这周有两次没刷牙就上床睡觉。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;非暴力沟通强调区分观察和评论，那么可以我们可以这样说：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;我儿子这周有两次没刷牙就上床睡觉，我觉得他的这种习惯很不好。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&#34;区分观察和评论的方法&#34;&gt;区分观察和评论的方法&lt;/h4&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;表达方式&lt;/th&gt;
&lt;th&gt;观察和评论被混为一谈&lt;/th&gt;
&lt;th&gt;区分观察和评论&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;使用的语言没有体现出评论的人对其评论负有责任。&lt;/td&gt;
&lt;td&gt;你太大方了。&lt;/td&gt;
&lt;td&gt;当我看到你把吃午饭的钱都给了别人，我认为你太大方了。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;把对他人思想、情感或愿望的推测当作唯一的可能。&lt;/td&gt;
&lt;td&gt;她无法完成工作。&lt;/td&gt;
&lt;td&gt;我不认为她能够完成工作。&lt;br&gt;她说：“我不能够完成工作。”&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;把预测当作事实。&lt;/td&gt;
&lt;td&gt;如果你饮食不均衡，你的健康就会出问题。&lt;/td&gt;
&lt;td&gt;如果你饮食不均衡，我就会担心你的健康出问题。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;缺乏依据。&lt;/td&gt;
&lt;td&gt;米奇花钱大手大脚。&lt;/td&gt;
&lt;td&gt;米奇上周买书花了一千元。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;评价他人能力时，把评论当作事实。&lt;/td&gt;
&lt;td&gt;欧文是个差劲的前锋。&lt;/td&gt;
&lt;td&gt;在过去的五场比赛中，欧文没有进一个球。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;使用形容词和副词时，把评论当作事实。&lt;/td&gt;
&lt;td&gt;索菲长得很丑。&lt;/td&gt;
&lt;td&gt;索菲对我没有什么吸引力。&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;在使用某些确定的频度副词时，有些情况下表达的是观察，而有些情况下表达的是评论。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;我看安迪打了几次电话，&lt;strong&gt;每次&lt;/strong&gt;都至少打半小时。（观察）&lt;/li&gt;
&lt;li&gt;你&lt;strong&gt;总是&lt;/strong&gt;很忙。（评论）&lt;/li&gt;
&lt;li&gt;在需要她的时候，她&lt;strong&gt;从不&lt;/strong&gt;出现。（评论）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;而在使用频度模糊的频度副词时，会混淆观察和评论。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;你&lt;strong&gt;很少&lt;/strong&gt;配合我。（评论）&lt;/li&gt;
&lt;li&gt;他&lt;strong&gt;经常&lt;/strong&gt;过来。（评论）&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;感受&#34;&gt;感受&lt;/h3&gt;
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34;
           src=&#34;https://bowenei.gitee.io/post/nonviolent-communication/%E6%84%9F%E5%8F%97.svg&#34;
           loading=&#34;lazy&#34; data-zoomable class=&#34; img-light&#34; /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;p&gt;过去人们认为感受是无关紧要的，重要的是各种权威主张的“正确思想”。于是，我们被鼓励服从权威而非倾听自己。渐渐地，我们的心灵就被压抑了。&lt;/p&gt;
&lt;h4 id=&#34;区分感受和想法&#34;&gt;区分感受和想法&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;我觉得我的吉他弹得不好。（想法）&lt;/li&gt;
&lt;li&gt;作为吉他手，我有些失落。（感受）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;我们可能习惯用“我觉得”、“我认为”来表达自己，实际上很多时候这表达的是我们的想法，并非感受。例如：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;我觉得你应该懂得更多。&lt;/p&gt;
&lt;p&gt;我觉得自己很无能。&lt;/p&gt;
&lt;p&gt;我觉得他很负责任。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;还有一些词语表达的是想法，而非感受。例如：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;我觉得我被误解了。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;“被误解”一词反映了我认为别人不理解我，但这只不过是我的想法而已。此时我的感受可能是很着急的。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;我觉得我被忽略了。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;“被忽略”是我的判断。此时并不能准确判断我的想法。如果想独处，那么我就会感到很高兴；如果想参加活动，那么我就会感到很难过。&lt;/p&gt;
&lt;p&gt;为了清楚地表达自己的感受，要学会建立表达感受的词汇表。&lt;/p&gt;
&lt;h3 id=&#34;需要&#34;&gt;需要&lt;/h3&gt;
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34;
           src=&#34;https://bowenei.gitee.io/post/nonviolent-communication/%E9%9C%80%E8%A6%81.svg&#34;
           loading=&#34;lazy&#34; data-zoomable class=&#34; img-light&#34; /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;p&gt;非暴力沟通强调，感受的根源在于我们自身。我们的需要和期待，以及对他人言行的看法，导致了我们的感受。&lt;/p&gt;
&lt;h4 id=&#34;感受与自身需要的关系&#34;&gt;感受与自身（需要）的关系&lt;/h4&gt;
&lt;p&gt;我们可以通过“我（感到）……因为我……”这种表达方式来认识感受与自身的关系。例如：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;看到公司海报出现拼写错误，我很不高兴。因为我重视公司的形象。&lt;/p&gt;
&lt;p&gt;你没把饭吃完，妈妈感到失望。因为妈妈希望你能健康成长。&lt;/p&gt;
&lt;p&gt;老板说话不算数，我很生气。因为我想有个长假去看弟弟。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;对他人的指责、批评、评论以及分析反映了我们的需要和价值观。如果我们通过批评来提出主张，人们的反应常常是申辩或反击。反之，如果直接说出我们的需要，其他人就较有可能作出积极的回应。&lt;/p&gt;
&lt;p&gt;然而，社会文化并不鼓励我们揭示个人需要。对妇女来说，尤其如此。因为她们的形象常常和无私奉献联系在一起——这是社会对女性的期待。&lt;/p&gt;
&lt;p&gt;对于大多数人来说，个人成长一般会经历三个阶段：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;情感的奴隶&lt;/strong&gt;：我们认为自己有义务使他人快乐。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;面目可憎&lt;/strong&gt;：我们拒绝考虑他人的感受和需要。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;生活的主人&lt;/strong&gt;：虽然我们对自己的意愿、感受和行动负有完全的责任，但无法为他人负责。我们也无法牺牲他人来满足自己的需要。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;请求&#34;&gt;请求&lt;/h3&gt;
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34;
           src=&#34;https://bowenei.gitee.io/post/nonviolent-communication/%E8%AF%B7%E6%B1%82.svg&#34;
           loading=&#34;lazy&#34; data-zoomable class=&#34; img-light&#34; /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;h4 id=&#34;提出具体的请求&#34;&gt;提出具体的请求&lt;/h4&gt;
&lt;p&gt;我们要学会提出具体的请求。首先，清楚地告诉对方，我们希望他们做什么。如果我们请求他人不做什么，对方也许会感到困惑，不知道我们到底想要什么。而且，这样的请求还容易引起别人的反感。&lt;/p&gt;
&lt;p&gt;下面的句子都没有提出明确的请求：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;我希望你理解我。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;在这个句子中，“理解”这个词并没有清楚地表达出发言者的请求，因为对话的双方对“理解”一词的理解可能不同。如果发言人这样说就是提出了明确的请求：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;你是否可以告诉我，你认为我刚才说的是什么意思？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;下面的这句话也没有提出明确的请求，因为这句话表达的是发言者想要避免的事情。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;不要再喝酒了。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;如果发言者要提出明确的请求，他可以这样说：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;你是否可以告诉我，喝酒可以满足你什么需要？是否有别的方式可以满足那些需要？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;其次，要明确谈话的目的。如果一个人提出了明确的请求，却没有提及感受和需要，也有可能导致交流的困难。&lt;/p&gt;
&lt;p&gt;另外，我们的意思和别人的理解有时可能是两回事。如果无法确定对方是否已经明白，我们可能就需要得到反馈。请求反馈能确保对方准确把握我们的意思。在确认对方已经明白后，我们还需要了解对方的反应。&lt;/p&gt;
&lt;h4 id=&#34;请求与命令&#34;&gt;请求与命令&lt;/h4&gt;
&lt;p&gt;请求没有得到满足时，提出请求的人如果批评和指责，那就是命令；如果想利用对方的内疚来达到目的，也是命令。如果我们愿意去体会是什么使他们无法说“是”，那么我们提出的就是请求而非命令。&lt;/p&gt;
&lt;p&gt;一旦人们相信我们看重彼此的感情，并能兼顾双方的需要，那么，他们也就会相信我们所表达的愿望是请求而非命令。然而在另一些时候，即使我们以适当的方式提出请求，有些人仍然误以为是命令。特别是当我们处于强势的一方，那些曾受过威胁的人尤其容易做出那样的判断。&lt;/p&gt;
&lt;p&gt;实际上，非暴力沟通的目的不是为了改变他人来迎合我们。相反，非暴力沟通重视每个人的需要，它的目的是帮助我们在诚实和倾听的基础上与人联系。&lt;/p&gt;
&lt;h2 id=&#34;倾听他人&#34;&gt;倾听他人&lt;/h2&gt;
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34;
           src=&#34;https://bowenei.gitee.io/post/nonviolent-communication/%E5%80%BE%E5%90%AC%E4%BB%96%E4%BA%BA.svg&#34;
           loading=&#34;lazy&#34; data-zoomable class=&#34; img-light&#34; /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;h3 id=&#34;体会他人的感受和需要&#34;&gt;体会他人的感受和需要&lt;/h3&gt;
&lt;p&gt;为了倾听他人，我们需要先放下已有的想法和判断，全神贯注地体会对方。然而，遭遇他人的痛苦时，我们常常急于提建议，安慰或表达我们的态度和感受。如果一个人想要别人了解他的处境，听到的却是安慰和建议，那么他就很有可能觉得不太舒服。具体来讲，如下行为会妨碍我们体会他人的处境：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;建议：我想你应该……&lt;/li&gt;
&lt;li&gt;比较：这算不了什么。你听听我的经历……&lt;/li&gt;
&lt;li&gt;说教：如果你这样做……你将会得到很大的好处。&lt;/li&gt;
&lt;li&gt;安慰：这不是你的错；你已经尽了最大努力了。&lt;/li&gt;
&lt;li&gt;回忆：这让我想起……&lt;/li&gt;
&lt;li&gt;否定：高兴一点，不要这么难过。&lt;/li&gt;
&lt;li&gt;同情：哦，你这可怜的人……&lt;/li&gt;
&lt;li&gt;询问：这种情况是什么时候开始的？&lt;/li&gt;
&lt;li&gt;辩解：我原想早点打电话给你，但昨晚……&lt;/li&gt;
&lt;li&gt;纠正：事情的经过不是那样的。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在非暴力沟通中，倾听他人意味着，放下已有的想法和判断，一心一意地体会他人。&lt;/p&gt;
&lt;p&gt;然而，有的时候，别人的话基于怎样的观察，并不一目了然。我们需要通过询问来了解我们的猜测是否准确。&lt;/p&gt;
&lt;h3 id=&#34;给他人反馈&#34;&gt;给他人反馈&lt;/h3&gt;
&lt;p&gt;在倾听他人的观察、感受、需要和请求之后，我们可以主动表达我们的理解。如果我们已经准确领会了他们的意思，我们的反馈将帮助他们意识到这一点。反之，如果我们的理解还不到位，他们也就有机会来纠正我们。&lt;/p&gt;
&lt;p&gt;具体来说，我们可以使用疑问句来给予他人反馈，问题可以围绕他人的观察、感受、需要和请求，并且先提及我们的感受和需要，在鼓励他人表达自己。不过，直接的提问方式很容易产生距离感。例如：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;你说的是什么事？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;这种特殊疑问句看起来很直接，但不是提问的最佳方式。我们可以先主动表达自己的感受和需要：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;我感到有些困惑。我想知道你是指哪件事，告诉我好吗？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;我们也可以直接给出我们的猜测，使用对方只需要回答是（否）的一般疑问句：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;上周末我不在家，你说的是这回事？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;什么时候需要给别人反馈呢？首先，在对自己的理解没有把握时，我们需要对方的确认。然而，即使确信自己已经明白了，我们可能还会发现别人正期待着我们的反馈。一般来说，如果一个人在说话时有很明显的情绪，他一般会期待得到他人的反馈。&lt;/p&gt;
&lt;p&gt;在给他人反馈时，我们的语气十分重要。一个人在听别人谈自己的感受和需要时，将会留意其中是否暗含着批评与嘲讽。一旦别人通过我们的语气意识到我们是在体会，而非下结论，他们就一般不会产生反感。&lt;/p&gt;
&lt;p&gt;有时，我们的意图可能会被误解。只要我们专注于他人的感受和需要，所有的批评、攻击、辱骂或者嘲讽就会消失。如果人们常常怀疑我们的诚意，那么我们需要好好审视自己的动机。也许，我们只是在机械地运用非暴力沟通，而忘记其目的。我们绝对不能想着改变他人来迎合我们的需要。&lt;/p&gt;
&lt;p&gt;另外，在解决问题或询问他人的请求前，要为他人的充分表达创造条件。如果过早地提及他人的请求，我们也许就无法传达出我们的关心，甚至还会被看作是应付。&lt;/p&gt;
&lt;h2 id=&#34;表达自己&#34;&gt;表达自己&lt;/h2&gt;
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34;
           src=&#34;https://bowenei.gitee.io/post/nonviolent-communication/%E8%A1%A8%E8%BE%BE%E8%87%AA%E5%B7%B1.svg&#34;
           loading=&#34;lazy&#34; data-zoomable class=&#34; img-light&#34; /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;h3 id=&#34;爱自己&#34;&gt;爱自己&lt;/h3&gt;
&lt;p&gt;爱自己的第一步首先是要转变自我评价的方式。我们要认识到自责的原因，即我的行为不符合我的需要。因此，我们需要专注于自我的需要是否满足。这样，我们就不再依赖羞愧、内疚、恼怒或沮丧的心理来寻求改变，而是让爱主导我们的学习和成长。&lt;/p&gt;
&lt;p&gt;要学会自我宽恕，思考清楚我做那件事情是为了满足什么需要。如果那件事情“不得不”做，却并不能满足我的需要，要学会用“选择做”代替“不得不”。&lt;/p&gt;
&lt;p&gt;在情绪低落的时候，我们也许会怨天尤人。然而，如果我们以苛刻的态度对人对己，我们的心情也好不到哪里去。通过非暴力沟通，我们就不会试图分析自己有什么毛病，而是用心去了解我们的需要。这样，我们的内心将逐渐变得平和。一旦我们发现自己心底深处的愿望，并采取积极的行动，我们将会重拾生活的热情。&lt;/p&gt;
&lt;h3 id=&#34;充分表达愤怒&#34;&gt;充分表达愤怒&lt;/h3&gt;
&lt;p&gt;首先，我们要认识到生气的原因在于我们的想法——对他人进行评判和指责。如果想要充分表达愤怒，我们就不能归咎于他人，而是把注意力放在自己的感受和需要上。与其批评和指责他人，不如直接说出我们的需要。&lt;/p&gt;
&lt;h3 id=&#34;运用强制力避免伤害&#34;&gt;运用强制力避免伤害&lt;/h3&gt;
&lt;p&gt;在有些情形中，我们没有机会和他人交流。这时，我们也许需要使用强制力来保护自己和他人。我们这样做，是为了避免伤害，而不是为了惩罚他人。如果我们威胁他人或实施惩罚，人们常常会产生敌意和抵触心理。这样，彼此的关系将会疏远。同时，惩罚还可能使人忽视事情本身的意义，而把注意力放在不服从的后果上。如果我们试图通过惩罚来使人们意识到自己的需要，那么我们可能适得其反。&lt;/p&gt;
&lt;p&gt;例如，中国式家长只关注孩子的成绩。一旦孩子学习成绩下降，或者说没有达到家长的期望，有些家长就会体罚孩子，或者说以某种奖励的取消来惩罚孩子。殊不知，这样做会让孩子产生为了不被父母打骂、得到奖励而去学习的想法，孩子不再关注学习本身的意义。&lt;/p&gt;
&lt;h3 id=&#34;表达感激&#34;&gt;表达感激&lt;/h3&gt;
&lt;p&gt;首先，要明确赞扬的动机是为了庆祝他人的行为提升了我们的生活品质，而不是想得到任何回报。要学会运用非暴力沟通来表达感激。要知道，绝大多数人是渴望得到他人的肯定和感激的。&lt;/p&gt;
&lt;p&gt;另外，当别人表达对我们的感激时，我们可以与对方一起庆祝生命的美——既不自大，也不假谦虚。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>“世界民主峰会”喜剧还是闹剧？</title>
      <link>https://bowenei.gitee.io/post/china-now-129/</link>
      <pubDate>Wed, 12 Jan 2022 09:47:54 +0800</pubDate>
      <guid>https://bowenei.gitee.io/post/china-now-129/</guid>
      <description>&lt;p&gt;2021年12月4日、5日，国务院、外交部先后发表了《中国的民主》白皮书&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;和《美国民主情况》报告&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;，可谓是意味深长。如果没有特别留意当时的新闻，我们还不知道12月9日美国要张罗的所谓“民主峰会”。可所谓“民主峰会”最后却没能达成任何的宣言或者共识，反倒是展现出了美式民主的虚伪和荒唐。&lt;/p&gt;
&lt;p&gt;复旦大学中国研究院副院长&lt;a href=&#34;http://www.cifu.fudan.edu.cn/95/39/c521a103737/page.htm&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;范勇鹏&lt;/a&gt;教授在&lt;a href=&#34;https://www.bilibili.com/bangumi/play/ep460055&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;《这就是中国》第129期&lt;/a&gt;节目上火力全开，做了精彩且犀利的演讲。本文是范教授在节目中的演讲原文，不代表本文作者观点。&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;2021年的12月9日，美国总统拜登先生张罗了一场所谓的“民主峰会”。当时看新闻的时候，我脑海中出现了两句中国俗语，一句是“来如风雨、去似微尘”。&lt;/p&gt;
&lt;h3 id=&#34;拜登张罗的民主峰会亲自剥去了美国的皇帝新衣&#34;&gt;拜登张罗的“民主峰会”亲自剥去了美国的“皇帝新衣”。&lt;/h3&gt;
&lt;p&gt;大家应该还记得，就在2021年3月中美阿拉斯加会谈的时候，当时美国代表团不顾外交礼仪，搞了很多小动作，当时我们的杨洁篪就讲了一句话，他说“我把你们想得太好了”。可以说，这句话说出了全世界人民的心声，美国这个国家一向披着国际秩序和民主价值的大旗，在世界上大搞单边主义、霸权主义，然后去剥削、欺凌，甚至去颠覆别的国家，杨主任的这句话戳破了美国长期的伪装，也打破了中国和世界上很多人对美国的幻想。&lt;/p&gt;
&lt;p&gt;开完了拜登先生这场峰会，我想说的是：“我们把你们想得太重要了”。&lt;/p&gt;
&lt;p&gt;之前，美国各种造势，拉帮结派。作为一个长期关注中美关系和国际舆论斗争的一个学者，我当时确实是有点紧张的，我不知道这次美国的这个峰会，会搞出多大的幺蛾子，担心会不会给我们的国际形象、话语权和国家利益带来什么损害。结果一看，真是“来如风雨、去似微尘”，我发现自己多虑了。&lt;strong&gt;这次峰会可以说是剥去了美国的“皇帝新衣”，着实让美国在全世界面前“祼奔”了一回&lt;/strong&gt;。&lt;/p&gt;
&lt;h3 id=&#34;拜登政府召集开民主峰会属于典型的缺乏自知之明&#34;&gt;拜登政府召集开“民主峰会”属于典型的缺乏自知之明。&lt;/h3&gt;
&lt;p&gt;我想到的第二句俗语是“力微休负重，言轻莫劝人”。&lt;/p&gt;
&lt;p&gt;人贵有自知之明。拜登的这次峰会就是典型的缺乏自知之明。美国曾经强大过，哈佛大学学者约瑟夫·奈，他曾经说自罗马帝国以来，从来没有哪个国家像美国这样让别的国家相形见绌。当然从我的观点来看，奈教授多少有点少见多怪，首先就是我们中国在过去几千年里边，我们经常让全世界相形见绌，罗马帝国算什么。其次就是二战后，美国如日中天的时候，你在朝鲜战场，在越南战场，最后不也是灰溜溜地退场吗？但是我们要承认，从世界权力结构来看，那个时候的美国确实是相当得强大。比如说在1944年，美国开了一次会，叫布雷顿森林会议，那次会议奠定了此后70余年世界体系的基本格局。然后1991年，美国虽然没有开会，但是苏联解体了，美国俨然成为单极霸权，执全球之牛耳，可谓是如日中天。然后后来美国的力量有所下降，但是你看“9·11”事件之后，美国小布什总统可以站在废墟上拿着“反恐”的理由，公然在全球划线，声称要么你站在我一边，要么你就是我的敌人，对吧？2003年伊拉克战争的时候，当时美国国防部长拉姆斯菲尔德跑到欧洲，公然地拉一派打一派，指责法、德这些国家，说你们是老欧洲，不跟我们玩，你们就是敌人。虽然后来伊拉克和阿富汗两场战争都是黯然收场，但是我们回想当时的那个美国，嘴上还是硬气的，而且其它国家面子还是要给足的。&lt;/p&gt;
&lt;p&gt;但是到了拜登的这场峰会，原本也是想搞出个万邦来朝，结果把里子面子全丢光了，不仅在世界上没人关注，连美国自己的媒体都不怎么报道，西方这些媒体其实滑头得很，它也不想把宝押在一个没有前途的方向，就像英语里有一句谚语，“老鼠都知道要逃离沉船”。当时那几天，如果咱们不看中文媒体，你几乎都注意不到这个峰会。另外来参会的代表大多数也是漫不经心，有的上去讲两句就下线了，更有甚者，阿根廷总统费尔南德斯虽然参会，却是专门来“砸场子”的，在演讲中大批了一通美国。这在以前几乎是不可想象的事。&lt;/p&gt;
&lt;p&gt;这就跟我们在生活里一样，当你有能力、有威信的时候，你说出话来别人会重视。当你没有这个实力和资格了，你最好三缄其口，这时候你非要跳到台上去搞事情，你只会让别人更快地认识到你无足轻重。这就是我们这句老话，叫“力微休负重，言轻莫劝人”。&lt;/p&gt;
&lt;h3 id=&#34;民主峰会成为反面教材给中国和世界上了一堂思政课&#34;&gt;“民主峰会”成为反面教材，给中国和世界上了一堂思政课。&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;我要讲的第二点，就是这场峰会它其实也不是一无是处，其实很有价值。对中国和世界人民来讲，这是一堂课，难得的一堂思政课，帮我们大大破除了对“美式自由民主”的幻想&lt;/strong&gt;。我们复旦大学中国研究院长期致力于解构、批判虚假的“美国式民主”观念，比如像张维为老师一直强调的，“自由民主”是重程序，不重实质，它是用程序的正义来掩盖实质的不公。再比如我们也指出过，“自由民主”它不是民主，它是自由。&lt;/p&gt;
&lt;p&gt;我自己在一期节目里也专门讲过，“自由”是资产阶级的价值观，就是资本权贵的护身符，“自由民主”就是披着民主外衣的自由而已。再比如我们也讲过，民主不是选举，美国的所谓“一人一票”实际上就是一美元一票，反过来，选举也不是民主，选举是中世纪贵族政治的一个标配，当然经过现代改造之后，形成了现代大众选举，但仍然是有很多先天弊端的，非常容易被各种力量操纵，会让地方性利益集团绑架整体利益，容易导致党争和分裂，导致财政破产，然后会导致政治的娱乐化等等。&lt;/p&gt;
&lt;p&gt;还有就是像“自由民主”与经济发展、科技进步、人民福利都没有直接的关系。没有一个西方国家是靠着“自由民主”发达起来的，也没有一个搞了“自由民主”的国家今天没有衰落。最近上海交大的文一教授出版了一本新书，叫《科学革命的密码》，大家可以读一读，他在书里就指出了，西方发展出现代科学技术是由于欧洲长期的战争带来的军事竞争，和民不民主没有一毛钱的关系。但是，有时候我们怎么讲，也比不过美国民主的本家自己出来现身说法。所以特朗普先生是用实力戳破了美国“民主”的几乎每一副面具，拜登本来是想修复这些面具，没想到这次峰会让“美国民主神话”破产这个事实呈现在世人面前。有时候想，这两位还在辛勤工作的老先生，着实为解构西方话语立下了汗马功劳。我之前在节目里还批评过我们中国学界有一些人不给力，很多人没有跳出西方的话语陷阱，其实我自己反思有可能多虑了，因为一个拜登和特朗普的组合，至少抵得上几十名教授十年之功。所以我建议将来可以给他们每人颁发一枚一吨重的“奖章”。授予他们一个“西方民主破壁人”的光荣称号。&lt;/p&gt;
&lt;h3 id=&#34;美国欲借民主峰会围剿中国却先坑了自己&#34;&gt;美国欲借“民主峰会”围剿中国却先坑了自己！&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;我要讲的第三点是美国信誉的破产，并不意味着我们要放松下来了&lt;/strong&gt;。我们为中国人民争取民主，为世界人民争取公平的伟大斗争才刚刚开始。美国资本力量的统治不会自动后退，美国继续剥削和掠夺别国的欲望从来没有放弃，美国的暴力手段、暴力能力也没有丧失。我们绝对不能排除一种可能，就是美国通过“民主峰会”来拉帮结派，对中国进行一个“体面”围攻的计划破产之后，它图穷匕现。所谓的“民主话语战略”受挫之后，不排除美国的战略重心会回到贸易战、地缘政治斗争、产业和科技竞争这方面，对中国进行更野蛮的攻击。甚至不排除美国进行军事冒险的可能性。近百年前，我们中国的社会学家费孝通先生曾经说过一句话，他说美国这样一个年轻的国家，手里握着如此强大的暴力武器，终究不让人放心。我们今天面对这个不再年轻的国家，当它面临着失败衰落的命运的时候，它会不会变得更绝望、更疯狂、更无底线，它手里的暴力武器是不是更值得我们警惕。毛主席说过一句话，战略上藐视敌人，战术上重视敌人。这次“民主峰会”的破产也许会成为一个转折点，会让美国的资本统治集团意识到玩“民主”这种虚头巴脑的东西已经对中国无效了，反过来会激起它们冒险去赌一把的心理。&lt;/p&gt;
&lt;h3 id=&#34;不扩张就内卷西方文明的第四次深呼吸能实现吗&#34;&gt;不扩张就“内卷”，西方文明的“第四次深呼吸”能实现吗？&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;德国历史学家兰克有一个观点，他把西方文明的兴起总结为“三次深呼吸”&lt;/strong&gt;。第一次是罗马帝国晚期的蛮族入侵，就是今天美、英、法、德这些国家的祖先，都是从大森林里边涌出来，然后占领了罗马帝国，夺取了大量的土地。第二次是基督教国家发起的十字军战争，夺取了东方的大量财富和技术。第三次是大航海时代，他们占领了美洲、大洋洲土地资源。我们回望西方文明的每次大发展，它有它非常值得我们学习的东西，但是总体上它是靠向外扩张、转嫁矛盾和释放内部压力而实现的。现代资本主义和科学技术、工业化也都是在掠夺剥削全世界的基础上开启的。可以说，离开了扩张，西方文明就失去了很大一部分生命力。这“三次深呼吸”它之间的间隔都差不多是五百年。今天又快到五百年了，美国所代表的西方文明已经陈陈相因、积重难返，面临着一个不扩张就“内卷”的两难抉择。而从地理上看，今天地球上几乎唯一的扩张空间，就剩我们中国了。&lt;/p&gt;
&lt;p&gt;然后我们再看除了地理维度，还有没有其他的扩张空间呢？其实是有的，从二战后到上世纪80年代，美国人开启了计算机、互联网、信息技术的时代，引领了人类文明的新探索，包括太空的探索，这本来是有可能成为西方文明进行“第四次深呼吸”的新边疆。但是由于美国国内资本的贪婪和傲慢，美国走上了一条金融化、虚拟化、空心化的邪路，最后是1%的资本家抛弃了99%的人民，使西方文明内部也产生了停滞和分裂。今天虽然有马斯克、扎克伯格这样的一些具有开拓、探索精神的企业家，但是在金融资本的逻辑下，他们不仅不大可能给腐朽的美国社会注入生机，反而有极大的可能，会沦为靠编故事来“割韭菜”的金融资本家，或者是运用资本和技术来统治社会的野心家，就像Facebook现在搞成叫“元宇宙”了。&lt;/p&gt;
&lt;h3 id=&#34;美国要如何探索真正的民主道路&#34;&gt;美国要如何探索真正的民主道路？&lt;/h3&gt;
&lt;p&gt;近几年有一个网络用语叫“费拉不堪”，这个词是形容人落魄而没有斗志的这种样子。这个词是来自于英语，最早是来自于阿拉伯语，叫Fellah，它是指一个国家或者一个文明，衰败之后人民的那种状态，今天我们看美国人的精神状态，其实就在越来越走向这种Fellah，这种“费拉不堪”的路上。&lt;/p&gt;
&lt;p&gt;与此同时，我们中国人经过几十年的艰苦奋斗，后发先至，在主要的方面，我们现在基本上都赶上西方了。这个时候，美国人就发现自己这“第四口气”明显喘不动了。地理上没有地方扩张了，然后新领域新空间，遇到了中国的竞争，然后它想通过“民主化”来对我们进行分化、进行剥削，这个计划也破产了。美国的统治集团，它会认为自己遇到了一个两难选择，哪两难呢？第一是我干脆改掉依赖“吸血”来生存的恶习，放弃霸权，回归平凡，但是这条路是他们非常不愿意走的。第二条就是孤注一掷，对中国搞各种无下限的攻击手段。这是我们当前面临的一个最大风险。&lt;/p&gt;
&lt;p&gt;其实，我认为美国还有一条路，但这条路可能属于美国人民，而不属于这个腐朽的统治集团，那就是探索真正的民主道路，真正保障人民的权利和利益，改革陈腐的选举代议制度，废除私权绑架的这种黑暗司法和美联储制度，建立有权威、有能力、负责任的政府，集中精力去防治新冠疫情，去救援龙卷风的受灾地区，去重建那些破败的基础设施体系，消除城市里的贫民窟，消除暴力和犯罪，清除种族歧视和身份政治，促进人民共享的科技创新和工业生产。另外就是在国际上和中国合作，与世界和解，我们共同来探索人类的新边疆。习主席讲过一句话，说太平洋足够大，容得下中美。其实在今天这个新科技、数字世界和外太空，我觉得它更是足够大，足以容得下全人类的共同利益。所以我希望美国人也能够认识到这一点，能够想清楚，选择一条真正符合自己利益和人类共同利益的道路。&lt;/p&gt;
&lt;p&gt;好，谢谢大家！&lt;/p&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;&lt;a href=&#34;http://www.gov.cn/zhengce/2021-12/04/content_5655823.htm&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;国务院新闻办公室4日发表《中国的民主》白皮书&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://www.fmprc.gov.cn/web/zyxw/202112/t20211205_10462534.shtml&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;外交部5日发表《美国民主情况》报告&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;</description>
    </item>
    
    <item>
      <title>【跨年演讲】温铁军：为什么我对中国2022年的经济前景保持乐观？</title>
      <link>https://bowenei.gitee.io/post/wen-tiejun-annual-speech/</link>
      <pubDate>Sat, 01 Jan 2022 11:33:32 +0800</pubDate>
      <guid>https://bowenei.gitee.io/post/wen-tiejun-annual-speech/</guid>
      <description>&lt;p&gt;2021年已经过去，2022年也已到来。在庆祝新年的同时，著名三农问题专家温铁军教授仍然十分关心中国的宏观经济。为此，温教授为国际会议提前预录的跨年演讲，从三个方面解释他对中国明年的经济形势保持乐观的原因。&lt;/p&gt;
&lt;p&gt;本文是温铁军教授跨年演讲的原文（详见下方视频），不代表本文作者观点。&lt;/p&gt;
&lt;iframe src=&#34;//player.bilibili.com/player.html?aid=252789197&amp;bvid=BV1FY411a7aZ&amp;cid=474169055&amp;page=1&#34; scrolling=&#34;no&#34; border=&#34;0&#34; frameborder=&#34;no&#34; framespacing=&#34;0&#34; allowfullscreen=&#34;true&#34; width=&#34;100%&#34; height=&#34;480&#34;&gt; &lt;/iframe&gt;
&lt;p&gt;大家好，我是温铁军。现在是我们2021~2022的跨年之际，我在中国的北京向大家问候新年好，同时也想就人们广泛关注的几个重大问题跟大家做一个交流。&lt;/p&gt;
&lt;p&gt;首先应该说的是中国的经济发展，很多国际组织包括中国国内的很多学者都在预测，因为2021年是中国最近这10年经济增长速度相对比较低的一年，或者甚至被人说成是经济增长速度下滑到最低的这一年，所以人们往往会认为2022年中国经济的发展前景堪忧。我倒是相对来讲还比较乐观一点，这个乐观产生于客观分析，是因为大家应该知道在2020年，我们因为遭遇到疫情的影响，同时也遭遇到全球经济增长下滑，也遭遇到上一轮贸易制裁所发生的后续影响。&lt;/p&gt;
&lt;p&gt;实际上在多重影响之下，2020年就是上一个年度，我们曾经出现过300多万家个体经济注销，40万家股份制公司注销2500万沿海的打工者失业等等，就是各种各样的问题，实际上已经在2020年发生过。在2021年应该说从就业的情况看，并没有那么明显，尽管仍然有相当一批的企业注销，但是它的严重性似乎还不及2020年。从发生问题的情况看，应该说不是突发的，而是一个不断演变，甚至是可以说是一个危机延续的过程。&lt;/p&gt;
&lt;p&gt;我们接着要看这是个什么危机。我们的看法经过很多讨论，我们认为现在的危机是全球过剩，全球的产业资本和金融资本都是过剩的，对中国来说就是中国实际上现在深陷于融入全球经济一体化所必然发生的受全球过剩影响的中国过剩，因为中国体量过大，所以中国的过剩某种程度上又是全球过剩的一个部分。&lt;/p&gt;
&lt;p&gt;我记得早在20年前，2000年，我在约翰霍普金斯大学有一次做讲座。当时给我主持讲座的是著名的阿瑞基，他当时对中国的发展也是充满疑惑的，20年前我就曾经跟他讨论过，我说因为1997年的东亚金融危机爆发，中国1998年就已经表现为第一轮受外部的影响外部因素影响而形成的国内的生产过剩。&lt;/p&gt;
&lt;p&gt;那么到2020年世界范围内的问题并没有从根本上得到缓解，所以说如果中国携带的自己的生产过剩的问题，加入到本已过剩的全球化，你认为会是个什么趋势？是全球绿化还是全球优化更好还是更差？&lt;/p&gt;
&lt;p&gt;我们现在20年过去，这个问题仍然客观存在，所以我的看法是中国目前所遭遇到的主要问题，仍然是和全球过剩几乎同步的，中国过剩只是因为中国体量过大，所以中国的过剩以及过剩条件下出现的经济增长下滑，应该是一个客观的演化过程，大可不必太重的来看中国已经出现的这些问题在2022年的演化，这是一个客观分析。&lt;/p&gt;
&lt;p&gt;我们接下来再看，其实大家很少注意，从2020年的中央五中全会到2021年12月份的中央经济工作会议，对宏观经济的分析，以及对于宏观经济调控所采用的这些政策话语，其实正在静悄悄的发生变化。有一个很重要的变化，大家可能不太关注。就是中国明确指出了以往面对危机的逆周期和跨周期的调节，他的经验过去是有效的，现在仍然是有效的。&lt;/p&gt;
&lt;p&gt;现在跨周期调节的一个很重要的表现就是我们提出了7万亿的乡村振兴的投资计划，很少有人意识到这是什么，如果大家愿意比一下的话，你们可能会知道这个美国县政府提出了一个投资来拉动基本建设的计划是1万多亿美元，1万多亿美元的刺激计划，正好跟中国现在提出的7万亿人民币的乡村振兴投资的计划可以大致在数额上相等。&lt;/p&gt;
&lt;p&gt;如果我们再稍微往前比较一下，大家可能知道2008年当美国遭遇到金融危机的时候，华尔街金融海啸爆发的时候，美国提出的是奥巴马的所谓量化宽松，4万亿美元救市，当年美国救的就是金融资本，中国当时也提出了4万亿人民币的救市计划，而中国的投资从2008年当年的投资主要投向了实体经济。&lt;/p&gt;
&lt;p&gt;所以从十几年前的情况看，和现在的情况看呢双方各自都有几乎相同规模，当然当年4万亿美元比4万亿人民币要大得多？大6~7倍，但是美国当年的投资投向了金融资本，当然还有大量的财政是投资了投到了战争，所以美国的投资投到的是方向上跟中国不同，中国是一直坚持投资实体经济。&lt;/p&gt;
&lt;p&gt;所以从那个时候开始呢应该说中国在十几年前大规模投资实体经济形成的不仅仅是一般建设，而是城市化的高速增长。在短短的十几年的时间里边，中国的城市化率已经达到了63%左右，现在可能达到64%，实际上它吸纳了大量的投资形成的这个更多的是实体的资本，我们把它叫做physical assets，实体的资本很大程度上是可以直接用于跨周期的经济增长的。&lt;/p&gt;
&lt;p&gt;我们现在用于乡村振兴的投资，其实是又一轮新的跨周期的投资调节，7万亿投下去，很大程度上是能够把以前这20年，无论是新农村建设还是脱贫攻坚等等，这些国家战略已经投到农村所形成的设施性资产，进一步用乡村振兴的产业投资把它激活，就是上一轮所形成的投资的资产，是一个大规模的资产存量，可以用这一轮投资把它激活。&lt;/p&gt;
&lt;p&gt;所以大家应该关注一下，中国在它的面对经济下滑所采取的宏观调控的政策思想上，已经有了一些和一般的。西方的分析家们所看到的情况，不同的新的动向，这恰恰是下一个年度乃至于下一个经济发展周期，可能会成为新的经济增长点的主要政策因素。我们应该再以一个数字，大家也知道，最近这20年其实是20多年，我们从1997年遭遇到东亚金融危机以后，那次生产过剩提出的就是投资拉动，投资拉动已经是20多年了，98年开始我们提出了一系列投资拉动的计划，无论是1999年提出的西部大开发，还是2001年提出的东北振兴，还是2003年提出的中部崛起，还是2005年提出的新农村建设那十几年一，差不多每两三年有一个大的投资计划推出来，这些年已经形成的总的资产规模，按照国家发改委和国家统计局给出的数据应该在1300万亿以上，这个数值应该相当于200万亿美元的设施资产，这些资产其实就是跨周期投资所形成的巨额的可开发的可激活的资产。&lt;/p&gt;
&lt;p&gt;如果我们说中国转向生态文明，转向乡村振兴，大家也都知道乡村是承载生态文明的，生态化要依靠对乡村的投资和发展，如果从这个角度来看，我们对中国经济未来的增长寄希望于战略转型带动跨周期调节的投资，激活原有的大规模投资形成的设施资产，形成中国经济增长的主要动力。当然这还包括着如何把现在中国正在热议的两山也，就是绿水青山就是金山银山，它其实指的是空间、生态、资源价值化实现的这样一个过程，能有大量的这些，比如说可以用于吸碳的林木、土壤等等这些，如果有机的立体化的开展，农业生产把它变成循环经济，对中国来说调整将会在未来的一段时期里边，成为中国经济增长的重要的基础性的动力来源。&lt;/p&gt;
&lt;p&gt;所以我们一般情况下，大家看到的是中国经济的下滑，但很少有人看到中国正在做的跨周期调节，某种程度上是支撑我们现在的发展战略转型的。因此中国承诺的对中国对国际社会所承诺的碳减排，包括这次在格拉斯哥跟美国签署的联合宣言，都不是空穴来风，都不是无源之水，无本之木，它是跟整个向生态化做战略转型的这些政策安排，以及投资的安排是直接相关的。&lt;/p&gt;
&lt;p&gt;从这个角度来说，我希望大家理解在战略转型时期一定是有某种代价的。就是说原有的城市化的发展方式，工业化和城市化叠加的发展方式，恐怕因向生态化向乡村发展这个战略转型而一定程度上有所下降，这是正常的。&lt;/p&gt;
&lt;p&gt;特别是当大家都知道我们现在房地产业所发生的问题，大家也都看到各种各样的爆雷在不断的出现这些问题，又像极了。美国人在2007年的房地产业出现危机而形成的所谓、次贷，因为它是一个自由资本的金融控制，所以它转向金融危机。中国现在正在让这些向次贷发展的，向次贷危机发展的这些房地产的虚拟化扩张的这些公司出现收缩，它带有某种程度上的自主调节，主动调节，因此很有可能会形成在战略转型时期出现的一些损失。&lt;/p&gt;
&lt;p&gt;但这些损失和战略转型所带来的正向收益相比，应该说还是可以容忍的，我们在跨年之际，希望大家关注的第二个问题，应该说也还是一个比较积极的层面，是因为经过了抗疫的考验，中国人现在应该说自信的感觉是明显增加了。&lt;/p&gt;
&lt;p&gt;如果我们跟其他的大国来比，无论是美国还是俄国，应该说中国是在这两年的抗疫过程中，相对而言最值得去总结经验的国家，因为我们的死亡率是最低的，我们的确诊率也是最低的，人口是世界最大，但是总量就是绝对数我们是最低，如果按照人口的比重来算算，人均这几乎就在世界抗疫问题上是个奇迹，了那主要原因是什么？&lt;/p&gt;
&lt;p&gt;我觉得其实大多数中国人都会感到，这是因为我们所采取的措施相对而言还是比较有效的，但是很少有人关注，其实中国人更多的增加了自信的原因，恐怕还和什么有关？&lt;/p&gt;
&lt;p&gt;和我们有广大的乡村有关，和中国是一个超大型的大陆国家，它的地理资源气候条件都相对而言更复杂，我们有一半左右的人实际上还生活在农村，这些人几乎是在零成本抗疫，也就说抗疫的成本在城市，它恐怕需要有更多的靠医疗队伍，靠建立医院，靠增加医疗设施等等，这些是高成本的。&lt;/p&gt;
&lt;p&gt;而你在农村，我们说到现在为止，我们生活在农村的人口既没有抗疫的设施，也没有抗疫的队伍，大家你如果到中国农村地区去看看，你会发现人们该干什么干什么，也没有什么必须戴口罩才能怎么样。&lt;/p&gt;
&lt;p&gt;所以如果说是真的实现了完全自主化的去面对疫情，而且是很从容的面对疫情的，应该说是在农村地区，为什么？是因为农村地区至今仍然还属于一种自然经济和自然生存，只要和大自然紧密结合，你就能够有效的防止疫情的爆发。&lt;/p&gt;
&lt;p&gt;所以我们看其实在世界上大多数国家疫情主要爆发在城市，而又主要爆发在城市中的人口高密度地区。&lt;/p&gt;
&lt;p&gt;所以从这个角度来看，中国现在加强乡村建设，加强乡村振兴，加强对乡村的投资等等，我们其实不仅是在做跨周期的调节，某种程度上也是在巩固中国面对这样一个因人类的过度活动而导致的资源地理气候条件各个方面的变化乃至疫情的变化，应该说这是有跨周期作用的。&lt;/p&gt;
&lt;p&gt;所以第二个方面，我觉得如果简单说一下，中国人的自信在增加，某种程度上是在抗疫这件事情上，或者在疫情爆发的应对措施的这件事情上，我们有很多内在的优势，或者有很多条件还没有被国际社会所广泛认识，更为重要的大家可能也应该有所体会了，就是其实用中药来对付疫情，比用西医西药的方式更有效，这些在中国国内已经有很多报道了，我就不重复了。第三个方面在跨年之际要向大家交代的，就是很少国际社会很少有人注意的，我们已经完成了脱贫攻坚实现全面小康的历史任务，这一点恐怕也很少有人认真关注。&lt;/p&gt;
&lt;p&gt;我们想强调一下，其实脱贫攻坚这个历史任务的完成和中国做逆周期调节又有关，我们甚至可以把它说成是国家承担了重资产投资的责任和资产投下去所形成的风险，也就说，责任和风险都是由国家承担的，因为国家可以发债，所以国家承担的责任和风险可以向后延期，那就不是要马上支付的。而随着后续的发展，比如说经济增长出现了高潮，乃至于带动一定的通货膨胀，就把前面已经投资所形成的这些债务相对而言就淡化了。&lt;/p&gt;
&lt;p&gt;所以应该说在一些重大的战略问题上和公共开支问题上，这只要是大国，只要它的财政税收体制是相对有效的，并且像中国这样财政税收跟金融体系，其实是某种程度上具有互相呼应的结构性作用的，它就能够把贫困地区贫困乡村贫困户所不可能承担的，靠重资产投资才能提升产业层次，才能获得收入增加才能。&lt;/p&gt;
&lt;p&gt;减贫就把这个责任不是由他们这些弱势地区贫困村和贫困户承担，而是由政府来承担中国脱贫攻坚的成功，乃至于中国在2020年到2021年完成了所以实现全面小康的世纪任务或者我们叫历史任务，很大程度上靠的就是这种所谓举国体制，以国家不是别的，而是国家承担了欠发达地区，贫困乡村和贫困农户自己不可能形成的资本投资能力，国家承担投资能力，同时国家承担了投资风险，因此就是贫困乡村和贫困户可以零风险的获得投资收益最大化，但它并不就并不做投资，这个投资国家会把80%的投资所形成的资产交给贫困乡村，这样就等于是贫困乡村不投资，却获得了国家投资所形成的设施资产，这样就可以使贫困乡村叫做轻资产的形成了重资产的结构。&lt;/p&gt;
&lt;p&gt;贫困农户则可以零资本的介入到重资产经营这样一套机制，我想也应该是我们在跨年之际，像世界上其他的各个国家，特别是有反贫困任务的国家，介绍的一个中国脱贫攻坚的经验。&lt;/p&gt;
&lt;p&gt;好了，我的发言就到这儿，谢谢大家。&lt;/p&gt;
&lt;p&gt;再次祝各位新年快乐。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>美式反恐 越反越恐</title>
      <link>https://bowenei.gitee.io/post/china-now-124/</link>
      <pubDate>Tue, 07 Dec 2021 14:06:44 +0800</pubDate>
      <guid>https://bowenei.gitee.io/post/china-now-124/</guid>
      <description>&lt;p&gt;复旦大学中国研究院院长&lt;a href=&#34;http://www.cifu.fudan.edu.cn/14/1d/c521a136221/page.htm&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;张维为&lt;/a&gt;教授认为，美国发动的所谓“全球反恐战争”带来的越反越恐这样一种局面，背后是美国这个国家缺少智慧。&lt;/p&gt;
&lt;p&gt;复旦大学中国研究院特邀研究员、上海社会科学院宗教所宗教学研究室主任&lt;a href=&#34;https://irs.sass.org.cn/2021/1025/c6253a129669/page.htm&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;邱文平&lt;/a&gt;在&lt;a href=&#34;https://www.bilibili.com/bangumi/play/ss26421&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;《这就是中国》第124期&lt;/a&gt;节目上做了精彩且犀利的演讲。本文是邱主任在节目中的演讲原文，不代表本文作者观点。&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;一般人理解的恐怖主义是西方话语霸权的产物&#34;&gt;一般人理解的“恐怖主义”是西方话语霸权的产物&lt;/h3&gt;
&lt;p&gt;我下面第一个想谈谈恐怖主义的定义，这个是很重要的。我们现在一般人理解的恐怖主义实际上是西方所主导的，我们大家约定俗成会这样来认为。但其实这是一个西方话语霸权的产物。&lt;/p&gt;
&lt;p&gt;1972年慕尼黑奥林匹克运动会上发生了11个以色列运动员被杀的恐怖事件，这一事件是现代恐怖主义兴起的坐标，但对此西方国家和第三世界国家代表在联合国关于“恐怖主义”（定义）产生一场激烈争论。&lt;/p&gt;
&lt;p&gt;当时的联合国秘书长瓦尔德海姆提议说，对于世界上到处发生的恐怖主义者的暴力行为，联合国不能再当“沉默的观众”，应当采取实际的步骤，以防止更多的流血。联合国的多数西方国家是支持秘书长的建议的，但却遭到了很多亚非拉国家代表的反对。他们说为了从外国压迫和剥削下获得自由而战的人们，有权自己决定使用包括暴力在内的一切方法。许多发展中国家代表认为“恐怖主义”一词不能够适用于那些反对外国占领的国家和被剥夺了基本的人权和尊严、自由和独立的人们。&lt;/p&gt;
&lt;p&gt;所以这一点就可以看到“恐怖主义”定性，它其实是一个政治立场问题，而没有一个放之四海而皆准的标准。&lt;/p&gt;
&lt;p&gt;如果我们真正要根据定义来追究一下恐怖主义的话，就会发现最早的恐怖主义其实是中世纪欧洲天主教世界对伊斯兰世界发起的十字军东征。它的口号我们都很清楚，就是从穆斯林这种异教徒手中解放圣地耶路撒冷，这种打着宗教旗号进行的意识形态战争，是一场延续300年的国家恐怖主义行为，我认为这才是恐怖主义最早的开端，因为它是以意识形态和宗教信仰为其导向。&lt;/p&gt;
&lt;p&gt;当代西方认定的恐怖主义一样是发端于穆斯林极端分子对以色列的袭击，“慕尼黑惨案”和以后诸多以色列飞机的被劫持，其实完全改造了现代国际体系的安全观。在这之前，我们乘客坐飞机是不需要安检的，所以对于以色列和西方国家来说，这种对平民和民用交通工具的袭击当然是彻头彻尾的恐怖主义。但对伊斯兰世界的穆斯林来说的话，以色列就是西方现代版“十字军东征”的产物，是帝国主义强加在伊斯兰世界的霸权主义和殖民主义的产物。客观地从伊斯兰世界的角度来看看伊斯兰怎么来看待恐怖主义定义的，可以给我们一些反思的机会。&lt;/p&gt;
&lt;h3 id=&#34;伊斯兰世界如何看待所谓恐怖主义&#34;&gt;伊斯兰世界如何看待所谓“恐怖主义”？&lt;/h3&gt;
&lt;p&gt;我们也可以从历史角度来分析。伊斯兰世界对所谓“恐怖主义”的心态，对美欧这种根深蒂固的仇恨和戒心，造就了恐怖主义的强大的民意基础。从19世纪以来，伊斯兰世界进入衰退的过程，到第一次世界大战结束，伊斯兰世界普遍变成了殖民地、半殖民地，遭到了空前的失败。广大的穆斯林普遍怀有深刻的羞辱感和复仇欲望。所以对于冲突上千年的伊斯兰教世界和基督教世界而言，基督教世界暂时处于优势，但是广大的伊斯兰国家随时准备卷土重来。&lt;/p&gt;
&lt;p&gt;第二点我们就看看伊斯兰世界的“西化政府”，无论是亲美还是反美，它实际上都对美国怀有深深的畏惧，这种以实力为基础的丛林社会的法则，深深地烙在了一神教国际体系之中，造成了许多斯德哥尔摩综合征患者，就是这种被迫害者，反而对美西方产生了崇拜和信赖。亲美的伊斯兰政府和民众自然会将美国视为“天堂”和“灯塔”，会认为恐怖袭击只会带来美西方的报复，进而否定其合法性。&lt;/p&gt;
&lt;p&gt;还有一个更大的问题是对他们的威胁，宗教极端主义恰恰就是反对这些“西化政府”。恐怖袭击实际上是在和“西化政府”争夺民心，他们的意图是颠覆这些媚美、亲美的世俗政府。而对于操弄宗教极端主义，纵容恐怖袭击的少数政府和少数的群体的话，它其实也无异于在玩火自焚。因为宗教极端主义是高度危险的思潮，它的洗脑功能是异常强大的，行为只会越来越极端，最后的结果就像打开了潘多拉魔盒。&lt;/p&gt;
&lt;p&gt;阿富汗发生了清真寺大爆炸，回答了恐怖分子执政之后的问题。塔利班执政之后，“伊斯兰国”就给它更极端的一个回应，就是有更加极端的宗教极端主义和恐怖分子兴起，所以这就成为了永无休止的，直到只剩下一个人生存的世界。从这点来说的话，对恐怖主义的定义和认知是一个多重标准博弈的过程，立场不同，定义可以完全相反。&lt;/p&gt;
&lt;h3 id=&#34;滑天下之大稽侵略者号称建立天堂般民主社会&#34;&gt;滑天下之大稽：侵略者号称建立天堂般民主社会&lt;/h3&gt;
&lt;p&gt;所以我们就要提，美国反恐为什么会以如此狼狈的结局收场。主要是美国反恐完全用错了方法。第一点我认为是美国侥幸获得“冷战”胜利之后，觉得我要将所谓的“民主”普及到全世界，这种“普世主义”的扩张其实沿袭了十字军东征的宗教战争的思路，差别只在于它用更加具有迷惑性的“民主”新瓶代替了“上帝”老梗，其手法依然是武力传教的模式，大家可以去思考一下。&lt;/p&gt;
&lt;p&gt;还有一个，美欧一直有居高临下的殖民者的心态，老欧洲殖民主义者曾经把整个世界都变成它的殖民地，它有一句名言，You cannot speak on behalf of yourself，就是说你不能够代表你自己，下半句就是说，你只能被我所代表，这是一种非常深刻的傲慢的种族主义和优势文明的心理。而美西方这种极其傲慢的传教方式，必然被所在国人民认为是侵略者。&lt;/p&gt;
&lt;p&gt;一个意图毁灭伊斯兰文明的元凶，一个催生了宗教极端主义的始作俑者，居然在伊斯兰世界反恐，号称“要启蒙野蛮民族，建立新的天堂般的民主社会”，这不简直是滑天下之大稽吗？&lt;/p&gt;
&lt;p&gt;现代国际体系在美西方主导下建立，它本质内核就是社会达尔文主义，是弱肉强食的丛林社会，所以说无论美西方如何舌灿莲花，巧言令色，吹嘘着多少“民主人权和自由”，其本质还是秉承了基督教排斥其它文明，只承认自己文明神圣性的弊病，是一种傲慢的唯我独尊，非此即彼的帝国主义精神。他们从来没有中国传统上所谓的“远人不服，修文德以来之”的精神，所以不可能有合作共荣、共同发展的人类命运共同体这种概念。他们所擅长的只有“强则盗寇，弱则卑伏”强权即真理的弱肉强食和所谓“分而治之”之类的离岸平衡权术。所以他们所谓的“普世主义”只是帝国扩张的借口和侵略掠夺的手段罢了。&lt;/p&gt;
&lt;p&gt;这样的世界观必然导致他们绝不会反思自己的问题，完全没有意识到自己才是最大的恐怖主义制造者，甚至是恐怖主义本身，其反恐思路和路径也必然是反人类的。&lt;/p&gt;
&lt;p&gt;美西方在阿富汗犯下的反人类罪，战争罪和屠杀罪就是最充分的证明，他们在阿富汗耻辱的失败，也证明了这种打着反恐旗号对其他种族其他文明进行侵略，进行改造是一种非正义的荒诞行为，注定是徒劳无功的。&lt;/p&gt;
&lt;p&gt;在美国狼狈逃离阿富汗的同时，新疆已经近5年没有发生任何暴恐事件，这其实是，中国文明和制度的巨大胜利。&lt;/p&gt;
&lt;h3 id=&#34;缺乏实践美西方反恐失败是其文明的失败&#34;&gt;缺乏实践：美西方反恐失败是其文明的失败&lt;/h3&gt;
&lt;p&gt;从我个人角度来说，我们从民族宗教的学术研究领域就可以看出面对许多具体的民族宗教问题和暴恐袭击的困局的时候，你才发现西方这些理论只是看上去很美，这些完美的理论遇到千差万别的现实问题的时候，是比玻璃还要脆弱的花瓶，它不仅不能够解决问题，反而加剧了民族地区宗教情况的思维的混乱，让各种民族宗教问题更加严重了。所以说最终我们在实践中发现，从实践中来到实践中去，用实践检验理论的马克思主义的世界观和方法论，才能真正地解决问题。&lt;/p&gt;
&lt;p&gt;而美西方后现代社会的一种狂乱的理论，其实只适合他们那种丛林社会，而美西方用他们那套殖民主义理论来看待中国时候，对新疆进行污名化是自然而然的结果。因为在他们看来少数民族就像美国的印第安人一样，就应该是动物园里的动物，保持他们原始的生存状态，让“高贵的”WASP（美国白人新教徒）参观就行了。&lt;/p&gt;
&lt;p&gt;用西方一位很著名的女影星对叙利亚难民说的话，说他们一无所有了，但是他们“自由”了，所以我经常觉得这个人是可以无耻到这种地步的，所以新疆的反恐事业和民族融合的双重伟大成功，居然被污名化为“种族灭绝”，足见西方话语霸权之强劲，而很少人反思美西方在阿富汗的彻底失败其实是其文明的失败，人类命运共同体才是人间的正道。&lt;/p&gt;
&lt;p&gt;好，谢谢大家！&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>系统爆破西方话语体系</title>
      <link>https://bowenei.gitee.io/post/system-blasting-the-western-discourse-system/</link>
      <pubDate>Fri, 03 Dec 2021 11:08:41 +0800</pubDate>
      <guid>https://bowenei.gitee.io/post/system-blasting-the-western-discourse-system/</guid>
      <description>&lt;p&gt;毫无疑问，自新中国建立以来，特别是改革开放以来，中国的发展、进步举世瞩目，这充分证明了中国走出了一条适合自己的道路。然而，改革开放以来的相当长的一段时间里，我们的道路、理论、制度和文化却没有得到恰当的表达，不管是在国内还是国际社会，中国都长期面临着话语的赤字。&lt;/p&gt;
&lt;p&gt;特别是近年来随着互联网的发展，西方价值观肆意激荡，侵蚀着我们的政治观念、社会道德和文化自信。对于一般党员干部和广大善良而单纯的群众来讲，去判断各种文化现象背后所隐藏的政治立场和价值倾向是十分困难的。&lt;/p&gt;
&lt;p&gt;今天的中国已经是世界第二大经济体，中国崛起已经不可阻挡。不管中国多么低调，也没有办法回避西方金融资本的攻击。中国已经到了“狭路相逢勇者胜”的关头，要丢掉幻想，准备斗争。因此，今天中国应该理直气壮地建构和传播中国的政治学知识体系。&lt;/p&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    &lt;p&gt;&lt;strong&gt;特别鸣谢&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;本文根据复旦大学中国研究院副院长&lt;a href=&#34;http://www.cifu.fudan.edu.cn/95/39/c521a103737/page.htm&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;范勇鹏&lt;/a&gt;教授在 bilibili 上创作的相关视频进行整理，链接如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1yg411F7MF&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;【范神论】范勇鹏：谁在定义自由？人民，贵族还是资本家&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV19Q4y1z7Fh&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;【范神论】美国：中国善良、负责任、有道德，但他是个坏人&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV12u411f7wf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;【范神论】美国：我花了100年，让“民主”成为资本主义话语的一员&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1EU4y1w7Ag&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;【范神论】范勇鹏：当资本抛弃美国的时候，美国也就走上了解体之路&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1gv41137wa&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;【合集·收藏向】范勇鹏：教你如何爆破西方话术&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

  &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;相关完整视频如下：&lt;/p&gt;
&lt;iframe src=&#34;//player.bilibili.com/player.html?aid=251073544&amp;bvid=BV1gv41137wa&amp;cid=424911016&amp;page=1&#34; scrolling=&#34;no&#34; border=&#34;0&#34; frameborder=&#34;no&#34; framespacing=&#34;0&#34; allowfullscreen=&#34;true&#34; width=&#34;100%&#34; height=&#34;480&#34;&gt; &lt;/iframe&gt;
&lt;details class=&#34;toc-inpage d-print-none  &#34; open&gt;
  &lt;summary class=&#34;font-weight-bold&#34;&gt;Table of Contents&lt;/summary&gt;
  &lt;nav id=&#34;TableOfContents&#34;&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;a href=&#34;#绪论打破中国话语赤字&#34;&gt;绪论：打破中国话语赤字&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#西方话语的核心概念&#34;&gt;西方话语的核心概念&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#自由&#34;&gt;自由&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#法治&#34;&gt;法治&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#宪政&#34;&gt;宪政&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#西方炮制的攻击性概念&#34;&gt;西方炮制的攻击性概念&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#极权主义&#34;&gt;极权主义&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#威权主义&#34;&gt;威权主义&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#转型&#34;&gt;转型&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#被西方偷换扭曲而为其所用的概念&#34;&gt;被西方偷换扭曲而为其所用的概念&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#平等&#34;&gt;平等&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#民主&#34;&gt;民主&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#文明&#34;&gt;文明&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#被西方有意掩盖的概念&#34;&gt;被西方有意掩盖的概念&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#国家&#34;&gt;国家&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#规模&#34;&gt;规模&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#阶级&#34;&gt;阶级&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#共同体&#34;&gt;共同体&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#秩序&#34;&gt;秩序&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
  &lt;/ul&gt;
&lt;/nav&gt;
&lt;/details&gt;

&lt;h2 id=&#34;绪论打破中国话语赤字&#34;&gt;绪论：打破中国话语赤字&lt;/h2&gt;
&lt;p&gt;范勇鹏教授认为，要想打破中国话语赤字，建构中国话语体系，首先要推翻西方的话语体系，这就要求我们要系统解构西方的概念体系。那么，何为概念？&lt;strong&gt;概念&lt;/strong&gt;是理论和日常话语之间的一个连接点，沟通理论和常识的桥梁。&lt;/p&gt;
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /post/system-blasting-the-western-discourse-system/fig1_huee1b7ffebc7f5fdfff4510d9bfe9a72c_659280_f230b11c73bcbe65421eccb6c7026580.webp 400w,
               /post/system-blasting-the-western-discourse-system/fig1_huee1b7ffebc7f5fdfff4510d9bfe9a72c_659280_1f1617e8c35ba3fefd2067de5bcd1d53.webp 760w,
               /post/system-blasting-the-western-discourse-system/fig1_huee1b7ffebc7f5fdfff4510d9bfe9a72c_659280_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://bowenei.gitee.io/post/system-blasting-the-western-discourse-system/fig1_huee1b7ffebc7f5fdfff4510d9bfe9a72c_659280_f230b11c73bcbe65421eccb6c7026580.webp&#34;
               width=&#34;760&#34;
               height=&#34;412&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;p&gt;任何一个理论体系都是始于一些基本概念的，理论本质上是对这些现实的概念化解释。因此，在形式上理论必然表现为一系列相互关联的概念的联系。例如西方的民主化理论由如下相互关联的概念组成：&lt;/p&gt;
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /post/system-blasting-the-western-discourse-system/fig2_huf99c8040b89f31faf24c6cee60e1e370_832969_baa9e40b69b46771ca2c773cf4d5c898.webp 400w,
               /post/system-blasting-the-western-discourse-system/fig2_huf99c8040b89f31faf24c6cee60e1e370_832969_fd13490d1c4e9bc2426efbf10cffb6bf.webp 760w,
               /post/system-blasting-the-western-discourse-system/fig2_huf99c8040b89f31faf24c6cee60e1e370_832969_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://bowenei.gitee.io/post/system-blasting-the-western-discourse-system/fig2_huf99c8040b89f31faf24c6cee60e1e370_832969_baa9e40b69b46771ca2c773cf4d5c898.webp&#34;
               width=&#34;760&#34;
               height=&#34;412&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;p&gt;在我们的日常生活中，我们很难理解甚至去使用这些概念和理论。那么，只有那些教条化的、庸俗化的表达可以渗透进我们的日常生活中，比如说我们熟知的“自由”、“民主”。这些教条化的、庸俗化的表达的最大特点就是简洁。&lt;/p&gt;
&lt;p&gt;要解构西方话语的概念体系，首先我们要区分不同的概念类别。范勇鹏教授将西方概念分为如下四类：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;西方话语的核心概念&lt;/strong&gt;：自由、法治、宪政、程序正义、产权、契约、个人主义、公民社会、三权分立、权力制衡、政治多元主义&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;西方炮制的攻击性概念&lt;/strong&gt;：极权主义、威权主义、转型国家、转型经济、东方专制主义、文明冲突、历史终结&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;被西方偷换扭曲而为其所用的概念&lt;/strong&gt;：平等、民主、文明、进步&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;被西方有意掩盖的概念&lt;/strong&gt;：国家、规模、阶级、主权、共同体、秩序&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;西方在建构自己意识形态的时候最大的挑战就是历史的真相，正如中国台湾著名学者朱云汉所说：“西方学者对他们自身的历史诠释是选择性的，甚至是有意漂白”。西方建立起来的概念和理论体系的最大特点就是抽象，并且有逻辑支撑点。因此，解构西方概念体系的第一步是&lt;strong&gt;以具体对抽象，以历史对逻辑&lt;/strong&gt;，这需要我们建立起实事求是的科学的概念体系和知识体系，当然我们也需要抽象的、纯粹的概念的建构。&lt;/p&gt;
&lt;p&gt;然而，有这么一些人，他们认为没有必要解构西方概念体系，认为西方概念体系已经是数百年意识形态的结晶，可以直接拿来照搬，甚至事半功倍。范勇鹏教授反对上述观点，因为&lt;strong&gt;概念是逻辑的起点，是理论的支点&lt;/strong&gt;。如果不去颠覆他的理论体系，你就很难真正揭露他的知识体系。换而言之，用别人的锅是炒不好自己的菜的。&lt;/p&gt;
&lt;h2 id=&#34;西方话语的核心概念&#34;&gt;西方话语的核心概念&lt;/h2&gt;
&lt;p&gt;西方话语本质上是资产阶级的意识形态，因此他的每一个概念背后都有明确的阶级属性和利益指向。但是在过去西方的长期宣传下，这些概念都被中性化了，带上了一些诸如“普世”、“进步”、“文明”的面具。我们普通群众受此影响，在使用这些概念的时候，不知不觉地就会把这些概念当成是不可否认的大前提，或者说是一个客观的、公正的概念。例如，在绪论中提到的自由、法治、宪政、程序正义、产权、契约、个人主义、公民社会、三权分立、权力制衡、政治多元主义等等。范勇鹏教授在这里就自由这个概念进入深入剖析。&lt;/p&gt;
&lt;h3 id=&#34;自由&#34;&gt;自由&lt;/h3&gt;
&lt;p&gt;自由是西方意识形态最为核心的一个概念，也是最底层的一个概念，其他很多概念都是从自由推演而来的。人权、法治、宪政等等都是从自由推演而来的，然后形成了一个概念体系。例如《世界人权宣言》中有这样一段话：“人人生而自由，在尊严和权利上一律平等……”这其实就说明了人权是从自由这个概念中产生的。那么，人权如何得以保障呢？很明显法律是一个很好的工具，于是资产阶级开始强调法治。既然要法治，那么政府和权力如何约束？于是就有了宪政，最典型的例子就是美国的《1787年宪法》。&lt;/p&gt;
&lt;p&gt;为什么西方如此重视自由呢？范勇鹏教授认为有如下四点原因：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1. 西方历史上极其缺乏自由&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;现代自由其实是以个人的自由为出发点的，即个人主义。而在古希腊、古罗马是没有个人意识的。例如在古希腊，人的价值体现在人是城邦的一员。到了基督教时代，教会对人实行无差别的精神控制，人紧紧地依附于教会。如果不信教，在欧洲连生存的权力都没有。即使是推翻罗马教皇之后的近代，新教也还是控制着人。因此相较于中国而言，西方在历史上极其缺乏自由，中国不存在像西方这种教权对人的愚昧统治。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2. 蛮族带来的原始自由&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;基督教的产生实际上日耳曼等蛮族入侵过程中完成的，日耳曼等蛮族带来了这种天性自然的传统。这其实是今天西方自由的一个重要来源。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;3. 中世纪贵族的特权自由&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;西方封建制度的一个重要特点就是权力分层。对于国王来讲，他的权力不能穿透贵族。所以对于贵族来讲，他在自己的一亩三分地是十分自由的。这种自由在我们看来其实是一种特权。我们通过很多西方自由主义者的视角去看待那段历史会觉得欧洲中世纪是十分自由而美好的，但那种自由仅限于贵族。所以我们要学会思考的一点是，这样的观点是从什么人的眼睛里看到的？假如换成下层农奴，那么所谓的贵族自由根本不是自由，而是灾难。&lt;/p&gt;
&lt;p&gt;在封建制度下产生了很多和自由相关的制度，其实都和贵族有特别密切的关系，比如代议制就是典型的贵族特权政体。代议制的起源有多种说法，但归根结底是不同类型的财产权按照比例来分享统治权力的一个制度。今天很多人会认为议会制是民主制度的一个形式，实际上恰恰相反，代议制在历史上和民主没有任何联系。因此，今天的美国代议制民主实际上和中世纪的封建制度没有本质上的区别，就是一美元一票的制度。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;4. 资本主义的现代自由&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;资本主义是最需要自由的，它需要的是一种基于财产权的自由。现代自由的本意是私有财产神圣不可侵犯，金钱在市场上不受约束和干预。现代自由的核心问题是个人和国家的关系问题，换而言之就是是否允许或者多大程度上允许国家干预个人财产的问题。&lt;/p&gt;
&lt;p&gt;13世纪的欧洲出现了资本主义萌芽，这些新兴的商人追求发财致富，却受到了天主教的约束。于是他们首先要做的事情就是阶级斗争——打倒教会，从教权的统治下解放个人。但仅仅有了自由还不够，还需要法律、和平、国家等等一系列阶级统治的工具来保障。然而，今天的自由主义者反对国家的干预、主张小政府、分权、放权，这其实和当时资产阶级崛起的历史事实是相违背的。&lt;/p&gt;
&lt;p&gt;资产阶级对内利用国家的权力掠夺农民的财富，强迫他们进入工厂接受剥削，然后再建立起劳资自由的契约原则；对外利用国家的力量轰开别的民族的大门，把这些地方变成殖民地掠夺财富，然后再编造自由贸易、航行自由、国际法等等神话。国家主权这一概念其实也是这一时期产生的，本质上是服务于资本的，为帝国主义发动战争提供了合理性、合法性。而一旦国家权力集中到不受资本控制，产生不符合资本利益的独立意志时，资本就会不断地对国家的权力进行限制，其结果就是产生了我们今天所熟悉法治和代议制。这样以来，资产阶级的这种自由相较于国家的优先性变成了现代的“政治正确”，自由主义哲学就是为了论证其正确性的。&lt;/p&gt;
&lt;p&gt;综上所述，我们要把资产阶级自由的本质认识清楚：&lt;strong&gt;自由就是财产权，自由就是市场原则至上，自由就是资本的统治&lt;/strong&gt;。至于我们所以为的言论自由不过是包裹在自由概念之上糖衣，目的是为了让毒药更容易下咽。&lt;/p&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    &lt;p&gt;&lt;strong&gt;马克思主义与自由&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;马克思主义认为，人类追求自由的最高境界就是人类的解放。在共产主义社会中，每个人都能得到自由而全面的发展。&lt;/p&gt;
&lt;p&gt;毛主席在《关于正确处理人民内部矛盾的问题》一文中也指出：“在人民内部，不可以没有自由，也不可以没有纪律；不可以没有民主，也不可以没有集中。这种民主和集中的统一，自由和纪律的统一，就是我们的民主集中制。在这个制度下，人民享受着广泛的民主和自由；同时又必须用社会主义的纪律约束自己。”&lt;/p&gt;
&lt;p&gt;可见自由和约束、自由和纪律是具有辩证关系的，没有绝对的自由存在。资产阶级利用自由这一概念建立起资产阶级的意识形态，其根本目的是为了维护资产阶级的利益，巩固资产阶级的统治。&lt;/p&gt;

  &lt;/div&gt;
&lt;/div&gt;

&lt;h3 id=&#34;法治&#34;&gt;法治&lt;/h3&gt;
&lt;p&gt;澄清了自由的概念，我们就能够很容易认清法治的概念。自由概念直接导向了法治，因为一旦自由概念获得霸权地位，国家就沦为了财产权的代言人。资产阶级最乐意看到的就是市场的规则决定一切，因为这是他们最擅长的事情，于是市场的规则就被他们称为“法”，与所谓的公权力对立起来。这样一来，法治就成为了一个资产阶级创造的独立的生命，法治强调的这种程序正义就成了至高无上的正义原则。&lt;/p&gt;
&lt;p&gt;今天美国独立的司法本质上就是一种程序正义，但它的结果是不是公正就另当别论了。现代政治多元主义被描述成一种可以依据法治和程序原则允许多元利益在里边自由博弈的游戏，这个游戏看起来表面上是透明的，但实际上只有那些所谓成功的“个人”——资产阶级——才能赢。&lt;/p&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    &lt;p&gt;&lt;strong&gt;社会主义法治&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;我们知道，法治是社会主义核心价值观在社会层面的重要体现之一。法治是治国理政的基本方式，依法治国是社会主义民主政治的基本要求。它通过法制建设来维护和保障公民的根本利益，是实现自由平等、公平正义的制度保证。&lt;/p&gt;
&lt;p&gt;因此社会主义法治归根结底是保障人民的合法权益，而不是个别资本家和利益集团。&lt;/p&gt;

  &lt;/div&gt;
&lt;/div&gt;

&lt;h3 id=&#34;宪政&#34;&gt;宪政&lt;/h3&gt;
&lt;p&gt;法治本身其实也存在问题，比方说法治也会失控。列宁曾经指出，既然资产阶级发明了代议制来允许通过选举的方式获得国家权力，那么理论上无产阶级也就可以通过议会斗争来夺权，这实际上是一个漏洞。还有一点就是统治阶级内部的矛盾，如果矛盾不可调和后果也十分严重。&lt;/p&gt;
&lt;p&gt;因此，还需要一个在法治之上的最终的机制对它进行制约，这就是宪政。宪政的作用就是确保真正的权威还在资产阶级手中，也就是说最后一票能够反映资本的意志。&lt;/p&gt;
&lt;h2 id=&#34;西方炮制的攻击性概念&#34;&gt;西方炮制的攻击性概念&lt;/h2&gt;
&lt;p&gt;西方非常擅长凭空捏造或者改造利用而炮制出一些概念，用来攻击和污蔑自己的对手或者受害方。例如，绪论当中提到的极权主义、威权主义、转型国家、转型经济、东方专制主义、文明冲突、历史终结等等。这些概念本身大多产生于冷战或者冷战后，本身就带有对别国的污蔑和妖魔化。&lt;/p&gt;
&lt;h3 id=&#34;极权主义&#34;&gt;极权主义&lt;/h3&gt;
&lt;p&gt;极权主义本来是用来指纳粹德国和苏联，今天也被一些人用来影射中国。受极权主义影响，今天中国的知识分子以及学术界、新闻界等依然洋溢着充满极权主义的陈词滥调，首当其冲的要属南方系媒体。中国的集体主义文化和强政府传统，以及包括像文化大革命这样的一些历史时期常常被一些学者或者媒体或明或暗地给指为极权主义。&lt;/p&gt;
&lt;p&gt;事实上，极权主义恰恰是西方文明的独特产物。希特勒曾公开表示，集中营是学习美国的做法，其根源甚至还可以追溯到基督教、新教等这种政教合一的宗教控制。极权主义最一开始被西方国家用来形容意大利墨索里尼政府，即指代法西斯。上世纪30年代，由于斯大林发动“大清洗”，西方又给苏联扣上了极权主义的帽子。不过在二战前的一段时期里，纳粹德国对西方威胁更大，苏联是极权主义的观点在西方国家特别是美国并不占主流。而二战结束后，没有了纳粹德国的威胁，西方为苏联量身定制了一顶极权主义的帽子，甚至将法西斯主义和苏联模式划上等号。&lt;/p&gt;
&lt;p&gt;西方政治学家海耶克将极权主义同共产主义联系起来，切断了同资本主义的联系。他赋予这一术语以超历史的、抽象的涵义，使之成为一种无需解释的定式、思想代码和印记。我们平时读到的大量自由主义的东西，是不是特别喜欢端着一种无关利益、无关权力、无关历史、无关细节等抽象正义的原则？其实这是西方话语一个久经检验，十分有效的忽悠大法。实际上只有法西斯主义才是极权主义在历史上唯一真实的形态，而法西斯主义是资本主义的一个产物和变态。&lt;/p&gt;
&lt;h3 id=&#34;威权主义&#34;&gt;威权主义&lt;/h3&gt;
&lt;p&gt;所谓威权，汉语中习惯把它称作权威。实际上权威和威权在英语里其实是一个词 &lt;code&gt;authority&lt;/code&gt;，为什么会翻译成两个词呢？是因为国内一些学者为了和极权主义形成文字上的对仗刻意生译出来的。&lt;/p&gt;
&lt;p&gt;威权主义最初是用于西班牙、葡萄牙等右翼国家，这些国家属于准法西斯国家，就是说没有达到德国、意大利那个程度，但也是右翼独裁。（蒋介石的国民政府也可以认为是威权主义。）后来美国学者亨廷顿把威权主义泛化成一切不民主的政体，结果近年来威权主义的帽子越来越多地扣在中国的头顶上，而且国内很多学者都心悦诚服地接受了这个定义。&lt;/p&gt;
&lt;p&gt;基于此，国内政治学界形成了一大套“黑话”、“行话”，然后堆叠出了大量毫无意义的文献，不断地自我复制、自我增生、自我强化。范勇鹏教授在这里猛烈地抨击了这种“文献霸权”现象，他认为这浪费了许多学者无数的生命和精力，最终无异于为西方话语打工，丝毫不贴近中国的实践、中国的现实。&lt;/p&gt;
&lt;div class=&#34;alert alert-warning&#34;&gt;
  &lt;div&gt;
    &lt;p&gt;基于威权主义的概念特别多，例如“负责任的威权主义”，让人有种概念的排列组合的感觉。范勇鹏教授不禁反问：如果一个政府负责任，那还是威权主义吗？&lt;/p&gt;
&lt;p&gt;实际上，西方话语自始至终就是建立在语言腐败的体系上的。打个比方，明明张三是一个好人，但西方非要给他贴上一个坏人的标签，但是又编不圆。怎么办呢？只好不停地加自相矛盾的定语，说张三是一个善良的坏人。&lt;/p&gt;

  &lt;/div&gt;
&lt;/div&gt;

&lt;h3 id=&#34;转型&#34;&gt;转型&lt;/h3&gt;
&lt;p&gt;依据威权主义的定义，威权主义政府必然要走向民主化，再到民主巩固的一个阶段，这就是转型的概念。我们在境外社交媒体上会经常看到类似的言论，他们认为中国最终必然走向美式民主。&lt;/p&gt;
&lt;p&gt;转型这一概念源于苏东剧变时期。转型这一概念本身就隐含有西方对“正常国家”、“正常道路”的一个定义权。西方价值观认为，非西方制度的国家就不是“正常国家”，非市场经济的道路就不是“正常道路”，所有国家或早或晚必将走向西方。要特别警惕转型一词，它往往暗含着对中国制度和发展道路的否定。因此，要坚定“四个自信”，自觉抵制这样的概念和理论。&lt;/p&gt;
&lt;p&gt;历史是最好的教科书。看看最近的阿富汗的情况，包括所谓“阿拉伯之春”，应该能够证明转型的概念和美国政治学的破产。&lt;/p&gt;
&lt;h2 id=&#34;被西方偷换扭曲而为其所用的概念&#34;&gt;被西方偷换扭曲而为其所用的概念&lt;/h2&gt;
&lt;p&gt;被西方偷换扭曲的概念中有很多本身并不属于西方意识形态或者核心概念，有一些概念甚至是具有反西方、反资本主义色彩的，曾一度被西方价值观避之而唯恐不及。但是这些概念被西方偷换、扭曲、再造之后，逐渐为西方所利用，形成了表面上的逻辑一致。这些概念在历史上往往具有进步性、正义性的特征，往往更容易被人们接受，而忽略它们含义的转换，因此这类概念的欺骗性非常强。例如绪论当中提到的平等、民主、文明、进步等等。&lt;/p&gt;
&lt;h3 id=&#34;平等&#34;&gt;平等&lt;/h3&gt;
&lt;p&gt;中国是世界上最早实现人的平等的文明。秦汉之后，中国开始逐渐消除人身依附，实现人的平等。欧美俄这些地方则都是到19世纪之后才废除奴隶制或者农奴制。直到资本主义的产生和发展，西方才有了以财产的不平等取代过去出身的不平等。&lt;/p&gt;
&lt;p&gt;资产阶级成为统治阶级后，他们实际上不希望平等的这种观念再继续往更进步的方向推进了，于是他们处心积虑地把平等的概念给改造成在市场竞争中的平等。然而，实质的平等、结果的平等却被西方资产阶级不断污名化，甚至把它视作暴政、极权的要素之一。&lt;/p&gt;
&lt;p&gt;国内的一些公知同样也有类似的观念，例如满口不离“乌合之众”。在他们眼里，精英拥有少数派否决权才是高大上的宪政民主，而带有平等倾向的制度和政策就是民粹主义。&lt;/p&gt;
&lt;h3 id=&#34;民主&#34;&gt;民主&lt;/h3&gt;
&lt;p&gt;现代民主概念最初是具有平等主义倾向的，它是早期社会主义运动的产物，本质上是反资本主义的。社会主义民主包含经济民主、社会平等、集体主义等等内涵。&lt;/p&gt;
&lt;p&gt;因此，资产阶级肯定是不喜欢民主的，他们想方设法来制约民主。直到上世纪七八十年代，西方都很少称自己是“民主”，而是自称“自由阵营”。而当时苏联、东欧才说自己是“民主阵营”。西方是在苏联解体之后才把自己给装扮成民主，中国的70后、80后大都是在这一时期成长起来的，所以也就习惯接受了自由民主这一概念。&lt;/p&gt;
&lt;p&gt;19世纪末20世纪初的世界社会主义运动迫使资产阶级一步步地向无产阶级妥协，接受民主的诉求。西方资产阶级并不甘心，为了解构掉民主这一概念，他们用了将近100年的时间，不断阉割民主的含义，最后把它改造成一个程序性的工具。这里面的始作俑者就是奥地利经济学家熊彼特，他解构了民主的价值内涵，使民主不再成为社会主义特有的概念。他将民主视作手段，而不是目的。这一点与社会主义民主集中制、苏维埃完全相悖，也与我国的人民民主完全相悖。&lt;/p&gt;
&lt;p&gt;今天一提到民主，我们仿佛脑海里只有自由民主的概念。今天的民主是二战后社会科学的一块重要基石，几乎所有重要的理论都是以它为支点。如果我们推翻了西方的民主，几乎可以摧毁西方的政治学；如果我们盲目地去跟从它，那么我们中国自主的政治知识就无从谈起。&lt;/p&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    &lt;p&gt;&lt;strong&gt;社会主义民主&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;民主这一概念起源于世界社会主义运动，它通常和“集中”一词成对出现，即民主集中制。苏联全称“苏维埃社会主义共和国联盟”，这里面的俄语苏维埃 совет 的含义就是“委员会”、“代表会议”，是一种工人和农民的民主形式。&lt;/p&gt;
&lt;p&gt;今天的新中国也采用这一体制，就是这种民主集中制，或者说人民民主专政。中国的根本政治制度——人民代表大会制度，其核心是人民当家作主，是社会主义民主政治的实现形式。&lt;/p&gt;
&lt;p&gt;复旦大学中国研究院院长&lt;a href=&#34;http://www.cifu.fudan.edu.cn/14/1d/c521a136221/page.htm&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;张维为&lt;/a&gt;教授指出，我国的社会主义民主是一种&lt;strong&gt;实质民主&lt;/strong&gt;。不同于西方&lt;strong&gt;程序民主&lt;/strong&gt;的是，我国的实质民主指的是民主所要实现的目标，它应该是良政善治，是解决人民最关切的问题，是提高人民的福祉和尊严。如果比较中美两国的民主制度，张维为教授认为在程序民主上，双方都有很大的改进余地，但在实质民主方面，中国做的更好，好很多。&lt;/p&gt;

  &lt;/div&gt;
&lt;/div&gt;

&lt;h3 id=&#34;文明&#34;&gt;文明&lt;/h3&gt;
&lt;p&gt;文明本身指的是文字产生以后人类的生产生活方式。然而在18世纪，“文明”一词被塑造成一个特殊的含义，就是以西方国家为代表的西方商业化的社会组织模式。进而，所有的非西方文明就被贬低为“野蛮”。于是，文明和西方划上了等号。随着以美国为首的西方在二战中的胜利，西方文明开始征服世界，成功地影响到了世界上的很多人。西方文明于是被奉为“普世价值”。&lt;/p&gt;
&lt;p&gt;大家在网络上经常会听到公知们说“中国要融入世界主流文明”、“和世界接轨”，实际上暗含了一个逻辑就是西方是“文明”的而中国是“野蛮”的。公知们对近代以来中国人民反帝反封建的进步运动进行历史虚无主义的解构，例如将义和团说成野蛮。&lt;/p&gt;
&lt;p&gt;由于西方对这些概念的偷换、扭曲、再造相当成功，今天我们在使用这些概念的时候很少会意识到它们的本来含义，往往是人云亦云地在西方意义上加以理解，并用这些改造后的概念来评价中国。&lt;/p&gt;
&lt;h2 id=&#34;被西方有意掩盖的概念&#34;&gt;被西方有意掩盖的概念&lt;/h2&gt;
&lt;p&gt;我们有时候要观察西方不使用什么概念，回避什么概念，往往和研究它使用什么概念同等重要，甚至更为重要。例如绪论中提到的国家、规模、阶级、主权、共同体、秩序等等。&lt;/p&gt;
&lt;h3 id=&#34;国家&#34;&gt;国家&lt;/h3&gt;
&lt;p&gt;国家这一概念在资本主义发展的早期是十分重要的，资本需要国家的保护，需要国家允许开拓殖民地、进行奴隶贸易等等。民族国家就是西方资产阶级创造的一个重要概念，用以解构东欧的那些帝国（奥斯曼土耳其帝国、大清帝国）等传统的国家。&lt;/p&gt;
&lt;p&gt;实际上，谁掌握了国家的定义权，谁就掌握了正义、进步和道德的定义权。西方的话语霸权离不开西方对国家概念的定义权。&lt;/p&gt;
&lt;p&gt;后来随着资本主义的迅速发展，资本的活动范围已超越了国家。另一方面，马克思主义对国家的阶级属性分析入木三分，使得资产阶级很难从理论上反驳马克思主义。所以资产阶级不得不采取某种回避策略。还有一点原因是，西方本身对国家概念的定义也过于狭窄。&lt;/p&gt;
&lt;p&gt;于是，西方用一些词来指代国家的全部或者部分含义。当他们不得不谈及国家时，他们会对国家进行“降维打击”。比方说，我们看到西方媒体在谈及中国政府时的用词经常是 &lt;code&gt;Beijing&lt;/code&gt; 而不是 &lt;code&gt;Chinese government&lt;/code&gt;；而我国官方媒体在报道新闻时都是使用“美国”、“美国政府”等词汇，而不是“华盛顿”。这一点充分体现了西方致力于建构一种中立性、功能性、价值无涉的国家观念，把国家给降到一种纯粹功能性的层次，或者把国家分解成具体而微的政府、政党、地方政府。&lt;/p&gt;
&lt;p&gt;于是国家和公民社会变得二元对立起来，国家成为一种需要被警惕、被审判的状态。此外，他们还会用法治、宪政的概念来消除国家的政治性内涵，本质上是要对政府和国家权力进行约束。然而，西方资产阶级却闭口不提法是谁的法？程序是谁的程序？&lt;/p&gt;
&lt;p&gt;我们都知道宪法是国家根本大法，但是很多政治教科书对宪政的定义是依宪法治理国家。范勇鹏教授认为，这是一个典型的糊涂说法。我国也是依宪治国的国家，但是我们的宪法规定中国共产党领导，规定中国是人民民主专政的社会主义国家。但是很多法学公知却认为中国不是宪政，天天想着在中国建立西方式的宪政。这里面背后的逻辑是，只有资产阶级的宪法。所以像这样的教材只讲抽象概念，不讲谁统治谁，谁是统治阶级，这怎么可能讲得清楚？&lt;/p&gt;
&lt;h3 id=&#34;规模&#34;&gt;规模&lt;/h3&gt;
&lt;p&gt;实际上现代西方政治都还处在小规模阶段，即使是像美国这种联邦制国家以及欧盟这样的共同体依然不能算作是大规模。例如美国各州政府的自治权很高，各州的法律也有各有差异，欧盟内部也并不是绝对团结的，只是实现了货币上的统一和贸易的便利。&lt;/p&gt;
&lt;p&gt;因此，规模仍然是西方政治学的一个挑战。因而，西方学界并不愿意在政治领域谈及规模。研究市场、经济的人都知道，规模是一个非常重要的变量。范勇鹏教授猜测，西方不重视政治领域的规模问题的一个客观原因是与西方小规模传统有密切关系。不论是代议制还是联邦制，都是为了解决小规模国家如何变成大规模的。&lt;/p&gt;
&lt;p&gt;这样一来，不考虑规模问题，我们就很容易把大象和老鼠放在一起比较，把中国和新加坡放在一起比较，而且都没什么本质区别。这岂不是很荒唐吗？&lt;/p&gt;
&lt;h3 id=&#34;阶级&#34;&gt;阶级&lt;/h3&gt;
&lt;p&gt;阶级是西方话语体系特别不愿意触及的一个概念，因为马克思主义科学的阶级斗争理论是为埋葬资本主义而生的，对资本主义具有颠覆性的意义。&lt;/p&gt;
&lt;p&gt;于是，西方社会学制造了大量的模糊概念，例如“阶层”。他们按照人群收入的高低将无产阶级分为中高收入人群和低收入人群，于是创造出了“中产阶级”这样的概念，这其实与马克思主义的阶级斗争理论中的阶级完全不是一回事。这样一来就有了社会分层的概念，阶级概念于是被去政治化了，用纯粹的收入高低来掩盖财产和生产资料的所有权。&lt;/p&gt;
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /post/system-blasting-the-western-discourse-system/fig3_hu806960bd106afc45e09df0c6daaa5372_562729_eef2caf8f4656b3523f36efd0e35b184.webp 400w,
               /post/system-blasting-the-western-discourse-system/fig3_hu806960bd106afc45e09df0c6daaa5372_562729_1b0c0afa798eacf58e635fa78ed9f3e7.webp 760w,
               /post/system-blasting-the-western-discourse-system/fig3_hu806960bd106afc45e09df0c6daaa5372_562729_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://bowenei.gitee.io/post/system-blasting-the-western-discourse-system/fig3_hu806960bd106afc45e09df0c6daaa5372_562729_eef2caf8f4656b3523f36efd0e35b184.webp&#34;
               width=&#34;760&#34;
               height=&#34;412&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;p&gt;我们国内学界相当多的一批学者对阶级问题的认识受到了西方概念的影响。范勇鹏教授的一个硕士生开题时正值2016年美国大选，范勇鹏教授给他的硕士生的选题是《特朗普当选美国总统背后的阶级问题》。结果在开题的时候很多老师不同意，因为他们觉得美国不存在阶级问题——美国是典型的中产阶级社会。最后范勇鹏教授据理力争才得以成功开题。&lt;/p&gt;
&lt;h3 id=&#34;共同体&#34;&gt;共同体&lt;/h3&gt;
&lt;p&gt;共同体本是人类历史上普遍存在的一种现象，在经济上表现为财产的共同拥有和使用。随马克思主义传入中国后的一些词语诸如“共产主义”、“同志”等都和共同体一词有词源联系。&lt;/p&gt;
&lt;p&gt;然而，资本主义起源于英国的圈地运动。圈地运动的一个很重要的观念就是消灭传统的共同体的共有产权，确立资产阶级的私人所有制的制度。因而资本主义与共同体的概念在本质上是有矛盾的。但是西方资本主义又需要国家作为载体，需要国家这样一个阶级统治的暴力工具，需要美国的轰炸机。因此西方资本主义暂时还无法接受共同体的完全解体。&lt;/p&gt;
&lt;p&gt;二战后，西方产业资本和金融资本发生了两个阶段的重要转变。第一个阶段是1944年的布雷顿森林会议，确立了美元与黄金挂钩，其他货币与美元挂钩的金汇兑本位制度。第一个阶段是比较促进贸易自由的，而对金融自由有不少限制。第二个阶段是1971年美国总统尼克松宣布美元与黄金脱钩，金融资本开始走上了一个上升的轨道，到80年代的里根主义（新自由主义）——资产阶级自由化改革和金融自由化立法。苏联解体后，新自由主义在国际上表现为全球化、资本流动、产业外移。在美西方国家内部金融资本也逐渐抛弃了社会，资本的增值越来越与实际的生产过程无关，这就导致了西方内部的阶级矛盾和种族问题的爆发。这样一来，国际金融资本不需要生产、劳动力、社会，最后甚至也不需要共同体乃至国家了，它变成了一个全球流动的幽灵。不过现在国际金融资本仍然还需要美国的战争机器和传媒的洗脑工具。&lt;/p&gt;
&lt;h3 id=&#34;秩序&#34;&gt;秩序&lt;/h3&gt;
&lt;p&gt;秩序是人类政治生活的第一原则，一切价值都基于政治秩序的存在。然而金融资本在全球推广美国民主模式，处处去打破秩序，目的就是为了金融资本的自由流动，能够收割全球。因而在西方话语中，西方金融资本也在极力掩盖秩序的第一性。直到西方国家自身开始遭到秩序和安全的困境的时候，才迫不得已开始讨论秩序问题。然而金融资本只会越来越脱离生产，靠投机和制造战争获利，来剥削发展中国家和边缘地区的国家剩余价值。&lt;/p&gt;
&lt;p&gt;因此美国的政治共同体的解体也是一个不可避免的命运，所以美国的霸权之路也必然以美国自身政治秩序的崩溃或者坍缩为结局。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale</title>
      <link>https://bowenei.gitee.io/post/an-image-is-worth-16x16-words-transformers-for-image-recognition-at-scale/</link>
      <pubDate>Tue, 30 Nov 2021 13:37:38 +0800</pubDate>
      <guid>https://bowenei.gitee.io/post/an-image-is-worth-16x16-words-transformers-for-image-recognition-at-scale/</guid>
      <description>&lt;p&gt;&lt;strong&gt;Vision Transformer (ViT)&lt;/strong&gt; 是目前计算机视觉 (CV) 领域影响力最大的一项工作，因为他挑战了自从 2012 年 AlexNet 提出以来的 CNN 模型在 CV 领域的绝对统治地位。实验表明，如果能够在足够多的数据集上做预训练，那么即使不使用 CNN 也能达到同等甚至更高的精度。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ViT&lt;/strong&gt; 不仅在 CV 领域挖了一个大坑，而且还打破了 CV 和 NLP 在模型上的壁垒，所以在多模态领域也挖了一个大坑。于是，在 2020 年 10 月本文在 arXiv 上公开以后，基于 &lt;strong&gt;ViT&lt;/strong&gt; 的工作层出不穷。毫无疑问，&lt;strong&gt;ViT&lt;/strong&gt; 标志着 Transformer 模型正式杀入 CV 界，也标志着 Transformer 模型正式成为继 MLP、CNN、RNN 之后的一种新的模型范式。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/2010.11929&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;原文链接&lt;/a&gt;&lt;/p&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    &lt;p&gt;&lt;strong&gt;特别鸣谢&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;本文结合亚马逊首席科学家&lt;a href=&#34;https://github.com/mli&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;李沐&lt;/a&gt;的&lt;a href=&#34;https://www.bilibili.com/video/BV15P4y137jb&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;深度学习论文精读系列视频&lt;/a&gt;进行整理。视频的主讲人是&lt;a href=&#34;https://bryanyzhu.github.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;朱毅&lt;/a&gt;研究员。&lt;/p&gt;

  &lt;/div&gt;
&lt;/div&gt;

&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;While the Transformer architecture has become the de-facto standard for natural language processing tasks, its applications to computer vision remain limited. In vision, attention is either applied in conjunction with convolutional networks, or used to replace certain components of convolutional networks while keeping their overall structure in place. We show that this reliance on CNNs is not necessary and a pure transformer applied directly to sequences of image patches can perform very well on image classification tasks. When pre-trained on large amounts of data and transferred to multiple mid-sized or small image recognition benchmarks (ImageNet, CIFAR-100, VTAB, etc.), Vision Transformer (ViT) attains excellent results compared to state-of-the-art convolutional networks while requiring substantially fewer computational resources to train.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;作者认为，Transformer 在 NLP 领域应用广泛并且成为标准，但在 CV 领域的应用仍然有限。注意力 &lt;code&gt;attention&lt;/code&gt; 机制要么与 CNN 结合使用，要么用于替换 CNN 中的某些部分而整体结构不变。作者通过实验证明，这种对 CNN 的依赖是不必要的，直接将序列化的图像块 &lt;code&gt;patches&lt;/code&gt; 输入进 Transformer 可以取得非常好的效果。尤其是在大规模的数据集上做预训练之后，再迁移到中小型数据上能够获得和最好的 CNN 相媲美的结果。&lt;/p&gt;
&lt;p&gt;朱老师提醒大家特别注意，这里作者说的花费更少的资源训练是指 TPU v3 训练 2500 天所花费的资源！&lt;/p&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;Self-attention-based architectures, in particular Transformers (Vaswani et al., 2017), have become the model of choice in natural language processing (NLP). The dominant approach is to pre-train on a large text corpus and then fine-tune on a smaller task-specific dataset (Devlin et al., 2019). Thanks to Transformers’ computational efficiency and scalability, it has become possible to train models of unprecedented size, with over 100B parameters (Brown et al., 2020; Lepikhin et al., 2020). With the models and datasets growing, there is still no sign of saturating performance.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;在 NLP 领域，目前主流的方式是先在一个大规模数据集上做预训练 &lt;code&gt;pre-train&lt;/code&gt;，然后在特定领域的小数据集上做微调 &lt;code&gt;fine-tune&lt;/code&gt;。（这实际上是 BERT 这篇论文里提出来的。）Transformer 的计算具有高效性 &lt;code&gt;efficiency&lt;/code&gt; 和可扩展性 &lt;code&gt;scalability&lt;/code&gt;，并且随着模型和数据集的增长，还没有看到出现性能饱和 &lt;code&gt;saturating&lt;/code&gt; 的现象。&lt;/p&gt;
&lt;div class=&#34;alert alert-warning&#34;&gt;
  &lt;div&gt;
    &lt;p&gt;&lt;strong&gt;Transformer 直接用于 CV 领域的困难&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;朱老师认为，在过去的工作中，Transformer 一直没能用于 CV 领域的原因是因为计算的复杂性。&lt;/p&gt;
&lt;p&gt;我们试想，如果我们偏要把图片当成序列送入 Transformer 里面训练该怎么做？我们很容易想到的是将二维的图片拉直成序列，然后就可以输入到 Transformer 里面了。然而这样的计算复杂度就达到 $O(n^2)$。如果输入图片为 224x224x3，即使不考虑通道，序列长度就高达 50176，这远远大于一句话甚至是一段话的长度。&lt;/p&gt;

  &lt;/div&gt;
&lt;/div&gt;

&lt;blockquote&gt;
&lt;p&gt;In computer vision, however, convolutional architectures remain dominant (LeCun et al., 1989; Krizhevsky et al., 2012; He et al., 2016). Inspired by NLP successes, multiple works try combining CNN-like architectures with self-attention (Wang et al., 2018; Carion et al., 2020), some replacing the convolutions entirely (Ramachandran et al., 2019; Wang et al., 2020a). The latter models, while theoretically efficient, have not yet been scaled effectively on modern hardware accelerators due to the use of specialized attention patterns. Therefore, in large-scale image recognition, classic ResNet-like architectures are still state of the art (Mahajan et al., 2018; Xie et al., 2020; Kolesnikov et al., 2020).&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;目前 CNN 在 CV 仍占主导地位。既然 Transformer 在 NLP 领域又特别火，注意力机制又那么香，为什么不可以在 CV 领域使用 Transformer 呢？其实是有相关工作的，一些工作将 CNN 和 self-attention 结合使用。例如，可以将网络中间的特征图当作是 Transformer 的输入。Ramachandran 等人认为可以添加一个小窗口以降低 Transformer 的计算复杂度，Wang 等人认为可以分别在图片的两个维度（宽和高）做自注意力。&lt;/p&gt;
&lt;p&gt;作者认为，上述优化理论上都是可行的，但是都是比较特殊的自注意力操作，很难在硬件上加速，训练更大的模型。个人认为，这种优化缺乏普适性。因此，传统的残差网络依然是最好的。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Inspired by the Transformer scaling successes in NLP, we experiment with applying a standard Transformer directly to images, with the fewest possible modifications. To do so, we split an image into patches and provide the sequence of linear embeddings of these patches as an input to a Transformer. Image patches are treated the same way as tokens (words) in an NLP application. We train the model on image classification in supervised fashion.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;作者是被 Transformer 在 NLP 领域应用的可扩展性所启发，所以他们希望将 Transformer 直接作用于图片而尽量做少的修改。作者将图片打成了很多个 &lt;code&gt;patch&lt;/code&gt;，每一个 &lt;code&gt;patch&lt;/code&gt; 的大小是 16x16。然后我们就可以将每一个 &lt;code&gt;patch&lt;/code&gt; 当成是 NLP 领域里的单词，这也就是本文标题 An Image is Worth 16x16 Words 的含义。这里作者还补充说明了训练方式是有监督训练，因为 NLP 领域绝大多数都是无监督训练。&lt;/p&gt;
&lt;p&gt;朱老师认为，读到这里可以认为作者真的是完全把 CV 任务当成是 NLP 任务去做。朱老师觉得本文其实是换了个角度讲故事，但是总而言之本文的作者只想说明一件事——Transformer在视觉领域也能取得很好的效果。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;When trained on mid-sized datasets such as ImageNet without strong regularization, these models yield modest accuracies of a few percentage points below ResNets of comparable size. This seemingly discouraging outcome may be expected: Transformers lack some of the inductive biases inherent to CNNs, such as translation equivariance and locality, and therefore do not generalize well when trained on insufficient amounts of data.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;如果在中等大小的数据集（ImageNet）上不加以强约束，&lt;strong&gt;ViT&lt;/strong&gt; 其实是比传统的残差网络更弱的。作者于是就解释到，看起来不太好的结果其实是可以预知的。因为 Transformer 和 CNN 相比它缺少 CNN 有的归纳偏置 &lt;code&gt;inductive biases&lt;/code&gt;，它指的是一种先验知识，或者是我们提前做好的假设。&lt;/p&gt;
&lt;p&gt;CNN 其实是有两个归纳偏置。一个是 &lt;code&gt;locality&lt;/code&gt;，因为卷积运算是一个滑动窗口一点一点在图片上做的，所以就可以假设图片中相邻的区域有相似的特征。另一个是平移同变性 &lt;code&gt;translation equivariance&lt;/code&gt;，用公式表示就是 $f(g(x)) = g(f(x))$。（这里将 $f$ 理解为卷积，$g$ 理解为平移。）&lt;/p&gt;
&lt;p&gt;正因为 CNN 有这两个归纳偏置，所以 CNN 在卷积之后只需要相对更少的数据就能够学到更多的特征，得到一个更好的模型。但是对于 Transformer 来说，它其实没有这些先验信息，所以 Transformer 里的所有参数都需要从数据里面自己学习。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;However, the picture changes if the models are trained on larger datasets (14M-300M images). We find that large scale training trumps inductive bias. Our Vision Transformer (ViT) attains excellent results when pre-trained at sufficient scale and transferred to tasks with fewer datapoints.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;果然，上了大数据以后没有归纳偏置的 Transformer 的效果要优于 CNN。&lt;/p&gt;
&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;按照沐神读论文的方式，先来看看结论。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;We have explored the direct application of Transformers to image recognition. Unlike prior works using self-attention in computer vision, we do not introduce image-specific inductive biases into the architecture apart from the initial patch extraction step. Instead, we interpret an image as a sequence of patches and process it by a standard Transformer encoder as used in NLP. This simple, yet scalable, strategy works surprisingly well when coupled with pre-training on large datasets. Thus, Vision Transformer matches or exceeds the state of the art on many image classification datasets, whilst being relatively cheap to pre-train.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;本文工作最大的特点是几乎不需要任何对 CV 领域有特别深的了解，只需要把图片当成是 NLP 领域当中的序列，即序列化的图像块，就可以用 Transformer 来做了。这种方法简单、可扩展性高，并且和大规模预训练结合起来的时候效果出奇地好。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;While these initial results are encouraging, many challenges remain. One is to apply ViT to other computer vision tasks, such as detection and segmentation. Our results, coupled with those in Carion et al. (2020), indicate the promise of this approach. Another challenge is to continue exploring self-supervised pre-training methods. Our initial experiments show improvement from self-supervised pre-training, but there is still large gap between self-supervised and large-scale supervised pre-training. Finally, further scaling of ViT would likely lead to improved performance.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;ViT&lt;/strong&gt; 属于挖坑型论文，这篇论文其实是挖了一个新模型的坑，即如何将 Transformer 应用到 CV。因此，很自然可以想到的第一个问题是，&lt;strong&gt;ViT&lt;/strong&gt; 能否在除了图像分类任务以外的任务上也达到很好的效果？例如语义分割 &lt;code&gt;segmentation&lt;/code&gt; 和目标检测 &lt;code&gt;detection&lt;/code&gt;。事实也的确如此，短短两个月不到，目标检测领域就出来了一个新的工作 ViT-FRCNN&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;，这就已经把 &lt;strong&gt;ViT&lt;/strong&gt; 用到目标检测上了。同年 12 月，语义分割也有一篇 SETR&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;。&lt;/p&gt;
&lt;p&gt;朱老师在这里不得不吐槽一波，大家的手速实在是太快了，CV 圈卷的程度已经不能用月来计算了！而且紧接着三个月后，Swin Transformer&lt;sup id=&#34;fnref:3&#34;&gt;&lt;a href=&#34;#fn:3&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;3&lt;/a&gt;&lt;/sup&gt; 横空出世，把多尺度设计融合到 Transformer 里面，真正让 Transformer 更适合来做 CV。&lt;/p&gt;
&lt;p&gt;另外一个可以探索的方向是自监督的训练方式，因为在 NLP 领域几乎所有基于 Transformer 的模型全都采用自监督的方式训练。本文也做了一些自监督训练的实验，但发现和有监督的训练比起来效果有明显差距。&lt;/p&gt;
&lt;p&gt;毕竟作者是 Google Brain，反正也没有谁有足够的计算资源能够填本文挖的大坑，那就自己来填吧！结果半年以后作者又提出了 Scaling Vision Transformer (ViT-G)&lt;sup id=&#34;fnref:4&#34;&gt;&lt;a href=&#34;#fn:4&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;4&lt;/a&gt;&lt;/sup&gt;，其实就是更大的 &lt;strong&gt;ViT&lt;/strong&gt;，然后就把 ImageNet 数据集的准确率刷到 $90\%$ 以上了。&lt;/p&gt;
&lt;p&gt;这篇论文不光是挖了一个 CV 大坑，更是待到 CV 和 NLP 大一统之后，挖了一个多模态的大坑。多模态深度学习领域的工作最近也呈井喷式增长，由此可见 &lt;strong&gt;ViT&lt;/strong&gt; 这篇论文的影响力是多么巨大。&lt;/p&gt;
&lt;h2 id=&#34;related-work&#34;&gt;Related Work&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;Transformers were proposed by Vaswani et al. (2017) for machine translation, and have since become the state of the art method in many NLP tasks. Large Transformer-based models are often pre-trained on large corpora and then fine-tuned for the task at hand: BERT (Devlin et al., 2019) uses a denoising self-supervised pre-training task, while the GPT line of workuses language modeling as its pre-training task (Radford et al., 2018; 2019; Brown et al., 2020).&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Transformer 模型目前一般都是先在一个大规模语料库上做预训练，然后在目标任务上做一些细小的微调。这里面有两大著名的工作：BERT&lt;sup id=&#34;fnref:5&#34;&gt;&lt;a href=&#34;#fn:5&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;5&lt;/a&gt;&lt;/sup&gt; 和 GPT&lt;sup id=&#34;fnref:6&#34;&gt;&lt;a href=&#34;#fn:6&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;6&lt;/a&gt;&lt;/sup&gt;。BERT 用的是一个被称为 &lt;code&gt;denoising&lt;/code&gt; 的自监督方式，其实就是完形填空。而 GPT 则使用 &lt;code&gt;language modeling&lt;/code&gt; 做自监督，它是指已经有一个句子，预测下一个词是什么。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Naive application of self-attention to images would require that each pixel attends to every other pixel. With quadratic cost in the number of pixels, this does not scale to realistic input sizes. Thus, to apply Transformers in the context of image processing, several approximations have been tried in the past.&lt;/p&gt;
&lt;p&gt;Many of these specialized attention architectures demonstrate promising results on computer vision tasks, but require complex engineering to be implemented efficiently on hardware accelerators.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;将自注意力简单地应用到图像的每个像素上会导致很大的计算开销，所以自注意力很难直接用到 CV。因此，想要用自注意力来处理图像就必须做一些近似 &lt;code&gt;approximation&lt;/code&gt;。下面作者列举了很多自注意力在 CV 领域的应用。例如只对邻近的像素做自注意力，或者只对一些稀疏的点做自注意力。但这些工作从本质上讲都是减少处理的数据大小，以求近似。许多这些专门的注意力架构在计算机视觉任务上展示了有希望的结果，但需要复杂的工程才能在硬件加速器上有效实施。&lt;/p&gt;
&lt;p&gt;本文这么简单的 idea 难道就没有人想到吗？其实是有类似的，作者在相关工作里面这样描述：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Most related to ours is the model of Cordonnier et al. (2020), which extracts patches of size 2 ×2 from the input image and applies full self-attention on top. This model is very similar to ViT, but our work goes further to demonstrate that large scale pre-training makes vanilla transformers competitive with (or even better than) state-of-the-art CNNs. Moreover, Cordonnier et al. (2020) use a small patch size of 2×2 pixels, which makes the model applicable only to small-resolution images, while we handle medium-resolution images as well.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;ICLR 2020 有一个工作是在 CIFAR-10 数据集上切 2x2 的 &lt;code&gt;patch&lt;/code&gt;，然后在上面做 self-attention。作者认为他们的工作和这项工作的区别是在大规模数据集上做预训练，不需要任何改动就能取得比目前最好的 CNN 还好的效果。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;There has also been a lot of interest in combining convolutional neural networks (CNNs) with forms of self-attention, e.g. by augmenting feature maps for image classification (Bello et al., 2019) or by further processing the output of a CNN using self-attention, e.g. for object detection (Hu et al., 2018; Carion et al., 2020), video processing (Wang et al., 2018; Sun et al., 2019), image classification (Wu et al., 2020), unsupervised objectdiscovery (Locatello et al., 2020), or unified text-vision tasks (Chen et al., 2020c; Lu et al., 2019; Li et al., 2019).&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;还有很多将 CNN 和自注意力结合起来的工作，而且基本涵盖了 CV 领域的很多任务。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Another recent related model is image GPT (iGPT) (Chen et al., 2020a), which applies Transformers to image pixels after reducing image resolution and color space. The model is trained in an unsupervised fashion as a generative model, and the resulting representation can then be fine-tuned or probed linearly for classification performance, achieving a maximal accuracy of 72% on ImageNet.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;一个特别新的工作是 image GPT (iGPT)。我们知道 GPT 是 NLP 领域的代表工作，iGPT 类似，它是一个生成式模型，用无监督的方式取训练的。但是这项工作的准确率最高仅仅只有 $72\%$，而本文的准确率已经达到 $88.5\%$ 了。但是另一个之后的工作 MAE&lt;sup id=&#34;fnref:7&#34;&gt;&lt;a href=&#34;#fn:7&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;7&lt;/a&gt;&lt;/sup&gt; 却反而让生成式模型比之前的判别式模型效果更好，随后爆火。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Our work adds to the increasing collection of papers that explore image recognition at larger scales than the standard ImageNet dataset.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;最后作者提到了比 ImageNet 还大的数据集上各个模型的效果。&lt;/p&gt;
&lt;p&gt;总结一下，本文的相关工作列举得非常彻底，基本上和本文工作相近的工作都涵盖到了。朱老师认为，在写相关工作章节时，就是要让读者知道在你的工作之前，别人做了哪些工作，你和他们的区别在哪里。这个只要写清楚了，其实是对你非常有利的，并不会因此降低论文的创新性，反而会让这个文章变得更加简单易懂。&lt;/p&gt;
&lt;h2 id=&#34;method&#34;&gt;Method&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;In model design we follow the original Transformer (Vaswani et al., 2017) as closely as possible. An advantage of this intentionally simple setup is that scalable NLP Transformer architectures – and their efficient implementations – can be used almost out of the box.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;作者强调，&lt;strong&gt;ViT&lt;/strong&gt; 在模型设计上是尽可能按照最原始的 Transformer 来做的。这样做的最大好处就是可以直接把 NLP 领域成功的 Transformer 架构直接拿过来使用，不需要再魔改模型了。&lt;/p&gt;
&lt;h3 id=&#34;vision-transformer-vit&#34;&gt;Vision Transformer (ViT)&lt;/h3&gt;
















&lt;figure  id=&#34;figure-figure-1-model-overview-we-split-an-image-into-fixed-size-patches-linearly-embed-each-of-them-add-position-embeddings-and-feed-the-resulting-sequence-of-vectors-to-a-standard-transformer-encoder-in-order-to-perform-classification-we-use-the-standard-approach-of-adding-an-extra-learnable-classification-token-to-the-sequence&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Figure 1: Model overview. We split an image into fixed-size patches, linearly embed each of them, add position embeddings, and feed the resulting sequence of vectors to a standard Transformer encoder. In order to perform classification, we use the standard approach of adding an extra learnable “classification token” to the sequence.&#34; srcset=&#34;
               /post/an-image-is-worth-16x16-words-transformers-for-image-recognition-at-scale/featured_hu64a7806ed9e97cb55f87b27af1c0aac1_126427_008558f1b5b4c64ea128a71be8e1da2f.webp 400w,
               /post/an-image-is-worth-16x16-words-transformers-for-image-recognition-at-scale/featured_hu64a7806ed9e97cb55f87b27af1c0aac1_126427_34ce1b785e7793a75231026b8d859947.webp 760w,
               /post/an-image-is-worth-16x16-words-transformers-for-image-recognition-at-scale/featured_hu64a7806ed9e97cb55f87b27af1c0aac1_126427_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://bowenei.gitee.io/post/an-image-is-worth-16x16-words-transformers-for-image-recognition-at-scale/featured_hu64a7806ed9e97cb55f87b27af1c0aac1_126427_008558f1b5b4c64ea128a71be8e1da2f.webp&#34;
               width=&#34;760&#34;
               height=&#34;392&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Figure 1: Model overview. We split an image into fixed-size patches, linearly embed each of them, add position embeddings, and feed the resulting sequence of vectors to a standard Transformer encoder. In order to perform classification, we use the standard approach of adding an extra learnable “classification token” to the sequence.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;朱老师认为，论文的总览图非常重要。总览图画得好，别人在不读整篇文章的情况下光看图就能够大致了解这篇文章在讲什么。&lt;strong&gt;ViT&lt;/strong&gt; 这篇文章的总览图画得非常好，以至于其他人在引用或者讲解 &lt;strong&gt;ViT&lt;/strong&gt; 的时候都是直接把图贴上去而不做任何修改。&lt;/p&gt;
&lt;p&gt;给定一张图片，首先将这张图打成了很多 &lt;code&gt;patch&lt;/code&gt;。然后他把这些 &lt;code&gt;patch&lt;/code&gt; 转化成一个序列，每个 &lt;code&gt;patch&lt;/code&gt; 会通过一个被称为线性投射层的操作得到一个特征，即图中的 &lt;code&gt;Patch + Position Embedding&lt;/code&gt;。我们知道，自注意力机制是所有的元素之间两两去做交互，所以说 attention 本身不存在顺序问题。但是对于图片来说它是一个整体，这个九宫格是有自己的顺序的。如果顺序颠倒了，就不是原来那张图片了，所以就需要 &lt;code&gt;Position Embedding&lt;/code&gt;。加上了位置编码的信息以后，每个 &lt;code&gt;token&lt;/code&gt; 既包括了原本的图像 &lt;code&gt;patch&lt;/code&gt; 信息，又包括了图像 &lt;code&gt;patch&lt;/code&gt; 所在的位置信息。&lt;/p&gt;
&lt;p&gt;接下来实际上就和 NLP 那边是完全一样了。经过 Transformer Encoder 之后，它会给我们很多输出。那么问题来了，应该用哪个输出去做最后的分类呢？这里还需要再次借鉴 BERT&lt;sup id=&#34;fnref:5&#34;&gt;&lt;a href=&#34;#fn:5&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;5&lt;/a&gt;&lt;/sup&gt; 当中的 extra learnable [class] embedding，即特殊字符 &lt;code&gt;cls&lt;/code&gt;。在 &lt;strong&gt;ViT&lt;/strong&gt; 中也加入了一个特殊字符，用 &lt;code&gt;*&lt;/code&gt; 代替，它的位置信息永远是 &lt;code&gt;0&lt;/code&gt;。因为自注意力机制使得每个 &lt;code&gt;token&lt;/code&gt; 之间都在互相学习，用一个空的 &lt;code&gt;token&lt;/code&gt; 就可以和图片的每个 &lt;code&gt;patch&lt;/code&gt; 交互学到完整的图片信息，所以只需要根据 &lt;code&gt;cls&lt;/code&gt; 对应的输出来判断即可。MLP Head 就是一个通用的分类头了，最后再用交叉熵函数去进行模型的训练。&lt;/p&gt;
&lt;p&gt;至于这里的 Transformer Encoder 也是完全标准的，即图中右边的部分。所以说从整体结构上来看，&lt;strong&gt;ViT&lt;/strong&gt; 的结构非常简洁，它的特殊之处就在于如何将一个图片转化成一系列的 &lt;code&gt;token&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;那么下面结合下图 &lt;strong&gt;ViT&lt;/strong&gt; 的 Transformer 部分对 Transformer 模型再做一个回顾。&lt;/p&gt;
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34;
           src=&#34;https://bowenei.gitee.io/post/an-image-is-worth-16x16-words-transformers-for-image-recognition-at-scale/ViT.svg&#34;
           loading=&#34;lazy&#34; data-zoomable class=&#34; img-light&#34; /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;p&gt;首先将输入的图片打成若干 &lt;code&gt;patch&lt;/code&gt;，这里的图片输入大小为 224x224x3，表示宽和高为 224 像素，RGB 3 通道。&lt;code&gt;patch&lt;/code&gt; 的大小为 16x16x3，因此原图被划分为 $14 \times 14 = 196$ 个 &lt;code&gt;patch&lt;/code&gt;。再加上 &lt;code&gt;cls&lt;/code&gt;，序列的总长度为 197。&lt;/p&gt;
&lt;p&gt;经过 Embedding 和位置编码之后，得到维度为 197x768 的 &lt;code&gt;tokens&lt;/code&gt;，因为每个 16x16x3 的 &lt;code&gt;patch&lt;/code&gt; 拉直之后是 $16 \times 16 \times 3 = 768$ 维。&lt;/p&gt;
&lt;p&gt;接下来进行 Self-Attention，需要映射出 3 个矩阵 Query、Key 和 Value。由于 Transformer 的多头自注意力机制，并且 &lt;strong&gt;ViT&lt;/strong&gt; 设置了 $h = 12$ 个头，那么 3 个矩阵的维度均为 197x64，因为 $768 \div 12 = 64$。最后经过拼接 &lt;code&gt;Concat&lt;/code&gt; 得到 197x768 维的 Attention 矩阵。&lt;/p&gt;
&lt;p&gt;最后经过 MLP 全连接层，一般先把维度放大 4 倍，即 197x3012，再回到原来的维度上输出。这就是 Transformer 一层 Encoder 上的计算过程。&lt;/p&gt;
&lt;h4 id=&#34;inductive-bias&#34;&gt;Inductive bias&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;We note that Vision Transformer has much less image-specific inductive bias than CNNs. In CNNs, locality, two-dimensional neighborhood structure, and translation equivariance are baked into each layer throughout the whole model. In ViT, only MLP layers are local and translationally equivariant, while the self-attention layers are global. The two-dimensional neighborhood structure is used very sparingly: in the beginning of the model by cutting the image into patches and at fine-tuning time for adjusting the position embeddings for images of different resolution (as described below). Other than that, the position embeddings at initialization time carry no information about the 2D positions of the patches and all spatial relations between the patches have to be learned from scratch.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;作者还补充了归纳偏置的一些细节。&lt;strong&gt;ViT&lt;/strong&gt; 相较于 CNN 而言要少很多这种图像特有的归纳偏置，例如 CNN 当中有平移性和模型的局部等变性（详见前文）。但是对于 &lt;strong&gt;ViT&lt;/strong&gt; 来说，MLP 是有上述的这些归纳偏置的，但是自注意力层是全局的 &lt;code&gt;global&lt;/code&gt;，即图片的 2D 信息自注意力层没怎么用。（基本上仅仅只是 Position Embedding 的时候用到了。）另外，位置编码也是随机初始化的，并没有携带任何 2D 信息，所有的 &lt;code&gt;patch&lt;/code&gt; 之间的距离信息、场景信息都得重头学。&lt;/p&gt;
&lt;p&gt;作者补充这一段的目的是为了给后面在中小数据集上 &lt;strong&gt;ViT&lt;/strong&gt; 不如 CNN 的实验结果的解释做铺垫。那么既然如此，Transformer 在全局上表现如此优秀，CNN 又在中小数据集上快速收敛，是不是可以将它们结合起来？&lt;/p&gt;
&lt;h4 id=&#34;hybrid-architecture&#34;&gt;Hybrid Architecture&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;As an alternative to raw image patches, the input sequence can be formed from feature maps of a CNN (LeCun et al., 1989). In this hybrid model, the patch embedding projection E (Eq. 1) is applied to patches extracted from a CNN feature map. As a special case, the patches can have spatial size 1x1, which means that the input sequence is obtained by simply flattening the spatial dimensions of the feature map and projecting to the Transformer dimension. The classification input embedding and position embeddings are added as described above.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;其实将 Transformer 和 CNN 的想法是可行的。我们假设现在不把图片打成 &lt;code&gt;patch&lt;/code&gt; 了，而是用一个 16x16 的卷积核去对原始图片进行卷积（步长也为 16），得到的也是一个 14x14 的特征图。后续的操作和 &lt;strong&gt;ViT&lt;/strong&gt; 一样，将特征图的每个像素当成 NLP 任务送入 Transformer Encoder 中。&lt;/p&gt;
&lt;h3 id=&#34;fine-tuning-and-higher-resolution&#34;&gt;Fine-tuning and Higher Resolution&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;When feeding images of higher resolution, we keep the patch size the same, which results in a larger effective sequence length. The Vision Transformer can handle arbitrary sequence lengths (up to memory constraints), however, the pre-trained position embeddings may no longer be meaningful. We therefore perform 2D interpolation of the pre-trained position embeddings, according to their location in the original image. Note that this resolution adjustment and patch extraction are the only points at which an inductive bias about the 2D structure of the images is manually injected into the Vision Transformer.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;微调 &lt;code&gt;fine-tuning&lt;/code&gt; 是指预训练好的 &lt;strong&gt;ViT&lt;/strong&gt; 模型（输入图片为 224x224x3）在更大尺寸的图片（例如 320x320x3）上进行“刷脸”。但是，这对于预训练好的 &lt;strong&gt;ViT&lt;/strong&gt; 有些麻烦，因为如果 &lt;code&gt;patch&lt;/code&gt; 的大小不变，而图片变大了，于是序列变长了。从理论上说，Transformer 可以处理任意长度的序列。但是，提前训练好的位置编码可能就完全没用了，因为预训练好的位置编码具有明确的物理意义。那么预训练的位置编码还是否有用呢？作者发现，再做一个 2D 的差值就可以了。但这里的差值也仅仅只是一个临时的解决方案，应该说这算是 &lt;strong&gt;ViT&lt;/strong&gt; 在微调的时候的一个局限性。&lt;/p&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    至此，已经可以基本了解 &lt;strong&gt;ViT&lt;/strong&gt; 的基本架构了。后面实验部分以及附录的有关说明，如有需要再进行补充。
  &lt;/div&gt;
&lt;/div&gt;

&lt;h2 id=&#34;experiments&#34;&gt;Experiments&lt;/h2&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Beal J, Kim E, Tzeng E, et al. Toward transformer-based object detection[J]. arXiv preprint arXiv:2012.09958, 2020.&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Zheng S, Lu J, Zhao H, et al. Rethinking semantic segmentation from a sequence-to-sequence perspective with transformers[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2021: 6881-6890.&amp;#160;&lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:3&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Liu Z, Lin Y, Cao Y, et al. Swin transformer: Hierarchical vision transformer using shifted windows[J]. arXiv preprint arXiv:2103.14030, 2021.&amp;#160;&lt;a href=&#34;#fnref:3&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:4&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Zhai X, Kolesnikov A, Houlsby N, et al. Scaling vision transformers[J]. arXiv preprint arXiv:2106.04560, 2021.&amp;#160;&lt;a href=&#34;#fnref:4&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:5&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Devlin J, Chang M W, Lee K, et al. Bert: Pre-training of deep bidirectional transformers for language understanding[J]. arXiv preprint arXiv:1810.04805, 2018.&amp;#160;&lt;a href=&#34;#fnref:5&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:6&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Radford A, Narasimhan K, Salimans T, et al. Improving language understanding by generative pre-training[J]. 2018.&amp;#160;&lt;a href=&#34;#fnref:6&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:7&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;He K, Chen X, Xie S, et al. Masked autoencoders are scalable vision learners[J]. arXiv preprint arXiv:2111.06377, 2021.&amp;#160;&lt;a href=&#34;#fnref:7&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;</description>
    </item>
    
    <item>
      <title>从公司到国家：美国制度困局的历史解释</title>
      <link>https://bowenei.gitee.io/post/from-corporation-to-country-a-historical-explanation-of-americas-institutional-dilemma/</link>
      <pubDate>Tue, 23 Nov 2021 22:35:29 +0800</pubDate>
      <guid>https://bowenei.gitee.io/post/from-corporation-to-country-a-historical-explanation-of-americas-institutional-dilemma/</guid>
      <description>&lt;p&gt;复旦大学中国研究院院长&lt;a href=&#34;http://www.cifu.fudan.edu.cn/14/1d/c521a136221/page.htm&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;张维为&lt;/a&gt;教授认为，中国已经崛起到今天这个地步，我们完全可以以中国人的眼光和话语来观察、评述自己的国家与外部世界。我们要建构全面的、透彻的、强势的话语体系。&lt;/p&gt;
&lt;p&gt;复旦大学中国研究院副院长&lt;a href=&#34;http://www.cifu.fudan.edu.cn/95/39/c521a103737/page.htm&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;范勇鹏&lt;/a&gt;教授的这本《从公司到国家：美国制度困局的历史解释》全景再现美利坚创制历程，深度解读一个公司型国家的制度逻辑。&lt;/p&gt;
&lt;p&gt;本文按照原书的目录编排，对书中的一些具体史实和范勇鹏教授的观点进行罗列、整理和归纳，形成了下面的读书笔记。&lt;/p&gt;
&lt;details class=&#34;toc-inpage d-print-none  &#34; open&gt;
  &lt;summary class=&#34;font-weight-bold&#34;&gt;Table of Contents&lt;/summary&gt;
  &lt;nav id=&#34;TableOfContents&#34;&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;a href=&#34;#导读&#34;&gt;导读&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#序言&#34;&gt;序言&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#第一章-底色&#34;&gt;第一章 底色&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#第一节-人&#34;&gt;第一节 人&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#第二节-地&#34;&gt;第二节 地&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#第三节-国家理由&#34;&gt;第三节 国家理由&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#第二章-代议制起源&#34;&gt;第二章 代议制起源&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#第一节-欧洲代议制的起源&#34;&gt;第一节 欧洲代议制的起源&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#第二节-美国代议制的起源&#34;&gt;第二节 美国代议制的起源&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#第三章-公司国家&#34;&gt;第三章 公司国家&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#第一节-公司国家的诞生&#34;&gt;第一节 公司国家的诞生&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#第二节-公司国家的发展尼德兰&#34;&gt;第二节 公司国家的发展：尼德兰&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#第三节-公司国家的成熟英国&#34;&gt;第三节 公司国家的成熟：英国&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#第四章-独立和立宪&#34;&gt;第四章 独立和立宪&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#第一节-独立运动&#34;&gt;第一节 独立运动&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#第二节-邦联条例&#34;&gt;第二节 《邦联条例》&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#第三节-制宪&#34;&gt;第三节 制宪&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#第五章-宪法制度&#34;&gt;第五章 宪法制度&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#第一节-公司与契约&#34;&gt;第一节 公司与契约&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#第二节-宪法制度&#34;&gt;第二节 宪法制度&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#第六章-宪政弊端&#34;&gt;第六章 宪政弊端&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#第一节-总统制与议会制&#34;&gt;第一节 总统制与议会制&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#第二节-官僚制度&#34;&gt;第二节 官僚制度&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#结论&#34;&gt;结论&lt;/a&gt;&lt;/li&gt;
  &lt;/ul&gt;
&lt;/nav&gt;
&lt;/details&gt;

&lt;h2 id=&#34;导读&#34;&gt;导读&lt;/h2&gt;
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34;
           src=&#34;https://bowenei.gitee.io/post/from-corporation-to-country-a-historical-explanation-of-americas-institutional-dilemma/%E4%BB%8E%E5%85%AC%E5%8F%B8%E5%88%B0%E5%9B%BD%E5%AE%B6%EF%BC%9A%E7%BE%8E%E5%9B%BD%E5%88%B6%E5%BA%A6%E5%9B%B0%E5%B1%80%E7%9A%84%E5%8E%86%E5%8F%B2%E8%A7%A3%E9%87%8A.svg&#34;
           loading=&#34;lazy&#34; data-zoomable class=&#34; img-light&#34; /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;h2 id=&#34;序言&#34;&gt;序言&lt;/h2&gt;
&lt;p&gt;2020 年 1 月中旬范勇鹏教授动笔时，一场突如其来的新冠肺炎疫情在武汉蔓延。2020 年 3 月底结稿之时，中国这波疫情已基本平息，而国外的疫情又开始蔓延。特别是 2020 年的特朗普政府应对疫情不利，一场关于中美制度看法的舆论斗争在微博、微信朋友圈等准公共领域展开。一旦有涉及到美国的话题，人们往往会迅速地分出两大阵营——恨美者，逢美必反，坚信美帝国主义亡我之心不死；爱美者，将美国视为正义代表、民主灯塔，以美国的价值观为普世大道，以美国的制度为理想样板。&lt;/p&gt;
&lt;p&gt;其实，这种现象并不稀奇，如何看美国，在中国从来是个大问题，是个政治问题。中美签订第一个不平等条约《望厦条约》后，当时的中国人并没有意识到自由贸易对中国社会结构的破坏性。八国联军侵华后，美国反对列强瓜分中国，要求利益均沾、门户开放，这在当时引起了中国人对美国不切实际的好感。巴黎和会后，美国的自由主义思潮和随新文化运动传入的马克思主义产生了正面碰撞，这&lt;strong&gt;埋下了中国思想界左右两翼长期角力的种子&lt;/strong&gt;。从某种意义上讲，今天中国的思潮之争依然未能摆脱 20 世纪初的影子。&lt;/p&gt;
&lt;p&gt;抗日战争后期，中美两国结为反法西斯盟友，中国人对美国的好感空前高涨。然而二战结束后美国的政策助长国民党专制统治和中国内战，站在了中国共产党、中国人民的对立面。随着人民民主革命走向胜利，中国共产党采取“一边倒”的外交战略，中美在朝鲜半岛兵戎相见。自此至 20 世纪 70 年代，中国一直视美国为“帝国主义”、“纸老虎”、“人类公敌”。1972 年尼克松访华后，中美关系正常化，到 1989 年中美关系持续改善。此后至今，中美关系有升有降，但基本也是正常的国家间关系，中国人对美国的看法日益多元。&lt;/p&gt;
&lt;p&gt;奥巴马第二任期中，美国对华政策发生巨大变化，奥巴马提出“重返亚太”的口号和“亚太再平衡”的战略。特朗普上台后，发动了对华贸易战，进而演变成科技战、舆论战，中美关系进入了一个下降期。可不论中美关系如何变化，自改革开放后，中国的知识精英对美国的制度大多抱着积极的态度乃至过于理想化的想法。&lt;/p&gt;
&lt;p&gt;实际上自清末以来，中国的知识界就对美国制度有所推崇。到了民国初期，也做过分权制衡制度的尝试。最不遗余力推崇美国制度的，首推自由主义者胡适。时至今日，国内外不少学识素养深厚的专业人士对美国制度抱有令人难以置信的幻想。因此，范勇鹏教授才有了写这本书的愿望，希望能够超然于价值观和舆论争议，以尽可能客观的角度分析美国制度的本质。&lt;/p&gt;
&lt;p&gt;范勇鹏教授承诺，写作过程中力求遵照以下原则：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;跳出美国看美国&lt;/li&gt;
&lt;li&gt;跳出历史读历史&lt;/li&gt;
&lt;li&gt;跳出常识找常识&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;为此，首先要回到历史境况之中，基于对美国先民的同情理解，运用常识来复盘其制度产生和发展的过程。正如巴西学者班代拉所说，欲了解一个国家的性质，必须要了解其产生、发展的过程。&lt;/p&gt;
&lt;h2 id=&#34;第一章-底色&#34;&gt;第一章 底色&lt;/h2&gt;
&lt;p&gt;孙中山先生说过一句话：&lt;strong&gt;政治乃管理众人之事&lt;/strong&gt;。人类天性喜好自由，政治之所以产生，人们之所以甘心接受政治的约束，是因为一群特定的人，为了一些特定的理由不得不共同生活。不论是为了免于自然、野兽的侵害，还是为了更舒适的生存，亦或是管理资源核分配权力，都离不开政治。于是，人们逐渐产生了一些管理共同事务的规则核习惯，是为制度。&lt;/p&gt;
&lt;p&gt;所以，理解制度最好的办法，是从人出发，看当时、当地的人们，出于什么样的目的、在什么样的环境约束下、在哪些传统核现实条件基础上创造出了该制度。而不是将制度当成神启的产物，少数立法者的发明，或是基于某种抽象原则的设计。&lt;/p&gt;
&lt;h3 id=&#34;第一节-人&#34;&gt;第一节 人&lt;/h3&gt;
&lt;p&gt;人类历史上各大文明的性格，如果说有什么要素可以拿来作为比较的尺度的话，“流动性”应该是最为重要的指标之一。&lt;/p&gt;
&lt;p&gt;相比地中海世界诸文明，华夏文明的流动性相对较低。理解中国文明的一个线索就是其长期而大规模的“定居性”。长期定居产生了代际之间的空间联系；代际关系产生祖先崇拜，因为祖先既是人也是鬼神；所以打破了人神界限，催生了人本主义；最后由自己的祖先推而广之到别人的祖先，产生了同理心、宽容心，形成了“兴灭继绝”、“己所不欲勿施于人”，乃至“天下大同”的伦理观。&lt;/p&gt;
&lt;p&gt;与华夏文明相比，地中海文明流动性相对更强。今天西方的主要祖先来源之一——日耳曼民族就是典型代表，它与古老的罗马制度相结合，奠定了今天西方政治文明的基石。而与欧洲相比，美国文明的流动性更为典型。&lt;/p&gt;
&lt;p&gt;最初是西班牙人奔着金银梦移民到美洲大陆的，因为中世纪末期的王室纷争阻碍了商品经济的发展。后来则是英国人，他们建立起殖民贸易公司，这反映了国家在重商主义贸易扩张中的巨大作用。后来的早期移民也主要是依托公司来到美洲，所谓著名的“五月花号”只不过是满载着远离故土的外出创业者或打工者的“劳务输出”船。这些移民可按身份分为两类，一类是业主或股东，另一类是契约劳工。除此之外，还有大量的被迫移民者，例如囚犯、政治犯、军事犯。&lt;/p&gt;
&lt;p&gt;在最早的殖民地中，要数弗吉尼亚和新英格兰最具代表性。弗吉尼亚是北美的第一个英国殖民地，新英格兰的早期移民则有很多清教徒，但他们都不是处于宗教动机，而是为了经济利益而来。除此之外，很多殖民地的早期移民也多少为了追求利益漂洋过海来到北美。&lt;/p&gt;
&lt;p&gt;提到新英格兰的宗教，范勇鹏教授在这里破除了所谓清教神话。当今一般人多认为清教是美国民主的基石，是美国文化的根基，塑造了美国人的性格。不了解清教，就不可能懂美国。实际上这种观念很大程度上后世历史学家的建构，“山巅之城”就是马萨诸塞殖民地的清教徒领袖温斯罗普喊出的极具宗教性的口号。范勇鹏教授例举很多实例证明，此后的历史中，清教在美国文化仅占极小一部分，而且越来越不重要。&lt;/p&gt;
&lt;p&gt;如果抛开清教神话，抱着历史唯物主义的观点来看待美国人民的构成，我们可以很自然地看到美国移民的功利主义动机。首先，逐利性的人口性质是使美国社会呈现出那个时代欧洲罕见的平等和自由状态。资本主义的社会关系是一种市场关系，任何基于传统、血缘、宗教和法律的不平等都是市场关系的障碍，因而都将被资本主义的政治平等所取代。&lt;/p&gt;
&lt;p&gt;然而，资本主义对平等的促进是有限度的，只能走到财产的平等，不可能再进一步。一旦新型资产阶级获得了基于财产的“平等”，他们就不再喜欢平等，而是捡起贵族政治的意识形态——自由——为自己所用，用一切努力将自由装扮成一种平等。具体的应用，是以一种在法律上自由的契约关系将财产的不平等、劳动和资本之间的不平等掩盖起来。&lt;/p&gt;
&lt;p&gt;人们耳熟能详的启蒙时代的欧洲思想家，大多为资本主义剥削的辩护作出过“贡献”，他们一边高举人的价值，一边却为剥夺和屠杀人类而提供理论论证。马克斯·韦伯将非洲人和亚洲人看作“野人”。面对印第安人和黑人奴隶时，英国空想社会主义者托马斯·莫尔从理论上“证明”他们根本不是人。英属北美殖民地曾对印第安人采取了有组织、有步骤的种族灭绝和驱逐，这个过程一直持续到二战后。这种“集中营”的发明连元首希特勒都“赞不绝口”，自称其种族灭绝方法是师从美国人。&lt;/p&gt;
&lt;p&gt;考虑人口因素，自然不应该将目光局限于早期移民，事实上美国至今还在接纳大量移民。从始至今不变的一点是，所有移民都是首先为了利益因素前往美国。解释移民的动机，一要看旧大陆的推力，二要看新大陆的拉力。因此，美国移民可以分为三个时代。第一个时代造就了十三个州和联邦主义，第二个时代造就了一个国家和一种新的国家政治。时至今日美国移民还处在第三个时代中，主要是出于利益动机。&lt;/p&gt;
&lt;p&gt;综上可见，美国人口最基本的特点是逐利性。美国几乎所有的人口都是为明确的利益目标而来，这与中国人口所构成命运共同体不同，也迥异于欧洲国家的价值（基督教）共同体和民族国家属性。从现代化的角度看，美国的人口性质，意味着美国先天具备其他国家求之不得的清晰化和简单化特征，因而具有极其有利于资本主义发展的竞争优势。&lt;/p&gt;
&lt;h3 id=&#34;第二节-地&#34;&gt;第二节 地&lt;/h3&gt;
&lt;p&gt;地理是历史之母。对于美国这样一个特殊的国家而言，地理因素的作用更是举足轻重。与亚欧大陆的多数国家相比，美国拥有无与伦比的地理环境。&lt;/p&gt;
&lt;p&gt;美国土地广阔、资源丰富，长期困扰中国的山川之隔和草原游牧民族的威胁都不存在。丰富的土地资源对美国文明和制度的发展之重要性，无论怎样强调都不为过。各民族早期普遍存在的“游耕制”生产方式，中国古代的“三圃制”等休耕制度，都与土地枯竭有关。对有限资源的存量竞争是人类历史中苦难和暴行的主要根源。美国人是在几乎无限的土地供给和资源条件下展开新的经济生活的。&lt;/p&gt;
&lt;p&gt;美国北边是加拿大，不仅不是威胁，反而是英帝国被扣押在美国手里的人质。南边是墨西哥，不仅未构成威胁，而且为美国提供了源源不断的新领土。美国周围没有同等量级的敌对国家，而且有两洋拱卫，这使其得以避免欧洲大陆国家面临的安全梦魇。&lt;/p&gt;
&lt;p&gt;但是地缘安全不是绝对的，首先它具有延展性，其次它是随时代变化而变化的。&lt;/p&gt;
&lt;p&gt;首先，美国本土虽然安全无虞，但是作为美国命脉的海上贸易路线始终存在着安全挑战。不过，只要船队能够自由航行，它就有把握赢得与欧洲国家的贸易竞争胜利。因而在两百余年的对外关系中，美国虽然有时开门，有时关门，有时搞贸易保护，有时大降关税，但是它始终钟情于“自由航行”的信条。只有中国的崛起真正威胁到美国的贸易优势，所以美国打压中国崛起是必然的。最典型的事件像2016年的所谓“南海仲裁案”，也是打着“自由航行”的旗号，但实际上已经没有了当年那个年轻的美国对自由航行的底气。&lt;/p&gt;
&lt;p&gt;其次，从时代变化来看，自珍珠港事件后，美国本土遭受攻击的噩梦开始困扰美国，美国人开始有了“国家安全”观念。同时，霸权利益要求美国在全世界重要地区保持军事存在。特别是二战后，美国不得不维持庞大的常备军和义务兵役，同时美国还产生了巨大的军事工业集团。“9·11”事件后，美国的“国家安全”观念发展为“国土安全”观。&lt;/p&gt;
&lt;p&gt;在丰富的土地资源和安全的战略环境下，英国殖民者来到美国历史的起跑线上。这条几乎在所有重大方面都有着“例外”优势的起跑线，从一开始就决定了美国发展的“开挂”旅程。&lt;/p&gt;
&lt;p&gt;经历北美独立战争和南北内战以后，美国就没有了紧迫的安全威胁，从邦联走上了立宪的道路。那么美国人为什么要立宪，为何要建立联邦国家？&lt;/p&gt;
&lt;h3 id=&#34;第三节-国家理由&#34;&gt;第三节 国家理由&lt;/h3&gt;
&lt;p&gt;殖民地的历史，可谓美国的国家前史。由此前史可以窥探到美国国家性质的一个重要方面：国家理由。也就是人们为什么愿意牺牲一部分自由而创造或接受国家。&lt;/p&gt;
&lt;p&gt;关于国家的起源，近代以来的政治哲学和社会科学已经做了大量的思考和研究，主要是两次大思考——启蒙思想和马克思主义。范勇鹏教授认为，结合现有的很多观点来看，人类创造国家大多出于两种机制：恐惧的驱使和利益的激励。接下来范勇鹏教授举了中国和地中海周边国家的例子，以说明恐惧和利益在国家理由中的各种组合形式。在古代，地理因素往往起较大的影响作用；而在近代，地理环境不再是唯一重要原因，资本主义和工业化从根本上改变了现代国家的恐惧和利益。&lt;/p&gt;
&lt;p&gt;具体来讲，现代运输技术和军事技术的发展，打破了地理对军事攻防关系的决定性影响，这是恐惧因素；另一方面，无论一个国家享有什么样的地理环境，无论历史上依赖于什么样的经济模式，无论以往的核心利益和资源是土地税收还是贸易收益，一旦并入资本主义轨道，所有国家的利益偏好都被均质化，同意转向追求资本的利益。&lt;/p&gt;
&lt;p&gt;地理和资本的交织一方面将恐惧拉平了，但地理因素仍然阻碍了绝对的平等。例如，“冷战”中美国和联邦德国对苏联军事威胁的感受不同便决定了他们的政策选择差异。另一方面，即使在资本主义时代，地理因素仍然对国家的利益界定产生影响。例如，马来西亚和巴基斯坦与新加坡的国家利益界定显然不同，中国介入马来西亚皇京港和巴基斯坦瓜达尔港建设的行为之所以引起新加坡的激烈反应，就是因为这将给该地区的地缘经济格局带来重大改变。在地理和资本这两个变量的综合影响之下，恐惧和利益这两个要素之间也存在着复杂的互动和相互制约的关系。&lt;/p&gt;
&lt;h4 id=&#34;总结&#34;&gt;总结&lt;/h4&gt;
&lt;p&gt;从上述分析出发，我们可以看到美国何其独特。美国没有前现代的历史，没有经历过去数千年中重复上演的国家间的安全危机和利益竞争。美国诞生于资本主义的起点上，建立国家就是为了资本主义的发展，人口构成、国家制度、法律体系乃至社会文化都是服务于资本主义的尽情生长。而这一切又受到两洋拱卫的空前安全的地理条件的保护，美国几乎实在没有恐惧的条件下建国和发展的。可以说，美国就是为资本主义而生，几乎是历史之神在接近理想状态下进行的一个资本主义试验。&lt;/p&gt;
&lt;h2 id=&#34;第二章-代议制起源&#34;&gt;第二章 代议制起源&lt;/h2&gt;
&lt;p&gt;谈起美国的政治制度，我们可以例举诸如代议制、总统制、联邦制、司法独立等等很多。但是要谈起源，首先还是要从代议制说起。&lt;/p&gt;
&lt;p&gt;代议制其实是个古老事物，早在美国立国建政之前很久就已存在。今天多数人会想当然地认为代议制是一种民主制度，而实际上在西方历史上，被称为“民主”的制度极少采用代议制。按照古希腊哲学家亚里士多德的说法，民主就是两条标准：一是直接参政，二是多数决定。既然是直接参政，就没有人可以代表别人，自然不需要代议制。而这里的多数决定，其实就是少数服从多数。&lt;/p&gt;
&lt;p&gt;既然原则不能违背，统治阶级就在概念上做文章——哪些人算人？这个答案实际上是只有成年男性公民才可以参政，妇女、儿童和奴隶都不可以。实际上按照古希腊古典思想，政体形式可按统治人数来划分类型，按照由一个人统治、少数人统治和多数人统治，分为君主制、贵族制和民主制。从表面上看，雅典、威尼斯都是民主制，但前提是绝大多数人都不被定义为“人”。&lt;/p&gt;
&lt;p&gt;这里面其实隐藏了一个话语陷阱：如果可以由统治者来定义哪些人是人，那么贵族制、寡头制都可以通过操纵定义而变成民主制度。因此，如果不考虑“谁统治”的问题，只凭形式上的选举和代议来判断是否民主是毫无意义的。&lt;/p&gt;
&lt;p&gt;前面说的人的定义的问题，其实就是“少数中的多数”问题。这里面的“少数”是指统治者仅仅只是少数人，后面的“多数”才是“少数服从多数”中“多数”的含义。雅典和威尼斯都是遵循少数统治者内部的多数原则。今天的美国政治中，这种“少数中的多数”也是一个很值得关注的现象。例如在总统选举中，候选人只获得了少数选民的选票，但是只要多于对手就可以当选；在国会中，只有100席的参议院可以否决有435席的众议院。&lt;/p&gt;
&lt;p&gt;然而，多数并不是一直说了算。美国的宪法程序中设置了各种各样的否决机制，目的就是令少数可以有机会否决多数的意志。允许少数利用程序来否决多数，就是“宪政”的本质含义。与之相反，不允许少数来否决多数，就是多数之“专政”。&lt;/p&gt;
&lt;p&gt;历史上采用代议制的国家是否自认为是民主国家呢？显然不是。一般认为代议制的起源是在英国，而从严格意义上讲英国是代议君主制。但其实代议制的起源可以追溯到更早——日耳曼民族的原始自由。因此代议制是一项“自由”制度，而非“民主”制度。&lt;/p&gt;
&lt;p&gt;自由难道不是民主吗？范勇鹏教授认为自由绝不是民主，二者在原则上是相悖的。首先“自由民主”在语义上存在矛盾，其次美西方从未在冷战时期称自己的阵营是“自由民主”，而是在苏联解体冷战结束之后才开始的。&lt;/p&gt;
&lt;p&gt;这样，把代议制本身和自由、民主等现代意识形态概念剥离开，回到代议制本身来追根溯源，这样也许更容易看清真相。&lt;/p&gt;
&lt;h3 id=&#34;第一节-欧洲代议制的起源&#34;&gt;第一节 欧洲代议制的起源&lt;/h3&gt;
&lt;p&gt;关于欧洲现代代议制，很多人认为它始于 1215 年的《大宪章》。然而，《大宪章》被神化，成为了权力斗争的产物。范勇鹏教授认为，《大宪章》确实与代议制有关，但不应该像英美学者和政客那样给它披上各种华而不实的外衣。&lt;/p&gt;
&lt;p&gt;那么以《大宪章》为代表的代议制及其精神来自哪里？有一类说法极其流行：代议制或者宪章精神是在反抗君主专制的过程中产生的。然而，范勇鹏教授质疑这种说法，他认为代议制在产生的过程中根本不存在君主专制。实际上，君主专制在西方历史上是一个纯粹的现代现象，而自由的起源则要古老得多。&lt;/p&gt;
&lt;p&gt;范勇鹏教授认为，欧洲的代议制主要起源于封建制，并且日耳曼部落制度、罗马帝国及其城市制度、商业城市和城市共和国乃至教会的教士制和教区制度，都与封建制度交织在一起，经过复杂的化合反应才产生了现代代议制的萌芽。这一过程始于罗马帝国的衰落和日耳曼蛮族的入侵。后来随着国王集权的失败和贵族自由的提升，欧洲进入分裂的封建时期。&lt;/p&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    &lt;p&gt;&lt;strong&gt;中央集权和地方自治&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;中央集权和地方自治是此消彼长的关系，凡是中央集权发达的政权，一旦解体，地方自治能力都很弱；而地方自治能力强的国家，就不可能存在高度的集权。&lt;/p&gt;
&lt;p&gt;这里范勇鹏教授提到的罗马帝国衰落的情况就是如此，特别像中国魏晋南北朝时期或五代十国时期的北方的境况。&lt;/p&gt;
&lt;p&gt;在人类目前的技术条件下，这二者不可兼得，任何制度都不能既享有集权之能力和高效，又保持社会肌体自组织之能力。而集权显然是数千年制度进化的基本方向。&lt;/p&gt;

  &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;分裂的欧洲各国踏上了不同道路：法国走向了君权扩张，最终走向绝对君主专制；德国则进入神圣罗马帝国阶段，但皇帝不久就丧失实权，帝国变成邦联；在欧洲大陆之外的英国却凭代议制在此阶段发展起来，与欧洲大陆各国形成了鲜明对照。&lt;/p&gt;
&lt;p&gt;范勇鹏教授认为，英国未出现欧洲大陆那种更加典型纯粹的封建制；同时部落自由制度也未被消灭，即使王权在英国的地位较高，也不会出现王权的专制；最后宗教未能形成独特的力量，无法像在欧洲大陆那样制约王权。因此，这些极其特殊的条件奠定了英国代议制的基础。&lt;/p&gt;
&lt;p&gt;在此基础上，英国开始逐步限制王权，并且随着小贵族的兴起，国王、大贵族、小贵族（城市特权阶级）这三者之间的斗争趋于平衡。这种“三体”的关系使英国一方面保持了较强的中央权力，另一方面王权也受到约束，这决定了英国代议制的命运。&lt;/p&gt;
&lt;p&gt;而相比较英国而言，以法国和西班牙为代表的欧洲大陆则截然不同。法国大贵族强大，西班牙的蛮族征服者建立起较强的王权，这产生了与英国不同性质的代议制萌芽。&lt;/p&gt;
&lt;p&gt;纵观西欧封建制和代议制的发展过程，背后起决定作用的首先是不同阶级和权力集团间的力量对比关系。范勇鹏教授认为，代议制本身必然包含三重性质：部落性、封建性和集权性。缺了任何一个因素，都无法产生现代代议制。&lt;/p&gt;
&lt;h3 id=&#34;第二节-美国代议制的起源&#34;&gt;第二节 美国代议制的起源&lt;/h3&gt;
&lt;p&gt;前文曾述，北美殖民地的主要特征是人口的流动性。那么这些人来到美洲如何共同生活，如何组织成社会，如何建立权力和利益的分配机制？&lt;/p&gt;
&lt;p&gt;首先，他们是征服者，面对着他们眼中的敌人——印第安人。在这种情况下，他们在很大程度上回到了准自然状态：为了生存和安全不得不结成群体。其次，他们携带者家乡的文化、组织和制度。再次，他们成立股份公司，已经有了现代雇佣概念。最后，他们是英帝国延伸的触角。&lt;/p&gt;
&lt;p&gt;于是，这些移民开展了人类政治制度史上罕见的对照实验。实验的对象就是北美殖民地，在这块殖民地上先后产生了三种殖民地制度形式：公司殖民地、业主殖民地、契约殖民地。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;公司殖民地：通常由民间投资人组成股份投资公司，然后从王室获得特许状和宪章。&lt;/li&gt;
&lt;li&gt;业主殖民地：是欧洲封建领地传统的延续。（这里的“业主”是指对殖民地享有产权者）&lt;/li&gt;
&lt;li&gt;契约殖民地（自治殖民地）：由殖民者以自发的形式组建，或从公司殖民地分裂出来、基于自由民之间的契约而形成。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;上述三种殖民地实际上都产生了议会的雏形，其中有两种形态。一种是参事会，另一种是代表议会。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;参事会：本质上是公司董事会的形态之一，类似上院。（例如美国的参议院）&lt;/li&gt;
&lt;li&gt;代表议会：由于殖民地范围扩大，直接参政不再可行，在复杂的社会矛盾和利益斗争中产生。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;英国“光荣革命”后，开始对北美殖民地进行中央集权式的管理，出现了王室殖民地。从英国方面看，这是国家从封建制度彻底转向资本主义制度的努力。而从殖民地的角度看，王室殖民地的出现恰恰表明了自治努力的失败。&lt;/p&gt;
&lt;p&gt;北美独立之前，殖民地并非独立的政治实体。殖民地虽然在北美实行自治，但实际上是在英帝国制度下的一种特殊地方自治制度。英国“光荣革命”后，英国议会获得了更大的权力，对殖民地的立场也更加强硬专横。而北美殖民者则认为“光荣革命”的效力仅限英国本土，议会不得干预殖民地事务。随着向国王请愿和在英国议会谋求代表权的诉求落空，殖民地转向了追求独立的道路。在这个过程中，各殖民地的代议制开始向美国联邦代议制逐渐演变。&lt;/p&gt;
&lt;h4 id=&#34;总结-1&#34;&gt;总结&lt;/h4&gt;
&lt;p&gt;范勇鹏教授认为，美国的代议制绝非简单地模仿英国，而是在内因和外因共同作用下的复杂机制的产物。&lt;/p&gt;
&lt;p&gt;首先，早期殖民地采取了殖民者或者股东共同决定重大事务的制度。然而，所有人亲自参加公共事务是不可能的，代议制政府是一个更理想的选择。其次，代议制的功能就是将财产权转化成政治权利，从源头就是一种“天下为私”的制度。再次，代议制在不同制度因素的融合与相互影响下产生和发展，并且美国的代议制和英国的代议制的产生模式不同。最后，在于英国的贸易冲突和围绕帝国宪制的争论中，殖民地产生了共同的意志。从独立运动爆发到立宪完成，经过大陆会议、邦联国会，它最终演变为联邦的国会两院。&lt;/p&gt;
&lt;h2 id=&#34;第三章-公司国家&#34;&gt;第三章 公司国家&lt;/h2&gt;
&lt;p&gt;上一章探讨了欧洲和北美代议制的起源。实际上美国的新制度是以共和为名，在诸多方面与英国议会制有较大差异。那么共和制度来源于哪里？&lt;/p&gt;
&lt;p&gt;在古希腊和古罗马，“共和”一词意指不同政体形式或政治元素的混合，通常是国家中不同阶级力量均衡的产物。但是古代毕竟太遥远，而且美国的资本主义共和也仅仅只是在形式上与之相似而已。因此，要探索美国的共和制度，还是要回溯至近代社会诞生的前夜。&lt;/p&gt;
&lt;p&gt;在古代罗马城市制度的基础上，威尼斯最早产生了公司国家制度，后经荷兰的发扬光大，在英国“光荣革命”后的宪制中达到了比较成熟的状态。&lt;/p&gt;
&lt;h3 id=&#34;第一节-公司国家的诞生&#34;&gt;第一节 公司国家的诞生&lt;/h3&gt;
&lt;p&gt;首先来探讨一下罗马城市。罗马人统治的范围远远大于希腊人，但是实际上并不存在全国性的政治生活，国家政治主要是罗马城市政治的辐射。罗马国家规模的扩张也是以各地的城市为支柱，到帝国时期，城市制度已经发展为帝国行政制度的基础。城市是中央与地方政治权利间的环节，是地方经济中心，也是罗马法律和政治制度的传播场所。&lt;/p&gt;
&lt;p&gt;公元5世纪罗马帝国崩溃后，城市制度却留了下来。城市在漫长的中世纪保存着共和制度的基因，并在近代的前夜将这一基因与新生的资本主义嫁接在了一起。&lt;/p&gt;
&lt;p&gt;自11世纪到12世纪初，意大利地区的城市普遍发生了公社革命，商业开始慢慢复苏。这些城市开始从帝国中游离出来，逐渐演变成独立共和国。然而，有一个问题较少受到当时人们的注意：主权问题。那个时代的欧洲人还没有现代主权概念，但在政治生活中又必须面对最高权威的问题。意大利没有中国的这种郡县制，而多数传统社会的政治权威大都靠军事或土地贵族。但是此时的意大利已经发展到现代资本主义的门槛上，商人阶级成为政治中最活跃的力量。他们绝不情愿将最高权力交给任何国王和贵族，因此发明出了共有的集体主权，以股份公司的形式解决统治问题。这就是所谓公社或共和国的本质所在。&lt;/p&gt;
&lt;p&gt;而意大利的城市威尼斯恰恰是这一类的代表。威尼斯其实代表了欧洲历史上一类十分特殊的国家——商业城市共和国，或者更形象地说是商业公司型国家。称其为商业公司国家，是因为它不同于欧洲大陆的几乎所有国家——它没有皇帝、国王，没有真正意义上的贵族或任何人格化的主权者，全由商业家族掌握一切政治权利。&lt;/p&gt;
&lt;p&gt;如果我们复盘威尼斯成长的过程，会发现这个国家在地理、人口、产业、制度乃至观念上都与美国有诸多相似之处。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;地理环境：良好的港口、得天独厚的贸易优势。&lt;/li&gt;
&lt;li&gt;人口与阶级：人口大多是在蛮族入侵的背景下，从罗马和意大利其他地方迁移而来。阶级则可分为贵族、市民和平民三个等级，没有欧洲大陆真正意义上的王室和贵族。&lt;/li&gt;
&lt;li&gt;国家与商业利益：开创了现代资本主义商业的新模式。（逐利性）&lt;/li&gt;
&lt;li&gt;公司国家制度：贵族集体讨论代替了大公的个人权威（商业贵族垄断），政府权力和职能分散到各个专门机构和委员会（分权与制衡）。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;威尼斯独立后，失去了帝国主权，也没有封建领主，对任何人都不承担义务，只剩下地方事务。但客观上它又是一个独立共和国，没有任何人可以声称拥有至高无上的统治地位，于是形成了一种共有主权的现象。商业的发展造成大家族共治，几乎完全以股份公司的形式塑造了共和国政府。&lt;/p&gt;
&lt;h3 id=&#34;第二节-公司国家的发展尼德兰&#34;&gt;第二节 公司国家的发展：尼德兰&lt;/h3&gt;
&lt;p&gt;2019 年底，“荷兰”政府宣布，从 2020 年起，对外停止使用“荷兰”这一非正式国名，一律使用正规的国名“尼德兰”。历史上荷兰是尼德兰最为著名的省，所以人们习惯上以荷兰指代尼德兰。&lt;/p&gt;
&lt;p&gt;尼德兰的人口与威尼斯有类似之处，即多为移民。但安全优势则比威尼斯逊色多了，不过地理位置所带来的贸易优势可以与威尼斯匹敌。&lt;/p&gt;
&lt;p&gt;尼德兰在独立之前处于神圣罗马帝国的统治之下，在反抗西班牙统治的过程中得到独立。尼德兰是标准的资本主义国家样板，尼德兰人也在商业活动中积累了大量货币资本，也创造了强大的金融力量。商业和金融阶级用财富把持官职，又利用政治权力来维护自己的利益，形成财富和权力的“闭环”。&lt;/p&gt;
&lt;p&gt;尼德兰虽然存在着法理意义上的共和国主权，但也面临中央权威事实上的阙如。各省都产生了相对独立的地方统治者，其主要成员多数是因商业成功而致富的地方城市精英。而荷兰省的经济力量过于强大，该省的统治阶级对中央权力形成了强大制约。因此，在尼德兰的黄金时期，政治生活的中心舞台是各自治城市。当时的共和国有两个中心城市，阿姆斯特丹是经济中心，省和联邦政府所在地海牙则是名义上的政治中心。&lt;/p&gt;
&lt;h3 id=&#34;第三节-公司国家的成熟英国&#34;&gt;第三节 公司国家的成熟：英国&lt;/h3&gt;
&lt;p&gt;前文提到英国的议会制度在“光荣革命”后达到了高峰。那么英国成熟起来的议会制度和之前讨论的威尼斯和尼德兰城市共和制度有何异同？又有无内在关联呢？&lt;/p&gt;
&lt;p&gt;虽然英国也是一个移民国家，但“光荣革命”后这些移民已经在英伦三岛生活了1000余年，并且和威尼斯以及尼德兰相比拥有更多的农业人口。从现代化进程来看，这是英国的一个劣势，因为农业人口和封建依附关系会阻碍资本主义制度的演进。但从为资本主义提供自由劳动力方面看，这又是个巨大优势，使英国比威尼斯和尼德兰更具有后劲。&lt;/p&gt;
&lt;p&gt;我们知道，“光荣革命”因其未发生大规模流血冲突而受人称赞。但细究起来，却发现革命之所以能够温和进行，是因为它本来就没有那么“革命”——“光荣革命”实际上就是英荷两国商人和新兴资产阶级联合进行的一项冒险事业，其目的就是将尼德兰的制度要素引入英国，以近乎公司合并的方式把英国改造成一个更适合商业和资本主义繁荣发展的天堂。&lt;/p&gt;
&lt;p&gt;当时的尼德兰共和国虽然掌握着大量金融资源，但是没有用来提高生产力发展资本主义，而是用来发展军事获得超经济的贸易优势。而当时英国的新型资产阶级饱经王室政治动荡以及宗教等因素的恼人干扰，亟需一次制度变革。对于当时的英国人而言，尼德兰既是竞争对手又是合作伙伴，时而是资金来源，尼德兰在英国内部也有很大的影响力。英国为了获得更高的利润，鼓励引进佛兰德尔的工匠和技术，以期把整个“产业链”都放在英国内部，获取重商主义利益。尼德兰移民和工匠不仅给英国带来了先进的技术和设备，而且打破了封建行会对生产力发展的阻碍，改进了产业组织。&lt;/p&gt;
&lt;div class=&#34;alert alert-warning&#34;&gt;
  &lt;div&gt;
    &lt;p&gt;&lt;strong&gt;“偷窃”？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;2018 年特朗普总统发动中美贸易战之后，美国不断指责中国“偷窃”技术，却不讲西方历史上“偷窃”了东方多少技术。其实技术的迁移和转让是再正常不过的事情，现代工业国家崛起都经历过这个阶段。&lt;/p&gt;
&lt;p&gt;例如，英国的爱德华三世就系统性的从尼德兰引进技术和产业。美国建国后，开国元勋汉密尔顿曾推动过同样的事业，大举从英国吸引和“走私”技术工人。&lt;/p&gt;

  &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;“光荣革命”中止了“复辟时代”的王权扩张和专制主义趋势，改变了国王与议会的关系。英国逐步确立了君主立宪制，王权被削弱。不过，“光荣革命”后的英国国王仍拥有较大权力，特别是行政权。这一时期英国政治的基本特征是混合式宪政，本质上是贵族寡头统治。&lt;/p&gt;
&lt;p&gt;随着资产阶级力量的上升，革命还在不断向前推进。1832 年的议会改革法开启了改革时期，维多利亚女王在位期间，英国确立了虚君制和议会至上原则，形成了责任内阁制。两党制度形成，政党也成了全国性的政治组织。此后的改革不断削弱贵族的力量，内阁和首相的权力不断扩张，上院衰落，下院逐步掌握领导权。这个基本架构一直持续到今天，也标志着英国已经最大限度地将一个“王朝国家”改造成了一个公司国家。&lt;/p&gt;
&lt;h4 id=&#34;威尼斯尼德兰和英国之比较&#34;&gt;威尼斯、尼德兰和英国之比较&lt;/h4&gt;
&lt;p&gt;马克思曾经指出，商人资本发展的大革命是促使封建生产方式向资本主义生产方式过渡的一个主要因素。威尼斯、尼德兰和英国的制度演变都是发生在这个过渡中。&lt;/p&gt;
&lt;p&gt;在这三个国家中，商人资本和金融资本共同的梦想就是令&lt;strong&gt;金钱等同于权力，公司等同于国家&lt;/strong&gt;。三个国家都比较成功地实现了这一梦想，但是它们处在从前资本主义商业向工商业资本主义发展道路的不同阶段，因而其公司国家的纯粹程度不同。威尼斯和尼德兰的城市商业阶层对商业机会不足的反应不是提高劳动生产率，而是借助超经济强制对生产者进行更残酷的压榨。英国则是投资技术革新以降低成本，转向资本主义的商业模式。&lt;/p&gt;
&lt;p&gt;还有一点就是国家主权所在和政府权力的配置问题。实际上封建制度没有最高主权，军事制度和行政制度建立在封建土地所有制上，即使原则上存在着最高主权，实际它已经归于消灭了。后来商人阶级成为共和国统治者后，俘获了这一制度，将国家改造成了一个股份制公司。&lt;/p&gt;
&lt;p&gt;英国则恰恰相反，它早已具有强大的王权。在王权、大贵族和小贵族与乡绅的长期斗争过程中，代议制获得高度发展。不过，王权和封建贵族仍是新兴商业资本发展的主要障碍，于是资产阶级发动了“光荣革命”，进行了一次“公司重组”。&lt;/p&gt;
&lt;p&gt;英国与威尼斯、尼德兰所不同者，即在于是否有强大的行政权力。这就是原本有无主权和主权强弱所造成的区别。总之，比起威尼斯和尼德兰，英国的资本主义更加发达，但是其公司国家的发展却不够纯粹。资本与国家全面一体化的公司国家的样板，要等待新生的美国来创建。&lt;/p&gt;
&lt;h2 id=&#34;第四章-独立和立宪&#34;&gt;第四章 独立和立宪&lt;/h2&gt;
&lt;h3 id=&#34;第一节-独立运动&#34;&gt;第一节 独立运动&lt;/h3&gt;
&lt;p&gt;北美殖民地的独立，被后世的美国历史学家涂上了一层层油彩，使其看起来完全是一场追求正义、反对不公、抵抗暴政的伟大革命。范勇鹏教授在这里尖锐地指出，美国独立运动的历史叙事充斥着借口、幻想、谎言以及精心建构的史诗。&lt;/p&gt;
&lt;p&gt;如果比较充分地了解当时的各种情形，不难发现革命的主要原因十分简单，就是殖民地对土地扩张和商业利益的追求。前文曾述，英国人之所以建立北美殖民地，是为了追求自己的重商主义利益。重商主义的关键是对货币的需求，其首要目标就是获取和保有尽可能多的货币。&lt;/p&gt;
&lt;p&gt;那么，依据重商主义理论，殖民地应该与母国形成互补贸易。然而，英国与殖民地虽然有共同利益，但也有很多潜在冲突。其中首要的冲突就是英国对殖民地贸易的限制，其次是英国对殖民地扩张的限制。（范勇鹏教授例举了很多史实和数据论证，这里不再展开。）还有观点认为殖民地对货币的需求未能满足，也有人认为殖民地人主要不满英法七年战争之后的新税，但后一种观点范勇鹏认为站不住脚，因为从事实上看，殖民地是受益者。&lt;/p&gt;
&lt;p&gt;结合上述分析，范勇鹏教授认为，殖民地要求独立并不完全是因为他们声称暴政、高税负，而是有很强的利益导向。这关系到一些群体的特殊利益，特别是以律师、商人和种植园主构成的“口齿伶俐的集团”、“爱国者”。独立运动就是由这些代表有产阶层的爱国者们所主导的。范勇鹏教授认为，没有什么字眼比用“资本主义”来形容美国更合适的了。&lt;/p&gt;
&lt;p&gt;实际上，北美独立运动不仅仅是殖民地与英国的一场斗争，也是殖民地内部对未来制度形式进行探索、比较和竞争的过程。范勇鹏教授举了一些史实来论证他的观点，例如组建新议会、通过新宪法等等，有一些州采取三权分立的制度，确立了议会拥有最高立法权的原则。范勇鹏教授认为这些制度变化大多显示了公司制度的特征，在上一章节当中范勇鹏教授详细地阐述了公司国家的本质。而究其原因，是因为这是一种有效的公司治理模式，它最能够保障股东的控制权，同时又能给经营活动留下足够的自由空间，它非常适合美国这种主权缺失和重建的国家。&lt;/p&gt;
&lt;h3 id=&#34;第二节-邦联条例&#34;&gt;第二节 《邦联条例》&lt;/h3&gt;
&lt;p&gt;从国际地位上看，当时签订英美和平协议的时候并不是英国和 13 个殖民地单独签订的，而是与所有的殖民地共同签订，因此用了大写的 United States。从主权角度看，英美条约意味着美国已经有了主权。那么按照欧洲的理论，主权不可分割，这样各州就失去了独立主权的地位。&lt;/p&gt;
&lt;p&gt;然而事实并不是如此，理论在政治活动中从来都无法真正阻碍为利益前进的步伐。那么如何从各殖民地的议会或者其他政治机构中创造出主权呢？独立之前的《邦联条例》就完成了第一步。&lt;/p&gt;
&lt;p&gt;1777 年，北美大陆会议通过《邦联和永久联合条例》（简称《邦联条例》），1781 年 3 月 1 日各州批准生效。条约内容总结起来就是一句话——各州拥有主权，但主权需因邦联的存在而存在。然而，邦联本身没有统一主权，但各州却又必须因邦联的存在而成为法定，这种奇怪的状态必然会引出新的矛盾。&lt;/p&gt;
&lt;p&gt;如果按照现代制度史观来看，邦联制度甚至比各州宪法有所倒退——它既不够自由，也不够强大。首先，不搞三权分立，从革命时期各州的权力分立立场上有所后退；其次，没有独立行政和司法部门；再次，上轻下重，中央权弱。因而这个制度无法满足新生合众国的需要，中央权力过弱带来了很多问题。例如欧洲国家利用其内部矛盾干预美国内部事务，英国拒绝为美国开放港口等等。&lt;/p&gt;
&lt;p&gt;于是，各州只好自求多福，尽可能更多地保全自身的利益。各州还发行自己的纸币，导致通货膨胀，引发了各地人民起义，其中影响最大的就是谢斯起义。然而邦联政府不能给当地政府帮助，因此统治阶级开始意识到要加强国家权力。&lt;/p&gt;
&lt;h3 id=&#34;第三节-制宪&#34;&gt;第三节 制宪&lt;/h3&gt;
&lt;p&gt;美国的统治阶级发挥了他们极大的主观能动性，要亲手改造这个制度，使之服务于他们的利益——制宪。&lt;/p&gt;
&lt;p&gt;制宪会议面临来自各州的复杂利益的纠葛，包括大州和小州的矛盾以及南方和北方的矛盾，等等。例如两院按人口分配议员，这样对大州有利而对小州不利；再比如奴隶到底算不算人的问题，南方希望奴隶算人口，这样就可以增加其在下院的势力。&lt;/p&gt;
&lt;p&gt;这些矛盾最终以主要的利益关系达成妥协而解决，美国制宪取得了成功。这是因为它符合当时各州统治阶层的根本利益——商业利益。在符合大利益的前提下，具体的冲突都不难解决。&lt;/p&gt;
&lt;h2 id=&#34;第五章-宪法制度&#34;&gt;第五章 宪法制度&lt;/h2&gt;
&lt;h3 id=&#34;第一节-公司与契约&#34;&gt;第一节 公司与契约&lt;/h3&gt;
&lt;p&gt;范勇鹏教授在本小节中主要阐述公司和契约的概念及其历史根源。&lt;/p&gt;
&lt;p&gt;然而，不同文化中的人们对社会现象的认识很难通约。例如，在中国人的观念中，政治实体和经济实体通常是截然不同的两类事物。但是，在地中海文明中，特别是在欧洲，政治实体、宗教实体和经济实体往往是同源的。所以，西方文化中的财产和权利、财产与自由、特权与权利、宗教与权利等等，往往都是同源共生的。这种关系中国人相对而言是难以理解的。同样，中国人的“公”和“私”的概念放在西方社会中也很难找到对应概念。&lt;/p&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    &lt;p&gt;&lt;strong&gt;“公”与 public &amp;amp; fair&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;“公”这一字在中国人看来除了有“公共”的含义以外，还有“公平”的含义，并且一个字的含义是二者兼而有之的，并不是每次使用只能表达一个意思。&lt;/p&gt;
&lt;p&gt;而在英语中，不论是 public，还是 fair，都不能表达出另外一个单词的意思。因此，范勇鹏教授认为中国人的“公”和“私”的概念放在西方社会中也很难找到对应概念。&lt;/p&gt;
&lt;p&gt;此外，在政治领域，西方国家往往只有 public 的概念，public 的人被称为公民。而在我国，公民是法制概念，人民才是政治概念。社会主义社会强调各民族人民平等、团结，这也是孙中山先生的三民主义“天下为公”的思想继承和发展。这就是中国人的“公”的概念。&lt;/p&gt;
&lt;p&gt;如果我们去了解中国人民大学的英文翻译，会发现被译成 Renmin University of China。那么为什么不翻译成 People University of China 呢？因为 people 一词在西方文化只有 public 的概念，不是中国人的“公”的概念，也不是马克思主义唯物史观中的人民群众的概念。如果这样翻译的话，西方人会认为这是中国普通人的大学。&lt;/p&gt;

  &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;之所以范勇鹏教授要花费大量篇幅解释这个问题，是为了让我们容易理解西方文化中公司和契约的概念。&lt;/p&gt;
&lt;h4 id=&#34;法人观念&#34;&gt;法人观念&lt;/h4&gt;
&lt;p&gt;法人的概念伴随着罗马法的复兴而产生。例如，基督教会自称为基督的身体。这种具有人格的身体的观念，与罗马法中萌芽的法人观念结合，在法律上导致了新的明确的法人概念。此后，法人的概念逐渐发展，并开始进入世俗领域。而到了都铎王朝后期，出现了公司法人观念。&lt;/p&gt;
&lt;p&gt;那么，把法人观念和国家观念结合起来，把国家视为一个人格，承当这一人格者就是主权者。这就是本章一开始讨论的主权和公司国家的关系问题，可以看到主权的概念是源于公司法人的概念的。我们知道，“法人”一词中的“人”未必是指一个人，可以说全体或一部分人组成的会议。这样一来，公司国家、法人、主权的概念就能说通了。&lt;/p&gt;
&lt;p&gt;君主立宪制的英国仍保有独体法人——国王，而原来是殖民地的美国各州也仍然残留有殖民地公司的法人的性质，由此可见其公司国家的性质。&lt;/p&gt;
&lt;h4 id=&#34;公司制度&#34;&gt;公司制度&lt;/h4&gt;
&lt;p&gt;范勇鹏教授认为，现代公司制度最早可以追溯到威尼斯。威尼斯的海上贸易风险很高，需要大规模投资，所以威尼斯人发明了集体投资、风险分担的公司形式。尼德兰发展了这一形式，并产生了股东有限责任的原则。英国人则将之发展成有限责任公司。显然，北美殖民地也是英国有限责任公司的一部分。&lt;/p&gt;
&lt;p&gt;有限责任公司一般由股东大会、董事会和经理人员构成。股东大会是最高权力机构，可以选举董事会负责经营决策。&lt;/p&gt;
&lt;h4 id=&#34;作为契约的宪法&#34;&gt;作为契约的宪法&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;我们合众国的人民，为了……，为美利坚合众国制定和确立本宪法。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;范勇鹏在这里彻底撕下了美国《宪法》的外衣。他写道“相信熟悉商务的读者由其措辞和结构立刻会联想到商业合同”，以说明它与商业活动的联系和其公司国家的本质。&lt;/p&gt;
&lt;p&gt;美国《宪法》中的“人民”在当时引起了很大的争议，有人认为这句话篡夺了州的权利。范勇鹏教授并不纠结于此，他认为这只不过是资产阶级的障眼法，真正的绝大多数人民并未被包含其中。&lt;/p&gt;
&lt;p&gt;200 余年来，政治理论家们将各种神圣的价值加之于这部宪法。但如果不带成见地阅读这一序言，应该很容易感受到扑面而来的商业气息。美国经济史家帕塞尔曾直白地承认，美国《宪法》的目的就是为美国建立自己的重商主义体制，为与那些奉行重商主义的欧洲国家展开更为有效的竞争铺平道路。&lt;/p&gt;
&lt;h3 id=&#34;第二节-宪法制度&#34;&gt;第二节 宪法制度&lt;/h3&gt;
&lt;h4 id=&#34;合同范本&#34;&gt;合同范本&lt;/h4&gt;
&lt;p&gt;相比起当代世界各国的宪法，美国《宪法》显得格外简洁——一共只有七条。美国宪法的核心就是前三条，分别规定了立法权、行政权和司法权——这就是美国的三权分立。&lt;/p&gt;
&lt;h5 id=&#34;立法权&#34;&gt;立法权&lt;/h5&gt;
&lt;p&gt;美国《宪法》的第一条规定立法权归国会。但要注意它特别强调了“本宪法授予的全部立法权”归国会，言下之意就是不是全部的立法权。这是因为各州主权对联邦转让，故《宪法》未列举的立法权仍归各州。&lt;/p&gt;
&lt;p&gt;第一条第八款规定了国会的 17 种权力，可以分为七类：财政的、商业的、金融的、智识的、司法的、防务的、管理的。这充分体现了美国《宪法》对商业事务的格外关心。范勇鹏教授还列举了其他一些具体的条款，以证明联邦是一个为了协调商业关系、实现商业利益而建立的实体。&lt;/p&gt;
&lt;h5 id=&#34;行政权&#34;&gt;行政权&lt;/h5&gt;
&lt;p&gt;美国《宪法》的第二条规定了总统的权力。从对总统的规定来看，《宪法》似乎并不怎么重视总统这个角色，甚至对一个人格化的总统抱着戒备之心。例如，代表们曾对总统的任期提出了不同的方案，最后选择四年作为折中方案。代表总统的行政权在 1787 年美国《宪法》中似乎没有什么地位和存在的意义，不像后来在实际运行时那么重要。&lt;/p&gt;
&lt;p&gt;首先，几乎一切行政权力都取决于国会的法律。即便总统使用“否决权”，国会还可以再次投票压倒总统的否决意见。其次，内阁部长们与总统的关系也没有明确规定，总统对部长的任命收到参议院的制约。最后，出来总统和部长们之外，并没有一个全国性的行政官僚机构。&lt;/p&gt;
&lt;h5 id=&#34;司法权&#34;&gt;司法权&lt;/h5&gt;
&lt;p&gt;美国《宪法》第三条第二款规定了司法权的范围，主要是各政治实体之间的诉讼。范勇鹏教授认为，司法权所管辖者大多属于商业领域的事务。美国国家的商业性质使之对普通法有高度依赖，因而美国必须有一个权威的法院，引导整个普遍法的形成和发展。&lt;/p&gt;
&lt;p&gt;范勇鹏教授认为，司法权从属于立法权，这是因为国会主要的权力是关于商业的，而司法权也都是商业领域的事务。虽然美国《宪法》没有明确这么讲，且人们往往人云亦云的认为法院是三权分立中的一权，但在实际运行过程中，法院几乎没有挑战过国会的权威。联邦最高法院没有总统的否决权就可以说明这一点。在历史上最高法院仅对两项国会法案做出过违宪审查。从实际效果看，每当法院与国会冲突，国家总会陷入僵局。&lt;/p&gt;
&lt;p&gt;综上所述，今天三权之间的关系远比《宪法》规定的要复杂。但是如果回到制宪者们所规定的这个原初合同，我们能够更清晰地看到美国国家诞生的性质，及其治理结构的原型。对于政治学者来说，这部《宪法》有留下了太多政治问题；但是对于商业人生，这却是值得一读的合同范本。&lt;/p&gt;
&lt;h4 id=&#34;有限责任公司&#34;&gt;有限责任公司&lt;/h4&gt;
&lt;p&gt;将美国《宪法》建立的制度放在从威尼斯、尼德兰到英国这一系列制度传统中来理解，我们就可以清晰地看到其演变源流及其类似商业公司法人的性质。&lt;/p&gt;
&lt;p&gt;国会就是美国的董事会，名义上与美国人民是一种委托—代理关系。但实际上这个“人民”只是那些真正的股东——极少数资产阶级。即使今天的美国公民获得了形式上平等的股东权力——选举权，但实际上却微不足道。&lt;/p&gt;
&lt;p&gt;国会与行政部门也是一对委托—代理关系。司法权则类似公司监事会，受董事会的委托来执行监督职责。&lt;/p&gt;
&lt;p&gt;美国的宪法制度与公司的治理结构也有异同。公司的委托—代理关系不是一种纵向的等级关系，而是一组授权关系。美国国会、总统和最高法院之间也是这样一种关系，其权力范围都由法律来制定，即所谓的权力分立与制衡。&lt;/p&gt;
&lt;p&gt;但是，国家毕竟不是纯粹的公司。事实上总统和最高法院都在分享一部分立法权，总统还获得了批准国会立法的权力。除了股东和雇员，还有实实在在的人民。所以，扩大普选权并且在形式上实现是有必要的。但这其实不符合立宪者本意，因而必然带来对宪法制度的调整，以维持精英的统治。这就是后来政党政治出现、行政区不断扩大以及司法权取得一定独裁权力的根本原因。&lt;/p&gt;
&lt;h4 id=&#34;主权权威&#34;&gt;主权权威&lt;/h4&gt;
&lt;p&gt;关于美国制度的讨论通常多关注权力的制约和平衡，忽略了真正关键的问题，即权力或权威的创生。&lt;/p&gt;
&lt;p&gt;历史上各个国家的权威强弱不一，总的来说流血的多少往往决定了权威的强弱。范勇鹏教授认为权威的强弱不是一个价值判断，只是一个事实，很难简单地说好或者不好。&lt;/p&gt;
&lt;p&gt;威尼斯的主权来源于罗马帝国权威的下放。恰好威尼斯拥有特殊的条件，产生了由商业资本主导的，与公司治理同构的政治制度。但是随着威尼斯陆地霸权的扩张，集体主权缺乏真正的权力中心，无法继续维持下去。&lt;/p&gt;
&lt;p&gt;尼德兰以各省联邦的形式独立，但实际影响不大。其结局与威尼斯颇可类比，也是由于陆地军事冲突的消耗和海上贸易竞争对手的出现而衰落。&lt;/p&gt;
&lt;p&gt;英国在“光荣革命”后创立了责任内阁制，大大巩固了资产阶级的权力。英国制度的成功，根本上源于拥有历史合法性的主权者——国王。英国制度是国家权力与公司治理结构结合较好的一个典范。&lt;/p&gt;
&lt;p&gt;北美殖民地原本只是英国宪制中的地方性制度产物，这些殖民地都不存在主权问题。美国独立战争主要是占人口不到 5% 的城市居民的事业，占人口多数的人民对独立事业并不关心，甚至有一些宗教团体拒绝为独立而战。自美国独立到南北战争期间，美国联邦政府的权威才慢慢通过一系列历史事件逐步加强，最终由林肯总统奠定了今天联邦政府的权威。&lt;/p&gt;
&lt;p&gt;因此，只靠宪法批准这样的程序性手段来抑制出一个虚构的国家人格是项艰难的工程。首先，殖民地法人实践留下的治理结构顺理成章地影响到美国宪法制度的创建；其次，美国人不得不像威尼斯人一样，建构起一种集体主权；最后，美国又不同于威尼斯，它要让多个法人合并成一个新的法人，这导致了双层主权的困境。&lt;/p&gt;
&lt;p&gt;而今天的三权分立，恰恰是在这种双重政权和困扰争议中产生的一种折中结果。今天很多中国人将之看作是“普世价值”。实际上，它既不“普世”，也非“价值”。范勇鹏教授认为，说它不“普世”是因为它在西方政治传统中是一个奇葩异类；说它非“价值”是因为美国的制度绝非建基于对正义、进步、民主或者其他价值的追求，而是商业利益。&lt;/p&gt;
&lt;h4 id=&#34;有限责任政府&#34;&gt;有限责任政府&lt;/h4&gt;
&lt;p&gt;美国的三权分立，最大的效用就是让责任无处可寻。密尔曾说，当任何人都不知道谁应负责的时候，就等于谁都不负责。这就是“有限责任”的原则，这跟我们中国人的观念以及中国的政治传统有很大的差异。国会立法权的有限性和“列举”性质，是对其权力的制约，同时也是对其责任的豁免。&lt;/p&gt;
&lt;p&gt;美国前总统威尔逊曾经指出美国政府的这种有限责任性。他在《国会政体》一书中写道：“国会采取行动，必须通过总统和内阁；总统和内阁必须等待国会做出决定……目前实行的权力分散但责任不清的做法，是我国联邦制度的根本缺陷。”美国抗击疫情不力足以证明美国制度的这种有限责任性质。&lt;/p&gt;
&lt;h2 id=&#34;第六章-宪政弊端&#34;&gt;第六章 宪政弊端&lt;/h2&gt;
&lt;h3 id=&#34;第一节-总统制与议会制&#34;&gt;第一节 总统制与议会制&lt;/h3&gt;
&lt;p&gt;在公司性国家的漫长演讲过程中，出现了两种主要的制度形式：总统制和议会制。一般认为，总统制通常是由选举分别产生立法和行政机关，总统既是国家元首又是政府首脑，行政机关与立法机关之间是分立和制衡的关系。议会制又称内阁制，由选举产生立法机关，议会选举中获胜的党组建内阁，立法权与行政权不分立。&lt;/p&gt;
&lt;p&gt;这两种制度均与公司治理中的“经理管理”模式有同有异。总统制，特别是美国宪法中规定的总统制，在结构上更接近经理管理模式。国会与总统分立，且存在委托—代理关系。不同点在于，总统在实际制度运作中获得了远高于公司经理的地位，国会也不像公司董事会一样对行政事务退避三舍。&lt;/p&gt;
&lt;p&gt;而议会制与经理管理模式在形式上有很大区别。除英国外，在非立宪君主的议会制国家，唯一民主的合法机构是议会，而政府从议会的信任中取得权力——行政权紧密地融合于立法权之中。&lt;/p&gt;
&lt;p&gt;这两种制度孰优孰劣，众说纷纭。但我们不乏可以见到很多认为总统制更有优势的观点，范勇鹏教授列举了很多并一一提出质疑。&lt;/p&gt;
&lt;h4 id=&#34;1-反对党可对总统权力形成制衡&#34;&gt;1. 反对党可对总统权力形成制衡&lt;/h4&gt;
&lt;p&gt;范勇鹏教授认为，在总统制中，特别是在存在国会两院的情况下，根本不存在执政党和反对党的概念。因为主权性质模糊，我们不能说总统的党就是执政党，占两院议席多数的党就是执政党。&lt;/p&gt;
&lt;h4 id=&#34;2-总统任期制可以防止独裁&#34;&gt;2. 总统任期制可以防止独裁&lt;/h4&gt;
&lt;p&gt;范勇鹏教授认为，任期制恰恰是美国制度僵化的主要原因之一。它将政治议程断裂为非连续性的、严格分界的时期，一旦选举结束，选民就与政治无关了。复旦大学中国研究院院长张维为教授将这种现象称为“四年一次的民主”。&lt;/p&gt;
&lt;h4 id=&#34;3-行政机关更加专业化&#34;&gt;3. 行政机关更加专业化&lt;/h4&gt;
&lt;p&gt;范勇鹏教授认为，真正专业化的行政官僚体系是在美国立宪 96 年之后才出现。在文官制度建立之前，每次总统选举的结果就是成千上万的官员大换班，导致美国完全由一帮猎取官职的政客来实行业余水平的行政管理。&lt;/p&gt;
&lt;h4 id=&#34;4-人民直接选举总统更加民主&#34;&gt;4. 人民直接选举总统更加民主&lt;/h4&gt;
&lt;p&gt;范勇鹏教授认为，这更加荒诞不经。首先，美国不是直接选举总统，而是通过选举人团间接选举。其次，总统制导致选举中的赢家通吃。&lt;/p&gt;
&lt;h4 id=&#34;5-总统制更加稳定&#34;&gt;5. 总统制更加稳定&lt;/h4&gt;
&lt;p&gt;范勇鹏教授认为，这需要澄清我们谈论的是什么样的稳定。如果内阁不会发生频繁更换，那么固定任期的总统制显然更加稳定。如果为了避免出现危机，那一定是议会制更加稳定。美国总统和国会发生冲突之后，常常会出现危机，例如弹劾总统、政府关门等等。&lt;/p&gt;
&lt;p&gt;实际上，美国总统制的致命弊端是国家的权威不足，这一弊端的根源就是立法权和行政权的分立。英国和美国不同，发生分歧之后，内阁可以负责，关键时刻可以辞职或威胁解散议会。不幸的是，在总统制中，如果出现分歧，立法和行政机构只能斗争。议会制国家是以双方同意的方式来执行管理，总统制国家是以对抗性的方式来执行决策。&lt;/p&gt;
&lt;h3 id=&#34;第二节-官僚制度&#34;&gt;第二节 官僚制度&lt;/h3&gt;
&lt;p&gt;提及官僚制度，不得不承认中国发展出了人类最早成熟的制度。中国官僚制度从诞生起就着意于公私之分，从周到秦即为“由亲到信”的演变阶段，之后官僚制度不断突破私人集团。西方官僚制度大体上仍是以私为本，今天仍未尽脱。&lt;/p&gt;
&lt;p&gt;在美国制度中，行政部门与官僚制度不是一回事。行政是三权之一，而官僚则产生较晚，且对行政权和立法权都有从属关系。韦伯观察到，只有美国采用了一种异样的制度：民选总统是官僚机构首脑，官员由他任命，只在预算和立法问题上受制于国会。然而，美国《宪法》并没有规定总统可以罢免官员，留下了一个长期诉讼。这就暴露出了一个问题：行政官员到递归谁管？&lt;/p&gt;
&lt;p&gt;在选举政治传统中，美国政治文化存在着一种轻视官僚的习惯。范勇鹏教授认为，其根源在于前述董事会于经理之关系。对于公司而言，股东（资产阶级）在不到特别必要的时候，不愿意将权柄交出，特别是交给一群由另一种逻辑选拔出来，并且往往出身平民的人——官僚。&lt;/p&gt;
&lt;p&gt;在人类历史上，官僚最初的产生都是作为统治的工具，但是官僚制度会产生自身利益和制度惰性，官僚集团也会形成自我认同和权力堡垒。在人们眼中，官僚往往是了无个性、照章办事、唯唯诺诺、文牍成风之辈，像机器一样毫无激情地执行者上级的指令，甚至经常在无意义地空转。正因为他们的这种保守性，使其对任何扩张性的政治权力——不管是军事扩张、宗教狂热还是商业冒险——都拥有一定的天然免疫力。官僚一方面是大规模复杂社会必需的工具，另一方面他们会在其工具性地位上不断积累权力，威胁到贵族、教会或资产阶级的地位。现代资产阶级非常清楚这一点，所以在他们的文化和意识形态中都是厌恶官僚的。&lt;/p&gt;
&lt;p&gt;因此，美国建国之初主要靠政治官员，而只在必要的岗位上使用极少的文官。而美国文官制度经历了一个漫长的发展历程。从华盛顿总统开始，官员论家庭出身，具有强烈的封建等级和商业扈从色彩。从第二任总统亚当斯开始，官员的任命带有明显的党派色彩。特别是杰克逊总统罢免之前共和党任命的官员，换用民主党的支持者。其结果是之后不管哪个党派上台，都会换上本党成员。然而，这样一来政府效率低下、官员能力不足、腐败横行，亟需改革。美国自 1871 年开始文官改革，通过公开竞争考试选拔。然而，即使规定文官不得参加政治活动和竞选，还是有很多文官迅速沦为利益集团，参与权钱交易，从利益集团的游说活动中赚钱，官僚主义、形式主义等弊端丛生。&lt;/p&gt;
&lt;p&gt;美国官僚制度的发展也有其客观逻辑。地理、安全等优势使得美国在建国早期对官僚制度的需求并不强烈。而美国文官制度的产生和发展，根本原因是工商业资本主义的发展对国家管理经济社会事务的能力提出了更高的要求。这里面还有两点直接原因：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;现代理性主义国家对官僚制度的促进。现代国家机器的中心问题是如何实现清晰化和理性化。前现代化国家不需要掌握人口、资源等精确信息也能实现基本有效的统治。现代资本主义将一切都放进了资本盈利公式之中，国家也变成了一家大企业，需要进行成本核算，这就要求对劳动力和资源有清晰的认识。&lt;/li&gt;
&lt;li&gt;西进拓荒对官僚制度的促进。在历史上，美国西部的治水文明产生了人对人的统治和官僚权力的扩张。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;官僚制度的兴起和发展标志着美国在由公司向国家演进的道路上迈进了一大步。这一转变不仅是官僚制度发展的结果，北方工商业企业的狂飙突进、垄断资本和金融资本的扩张共同奏出了国家主义的乐章。一些思想家认为国家是自由的来源，这其实已经有了一些政府干预主义的苗头。还有思想家认为国家不仅为个人，也要为全社会的利益着想，积极地促进全民福利。&lt;/p&gt;
&lt;p&gt;不过，我们千万不能忽视一点，一个国家的初始基因绝不会轻易死亡。从公司治理结构脱胎而来的宪法制度绝非中性，股份是权力的价格，是董事会权力的最初来源，因而这个制度是天然有利于金钱的。看看今天的军工复合体、华尔街集团和硅谷高科技具体，它们牢牢地把握着国家制度的核心权力。在自由放任更适合它们的利益时，它们可以让国家权力受到重重限制；当需要国家力量来保驾护航时，它们可以随时举起集权和干预的旗帜。国家的自主性，永远是个笑话！&lt;/p&gt;
&lt;h4 id=&#34;美国官僚制的困境&#34;&gt;美国官僚制的困境&lt;/h4&gt;
&lt;p&gt;因此，在资本主义制度下，行政官僚只能说是资本的仆人。这种官僚制的产生促使国会通过一般性的规则和程序来影响官僚机构，其结果就是对程序的畸形关注。&lt;/p&gt;
&lt;p&gt;过度关注程序和规则还产生了一个副产品——法官和律师对政策的影响。美国是一个高度法治的国家，法治存在于制度基因之中。托克维尔早就发现，在美国，一切政治问题都转化为法律问题。因此，善用法律者自然长袖善舞。&lt;/p&gt;
&lt;p&gt;很多中国人刚到了美国会感觉到很自由，但熟悉习俗之后就会发现日常行为受到的约束比在中国更多——法律无处不在。当然，如果足够有钱，请得起律师和会计师，交得起保释金，那么法律往往意味着自由。对于穷人，一次账单违约就可能带来信用污点，一次交通违法就可能带来牢狱之灾，对执法人员稍不顺从就有可能被当场击毙。&lt;/p&gt;
&lt;p&gt;政治问题法治化使得诉讼成了官僚政治中的日常。诉讼一方面损害了人们的合作精神，当两个团体得知最终决定权在法院而不是政府时，双方都开始准备打官司了。诉讼导致律师在官僚机构中的分量变重，律师在国会中成了举足轻重的势力团伙。&lt;/p&gt;
&lt;p&gt;决策问题司法化最令人担心的是产生了不公正的社会后果。法治往往只有利于富人和强者，因为普通民众既不熟悉法律，也支付不起昂贵的律师费。&lt;/p&gt;
&lt;p&gt;但真正让律师得以垄断政治权力的，还是资本主义。商业和金钱的活动不喜欢任何约束，但是它们离不开法律，因为法律有助于提供生意的规则、确保契约的执行、提供可预期的投资环境以及保护财产的安全。所以商人的理想国家是法律决定一切的国家。资本主义的国家必然会以法治为基本原则。&lt;/p&gt;
&lt;h4 id=&#34;总统国会与官僚的权力游戏&#34;&gt;总统、国会与官僚的权力游戏&lt;/h4&gt;
&lt;p&gt;总统和国会竞争的结果并不是两者权力的此消彼长，而是总统和国会对行政机构的权力都上升了。行政机构同时成为国会和总统的代理人。&lt;/p&gt;
&lt;p&gt;这种府会竞争和对官僚机构的双重控制产生了非常复杂的后果。官僚机构夹在两院和白宫之间，这弱化了总统和议员的直接联系，双方都只和官僚机构联系。另一方面，官僚机构在总统和国会的竞争中获得了额外的权力和活动空间。虽然从表面上看，官僚机构在总统和国会的双双控制之下，但是却借这个结构获得了更大的独立性。&lt;/p&gt;
&lt;p&gt;强势的特朗普总统对这个官僚机器束手无策。特朗普总统很大程度上采取了避开官僚机器的做法，因为他不可能真正触动这个复杂机器中的权力循环。&lt;/p&gt;
&lt;p&gt;随着行政官僚权力在夹缝中不断增长，专家和官僚媒体在美国政治中变得越来越重要，美国也向“行政国家”方向发展。&lt;/p&gt;
&lt;p&gt;从公司治理结构中生长出来的美国宪法制度，就像刘慈欣的科幻小说《三体》中被发射到地球上的“智子”一般，锁死了美国国家体制发生革命性变化的可能。然而这样一个从源头上不完善的制度，却在宪政的名义下成了神圣至高的理想原则，这也许就是美国制度最深层的悲剧。&lt;/p&gt;
&lt;h2 id=&#34;结论&#34;&gt;结论&lt;/h2&gt;
&lt;p&gt;通过对美国殖民地时期历史的回顾，我们可以看到美国独特的逐利性人口特征，以及北美大陆提供的丰富资源和安全环境，这是我们理解美国历史须臾不可忘的起点，是美国制度发展的底色。&lt;/p&gt;
&lt;p&gt;本书从北美殖民地的起源和发展中发现，原始自由、封建领地、商业公司和王室集权四种制度因素都影响到美国代议制的形成，它们共同决定了美国代议制的特征。因而，美国的代议制显然既有对现成的英国制度的模仿，也有自身独立的发展逻辑。&lt;/p&gt;
&lt;p&gt;美国制度毕竟不同于英国议会制，本书从威尼斯、尼德兰、英国的历史中梳理出商业公司因素在国家建构中的作用，提出了公司国家的概念。公司国家的基本特征是商人（资本家）掌握国家，金钱与权力挂钩，经济权力等于政治权力。&lt;/p&gt;
&lt;p&gt;本书认为《宪法》文本接近一份商业契约，各州所构成的联邦类似不同法人合并成的一个新的法人实体。但是在实际运行中，这个比较纯粹的公司理性制度模式很快暴露出诸多不足，例如国家权威不足、国会与总统对行政权的双重控制、司法权对国会立法的解释和审查权，以及行政权的软弱和官僚制度缺失的问题。&lt;/p&gt;
&lt;p&gt;立宪 230 余年来，这部《宪法》一直处于被修正、被背离的命运之中，虽然名义上它被高高地供在神坛之上。美国的制度一直在不断演进，联邦主权越来越强，总统权力不断上升，司法机关也获得了一定的独裁权力，官僚制度逐渐产生并且在国会和总统的夹缝中生长，成了一架庞大的机器，拥有了自己的利益、认同和势力。美国在从公司向国家的方向不断发展。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Attention Is All You Need</title>
      <link>https://bowenei.gitee.io/post/attention-is-all-you-need/</link>
      <pubDate>Tue, 09 Nov 2021 22:59:13 +0800</pubDate>
      <guid>https://bowenei.gitee.io/post/attention-is-all-you-need/</guid>
      <description>&lt;p&gt;&lt;strong&gt;Transformer&lt;/strong&gt; 是目前人工智能和深度学习领域最著名的模型之一，由 Google 团队于 2017 年 6 月提出，发表在 NeuralPS（Conference on Neural Information Processing Systems）上。起初是为了解决自然语言处理（Natural Language Processing, NLP）领域中的机器翻译问题，没想到它的效果竟然超越了循环神经网络（Recurrent Neural Networks, RNN），只需要用 &lt;code&gt;encoder&lt;/code&gt; 和 &lt;code&gt;decoder&lt;/code&gt; 以及注意力 &lt;code&gt;attention&lt;/code&gt; 机制就可以达到很好的效果。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Transformer&lt;/strong&gt; 本身是专门为 NLP 领域量身定制的，但是后来人们将图像等数据编码和序列化之后同样可以放进 &lt;strong&gt;Transformer&lt;/strong&gt; 中进行训练，并且也能让模型达到和卷积神经网络（Convolutional Neural Networks, CNN）和深度神经网络（Deep Neural Networks, DNN）相比更加出其不意的效果。这才让 &lt;strong&gt;Transformer&lt;/strong&gt; 在计算机视觉领域大火了起来。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://dl.acm.org/doi/abs/10.5555/3295222.3295349&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;原文链接&lt;/a&gt;&lt;/p&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    &lt;p&gt;&lt;strong&gt;特别鸣谢&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;本文结合亚马逊首席科学家&lt;a href=&#34;https://github.com/mli&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;李沐&lt;/a&gt;的&lt;a href=&#34;https://www.bilibili.com/video/BV1pu411o7BE&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;深度学习论文精读系列视频&lt;/a&gt;进行整理。&lt;/p&gt;

  &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;这篇文章最具特色的就是标题 Attention Is All You Need，翻译成中文就是“你需要注意”。后来这个标题成为了一个梗，即 xxx Is All You Need。&lt;/p&gt;
&lt;p&gt;值得注意的是，这篇文章的每一位作者后面都打了 &lt;code&gt;*&lt;/code&gt; 号，这说明这几位作者的贡献是均等的，论文首先下的注释已经充分说明了这一点。通常我们会认为论文的第一作者是主要贡献者，但是这篇文章是个例外。&lt;/p&gt;
&lt;details class=&#34;toc-inpage d-print-none  &#34; open&gt;
  &lt;summary class=&#34;font-weight-bold&#34;&gt;Table of Contents&lt;/summary&gt;
  &lt;nav id=&#34;TableOfContents&#34;&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;a href=&#34;#abstract&#34;&gt;Abstract&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#7-conclusion&#34;&gt;7 Conclusion&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#1-introduction&#34;&gt;1 Introduction&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#2-background&#34;&gt;2 Background&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#3-model-architecture&#34;&gt;3 Model Architecture&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#31-encoder-and-decoder-stacks&#34;&gt;3.1 Encoder and Decoder Stacks&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#32-attention&#34;&gt;3.2 Attention&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#33-position-wise-feed-forward-networks&#34;&gt;3.3 Position-wise Feed-Forward Networks&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#34-embeddings-and-softmax&#34;&gt;3.4 Embeddings and Softmax&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#35-positional-encoding&#34;&gt;3.5 Positional Encoding&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#4-why-self-attention&#34;&gt;4 Why Self-Attention&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#5-training&#34;&gt;5 Training&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#51-training-data-and-batching&#34;&gt;5.1 Training Data and Batching&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#52-hardware-and-schedule&#34;&gt;5.2 Hardware and Schedule&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#53-optimizer&#34;&gt;5.3 Optimizer&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#54-regularization&#34;&gt;5.4 Regularization&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#6-results&#34;&gt;6 Results&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#61-machine-translation&#34;&gt;6.1 Machine Translation&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#62-model-variations&#34;&gt;6.2 Model Variations&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
  &lt;/ul&gt;
&lt;/nav&gt;
&lt;/details&gt;

&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;The dominant sequence transduction models are based on complex recurrent or convolutional neural networks that include an encoder and a decoder. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 Englishto-German translation task, improving over the existing best results, including ensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.0 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;所谓序列转录模型 &lt;code&gt;sequence transduction models&lt;/code&gt; 是指输入为一个序列，输出也为一个序列的模型。例如在机器翻译中，输入一段中文，然后输出其对应的英文翻译。当时（作者写这篇文章的时候），主流的序列转录模型主要基于复杂的 CNN 和 RNN，一般采用 &lt;code&gt;encoder&lt;/code&gt; 和 &lt;code&gt;decoder&lt;/code&gt; 架构。作者提出了一种基于注意力机制 &lt;code&gt;attention mechanisms&lt;/code&gt; 的网络结构 &lt;strong&gt;Transformer&lt;/strong&gt;。作者做了两个机器翻译的实验，证明了他们提出的模型效果非常好。&lt;/p&gt;
&lt;h2 id=&#34;7-conclusion&#34;&gt;7 Conclusion&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;In this work, we presented the Transformer, the first sequence transduction model based entirely on attention, replacing the recurrent layers most commonly used in encoder-decoder architectures with multi-headed self-attention.&lt;/p&gt;
&lt;p&gt;For translation tasks, the Transformer can be trained significantly faster than architectures based on recurrent or convolutional layers. On both WMT 2014 English-to-German and WMT 2014 English-to-French translation tasks, we achieve a new state of the art. In the former task our best model outperforms even all previously reported ensembles.&lt;/p&gt;
&lt;p&gt;We are excited about the future of attention-based models and plan to apply them to other tasks. We plan to extend the Transformer to problems involving input and output modalities other than text and to investigate local, restricted attention mechanisms to efficiently handle large inputs and outputs such as images, audio and video. Making generation less sequential is another research goals of ours.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;按照沐神读论文的习惯，摘要读完以后直接跳到结论。沐神总结的结论主要有如下几点：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Transformer&lt;/strong&gt; 是当时第一个完全基于注意力的序列转录模型，它把过去常用的循环层全部换成了 &lt;code&gt;multi-headed self-attention&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Transformer&lt;/strong&gt; 在机器翻译的任务中比基于循环层和卷积层的架构要快很多。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Transformer&lt;/strong&gt; 未来可以用在文本以外的数据类型上，例如图像、音频、视频等。现在看来，作者在当时多多少少是预测到未来的研究方向的，我十分佩服！&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/tensorflow/tensor2tensor&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;仓库链接&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;1-introduction&#34;&gt;1 Introduction&lt;/h2&gt;
&lt;p&gt;这篇文章的导言 &lt;code&gt;Introduction&lt;/code&gt; 相对来说比较短，基本上是摘要 &lt;code&gt;Abstract&lt;/code&gt; 的扩充。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Recurrent neural networks, long short-term memory&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt; and gated recurrent&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt; neural networks in particular, have been firmly established as state of the art approaches in sequence modeling and transduction problems such as language modeling and machine translation. Numerous efforts have since continued to push the boundaries of recurrent language models and encoder-decoder architectures.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;当时机器翻译最常用的模型是 RNN，主要包括如下两个著名的网络模型：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;LSTM&lt;/strong&gt; (Long Short-Term Memory): 长短期记忆网络。它是一种时间循环神经网络，是为了解决一般的 RNN 存在的长期依赖问题而专门设计出来的，所有的 RNN 都具有一种重复神经网络模块的链式形式。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;GRU&lt;/strong&gt; (Gate Recurrent Unit): 门控循环单元。是 LSTM 网络的一种效果很好的变体，它较 LSTM 网络的结构更加简单，而且效果也很好，因此也是当前非常流形的一种网络。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;后续的工作主要围绕着循环语言模型 &lt;code&gt;recurrent language models&lt;/code&gt; 和编码器/解码器 &lt;code&gt;encoder-decoder&lt;/code&gt; 架构展开。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Recurrent models typically factor computation along the symbol positions of the input and output sequences.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;RNN 的特点是序列从左向右移一步一步往前做。当前时刻 $t$ 的隐藏状态 &lt;code&gt;hidden states&lt;/code&gt; 记作 $h_t$，它由上一个隐藏状态 $h_{t-1}$ 和当前时刻 $t$ 的输入决定。这就是为什么 RNN 能够处理时序信息的原因。也正因为 RNN 的这一特点，导致 RNN 存在如下问题：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;计算难以并行，主流的多线程 GPU 只能按照时序一个一个计算。&lt;/li&gt;
&lt;li&gt;序列长度和 $h_t$ 的长度之间的矛盾。如果序列长度特别长而 $h_t$ 不够长的话，前面的信息很可能会丢掉；但如果 $h_t$ 也设计得很长的话，内存开销太大。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;针对 RNN 的这些问题，近年来的改进工作很多，但都没有从根本上解决问题。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Attention mechanisms have become an integral part of compelling sequence modeling and transduction models in various tasks, allowing modeling of dependencies without regard to their distance in the input or output sequences.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;注意力机制并不是本文的创新点。在现有的工作中，注意力机制已经被成功地用在编码器/解码器里面了。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;In this work we propose the Transformer, a model architecture eschewing recurrence and instead relying entirely on an attention mechanism to draw global dependencies between input and output. The Transformer allows for significantly more parallelization and can reach a new state of the art in translation quality after being trained for as little as twelve hours on eight P100 GPUs.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;作者在本文提出的 &lt;strong&gt;Transformer&lt;/strong&gt; 则与 RNN 不同，是完全依赖注意力机制的一种模型架构。作者特别强调了他们在训练时候的并行性 &lt;code&gt;parallelization&lt;/code&gt;。&lt;/p&gt;
&lt;h2 id=&#34;2-background&#34;&gt;2 Background&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;The goal of reducing sequential computation also forms the foundation of the Extended Neural GPU, ByteNet and ConvS2S, all of which use convolutional neural networks as basic building block, computing hidden representations in parallel for all input and output positions.&lt;/p&gt;
&lt;p&gt;In the Transformer this is reduced to a constant number of operations, albeit at the cost of reduced effective resolution due to averaging attention-weighted positions, an effect we counteract with Multi-Head Attention as described in section 3.2.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;为了解决 RNN 训练的并行性问题，有很多工作考虑采用 CNN 来代替 RNN 以增加并行性，但问题是 CNN 对长序列难以建模。例如相隔很远的两个像素块，需要多层卷积才能建立起联系。不过卷积计算的好处是可以做多个输出通道，基于此作者提出了多头注意力 &lt;code&gt;Multi-Head Attention&lt;/code&gt; 机制。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Self-attention, sometimes called intra-attention is an attention mechanism relating different positions of a single sequence in order to compute a representation of the sequence.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;接下来就是自注意力 &lt;code&gt;Self-attention&lt;/code&gt; 机制，这其实也是 &lt;strong&gt;Transformer&lt;/strong&gt; 中很重要的一点。不过该工作并不是 &lt;strong&gt;Transformer&lt;/strong&gt; 的创新点，已经有不少相关工作了。&lt;/p&gt;
&lt;h2 id=&#34;3-model-architecture&#34;&gt;3 Model Architecture&lt;/h2&gt;
&lt;p&gt;为了解释清楚 &lt;code&gt;encoder-decoder&lt;/code&gt;，作者首先给出如下 3 个非常重要的定义：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$\left(x_1, x_2, &amp;hellip;, x_n\right)$：表示一个序列。假设这个序列是一个英文句子，那么 $x_t$ 就表示第 $t$ 个单词。&lt;/li&gt;
&lt;li&gt;$\textbf{z} = \left(z_1, z_2, &amp;hellip;, z_n\right)$：编码器的输出。$z_t$ 是 $x_t$ 的一个向量表示。&lt;/li&gt;
&lt;li&gt;$\left(y_1, y_2, &amp;hellip;, y_m\right)$：编码器的输出，是一个长为 $m$ 的序列。和编码器不同的是，解码器的词是一个个生成的，这叫做自回归 &lt;code&gt;auto-regressive&lt;/code&gt;。自回归的意思是当前的输出也会作为输入参与下一轮的输出。换句话说就是，翻译的结果出来是一个个词往外蹦儿的。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这样也就弄清楚 &lt;strong&gt;Transformer&lt;/strong&gt; 的输入和输出了，后文则主要对这里面的每个块进行说明。&lt;/p&gt;
















&lt;figure  id=&#34;figure-the-transformer---model-architecture&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;The Transformer - model architecture.&#34; srcset=&#34;
               /post/attention-is-all-you-need/featured_hu8b54ce84adafe40779efe33571820b6c_96849_69939f503c2e2d5c874ab43c5d89ab3f.webp 400w,
               /post/attention-is-all-you-need/featured_hu8b54ce84adafe40779efe33571820b6c_96849_7401b658ad7641a955eec6102478b257.webp 760w,
               /post/attention-is-all-you-need/featured_hu8b54ce84adafe40779efe33571820b6c_96849_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://bowenei.gitee.io/post/attention-is-all-you-need/featured_hu8b54ce84adafe40779efe33571820b6c_96849_69939f503c2e2d5c874ab43c5d89ab3f.webp&#34;
               width=&#34;536&#34;
               height=&#34;760&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption data-pre=&#34;Figure&amp;nbsp;&#34; data-post=&#34;:&amp;nbsp;&#34; class=&#34;numbered&#34;&gt;
      The Transformer - model architecture.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;h3 id=&#34;31-encoder-and-decoder-stacks&#34;&gt;3.1 Encoder and Decoder Stacks&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Encoder&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;layers: $N=6$&lt;/li&gt;
&lt;li&gt;sub-layers:
&lt;ul&gt;
&lt;li&gt;multi-head self-attention mechanism: 多头自注意力机制&lt;/li&gt;
&lt;li&gt;position-wise fully connected feed-forward network: 本质上就是一个 MLP（多层感知机，Multilayer Perceptron）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;output: $\textrm{LayerNorm}(x + \textrm{Sublayer}(x))$&lt;/li&gt;
&lt;li&gt;dimension: $d_{model} = 512$&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    &lt;p&gt;&lt;strong&gt;BatchNorm 和 LayerNorm 的区别&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;沐神就 &lt;code&gt;BatchNorm&lt;/code&gt; 和 &lt;code&gt;LayerNorm&lt;/code&gt; 的区别作了详细讲解。我们知道，&lt;code&gt;Norm&lt;/code&gt; 即 &lt;code&gt;Normalization&lt;/code&gt;，对数据进行归一化处理。这和概率论中对随机变量进行标准化的操作类似，即把原向量化为均值为 $0$ 方差为 $1$ 的标准化向量。&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
Y = \frac{X - \mu}{\sigma}
\end{align}
$$&lt;/p&gt;
&lt;p&gt;如图所示，&lt;code&gt;BatchNorm&lt;/code&gt; 和 &lt;code&gt;LayerNorm&lt;/code&gt; 的区别一目了然。&lt;code&gt;BatchNorm&lt;/code&gt; 是在每一个特征 &lt;code&gt;feature&lt;/code&gt; 上对 &lt;code&gt;batch&lt;/code&gt; 进行归一化，而 &lt;code&gt;LayerNorm&lt;/code&gt; 是在每一个样本 &lt;code&gt;batch&lt;/code&gt; 上对 &lt;code&gt;feature&lt;/code&gt; 进行归一化。&lt;/p&gt;
&lt;figure  id=&#34;figure-difference-between-batchnorm-and-layernorm&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Difference between BatchNorm and LayerNorm.&#34; srcset=&#34;
               /post/attention-is-all-you-need/layernorm-batchnorm_huf61da6cf384951cc94fe6d875380b93b_18215_3780baf8790d7bad91ed2224590b2089.webp 400w,
               /post/attention-is-all-you-need/layernorm-batchnorm_huf61da6cf384951cc94fe6d875380b93b_18215_190a222c2ad3ad97c203eeb42329026d.webp 760w,
               /post/attention-is-all-you-need/layernorm-batchnorm_huf61da6cf384951cc94fe6d875380b93b_18215_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://bowenei.gitee.io/post/attention-is-all-you-need/layernorm-batchnorm_huf61da6cf384951cc94fe6d875380b93b_18215_3780baf8790d7bad91ed2224590b2089.webp&#34;
               width=&#34;657&#34;
               height=&#34;276&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption data-pre=&#34;Figure&amp;nbsp;&#34; data-post=&#34;:&amp;nbsp;&#34; class=&#34;numbered&#34;&gt;
      Difference between BatchNorm and LayerNorm.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;为什么要使用 &lt;code&gt;LayerNorm&lt;/code&gt; 呢？一个原因是样本长度可能发生变化（即 &lt;code&gt;sequence&lt;/code&gt; 的长度 $n$），如果使用 &lt;code&gt;BatchNorm&lt;/code&gt; 的话，切片的结果可能长度参差不齐，会有很多零填充。而使用 &lt;code&gt;LayerNorm&lt;/code&gt; 则不会出现这样的问题，因为是同一个样本（即同一个序列）。由于序列长度不一有零填充，计算均值和方差的时候每个样本的计算方法不一样，不能把零算进去，因为零不是有效值。&lt;/p&gt;
&lt;p&gt;还有一点原因是，假如在做预测的时候，序列特别特别长以至于训练所得的均值和方差并不好用。而使用 &lt;code&gt;LayerNorm&lt;/code&gt; 则不会出现这样的问题，因为它是每个样本独立计算的，最后也并不像 &lt;code&gt;BatchNorm&lt;/code&gt; 那样需要算出一个全局的均值和方差。因此不管序列有多长，均值和方差都是在序列本身的基础上算的。&lt;/p&gt;

  &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Decoder&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;layers: $N=6$&lt;/li&gt;
&lt;li&gt;sub-layers:
&lt;ul&gt;
&lt;li&gt;multi-head self-attention mechanism: 和 &lt;code&gt;encoder&lt;/code&gt; 相同&lt;/li&gt;
&lt;li&gt;position-wise fully connected feed-forward network: 和 &lt;code&gt;encoder&lt;/code&gt; 相同&lt;/li&gt;
&lt;li&gt;masked multi-head attention: 带掩码的多头注意力机制&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;masking: 确保位置 $i$ 的预测只能依赖于小于 $i$ 位置的已知输出。因为训练时 &lt;code&gt;decoder&lt;/code&gt; 的输入是上面一些时刻在 &lt;code&gt;encoder&lt;/code&gt; 的输出，不应该看到后面时刻的输入。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;32-attention&#34;&gt;3.2 Attention&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;An attention function can be described as mapping a query and a set of key-value pairs to an output, where the query, keys, values, and output are all vectors. The output is computed as a weighted sum of the values, where the weight assigned to each value is computed by a compatibility function of the query with the corresponding key.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;注意力函数是将 &lt;code&gt;query&lt;/code&gt; 和一些键值对 &lt;code&gt;key-value pairs&lt;/code&gt; 映射成一个输出 &lt;code&gt;output&lt;/code&gt; 的函数，这里面的 &lt;code&gt;query&lt;/code&gt;、&lt;code&gt;keys&lt;/code&gt;、&lt;code&gt;values&lt;/code&gt;、&lt;code&gt;output&lt;/code&gt; 都是向量 &lt;code&gt;vectors&lt;/code&gt;。具体来说，&lt;code&gt;output&lt;/code&gt; 是 &lt;code&gt;values&lt;/code&gt; 的加权，其输出维度和 &lt;code&gt;value&lt;/code&gt; 的维度是一样的。权重是通过每个 &lt;code&gt;value&lt;/code&gt; 对应的 &lt;code&gt;key&lt;/code&gt; 和 &lt;code&gt;query&lt;/code&gt; 计算相似度 &lt;code&gt;compatibility function&lt;/code&gt; 得来的。这里的相似度针对不同的注意力机制有不同的算法。&lt;/p&gt;
&lt;h4 id=&#34;321-scaled-dot-product-attention&#34;&gt;3.2.1 Scaled Dot-Product Attention&lt;/h4&gt;
&lt;p&gt;作者在本小节主要说明了 &lt;strong&gt;Transformer&lt;/strong&gt; 采用的注意力机制。作者将之命名为 &lt;code&gt;Scaled Dot-Product Attention&lt;/code&gt;，如图所示。&lt;/p&gt;
















&lt;figure  id=&#34;figure-scaled-dot-product-attention&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Scaled Dot-Product Attention.&#34; srcset=&#34;
               /post/attention-is-all-you-need/Scaled%20Dot-Product%20Attention_hu70c1dc728f23523ace7510001a2e738b_44270_c58055229fb3f7179931f9e847824dec.webp 400w,
               /post/attention-is-all-you-need/Scaled%20Dot-Product%20Attention_hu70c1dc728f23523ace7510001a2e738b_44270_e6cb6d0f00c311b886504a93a84edf8a.webp 760w,
               /post/attention-is-all-you-need/Scaled%20Dot-Product%20Attention_hu70c1dc728f23523ace7510001a2e738b_44270_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://bowenei.gitee.io/post/attention-is-all-you-need/Scaled%20Dot-Product%20Attention_hu70c1dc728f23523ace7510001a2e738b_44270_c58055229fb3f7179931f9e847824dec.webp&#34;
               width=&#34;415&#34;
               height=&#34;681&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption data-pre=&#34;Figure&amp;nbsp;&#34; data-post=&#34;:&amp;nbsp;&#34; class=&#34;numbered&#34;&gt;
      Scaled Dot-Product Attention.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;注意力函数的计算公式如下：&lt;/p&gt;

$$
\begin{align}
\textrm{Attention}\left(Q, K, V\right) = \textrm{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V
\end{align}
$$

&lt;p&gt;$Q$ 即 &lt;code&gt;query&lt;/code&gt;，$K$ 即 &lt;code&gt;key&lt;/code&gt;，$QK^T$ 即 &lt;code&gt;query&lt;/code&gt; 和 &lt;code&gt;key&lt;/code&gt; 做内积。作者认为，两个向量的内积值越大，说明相似度越高。除以 $\sqrt{d_k}$ 则表示单位化，然后再用 softmax 得到权重。这里的道理其实就是机器学习中的余弦相似度（余弦距离）：&lt;/p&gt;

$$
\begin{align}
\textrm{similarity} = \cos{\theta} = \frac{\alpha \cdot \beta}{||\alpha|| \cdot ||\beta||}
\end{align}
$$

&lt;p&gt;注意这里 &lt;code&gt;Mask&lt;/code&gt; 的作用是为了避免 $t$ 时刻看到后面的输入。在数学上的具体实现方式是以一个绝对值非常大的负数（$-\infty$）作为指数，计算出来的幂趋向于零，这样就实现了掩盖 $t$ 时刻后面的输入的效果。&lt;/p&gt;
&lt;h4 id=&#34;322-multi-head-attention&#34;&gt;3.2.2 Multi-Head Attention&lt;/h4&gt;
&lt;p&gt;作者认为，与其计算单个的注意力函数，不如把 &lt;code&gt;query&lt;/code&gt;、&lt;code&gt;key&lt;/code&gt;、&lt;code&gt;value&lt;/code&gt; 投影到一个更低的维度上，投影 $h$ 次，然后再计算 $h$ 次注意力函数，最后每一个函数的输出合并再投影得到最终的输出。如图所示。&lt;/p&gt;
















&lt;figure  id=&#34;figure-multi-head-attention&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Multi-Head Attention.&#34; srcset=&#34;
               /post/attention-is-all-you-need/Multi-Head%20Attention_hua1dcc6ec3dc6caf1927d2a8edcfb7688_72171_b0ffdf9e71d8f398d7da638889de4d27.webp 400w,
               /post/attention-is-all-you-need/Multi-Head%20Attention_hua1dcc6ec3dc6caf1927d2a8edcfb7688_72171_5b175683df723a45c4ed255077096fd1.webp 760w,
               /post/attention-is-all-you-need/Multi-Head%20Attention_hua1dcc6ec3dc6caf1927d2a8edcfb7688_72171_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://bowenei.gitee.io/post/attention-is-all-you-need/Multi-Head%20Attention_hua1dcc6ec3dc6caf1927d2a8edcfb7688_72171_b0ffdf9e71d8f398d7da638889de4d27.webp&#34;
               width=&#34;551&#34;
               height=&#34;685&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption data-pre=&#34;Figure&amp;nbsp;&#34; data-post=&#34;:&amp;nbsp;&#34; class=&#34;numbered&#34;&gt;
      Multi-Head Attention.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;多头注意力函数的计算公式如下：&lt;/p&gt;

$$
\begin{align}
\textrm{MultiHead}\left(Q, K, V\right) &amp;= \textrm{Concat}\left(\textrm{head}_1, ..., \textrm{head}_h\right)W^O \\\\
\textbf{where}\quad\textrm{head}_i &amp;= \textrm{Attention}\left(QW^Q_i, KW^K_i, VW^V_i\right)
\end{align}
$$

&lt;p&gt;在本文中作者定义 $h=8$，于是 $d_k = d_v = d_{model}/h = 64$，也就是输出维度。&lt;/p&gt;
&lt;h4 id=&#34;323-applications-of-attention-in-our-model&#34;&gt;3.2.3 Applications of Attention in our Model&lt;/h4&gt;
&lt;p&gt;这一小节作者主要介绍 &lt;strong&gt;Transformer&lt;/strong&gt; 是如何使用注意力的，归结起来一共有如下 3 种情况：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;In &amp;ldquo;encoder-decoder attention&amp;rdquo; layers, the queries come from the previous decoder layer, and the memory keys and values come from the output of the encoder. This allows every position in the decoder to attend over all positions in the input sequence.&lt;/p&gt;
&lt;p&gt;The encoder contains self-attention layers. In a self-attention layer all of the keys, values and queries come from the same place, in this case, the output of the previous layer in the encoder. Each position in the encoder can attend to all positions in the previous layer of the encoder.&lt;/p&gt;
&lt;p&gt;Similarly, self-attention layers in the decoder allow each position in the decoder to attend to all positions in the decoder up to and including that position. We need to prevent leftward information flow in the decoder to preserve the auto-regressive property. We implement this inside of scaled dot-product attention by masking out (setting to $-\infty$) all values in the input of the softmax which correspond to illegal connections.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;encoder&lt;/code&gt; 的 &lt;code&gt;Multi-Head Attention&lt;/code&gt; 以 &lt;code&gt;key&lt;/code&gt;、&lt;code&gt;value&lt;/code&gt;、&lt;code&gt;query&lt;/code&gt; 作为输入。图中的箭头一分为三，表示同一数据复制三次，这就叫做自注意力机制。输出的维度和输入一致。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;decoder&lt;/code&gt; 的 &lt;code&gt;Masked Multi-Head Attention&lt;/code&gt; 和 &lt;code&gt;encoder&lt;/code&gt; 的 &lt;code&gt;Multi-Head Attention&lt;/code&gt; 类似，只不过需要掩盖后面的输入，前文已详述。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;decoder&lt;/code&gt; 的 &lt;code&gt;Multi-Head Attention&lt;/code&gt; 则不再像 &lt;code&gt;encoder&lt;/code&gt; 那样是自注意力了，而是 &lt;code&gt;key&lt;/code&gt; 和 &lt;code&gt;value&lt;/code&gt; 来自于编码器的输出，&lt;code&gt;query&lt;/code&gt; 来自于解码器下一个 &lt;code&gt;attention&lt;/code&gt; 的输入。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;为了更便于大家理解，沐神举了一个非常简单的机器翻译的例子：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Hello world&lt;/p&gt;
&lt;p&gt;你好世界&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;显然，输入的英文序列 $n=2$，输出的中文序列 $m=4$。当 &lt;strong&gt;Transformer&lt;/strong&gt; 在计算“好”字时，把“好”字对应的向量作为 &lt;code&gt;query&lt;/code&gt; 时，计算和 &lt;code&gt;Hello&lt;/code&gt; 对应的向量的相似度会更高一些，就会赋一个较大的权重。这就是注意力机制给我们最直观的感受！&lt;/p&gt;
&lt;h3 id=&#34;33-position-wise-feed-forward-networks&#34;&gt;3.3 Position-wise Feed-Forward Networks&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;In addition to attention sub-layers, each of the layers in our encoder and decoder contains a fully connected feed-forward network, which is applied to each position separately and identically. This consists of two linear transformations with a ReLU activation in between.&lt;/p&gt;
&lt;/blockquote&gt;

$$
\begin{align}
\textrm{FFN}\left(x\right) = \max \left(0, xW_1 + b_1\right)W_2 + b_2
\end{align}
$$

&lt;p&gt;在注意力层之后，&lt;code&gt;encoder&lt;/code&gt; 和 &lt;code&gt;decoder&lt;/code&gt; 都会有一个前馈网络层，首先是一个全连接层，然后是 ReLU 激活函数，最后再过一个全连接层。&lt;/p&gt;
&lt;h3 id=&#34;34-embeddings-and-softmax&#34;&gt;3.4 Embeddings and Softmax&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;Similarly to other sequence transduction models, we use learned embeddings to convert the input tokens and output tokens to vectors of dimension $d_{model}$. We also use the usual learned linear transformation and softmax function to convert the decoder output to predicted next-token probabilities.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;code&gt;Embeddings&lt;/code&gt; 将输入的每一个词 &lt;code&gt;token&lt;/code&gt; 映射成维度为 $d_{model}$ 的向量。&lt;code&gt;Softmax&lt;/code&gt; 的作用是归一化。&lt;/p&gt;
&lt;h3 id=&#34;35-positional-encoding&#34;&gt;3.5 Positional Encoding&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;Since our model contains no recurrence and no convolution, in order for the model to make use of the order of the sequence, we must inject some information about the relative or absolute position of the tokens in the sequence. To this end, we add &amp;ldquo;positional encodings&amp;rdquo; to the input embeddings at the bottoms of the encoder and decoder stacks. The positional encodings have the same dimension $d_{model}$ as the embeddings, so that the two can be summed.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;为什么需要位置编码呢？因为 &lt;code&gt;attention&lt;/code&gt; 本身并没有时序信息，它只是计算了 &lt;code&gt;key&lt;/code&gt; 和 &lt;code&gt;query&lt;/code&gt; 之间的余弦距离，它与序列的时序性无关。例如我们阅读下面这句话：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;序语倒颠不响影读阅。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;我们会觉得有些别扭，因为语义发生变化了。但其实 &lt;code&gt;attention&lt;/code&gt; 在计算的时候根本处理不了这种情况，这个时候就需要把时序信息加进来。与 RNN 不同的是，&lt;strong&gt;Transformer&lt;/strong&gt; 在输入里面加入时序信息，而 RNN 则是以上一时刻的输出作为部分输入。&lt;/p&gt;
&lt;h2 id=&#34;4-why-self-attention&#34;&gt;4 Why Self-Attention&lt;/h2&gt;
&lt;p&gt;本节作者介绍了为什么要采用自注意力机制。沐神认为，作者并没有把这个原因讲得特别清楚。不过，我们可以首先来看看下表：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;Layer Type&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;Complexity per Layer&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;Sequential Operations&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;Maximum Path Length&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Self-Attention&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;$O(n^2 \cdot d)$&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;$O(1)$&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;$O(1)$&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Recurrent&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;$O(n \cdot d^2)$&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;$O(n)$&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;$O(n)$&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Convolutional&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;$O(k \cdot n \cdot d^2)$&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;$O(1)$&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;$O(\log_k{n})$&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Self-Attention (restricted)&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;$O(r \cdot n \cdot d)$&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;$O(1)$&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;$O(n/r)$&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;作者对比了自注意力机制、RNN、CNN 和受限制的 &lt;code&gt;restricted&lt;/code&gt; 自注意力机制的三个方面：计算复杂度、顺序计算、最大路径长度。显然计算复杂度越低越好；顺序计算是指下一步计算必须等前面几步计算完成才能计算，当然越低越好，并行度越高；最大路径长度是指一个序列信息从一个数据点走到另一个数据点需要走多远，当然越短越好。&lt;/p&gt;
&lt;p&gt;这里需要额外解释的是受限制的自注意力机制。为什么相比与自注意力机制，其计算复杂度会有所降低？是因为 &lt;code&gt;query&lt;/code&gt; 只跟最近的 $r$ 个邻居做运算。但带来的问题是最大路径长度的增加。&lt;/p&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    至此，已经可以基本了解 &lt;strong&gt;Transformer&lt;/strong&gt; 的基本架构了。后面的章节是训练和模型效果，如有需要再进行补充。
  &lt;/div&gt;
&lt;/div&gt;

&lt;h2 id=&#34;5-training&#34;&gt;5 Training&lt;/h2&gt;
&lt;h3 id=&#34;51-training-data-and-batching&#34;&gt;5.1 Training Data and Batching&lt;/h3&gt;
&lt;h3 id=&#34;52-hardware-and-schedule&#34;&gt;5.2 Hardware and Schedule&lt;/h3&gt;
&lt;h3 id=&#34;53-optimizer&#34;&gt;5.3 Optimizer&lt;/h3&gt;
&lt;h3 id=&#34;54-regularization&#34;&gt;5.4 Regularization&lt;/h3&gt;
&lt;h2 id=&#34;6-results&#34;&gt;6 Results&lt;/h2&gt;
&lt;h3 id=&#34;61-machine-translation&#34;&gt;6.1 Machine Translation&lt;/h3&gt;
&lt;h3 id=&#34;62-model-variations&#34;&gt;6.2 Model Variations&lt;/h3&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Hochreiter S, Schmidhuber J. Long short-term memory[J]. Neural computation, 1997, 9(8): 1735-1780.&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Chung J, Gulcehre C, Cho K H, et al. Empirical evaluation of gated recurrent neural networks on sequence modeling[J]. arXiv preprint arXiv:1412.3555, 2014.&amp;#160;&lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;</description>
    </item>
    
    <item>
      <title>我的马克思主义爱情观</title>
      <link>https://bowenei.gitee.io/post/my-marxism-view-of-love/</link>
      <pubDate>Mon, 09 Aug 2021 22:38:41 +0800</pubDate>
      <guid>https://bowenei.gitee.io/post/my-marxism-view-of-love/</guid>
      <description>&lt;p&gt;本文是一篇哲学论文，基于马克思主义基本原理中的辩证唯物论、认识论、唯物辩证法以及人的解放四个方面，对爱情进行了深入剖析，建立起我的马克思主义爱情观。&lt;/p&gt;
&lt;details class=&#34;toc-inpage d-print-none  &#34; open&gt;
  &lt;summary class=&#34;font-weight-bold&#34;&gt;Table of Contents&lt;/summary&gt;
  &lt;nav id=&#34;TableOfContents&#34;&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;a href=&#34;#爱情辩证唯物论&#34;&gt;爱情辩证唯物论&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#爱情的物质性&#34;&gt;爱情的物质性&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#爱与爱情的辩证关系&#34;&gt;爱与爱情的辩证关系&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#对爱情唯心主义的批判&#34;&gt;对爱情唯心主义的批判&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#爱情的自然性与社会性的对立统一&#34;&gt;爱情的自然性与社会性的对立统一&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#爱情实践论&#34;&gt;爱情实践论&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#第一阶段爱之初&#34;&gt;第一阶段：爱之初&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#第二阶段恋爱关系&#34;&gt;第二阶段：恋爱关系&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#第三阶段爱情&#34;&gt;第三阶段：爱情&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#爱情矛盾论&#34;&gt;爱情矛盾论&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#爱情的基本矛盾&#34;&gt;爱情的基本矛盾&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#爱情的主要矛盾&#34;&gt;爱情的主要矛盾&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#方法论&#34;&gt;方法论&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#爱情与人的解放&#34;&gt;爱情与人的解放&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#各个社会形态下的爱情与人的解放&#34;&gt;各个社会形态下的爱情与人的解放&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#共产主义下的爱情与人的解放&#34;&gt;共产主义下的爱情与人的解放&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#方法论-1&#34;&gt;方法论&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
  &lt;/ul&gt;
&lt;/nav&gt;
&lt;/details&gt;

&lt;h2 id=&#34;爱情辩证唯物论&#34;&gt;爱情辩证唯物论&lt;/h2&gt;
&lt;p&gt;马克思主义认为，物质是一切客观实在，不依赖人的感觉而存在。物质和意识具有辩证关系。物质决定意识，意识是物质的反映，对物质具有反作用。&lt;/p&gt;
&lt;p&gt;爱情同理。&lt;/p&gt;
&lt;h3 id=&#34;爱情的物质性&#34;&gt;爱情的物质性&lt;/h3&gt;
&lt;p&gt;个人认为，根据马克思主义辩证唯物论的基本原理，爱情隶属于物质范畴，而不是意识范畴。具体表现在如下几个方面：&lt;/p&gt;
&lt;h4 id=&#34;1-爱情是男女双方相处过程中在已有关系的基础上在一定条件下随着关系的发展而产生的&#34;&gt;1. 爱情是男女双方相处过程中，在已有关系的基础上，在一定条件下，随着关系的发展而产生的。&lt;/h4&gt;
&lt;p&gt;首先，爱情必须建立在已有关系的基础上。这种关系可以是男女双方之间的普通朋友关系，也可以是男女双方追求与被追求的关系。因此，“一见钟情”就是爱情的理论应该受到批判，“一见钟情”是一种夸大了人的主观能动性的说法。&lt;/p&gt;
&lt;p&gt;其次，爱情需要在一定条件下才能发展。这里的一定条件包括男女双方需要同时对对方有一定的好感或者喜欢，或者说同时吸引着彼此，有着共同的理想和目标，性格相合，三观相投等等。&lt;/p&gt;
&lt;p&gt;最后，爱情的产生必须经历一个从量变到质变的过程。上述所有条件都能够促进男女两性关系的发展，但爱情的产生需要内因外因同时作用于恋爱关系中的男女双方，发生质变产生爱情。爱情产生以后，男女双方通过主观能动性认识到了爱情的产生，进而脑海里产生了对对方的爱。&lt;/p&gt;
&lt;h4 id=&#34;2-爱情的存在产生是客观的不以人的意志为转移的&#34;&gt;2. 爱情的存在、产生是客观的，不以人的意志为转移的。&lt;/h4&gt;
&lt;p&gt;谁否定这一点，谁就会犯主观（唯心）主义的错误。在爱情这个二元系统，处于恋爱关系的男女双方是系统中的要素，爱情则是系统中要素间的联系。依系统的整体性原理，是相对独立于系统间要素存在的。即使是处于恋爱关系的男女双方，也不可能纯粹地在主观上决定爱情产生和发展。&lt;/p&gt;
&lt;h4 id=&#34;3-处于恋爱关系中的男女双方是爱情的创造者&#34;&gt;3. 处于恋爱关系中的男女双方是爱情的创造者。&lt;/h4&gt;
&lt;p&gt;这就好比马克思主义唯物史观的基本观点——人民群众是历史的创造者一样。处于恋爱关系中的男女双方是爱情的创造者，也是推动两性亲密关系发展的决定力量。&lt;/p&gt;
&lt;p&gt;因此，我们要像批判唯心史观那样，反对将个人意志凌驾于爱情之上。&lt;/p&gt;
&lt;h4 id=&#34;4-爱情的产生是有其客观规律可循的&#34;&gt;4. 爱情的产生是有其客观规律可循的。&lt;/h4&gt;
&lt;p&gt;马克思主义认为，规律可以主观能动地认识，可以主观能动地利用，但不可违背。谁否定这一点谁就会犯不可知论的错误。要在主观上主观能动地在理论上认识规律，客观上主观能动地在实践上利用规律，才能正确的将主观与客观结合起来，推动矛盾向主观所期望的方向发展。反之，不认识、应用规律，或是认识、应用错误的规律，主观与客观就很有可能分离而非结合，这样一来往往事与愿违。&lt;/p&gt;
&lt;p&gt;因此，我们要树立正确的爱情观。我们首先要认识到，爱情的产生是有其客观规律可循的。男女双方基于已有的关系，彼此相互欣赏、性格相投、志同道合，使得关系不断发展进而促使爱情的产生。然后，我们要学会主观能动地利用规律。例如，积极主动地同对方进行情感的深入交流，就一些事情互相角换看法和观点，以便于彼此之间更加互相了解。如果我们违背了爱情产生的客观规律，例如犯爱情唯心主义错误，认为“我爱你，你也应该爱我”，结果必将适得其反。&lt;/p&gt;
&lt;h3 id=&#34;爱与爱情的辩证关系&#34;&gt;爱与爱情的辩证关系&lt;/h3&gt;
&lt;p&gt;爱情，如果我们要用定语来修饰它，我们通常会用“我们的”、“男女双方的”等等。总而言之，爱情是两个人才能够创造的。根据马克思主义辩证唯物论的基本原理，爱情隶属于物质范畴。&lt;/p&gt;
&lt;p&gt;爱，如果我们要用定语来修饰它，我们通常会用“我的”、“你的”、“我对你的”、“你对我的”等等。总而言之，爱是一个人作用于另一个人并且在另一个人的脑海里产生的一种感觉。根据马克思主义辩证唯物论的基本原理，爱隶属于意识范畴。&lt;/p&gt;
&lt;p&gt;马克思主义认为，物质决定意识，意识是物质的反映，对物质具有反作用。那么爱与爱情同样具有辩证关系：&lt;strong&gt;（男女双方之间的）爱情决定（男女双方对彼此的）爱，爱能够反映出爱情，并且对爱情具有反作用&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;如何理解爱情决定爱呢？我们之所以爱一个人，或者说我们之所以能够感受到另一个人的爱，是因为爱情已经产生了。爱情的产生不是因为我爱你，你也爱我，而是基于双方一定的关系基础，在一定条件下发展而产生的。相反，正因为爱情的产生，我们通过主观能动性感受到了爱情的存在，这在我们的脑海中就产生了爱的感觉。&lt;/p&gt;
&lt;p&gt;爱能够反映出爱情相对来说比较容易理解。男女双方对彼此的爱通过实践转化为物质，再被大家认识到，这里的认识就能反映出男女双方的爱情。例如，七夕佳节男女双方对彼此的祝福话语、精心制作的礼物等等。其实不光在男女双方看来，在旁人看来，都是爱情的反映。&lt;/p&gt;
&lt;p&gt;如何理解爱对爱情具有反作用呢？男女双方舒适的、恰当的表达对对方的爱的方式能够促进爱情的发展，使爱情更加忠贞、牢固；相反，男女双方偏激的、不恰当的表达对对方的爱的方式却会阻碍爱情的发展，使爱情消磨、破裂。&lt;/p&gt;
&lt;h3 id=&#34;对爱情唯心主义的批判&#34;&gt;对爱情唯心主义的批判&lt;/h3&gt;
&lt;p&gt;爱情唯心主义归根结底是认为爱情是特定的一个人或者几个人的意志决定的，我们必须要加以批判。具体来说分为以下两类：&lt;/p&gt;
&lt;h4 id=&#34;1-爱情主观唯心主义&#34;&gt;1. 爱情主观唯心主义&lt;/h4&gt;
&lt;p&gt;这一类最典型的代表就是“我爱你，你也爱我，我们之间就有了爱情”。这是典型的爱情主观唯心主义观点，认为先有爱，后有爱情。&lt;/p&gt;
&lt;p&gt;更有甚者认为，“爱情只要我爱你就够了”。这夸大了人的主观能动性，不按客观规律办事，主观与客观相违背，往往适得其反。因此，所谓的“暗恋”、“单相思”绝不是爱情，它们只不过是脑海中的一种意识罢了。&lt;/p&gt;
&lt;h4 id=&#34;2-爱情客观唯心主义&#34;&gt;2. 爱情客观唯心主义&lt;/h4&gt;
&lt;p&gt;这一类最典型的代表就是“爱情是上天的眷顾”、“爱情是丘比特创造的”。无产阶级伟大导师恩格斯曾经指出：一切宗教都不过是支配着人们日常生活的外部力量在人们头脑中的幻想的反映，在这种反映中，人间的力量采取了超人间的力量的形式。爱情也是同理，当人们不能够从客观实际中认识爱情时，就会创造一些超人间的力量试图解释爱情产生的原因。例如很多渴望爱情的人找不到自己满意的伴侣，就把原因归结为命不好，不懂得从自己身上和客观环境寻找原因（内因和外因）。&lt;/p&gt;
&lt;p&gt;受传统儒家文化以及封建礼教的影响，“指腹为婚”、包办婚姻以及传统的门当户对在今天仍然屡见不鲜。它们也都属于爱情客观唯心主义的观点，应当加以批判。恩格斯曾经指出：在整个古代，婚姻的缔结都是由父母包办，当事人则安心顺从。古代所仅有的那一点夫妇之爱，并不是主观的爱好，而是客观的义务，不是婚姻的基础，而是婚姻的附加物。&lt;/p&gt;
&lt;h3 id=&#34;爱情的自然性与社会性的对立统一&#34;&gt;爱情的自然性与社会性的对立统一&lt;/h3&gt;
&lt;p&gt;什么是爱情的自然性呢？人类同自然界中的其他高级动物一样，需要繁衍后代，这是人类的生物本能决定的。爱情是建立在性关系的基础之上的，违背这一基本规律是要不得的。如果没有了性关系，爱情则只能退化成友情了。因此，爱情的自然性是必不可少的。&lt;/p&gt;
&lt;p&gt;什么是爱情的社会性呢？马克思主义认为，人类和自然界中的其他高级动物不同的是，人类拥有他们特有的意识，这来源于人类在生产生活中的实践。人类主观能动地认识世界、改造世界，同他人建立联系，形成了最早的原始社会。而性关系在人们头脑中的反映就逐渐衍化成了爱，性关系本身也随之发展并形成爱情。从原始社会开始，人类社会发展至今，即使私有制、阶级的产生，也依然没有改变人类是社会动物的性质。因此，爱情也是具有社会性的。&lt;/p&gt;
&lt;p&gt;因此，爱情是自然性和社会性的对立统一。&lt;/p&gt;
&lt;p&gt;这里的对立体现在爱情的自然性会受到社会性的约束，爱情的社会性也会受到自然性的约束。例如，我们每个人都有正常的生理需求，但是由于人类是社会动物，受到道德和法律的约束，不可能随意同他人发生性关系。这就是爱情的自然性会受到社会性的约束。同理，爱情的社会性也会受到自然性的约束。例如，真心相爱的两个人决定丁克，周围的亲朋好友很可能就会因为他们不繁衍后代而对他们议论纷纷。&lt;/p&gt;
&lt;p&gt;同样，爱情的自然性和社会性也是统一的，它们相互依存、密不可分。如果这两种特性失去了任意一种，便不再是爱情了，就会退化成纯粹的性关系和友情了。&lt;/p&gt;
&lt;p&gt;总而言之，爱情的本质，是人的社会属性与人的自然属性相结合的异性间的崇高感情。&lt;/p&gt;
&lt;h2 id=&#34;爱情实践论&#34;&gt;爱情实践论&lt;/h2&gt;
&lt;p&gt;马克思主义认为，实践决定认识，认识对实践具有反作用。人的意识可以通过主观能动地实践转化为物质，而物质可以被人们认识从而转化为人的意识。&lt;/p&gt;

$$
\begin{array}{c}
\mbox{实践} \\\\
\mbox{意识} \rightleftharpoons \mbox{物质} \\\\
\mbox{认识} 
\end{array}
$$

&lt;p&gt;上面的公式已经非常清晰地表达了物质、意识、实践、认识四者之间的关系。实际上，爱情也是如此。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;爱情是处于恋爱关系的男女双方实践的产物&lt;/strong&gt;，具体分为如下三个阶段：&lt;/p&gt;
&lt;h3 id=&#34;第一阶段爱之初&#34;&gt;第一阶段：爱之初&lt;/h3&gt;

$$
\begin{array}{c}
\mbox{吸引（认识）} \\\\
\mbox{性魅力（物质）} \rightleftharpoons \mbox{好感（意识）} \\\\
\mbox{追求（实践）} 
\end{array}
$$

&lt;p&gt;我们经常会听到这样的观点：“爱情是吸引来的，而不是追求来的。”这句话其实说得非常有道理，而且符合爱情唯物主义的基本观点。一开始，男女双方其实是被彼此身上散发的性魅力所吸引，这其实就是物质在人的脑海中的反映，人可以主观能动地认识从而产生感觉。具体来说，这里的性魅力包括男女两性的生理性别特征（第一性征、第二性征）、社会性别特征（例如一提到漂亮的裙子我们就很容易想到美丽的女性，一提到健硕的肌肉我们就很容易想到勇敢的男性）以及相较于其他异性对方所散发出来的独有人格魅力，等等。&lt;/p&gt;
&lt;p&gt;当人们认识到这些性魅力以后，就会在脑海中产生对对方的好感。正因为有好感，人们才会主观能动地去实践，具体表现为追求对方，想要和对方建立连接。然而，单方面的被吸引和主动追求并不能建立起一定程度上的恋爱关系，男女双方必须同时被彼此吸引并且主动追求对方才可以建立起恋爱关系。&lt;/p&gt;
&lt;h3 id=&#34;第二阶段恋爱关系&#34;&gt;第二阶段：恋爱关系&lt;/h3&gt;

$$
\begin{array}{c}
\mbox{感受好感（认识）} \\\\
\mbox{恋爱关系（物质）} \rightleftharpoons \mbox{相互喜欢（意识）} \\\\
\mbox{表达好感（实践）} 
\end{array}
$$

&lt;p&gt;男女双方建立起一定的恋爱关系以后，这种关系会使得男女双方认识到对方对自己是有好感的，那么就会在自己的脑海里产生喜欢对方的感觉。正因为喜欢对方，男女双方就会主观能动地去实践，表达自己对对方的好感。例如，跟对方分享自己的日常生活，向对方倾诉自己的情感，和对方一起去做情侣应该做的事情，等等。在不断地认识、实践过程当中，男女双方对彼此之间会更加了解，推动着恋爱关系的不断发展。同时，男女双方在三观、性格、理想等方面进行着深入交流，为恋爱关系发展为爱情提供了必要准备。&lt;/p&gt;
&lt;h3 id=&#34;第三阶段爱情&#34;&gt;第三阶段：爱情&lt;/h3&gt;

$$
\begin{array}{c}
\mbox{感受爱意（认识）} \\\\
\mbox{爱情（物质）} \rightleftharpoons \mbox{爱（意识）} \\\\
\mbox{表达爱意（实践）} 
\end{array}
$$

&lt;p&gt;男女双方在恋爱关系的基础上，有着共同的理想和目标，性格相合，三观相投，在各自的内心中形成对对方的最真挚的倾心爱慕，并且渴望对方成为自己终生伴侣。在内外因的共同作用下，恋爱关系不断发展，从量变到质变，最终产生了爱情。&lt;/p&gt;
&lt;p&gt;爱情产生后，相爱的男女双方认识到彼此之间的爱，那么就会在自己的脑海里产生爱对方的感觉。而也正因为爱对方，男女双方就会主观能动地去实践，表达自己对对方的爱。例如，在法律上结为夫妻关系，用婚姻来作为自己爱对方的一种承诺。在不断地认识、实践过程当中，爱情也在不断发展。从一开始的相互吸引，到相识之后的志趣相投，再到进入婚姻以后的责任，最后到年老时的相互依靠。&lt;/p&gt;
&lt;h2 id=&#34;爱情矛盾论&#34;&gt;爱情矛盾论&lt;/h2&gt;
&lt;p&gt;马克思主义认为，任何事物都是矛盾的对立统一。矛盾分析方法是联系发展规律的核心方法，掌握了矛盾，就抓住了核心。那么隶属于物质范畴的爱情自然也是一分为二，是多对矛盾的统一体。&lt;/p&gt;
&lt;p&gt;在所有的矛盾当中，基本矛盾贯穿整个事物的发展，主要矛盾处于支配地位，对事物发展起决定作用。打个比方，基本矛盾就好比天平，而其他各个矛盾就好比质量不一的砝码。主要矛盾则好比那个质量最大的砝码，它处于支配地位。无论将这个质量最大的砝码放在天平的哪一边，都对天平的平衡起决定作用。而次要矛盾就好比其他砝码，它们虽然不处于支配地位，但也对天平的平衡起重要作用。&lt;/p&gt;
&lt;p&gt;每一个矛盾中的两个方面的力量是不平衡的。其中，处于支配地位，起主导作用的方面叫矛盾的主要方面。事物的性质主要是由矛盾的主要方面决定的。矛盾的主要方面与次要方面既相互排斥，又相互依赖，并在一定条件下相互转化。&lt;/p&gt;
&lt;h3 id=&#34;爱情的基本矛盾&#34;&gt;爱情的基本矛盾&lt;/h3&gt;
&lt;p&gt;个人认为，根据马克思主义唯物辩证法的基本原理，爱情的基本矛盾是&lt;strong&gt;男女两性在爱情中投入和收获之间的矛盾&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;一方面，爱情产生以后，男女双方都希望投入到这段感情当中，他们会发挥自己的主观能动性去表达自己的爱，这是爱情的投入方面；另一方面，男女双方可以感受到对方表达的爱意，不论是物质层面还是精神层面，都会有所收获。我们知道，爱情作为不为人的主观意志为转移的男女之间的真挚情感，需要男女双方共同经营。男女两性在爱情中投入和收获之间的矛盾作为爱情的基本矛盾，贯穿爱情发展的始终。&lt;/p&gt;
&lt;p&gt;爱情的基本矛盾与男女两性在爱情中投入和收获的辩证关系密不可分。在爱情中，男女两性的投入决定收获，与此同时，收获对投入具有反作用。爱情产生之后，男女双方都会投入到这段感情当中，这个时候投入在爱情的基本矛盾中占主要方面。而当男女双方都因感受到对方的爱意而感到愉悦时，这个时候收获在爱情的基本矛盾中占主要方面。正因为男女双方对爱情的投入和在爱情中的收获在爱情的基本矛盾中不断相互转化，爱情才得以发展。而且，这种发展是事物内部矛盾运动的结果（男女双方的投入和收获），而不是外因干预之下的结果。&lt;/p&gt;
&lt;p&gt;当男女两性在爱情中投入和收获出现不平衡时，一方面能够推动爱情向着更加亲密的男女两性关系发展，另一方面也会阻碍爱情的发展。例如，男女双方一方过多地投入，而另外一方过多地收获，这就造成了男女双方地位的不平等。而我们知道，爱情是平等的，所以这就会阻碍爱情的发展。如果上面例子当中的男女双方意识到了这种不平等，一方主动地减少投入而另外一方主动地增加投入，使爱情回到相对平等的状态，这就促进了爱情向着更加亲密的男女两性关系发展。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;爱情发展的本质是爱情基本矛盾运动的结果&lt;/strong&gt;。而随着爱情基本矛盾的解决，爱情必然要从量变到质变，那么爱情质变的结果就是真爱。真爱是爱情的高级阶段，是爱情不断发展的结果。因此，要树立正确的爱情观，主观能动地利用规律，与伴侣共同创造专属于我们自己的爱情，在实践和认识中不断发展爱情，结为一生一世的真爱。&lt;/p&gt;
&lt;h3 id=&#34;爱情的主要矛盾&#34;&gt;爱情的主要矛盾&lt;/h3&gt;
&lt;h4 id=&#34;1-两性的差异性和同一性之间的矛盾&#34;&gt;1. 两性的差异性和同一性之间的矛盾&lt;/h4&gt;
&lt;p&gt;男女两性本身就是矛盾，这在人的自然属性和社会属性层面均有体现。在自然属性方面，男女两性存在着生理方面的差异，例如第一性征、第二性征等，这些都是差异性；而男女两性在自然属性方面又是统一的，只有两性生殖器官结合进而使得精卵结合才能够繁衍后代。在社会属性方面，男女两性存在着思维和意识方面的差异，例如男性的思维偏理性而女性的思维偏感性，这是人类长期以来的（社会）实践决定的；而男女两性在社会属性方面也是统一的，男女双方都希望找到属于自己的伴侣，在亲密关系中可以给予和感受爱。&lt;/p&gt;
&lt;p&gt;作为男女两性关系实践的产物，爱情中也存在着男女两性的差异性和同一性。爱情中两性的差异性主要体现在以下几个方面：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;男女双方思维方式的差异：男性的思维方式偏理性，女性的思维方式偏感性。具体来讲，碰到同样的一个问题，男性往往会首先考虑如何解决这个问题，而女性则往往会首先表达自己遇到问题时（不知所措）的感受。&lt;/li&gt;
&lt;li&gt;男女双方在爱情中的需求的差异：男性通常希望得到女性的鼓励、认可，女性通常希望得到男性的关爱、依靠。&lt;/li&gt;
&lt;li&gt;男女双方性格、三观之间的差异性。&lt;/li&gt;
&lt;li&gt;……&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;爱情中两性的同一性主要体现在以下几个方面：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;男女双方主观上都希望有自己的伴侣，他（她）不仅可以满足自己的性需求，而且还能够提供物质价值和精神价值。&lt;/li&gt;
&lt;li&gt;男女双方性格、三观之间的相似性。&lt;/li&gt;
&lt;li&gt;……&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;当两性的差异性和同一性之间的矛盾成为爱情的主要矛盾时，表现在具体的亲密关系中就是男女双方相处时的合与不合。当差异性成为矛盾的主要方面时，男女双方眼中的对方就和自己不同，而差异容易导致冲突，冲突就会使得这种不同变成不合。当同一性成为矛盾的主要方面时，男女双方就会觉得对方跟自己很合。&lt;/p&gt;
&lt;p&gt;不论合与不合，主要矛盾都起决定作用，它通过爱情的基本矛盾推动爱情的发展。当男女双方觉得对方跟自己很合时，此时两性的同一性占主要矛盾的主要方面，他们就会更愿意在爱情中投入，也能在爱情中收获更多的爱。当男女双方觉得对方跟自己有差异，进而觉得对方跟自己不合时，此时两性的差异性占主要矛盾的主要方面，他们就会质疑和否定他们在爱情中的收获，进而减少在爱情中的投入。&lt;/p&gt;
&lt;p&gt;举一个简单的例子，女生向男生吐槽工作繁忙但是薪资少，这个时候男生就直接建议女生辞职换一个工资高的单位，结果这个女生生气了。这实际上就是两性的差异性占主要矛盾的主要方面了。具体来说，男生遇到问题往往会首先考虑如何解决问题，譬如这个例子中男生直接建议女生辞职，因为工作忙而薪资少，换单位是一种解决方法。但是，女生遇到问题往往比较情绪化，她是希望男生能够安慰和体谅自己工作的不易。女生看到了两性的差异性，并且认为这不合适，在爱情基本矛盾的作用下，女生对爱情中的收获产生质疑，所以才会生气。如果这个时候男生还不能意识到问题之所在，那么两性的差异性就会占据主导地位，由此引发的冲突通过爱情的基本矛盾使爱情逐渐消磨。&lt;/p&gt;
&lt;p&gt;在男女两性交往和爱情产生的初期，两性的差异性和同一性之间的矛盾往往会成为主要矛盾。男女双方都是独立的个体，彼此在不同的环境下成长起来，此时的差异性占据矛盾的主要方面。需要特别注意的是，差异性并不会阻碍爱情的发展，而是因差异而起的冲突会阻碍爱情的发展。因此，我们既要看到恋爱对象和自己的相似性，又要正视恋爱对象和自己的差异性。&lt;/p&gt;
&lt;h4 id=&#34;2-物质需求与精神需求之间的矛盾&#34;&gt;2. 物质需求与精神需求之间的矛盾&lt;/h4&gt;
&lt;p&gt;爱情的自然性与社会性的辩证统一关系决定了人们对爱的需求既包括物质层面又包括精神层面。物质需求与精神需求之间的矛盾常常体现在同一事物上，是同一事物矛盾的不同方面。&lt;/p&gt;
&lt;p&gt;例如，男生因为工作忙碌的原因没能陪女生过生日，于是双方各执一词。男生觉得如果不工作薪水就会大打折扣，而女生觉得生日这么重要的日子都不能抽出时间，因此感到失望、孤独。看似这个例子是男女双方主观上的冲突，但本质上则是物质需求与精神需求之间的矛盾。男生物质需求相对更多，而女生的精神需求相对更多。而且矛盾的两个方面同时作用于同一事物——时间，使得男女双方的爱情斗争异常激烈。（如果女生的生日和男生的工作不在同一时间，因时间而起的物质需求和精神需求之间的矛盾不可能表现出如此明显的斗争性。）当双方不能够认识到这一点而上纲上线时，极其容易质疑对方是不是不爱自己，那么实际上就是爱情的基本矛盾作用的结果。&lt;/p&gt;
&lt;h4 id=&#34;3-理想与现实之间的矛盾&#34;&gt;3. 理想与现实之间的矛盾&lt;/h4&gt;
&lt;p&gt;理想与现实之间的矛盾经常发生在谈婚论嫁的时候。（当然，也不仅仅只在谈婚论嫁的时候，本小节重点探讨这一点。）&lt;/p&gt;
&lt;p&gt;马克思主义认为，爱情的自然性与社会性是辩证统一的。然而，婚姻并不是男女双方爱情实践的产物，而是家庭社会实践的产物。婚姻没有自然性，只有社会性，这是因为婚姻是家庭、宗族为了维系血缘，保证血统的纯正性而产生的一种契约关系。在古代，婚姻是凌驾于爱情之上的。即使婚姻规定了男女双方发生性关系是合法的，也不能够体现婚姻是具有自然性的。这只能说明性关系是婚姻制度的附加产物，取决于统治阶级的意志。马克思主义认为，社会主义的婚姻关系应当建立在爱情的基础上。&lt;/p&gt;
&lt;p&gt;我国目前正处于并将长期处于社会主义初级阶段，在我们的社会文化里还是或多或少存在封建的、资产阶级的婚姻观。在谈婚论嫁时，男女双方常常会因为彩礼问题谈崩，还会受到传统的门当户对观念的影响。在日常生活中我们经常听闻的理想与现实之间的矛盾主要有以下两种情况：一是恋爱时间久感情基础牢固但因各种原因不能进入婚姻而被一拍两散的，二是渴望甜甜的恋爱、渴望爱情却不能接受很草率地直接进入婚姻的。&lt;/p&gt;
&lt;p&gt;与北欧发达国家相比，我们的社会不能接受只有爱情而没有婚姻，我们把婚姻这样一个契约关系看得比爱情重要得多。这里面跟生产力与生产关系、经济基础与上层建筑（社会文化等）许多因素有关，比较复杂，但绝不是社会上人们的主观意愿决定的。因此，理想与现实之间的矛盾非常容易在爱情发展的后期凸显出来。这一主要矛盾处理得当能够极大地促进爱情的发展，反之则极有可能使得爱情加速破裂。&lt;/p&gt;
&lt;h4 id=&#34;4-空间上的聚离之间的矛盾&#34;&gt;4. 空间上的聚离之间的矛盾&lt;/h4&gt;
&lt;p&gt;我们通常所说的“异地恋”就是空间上的聚离之间的矛盾成为了主要矛盾。在这样一种矛盾占据支配地位的前提下，一方面，男女双方会因为空间上的分离而朝思暮盼着对方，希望通过事物内部的矛盾运动使相聚成为矛盾的主要方面（即结束异地）。另一方面，男女双方会因为对方长期不在身边无法得到爱的满足而很容易产生不安全感，或者对于两个人的未来感到迷茫，进而否定这段感情。&lt;/p&gt;
&lt;p&gt;前文曾述，爱情的基本矛盾是男女两性在爱情中投入和收获之间的矛盾。当空间上的聚离之间的矛盾成为爱情的主要矛盾时，爱情的基本矛盾就体现在：男女双方相比于相聚更难在爱情中有所收获，不论是在物质层面还是在精神层面都更难感受到对方的爱。既然爱情的基本矛盾是推动爱情发展的根本原因，那么男女双方就会发挥主观能动性去表达爱意，例如节日制造惊喜、煲电话粥，等等。这在一定程度上缓和了爱情的基本矛盾，使得男女双方能够更多地在爱情中感受到对方的爱。但是，这些实践活动并不能解决当前爱情的主要矛盾，唯一的办法就是结束异地。而随着爱情主要矛盾的解决，男女双方在爱情中的投入和收获不断得到正反馈，爱情在爱情的基本矛盾的作用下发展，男女双方的亲密关系达到了一个前所未有的高度。&lt;/p&gt;
&lt;p&gt;很多时候，我们会将两个人不合适的原因归结为异地。那么之所以我们会将不合适的原因归结为异地，是因为我们只看到了异地对爱情发展的阻碍作用。实际上，异地对爱情的发展也有促进作用——即上一段中叙述的那样，男女双方发挥主观能动性去表达爱意，积极缓和甚至解决爱情的基本矛盾。实际上，异地是影响因素，或者说是外因。两个人不合适，或者说爱情走向破裂的根本原因是爱情基本矛盾运动的结果。当男女双方因异地而感受不到对方的爱时，他们由于得不到正反馈，主观上表现为不愿意加大在感情中的投入。例如，在物质层面上，异地的男女双方都不愿意到对方的城市生活，特别是女性受远嫁观念影响更加不愿意做出这样的决策。在精神层面上，长期没有联系和来往导致男女双方关系疏远，难以产生精神上的共鸣，进而不愿意主动联系对方，甚至冷战。不过，归根结底是因为男女双方没有认识到爱情的基本矛盾，没有认识到可以发挥主观能动性加大在感情中的投入进而在爱情中有所收获，因为投入决定收获。&lt;/p&gt;
&lt;p&gt;要特别注意异地恋的时候，不能将爱情的主要矛盾和爱情的基本矛盾混淆。&lt;/p&gt;
&lt;h3 id=&#34;方法论&#34;&gt;方法论&lt;/h3&gt;
&lt;p&gt;爱情矛盾论的基本观点告诉我们，爱情是多对矛盾的统一体。我们要把握住爱情的基本矛盾，认识到爱情发展的本质是爱情基本矛盾运动的结果，反对将爱情发展的原因归结为外部事物或条件。在爱情的各个阶段，我们要抓住这个阶段爱情的主要矛盾，让每一阶段爱情的主要矛盾朝着促进爱情发展的方面转化，不断地解决矛盾促进爱情的发展。最终解决爱情的基本矛盾，找到真爱。&lt;/p&gt;
&lt;h2 id=&#34;爱情与人的解放&#34;&gt;爱情与人的解放&lt;/h2&gt;
&lt;p&gt;马克思主义认为，人类追求自由的最高境界就是人类的解放。人类的解放就是指从自然力和社会关系的制约中获得自由。所以，人的解放和人的自由是分不开的，如果人不能在自然规律和社会规律面前获得自由，人就不能获得真正的解放。在自然规律面前获得自由就必须能够认识自然、驾驭和使用自然力，不受盲目的自然力的控制和束缚；在社会规律面前获得自由，从根本上讲就是要最终消除人对人的剥削关系、压迫关系和统治关系。&lt;/p&gt;
&lt;p&gt;马克思指出，“解放”是一种历史活动，而不同于思想活动，“解放”是由历史的关系，是由工业状况、商业状况、农业状况、交往关系的状况促成的。就是说，解放是历史地发展着的，在不同的历史时期具有不同的内容，表现为不同程度的自由。社会历史的每一重大进步，都有人的某种解放的意义，都是人类走向彻底解放的必要环节。&lt;/p&gt;
&lt;h3 id=&#34;各个社会形态下的爱情与人的解放&#34;&gt;各个社会形态下的爱情与人的解放&lt;/h3&gt;
&lt;p&gt;与社会形态的变革类似，爱情的发展和变革也伴随着人的解放。在原始社会，人们既无力支配自然，也不是社会关系的主人。大家平等互助，目的只有一个——生存。这个时期，爱情更接近纯粹的性关系，因为如果没有性关系，人类就无法生存繁衍下去。后来进入母系氏族社会，人类开始按性别分工。再后来随着生产力的发展，私有制的产生，进入父系氏族社会。&lt;/p&gt;
&lt;p&gt;奴隶社会生产力有了发展，社会物质财富有较多增长，人从自然力中争得了一定的自由，使人类在很大程度上摆脱了野蛮状态，跨进了文明的大门。但这个进步是以牺牲原始平等关系，代之以人剥削人的阶级关系为代价的。&lt;/p&gt;
&lt;p&gt;封建社会同理，依然存在着人剥削人的关系。这一时期，婚姻、家庭、宗族是凌驾在爱情之上的。不论是奴隶主、王侯将相，还是地主、士大夫，他们为了确保血统的纯正以及自己宗族统治阶级的地位，利用国家、法律等统治阶级的工具创造了婚姻这样一种契约制度。“女子无才便是德”、“三从四德”，本质上是统治阶级利用儒家思想作为阶级统治工具在男女两性关系方面的体现。&lt;/p&gt;
&lt;p&gt;此时的爱情受到社会的极大约束，性关系也只不过是婚姻的附属品。但相较于原始社会，人类从原始的野蛮生活解放出来，性关系不再像原始社会那样混乱，必须遵守一定的社会道德。这就是爱情伴随人的解放第一次产生的重大变革，两性关系从自然的约束中解放出来，被社会牢牢地约束。&lt;/p&gt;
&lt;p&gt;资本主义制度是私有制范围内最大的历史进步，它不仅带来了生产力的大发展，人从自然力中争得了整套的自由，而且加速了人从社会关系中解放出来的进程。资产阶级法权思想推动着爱情朝着更加自由的方向发展，使得爱情和婚姻不必在一定的范围（贵族）内产生，人人生而平等。&lt;/p&gt;
&lt;p&gt;科学社会主义理论诞生以后，第二国际为马克思主义的传播尽了极大努力，男女同工同酬、三八妇女节等一定程度上提高了女性的社会地位。五四运动促进了马克思列宁主义在中国的传播，解放后的“妇女能顶半边天”，也都一定程度上推动了女性的觉醒。这就是爱情伴随人的解放第二次产生的重大变革，女性的社会地位不断提高，男女双方的社会关系更加平等。&lt;/p&gt;
&lt;h3 id=&#34;共产主义下的爱情与人的解放&#34;&gt;共产主义下的爱情与人的解放&lt;/h3&gt;
&lt;p&gt;马克思主义认为，人类追求自由的最高境界就是人类的解放。&lt;strong&gt;爱情的最终目的就是追求个人的幸福&lt;/strong&gt;。因此，相爱的男女双方应该在爱情中解放自己、解放对方，相互解放、相互给予对方自由，而非相互压迫、相互剥夺自由。&lt;/p&gt;
&lt;p&gt;随着生产力的发展，私有制、等级制的消灭，国家、家庭的解体，共产主义的逐步实现，爱情也必然要解除与生育、资本、阶级、宗族、家庭、婚姻等的结合，转变为“仅仅和当事人有关而社会无须干预的纯粹私人关系”。无论性别、年龄、其他社会关系等，只要是两个灵魂、两个独立人格间的独立的自由的真诚的相互吸引，即只要是真爱，都会得到马克思主义者在人的解放的立场上的支持。&lt;/p&gt;
&lt;p&gt;今天的北欧发达国家非常接近马克思设想的共产主义下的理想爱情模式，但也略有不同。在北欧，性关系或者生育常常是被排在结婚之前的，当地人将婚姻看作是一种荣誉，是真爱的象征。这种社会现象与北欧发达国家的高福利制度的关系密不可分。&lt;/p&gt;
&lt;p&gt;作为中国人，我们一定会对这样的现象感到十分诧异。这是生产力与生产关系、经济基础与上层建筑决定的，而且受到中华传统文化的影响。因为我国是农耕文明，几千年以来自给自足的自然经济要求以家庭为单位进行生产。因此，家庭、国家的消亡在我国必然要经历一个相当漫长的历史过程。&lt;/p&gt;
&lt;h3 id=&#34;方法论-1&#34;&gt;方法论&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;解放伴侣就是解放自己，追求真爱就是追求幸福。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;今天的新中国已经从三座大山中解放出来七十多年了，然而社会意识是具有滞后性的，封建的、资产阶级的爱情观、婚姻观依然屡见不鲜，并且很可能还要存在一段时间。大男子主义、物化女性、重男轻女、门当户对等传统思想依然对男女双方之间真挚的情感有较大的阻碍。不过，我们乐于见到的是，今天的女性已经从纯粹的家庭生活解放出来，成为职场当中的独立女性。然而，这导致的后果是家庭矛盾、代际矛盾日益尖锐，根本原因是中国自改革开放以来的发展速度之快使得人们的思想观念还不能够适应社会生产力的发展。女性往往要承担来自社会（职场）和家庭的双重压力，而且男性还觉得女性完全承担家庭责任是天经地义的。&lt;/p&gt;
&lt;p&gt;作为女性，要有意识地解放自己，把自己从传统的、纯粹的家庭生活中解放出来，和男性一样在职场上绽放自己，经济独立，追求属于我们女性自己的价值。与此同时，实际上也是解放了伴侣，一定程度上为伴侣减轻家庭经济压力，使得伴侣可以有更多的时间投入到家庭当中。&lt;/p&gt;
&lt;p&gt;作为男性，要有意识地解放伴侣，主动为伴侣分担家务劳动，承担养育子女的责任，不搞“丧偶式育儿”，让伴侣从传统的、纯粹的家庭生活和相夫教子中解放出来。与此同时，实际上也是解放我们男性自己，男性可以在家庭生活中收获更多的幸福，而不是过去享受妻子的顺从。&lt;/p&gt;
&lt;p&gt;最后，始终将追求个人的幸福作为人生的最终目标，实现这一最终目标的一个绝佳途径就是大胆追求真爱。在面对社会、家庭等各方面的压力时，心中始终架起一个天平——这样的决策能让我自己的人生幸福吗？究竟什么样的决策才能够使我自己的人生幸福？&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Edge Intelligence: Architectures, Challenges, and Applications</title>
      <link>https://bowenei.gitee.io/post/edge-intelligence-architectures-challenges-and-applications/</link>
      <pubDate>Thu, 08 Jul 2021 11:53:13 +0800</pubDate>
      <guid>https://bowenei.gitee.io/post/edge-intelligence-architectures-challenges-and-applications/</guid>
      <description>&lt;p&gt;这篇关于边缘智能的综述文章最近一次修订时间为2020年12月。这篇文章的作者将边缘智能的相关工作分为四大部分：边缘缓存、边缘训练、边缘推断、边缘卸载，并且针对每部分研究工作进行了深入的文献调研和阐述分析。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/2003.12172&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;原文链接&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;Edge intelligence refers to a set of connected systems and devices for data collection, caching, processing, and analysis proximity to where data is captured based on artificial intelligence. Edge intelligence aims at enhancing data processing and protect the privacy and security of the data and users. Although recently emerged, spanning the period from 2011 to now, this field of research has shown explosive growth over the past five years. In this paper, we present a thorough and comprehensive survey on the literature surrounding edge intelligence. We first identify four fundamental components of edge intelligence, i.e. edge caching, edge training, edge inference, and edge offloading based on theoretical and practical results pertaining to proposed and deployed systems. We then aim for a systematic classification of the state of the solutions by examining research results and observations for each of the four components and present a taxonomy that includes practical problems, adopted techniques, and application goals. For each category, we elaborate, compare and analyse the literature from the perspectives of adopted techniques, objectives, performance, advantages and drawbacks, etc. This article provides a comprehensive survey to edge intelligence and its application areas. In addition, we summarise the development of the emerging research fields and the current stateof-the-art and discuss the important open issues and possible theoretical and technical directions.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;作者在摘要中首先指出了边缘智能的四个基本组成部分：边缘缓存、边缘训练、边缘推断、边缘卸载；然后对这四部分的研究成果进行系统分类，从采用的技术、目标、性能、优点和缺点等角度对文献进行阐述、比较和分析；最后总结了新兴研究领域的发展和当前的技术水平，并讨论了重要的开放问题和可能的理论和技术方向。&lt;/p&gt;
&lt;h2 id=&#34;i-introduction&#34;&gt;I. Introduction&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;With the breakthrough of Artificial Intelligence (AI), we are witnessing a booming increase in AI-based applications and services.&lt;/p&gt;
&lt;p&gt;However, existing intelligent applications are computationintensive, which present strict requirements on resources, e.g., CPU, GPU, memory, and network, which makes it impossible to be available anytime and anywhere for end users. Although current end devices are increasingly powerful, it is still insufficient to support some deep learning models.&lt;/p&gt;
&lt;p&gt;Moreover, existing intelligent applications generally adopt centralised data management, which requires users to upload their data to central cloud based data-centre.&lt;/p&gt;
&lt;p&gt;However, there is giant volume of data which has been generated and collected by billions of mobile users and Internet of Thing (IoT) devices distributed at the network edge. Uploading such volume of data to the cloud consumes significant bandwidth resources, which would also result in unacceptable latency for users.&lt;/p&gt;
&lt;p&gt;On the other hand, users increasingly concern their privacy. If mobile users upload their personal data to the cloud for a specific intelligent application, they would take the risk of privacy leakage, i.e., the personal data might be extracted by malicious hackers or companies for illegal purposes.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;作者首先指出了研究的背景：人工智能应用和服务的飞速发展。但是，这些智能应用和服务存在一些问题，归结起来主要是以下三点：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;终端计算资源不足&lt;/strong&gt;：现有的智能应用程序是计算密集型的，对资源提出了严格的要求。虽然目前的终端设备越来越强大，但仍然不足以支持一些深度学习模型。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;集中式云计算架构高时延&lt;/strong&gt;：现有的智能应用程序通常采用集中式数据管理，这要求用户将其数据上传到基于云的中央数据中心。然而，网络边缘的用户数量十分庞大，将如此大量的数据上传到云中会消耗大量的带宽资源，这也将导致用户无法接受的延迟。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;用户隐私安全问题&lt;/strong&gt;：如果移动用户将他们的个人数据上传到云上用于特定的智能应用，他们将承担隐私泄露的风险。&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;The main advantages of the edge computing paradigm could be summarised into three aspects. (i) Ultra-low latency: computation usually takes place in the proximity of the source data, which saves substantial amounts of time on data transmission. Edge servers provides nearly real-time responses to end devices. (ii) Saving energy for end devices: since end devices could offload computing tasks to edge servers, the energy consumption on end devices would significantly shrink. Consequently, the battery life of end devices would be extended. (iii) Scalability: cloud computing is still available if there are no enough resource on edge devices or edge servers. In such a case, the cloud server would help to perform tasks. In addition, end devices with idle resources could communicate amongst themselves to collaboratively finish a task. The capability of the edge computing paradigm is flexible to accommodate different application scenarios.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;因此，接下来作者顺理成章地提出了边缘计算的概念。作者首先阐述了边缘计算范式的三点优势：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;超低延迟&lt;/strong&gt;：计算通常在源数据附近进行，这节省了大量数据传输时间。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;为终端设备节省能源&lt;/strong&gt;：由于终端设备可以将计算任务卸载到边缘服务器，终端设备上的能耗将大幅减少。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;可扩展性&lt;/strong&gt;：如果边缘设备或边缘服务器上没有足够的资源，云计算仍然可用。在这种情况下，云服务器将有助于执行任务。此外，拥有空闲资源的终端设备可以相互通信，以协作方式完成任务。边缘计算范式的能力是灵活的，以适应不同的应用场景。&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;Edge computing addresses the critical challenges of AI based applications and the combination of edge computing and AI provides a promising solution. This new paradigm of intelligence is called edge intelligence, also named mobile intelligence.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;边缘计算解决了基于人工智能的应用程序的关键挑战，边缘计算和人工智能的结合提供了一个有前途的解决方案。这种新的智能范式被称为&lt;strong&gt;边缘智能&lt;/strong&gt;，也称为移动智能。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;It is also worth noting that AI could also be a powerful assistance for edge computing. This paradigm is called intelligent edge, which is different from edge intelligence. The emphasis of edge intelligence is to realize intelligent applications in edge environment with the assistance of edge computing and protect users’ privacy, while intelligent edge focuses on solving problems of edge computing with AI solutions, e.g., resource allocation optimization. Intelligent edge is out of our scope in this survey.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;同样值得注意的是，人工智能也可以成为边缘计算的有力辅助。这种范式称为智能边缘，不同于边缘智能。边缘智能的重点是借助边缘计算在边缘环境中实现智能应用，保护用户隐私，而智能边缘则侧重于用AI解决方案解决边缘计算的问题，例如资源分配优化。智能边缘并不在作者的调研范围内。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;This paper aims at providing a comprehensive survey to the development and the state-of-the-art of edge intelligence.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;本文旨在对边缘智能的发展和现状进行全面综述。这方面已有很多相关工作，作者在介绍中主要提到了以下几个方面：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;（边缘环境下的）联邦学习&lt;/li&gt;
&lt;li&gt;边缘智能深度学习模型训练与推理（包括模型设计、模型压缩和模型加速等角度）&lt;/li&gt;
&lt;li&gt;卸载策略和缓存策略&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;Our survey focuses on how to realise edge intelligence in a systematic way. There exist three key components in AI, i.e. data, model/algorithm, and computation. A complete process of implementing AI applications involves data collection and management, model training, and model inference. Computation plays an essential role throughout the whole process. Hence, we limit the scope of our survey on four aspects, including how to cache data to fuel intelligent applications (i.e., edge caching), how to train intelligent applications at the edge (i.e., edge training), how to infer intelligent applications at the edge (edge inference), and how to provide sufficient computing power for intelligent applications at the edge (edge offloading).&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;本文的调研侧重于如何以系统的方式实现边缘智能。人工智能有三个关键组成部分，即数据、模型/算法和计算。实现人工智能应用程序的完整过程包括数据收集和管理、模型训练和模型推理。计算在整个过程中起着重要的作用。因此，作者将调研范围限制在四个方面，包括如何缓存数据以支持智能应用（即边缘缓存），如何在边缘训练智能应用（即边缘训练），如何在边缘推断智能应用（边缘推断），以及如何在边缘为智能应用提供足够的计算能力（边缘卸载）。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Our contributions are summarized as following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;We survey recent research achievements on edge intelligence and identify four key components: edge caching, edge training, edge inference, and edge offloading. For each component, we outline a systematical and comprehensive classification from a multi-dimensional view, e.g., practical challenges, solutions, optimisation goals, etc.&lt;/li&gt;
&lt;li&gt;We present thorough discussion and analysis on relevant papers in the field of edge intelligence from multiple views, e.g., applicable scenarios, methodology, performance, etc. and summarise their advantages and shortcomings.&lt;/li&gt;
&lt;li&gt;We discuss and summarise open issues and challenges in the implementation of edge intelligence, and outline five important future research directions and development trends, i.e., data scarcity, data consistency, adaptability of model/algorithms, privacy and security, and incentive mechanisms.&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;p&gt;本文的贡献总结如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;作者调研了边缘智能的最新研究成果，并确定了四个关键的组成部分：边缘缓存、边缘训练、边缘推理和边缘卸载。对于每个部分，作者从多个维度概述了一个系统和全面的分类，例如，实际挑战、解决方案、优化目标等。&lt;/li&gt;
&lt;li&gt;作者从应用场景、方法论、性能等多个角度对边缘智能领域的相关论文进行了深入的讨论和分析。并总结它们的优点和缺点。&lt;/li&gt;
&lt;li&gt;作者讨论和总结了边缘智能实现中的开放问题和挑战，并概述了五个重要的未来研究方向和发展趋势，即数据稀缺性、数据一致性、模型/算法的适应性、隐私和安全以及激励机制。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;ii-overview&#34;&gt;II. Overview&lt;/h2&gt;
















&lt;figure  id=&#34;figure-fig-1-the-comparison-of-traditional-intelligence-and-edge-intelligence-from-the-perspective-of-implementation-in-traditional-intelligence-all-data-must-be-uploaded-to-a-central-cloud-server-whilst-in-edge-intelligence-intelligent-application-tasks-are-done-at-the-edge-with-locally-generated-data-in-a-distributed-manner&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Fig. 1. The comparison of traditional intelligence and edge intelligence from the perspective of implementation. In traditional intelligence, all data must be uploaded to a central cloud server, whilst in edge intelligence, intelligent application tasks are done at the edge with locally-generated data in a distributed manner.&#34; srcset=&#34;
               /post/edge-intelligence-architectures-challenges-and-applications/fig1_hu665fd517c4c5fb8d44d6086cebe5faec_1257683_951bce64514f827732989c6e679a190e.webp 400w,
               /post/edge-intelligence-architectures-challenges-and-applications/fig1_hu665fd517c4c5fb8d44d6086cebe5faec_1257683_eee8624ef4c5156511f9dd00a2d261d9.webp 760w,
               /post/edge-intelligence-architectures-challenges-and-applications/fig1_hu665fd517c4c5fb8d44d6086cebe5faec_1257683_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://bowenei.gitee.io/post/edge-intelligence-architectures-challenges-and-applications/fig1_hu665fd517c4c5fb8d44d6086cebe5faec_1257683_951bce64514f827732989c6e679a190e.webp&#34;
               width=&#34;760&#34;
               height=&#34;388&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Fig. 1. The comparison of traditional intelligence and edge intelligence from the perspective of implementation. In traditional intelligence, all data must be uploaded to a central cloud server, whilst in edge intelligence, intelligent application tasks are done at the edge with locally-generated data in a distributed manner.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;blockquote&gt;
&lt;p&gt;The comparison of traditional intelligence and edge intelligence from the perspective of implementation. In traditional intelligence, all data must be uploaded to a central cloud server, whilst in edge intelligence, intelligent application tasks are done at the edge with locally-generated data in a distributed manner.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;作者从实现的角度比较了传统智能和边缘智能。在传统智能中，所有数据都必须上传到中央云服务器，而在边缘智能中，智能应用任务是在边缘以分布式方式使用本地生成的数据完成的。&lt;/p&gt;
















&lt;figure  id=&#34;figure-fig-2-the-classification-of-edge-intelligence-literature&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Fig. 2. The classification of edge intelligence literature.&#34; srcset=&#34;
               /post/edge-intelligence-architectures-challenges-and-applications/fig2_huebe64dc92fa1caf2b3134795d72fd7d7_287466_7e0ed7359a71814facde3a539262362a.webp 400w,
               /post/edge-intelligence-architectures-challenges-and-applications/fig2_huebe64dc92fa1caf2b3134795d72fd7d7_287466_c177eff801eb08096dfc7476627274dd.webp 760w,
               /post/edge-intelligence-architectures-challenges-and-applications/fig2_huebe64dc92fa1caf2b3134795d72fd7d7_287466_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://bowenei.gitee.io/post/edge-intelligence-architectures-challenges-and-applications/fig2_huebe64dc92fa1caf2b3134795d72fd7d7_287466_7e0ed7359a71814facde3a539262362a.webp&#34;
               width=&#34;760&#34;
               height=&#34;365&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Fig. 2. The classification of edge intelligence literature.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;作者将边缘智能的文献分类绘制成上面的图，下面作者将给出这些模块的概述：&lt;/p&gt;
&lt;h3 id=&#34;a-edge-caching&#34;&gt;A. Edge Caching&lt;/h3&gt;
















&lt;figure  id=&#34;figure-fig-3-the-illustration-of-edge-caching-data-generated-by-mobile-users-and-collected-from-surrounding-environments-is-collected-and-stored-on-edge-devices-micro-bss-and-macro-bss-such-data-is-processed-and-analysed-by-intelligent-algorithms-to-provide-services-for-end-users&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Fig. 3. The illustration of edge caching. Data generated by mobile users and collected from surrounding environments is collected and stored on edge devices, micro BSs, and macro BSs. Such data is processed and analysed by intelligent algorithms to provide services for end users.&#34; srcset=&#34;
               /post/edge-intelligence-architectures-challenges-and-applications/fig3_hu0256fc95866280af08a469ae8c381815_117422_bc05fe2df8bae3d068fcb98f5a6016d0.webp 400w,
               /post/edge-intelligence-architectures-challenges-and-applications/fig3_hu0256fc95866280af08a469ae8c381815_117422_e9cb8cdd3cc9e296fae99764bfeb8d8f.webp 760w,
               /post/edge-intelligence-architectures-challenges-and-applications/fig3_hu0256fc95866280af08a469ae8c381815_117422_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://bowenei.gitee.io/post/edge-intelligence-architectures-challenges-and-applications/fig3_hu0256fc95866280af08a469ae8c381815_117422_bc05fe2df8bae3d068fcb98f5a6016d0.webp&#34;
               width=&#34;760&#34;
               height=&#34;386&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Fig. 3. The illustration of edge caching. Data generated by mobile users and collected from surrounding environments is collected and stored on edge devices, micro BSs, and macro BSs. Such data is processed and analysed by intelligent algorithms to provide services for end users.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;blockquote&gt;
&lt;p&gt;In edge intelligence, edge caching refers to a distributed data system proximity to end users, which collects and stores the data generated by edge devices and surrounding environments, and the data received from the Internet to support intelligent applications for users at the edge.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;在边缘智能中，边缘缓存是指接近终端用户的分布式数据系统，它收集和存储边缘设备和周围环境生成的数据，以及从互联网接收的数据，以支持边缘用户的智能应用。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;To implement edge caching, we answer three questions: (i) what to cache, (ii) where to cache, and (iii) how to cache.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;为了实现边缘缓存，我们需要回答三个问题：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;缓存什么&lt;/li&gt;
&lt;li&gt;缓存到哪里&lt;/li&gt;
&lt;li&gt;如何缓存&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;For the first problem, what to cache, we know that caching is based on the redundancy of requests. In edge caching, the collected data is inputted into intelligent applications and results are sent back to where data is cached. Hence, there are two kinds of redundancy: data redundancy and computation redundancy.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;作者认为，在边缘缓存中，收集的数据被输入到智能应用程序中，结果被发送回缓存数据的地方。因此，有两种冗余：数据冗余和计算冗余。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Data redundancy, also named communication redundancy, means that the inputs of an intelligent application may be the same or partially the same. For example, in continuous mobile vision analysis, there are large amounts of similar pixels between consecutive frames. Some resourceconstrained edge devices need to upload collected videos to edge servers or the cloud for further processing. With cache, edge devices only needs to upload different pixels or frames. For the repeated part, edge devices could reuse the results to avoid unnecessary computation.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;数据冗余，也称为通信冗余，意味着智能应用程序的输入可能相同或部分相同。例如，在连续移动视觉分析中，连续帧之间存在大量相似像素。一些资源受限的边缘设备需要将收集到的视频上传到边缘服务器或云端进行进一步处理。有了缓存，边缘设备只需要上传不同的像素或帧。对于重复的部分，边缘设备可以重用结果，以避免不必要的计算。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Caching based on such redundancy could effectively reduce computation and accelerate the inference. Computation redundancy means that the requested computing tasks of intelligent applications may be the same. For example, an edge server provides image recognition services for edge devices. The recognition tasks from the same context may be the same, e.g., the same tasks of flower recognition from different users of the same area. Edge servers could directly send the recognition results achieved previously back to users. Such kind of caching could significantly decrease computation and execution time.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;基于这种冗余的缓存可以有效减少计算量，加快推理速度。计算冗余意味着智能应用程序所请求的计算任务可能是相同的。例如，边缘服务器为边缘设备提供图像识别服务。来自相同上下文的识别任务可以是相同的，例如来自相同区域的不同用户的花识别的相同任务。边缘服务器可以直接将之前获得的识别结果发送回用户。这种缓存可以显著减少计算和执行时间。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;For the second problem, where to cache, existing works mainly focus on three places to deploy caches: macro BSs, micro BSs, and edge devices.&lt;/p&gt;
&lt;p&gt;Since the storage capacity of macro BSs, micro BSs, and edge devices is limited, the content replacement must be considered. Works on this problem focus on designing replacement policies to maximise the service quality.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;现有的工作主要集中在三个地方部署缓存：宏基站、微基站和边缘设备。由于宏基站、微基站和边缘设备的存储容量有限，因此必须考虑内容替换。关于这个问题的工作集中在设计替换策略以最大化服务质量。&lt;/p&gt;
&lt;h3 id=&#34;b-edge-training&#34;&gt;B. Edge Training&lt;/h3&gt;
















&lt;figure  id=&#34;figure-fig-4-the-illustration-of-edge-training-the-modelalgorithm-is-trained-either-on-a-single-device-solo-training-or-by-the-collaboration-of-edge-devices-collaborative-training-with-training-sets-cached-at-the-edge-acceleration-module-speeds-up-the-training-whilst-the-optimisation-module-solves-problems-in-training-eg-update-frequency-update-cost-and-privacy-and-security-issues-uncertainty-estimates-module-controls-the-uncertainty-in-training&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Fig. 4. The illustration of edge training. The model/algorithm is trained either on a single device (solo training), or by the collaboration of edge devices (collaborative training) with training sets cached at the edge. Acceleration module speeds up the training, whilst the optimisation module solves problems in training, e.g., update frequency, update cost, and privacy and security issues. Uncertainty estimates module controls the uncertainty in training.&#34; srcset=&#34;
               /post/edge-intelligence-architectures-challenges-and-applications/fig4_hu7ec90193ca0acb0c2a451cc39a7eb52f_137068_1263036f0886f1db066486065918a93d.webp 400w,
               /post/edge-intelligence-architectures-challenges-and-applications/fig4_hu7ec90193ca0acb0c2a451cc39a7eb52f_137068_59ad8d9fdb19facbfe41eaab4d4f40cf.webp 760w,
               /post/edge-intelligence-architectures-challenges-and-applications/fig4_hu7ec90193ca0acb0c2a451cc39a7eb52f_137068_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://bowenei.gitee.io/post/edge-intelligence-architectures-challenges-and-applications/fig4_hu7ec90193ca0acb0c2a451cc39a7eb52f_137068_1263036f0886f1db066486065918a93d.webp&#34;
               width=&#34;760&#34;
               height=&#34;596&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Fig. 4. The illustration of edge training. The model/algorithm is trained either on a single device (solo training), or by the collaboration of edge devices (collaborative training) with training sets cached at the edge. Acceleration module speeds up the training, whilst the optimisation module solves problems in training, e.g., update frequency, update cost, and privacy and security issues. Uncertainty estimates module controls the uncertainty in training.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;blockquote&gt;
&lt;p&gt;Edge training refers to a distributed learning procedure that learns the optimal values for all the weights and bias, or the hidden patterns based on the training set cached at the edge.&lt;/p&gt;
&lt;p&gt;Different from traditional centralised training procedures on powerful servers or computing clusters, edge training usually occurs on edge servers or edge devices, which are usually not as powerful as centralised servers or computing clusters.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;作者认为，边缘训练指的是一种分布式学习过程，它基于缓存在边缘的训练集来学习所有权重和偏差的最优值或隐藏模式。与传统的在功能强大的服务器或计算集群上的集中式训练过程不同，边缘训练通常发生在边缘服务器或边缘设备上，它们通常不如集中式服务器或计算集群强大。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Hence, in addition to the problem of training set (caching), four key problems should be considered for edge training: (i) how to train (the training architecture), (ii) how to make the training faster (acceleration), (iii) how to optimise the training procedure (optimisation), and (iv) how to estimate the uncertainty of the model output (uncertainty estimates).&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;因此，除了训练集（缓存）的问题之外，边缘训练还应考虑四个关键问题：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;如何训练（训练架构）&lt;/li&gt;
&lt;li&gt;如何使训练更快（加速）&lt;/li&gt;
&lt;li&gt;如何优化训练过程（优化）&lt;/li&gt;
&lt;li&gt;如何估计模型输出的不确定性（不确定性估计）&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;For the first problem, researchers design two training architectures: solo training and collaborative training. Solo training means training tasks are performed on a single device, without assistance from others, whilst collaborative training means that multiple devices cooperate to train a common model/algorithm. Since solo training has a higher requirement on the hardware, which is usually unavailable, most existing literature focuses on collaborative training architectures.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;对于第一个问题，研究人员设计了两种训练架构：单独训练和协同训练。单独训练意味着在单个设备上执行训练任务，无需其他设备的帮助，而协同训练意味着多个设备协同训练一个公共模型/算法。由于单独训练对硬件有更高的要求，而这通常是不可用的，大多数现有的文献集中在协同训练体系结构上。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Different from centralised training paradigms, in which powerful CPUs and GPUs could guarantee a good result with a limited training time, edge training is much slower. Some researchers pay attention to the acceleration of edge training. Corresponding to training architecture, works on training acceleration are divided into two categories: acceleration for solo training, and collaborative training.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;与集中式训练模式不同，在集中式训练模式中，强大的中央处理器和图形处理器可以在有限的训练时间内保证良好的结果，边缘训练要慢得多。一些研究者关注边缘训练的加速。与训练架构相对应，关于训练加速的工作分为两类：针对单独训练的加速，以及协同训练。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Solo training is a closed system, in which only iterative computation on single devices is needed to get the optimal parameters or patterns. In contrast, collaborative training is based on the cooperation of multiple devices, which requires periodic communication for updating. Update frequency and update cost are two factors which affect the performance of communication efficiency and training result. Researchers on this area mainly focus on how to maintain the performance of the model/algorithm with lower update frequency, and update cost. In addition, the public nature of collaborative training is vulnerable to malicious users. There is also some literature which focuses on the privacy and security issues.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;单独训练是一个封闭的系统，只需要在单个设备上进行迭代计算就可以获得最佳的参数或模式。相比之下，协同训练是基于多个设备的协作，需要定期沟通进行更新。更新频率和更新成本是影响通信效率和训练效果的两个因素。该领域的研究人员主要关注如何在较低的更新频率下保持模型/算法的性能，以及更新成本。此外，协作培训的公共性容易受到恶意用户的攻击。还有一些文献关注隐私和安全问题。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;In DL training, the output results may be erroneously interpreted as model confidence. Estimating uncertainty is easy on traditional intelligence, whilst it is resource-consuming for edge training. Some literature pays attention to this problem and proposes various kinds of solutions to reduce computation and energy consumption.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;在深度学习训练中，输出结果可能会被错误地解释为模型置信度。对传统智能来说，估计不确定性是容易的，而对边缘训练来说则是耗费资源的。一些文献关注了这个问题，并提出了各种解决方案来减少计算和能耗。&lt;/p&gt;
&lt;h3 id=&#34;c-edge-inference&#34;&gt;C. Edge Inference&lt;/h3&gt;
















&lt;figure  id=&#34;figure-fig-5-the-illustration-of-edge-inference-ai-modelsalgorithms-are-designed-either-by-machines-or-humans-models-could-be-further-compressed-through-compression-technologies-low-rank-approximation-network-pruning-compact-layer-design-parameter-quantisation-and-knowledge-distillation-hardware-and-software-solutions-are-used-to-accelerate-the-inference-with-input-data&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Fig. 5. The illustration of edge inference. AI models/algorithms are designed either by machines or humans. Models could be further compressed through compression technologies: low-rank approximation, network pruning, compact layer design, parameter quantisation, and knowledge distillation. Hardware and software solutions are used to accelerate the inference with input data.&#34; srcset=&#34;
               /post/edge-intelligence-architectures-challenges-and-applications/fig5_hu110700a7e9772abec25a80ee1df09d52_150363_f3157c1b1fd8fca4f8413c4ccc537795.webp 400w,
               /post/edge-intelligence-architectures-challenges-and-applications/fig5_hu110700a7e9772abec25a80ee1df09d52_150363_3d5d7f8d157f9b7e849b0299e4641b9c.webp 760w,
               /post/edge-intelligence-architectures-challenges-and-applications/fig5_hu110700a7e9772abec25a80ee1df09d52_150363_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://bowenei.gitee.io/post/edge-intelligence-architectures-challenges-and-applications/fig5_hu110700a7e9772abec25a80ee1df09d52_150363_f3157c1b1fd8fca4f8413c4ccc537795.webp&#34;
               width=&#34;760&#34;
               height=&#34;735&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Fig. 5. The illustration of edge inference. AI models/algorithms are designed either by machines or humans. Models could be further compressed through compression technologies: low-rank approximation, network pruning, compact layer design, parameter quantisation, and knowledge distillation. Hardware and software solutions are used to accelerate the inference with input data.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;blockquote&gt;
&lt;p&gt;Edge inference is the stage where a trained model/algorithm is used to infer the testing instance by a forward pass to compute the output on edge devices and servers.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;边缘推断是使用训练好的模型/算法通过向前传递来推断测试实例以计算边缘设备和服务器上的输出的阶段。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Most existing AI models are designed to be implemented on devices which have powerful CPUs and GPUs, this is not applicable in an edge environment. Hence, the critical problems of employing edge inference are: (i) how to make models applicable for their deployment on edge devices or servers (design new models, or compress existing models), and (ii) how to accelerate edge inference to provide real-time responses.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;大多数现有的人工智能模型被设计成在具有强大的中央处理器和图形处理器的设备上实现，这不适用于边缘环境。因此，采用边缘推断的关键问题是：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;如何使模型适用于它们在边缘设备或服务器上的部署（设计新模型，或压缩现有模型）&lt;/li&gt;
&lt;li&gt;如何加速边缘推断以提供实时响应&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;For the problem of how to make models applicable for the edge environment, researchers mainly focus on two research directions: design new models/algorithms that have less requirements on the hardware, naturally suitable for edge environments, and compress existing models to reduce unnecessary operation during inference. For the first direction, there are two ways to design new models: let machines themselves design optimal models, i.e., architecture search; and human-invented architectures with the application of depth-wise separable convolution and group convolution.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;对于如何使模型适用于边缘环境的问题，研究者主要集中在两个研究方向：设计对硬件要求较少、自然适用于边缘环境的新模型/算法，压缩现有模型以减少推理时不必要的操作。对于第一个方向，设计新模型有两种方式：让机器自己设计最优模型，即架构搜索；和群卷积的人类发明的体系结构。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;For the second direction, i.e., model compression, researchers focus on compressing existing models to obtain thinner and smaller models, which are more computation- and energy-efficient with negligible or even no loss on accuracy. There are five commonly used approaches on model compression: low-rank approximation, knowledge distillation, compact layer design, network pruning, and parameter quantisation.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;对于第二个方向，即模型压缩，研究人员专注于压缩现有模型，以获得更薄、更小的模型，这些模型更具计算和能源效率，精度损失可以忽略甚至没有。有五种常用的模型压缩方法：低秩近似，知识蒸馏，紧凑层设计，网络剪枝，以及参数量化。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Similar to edge training, edge devices and servers are not as powerful as centralised servers or computing clusters. Hence, edge inference is much slower. Some literature focuses on solving this problem by accelerating edge inference. There are two commonly used acceleration approaches: hardware acceleration and software acceleration. Literature on hardware acceleration mainly focuses on the parallel computing which is available as hardware on devices, e.g., CPU, GPU, and DSP. Literature on software acceleration focus on optimising resource management, pipeline design, and compilers, based on compressed models.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;与边缘训练类似，边缘设备和服务器不如集中式服务器或计算集群强大。因此，边缘推断要慢得多。一些文献集中于通过加速边缘推断来解决这个问题。有两种常用的加速方法：硬件加速和软件加速。关于硬件加速的文献主要集中在并行计算上，并行计算可作为设备上的硬件，例如中央处理器、图形处理器和数字信号处理器。关于软件加速的文献侧重于基于压缩模型优化资源管理、流水线设计和编译器。&lt;/p&gt;
&lt;h3 id=&#34;d-edge-offloading&#34;&gt;D. Edge Offloading&lt;/h3&gt;
















&lt;figure  id=&#34;figure-fig-6-the-illustration-of-edge-offloading-edge-offloading-is-located-at-the-bottom-layer-in-edge-intelligence-which-provides-computing-services-for-edge-caching-edge-training-and-edge-inference-the-computing-architecture-includes-d2c-d2e-d2d-and-hybrid-computing&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Fig. 6. The illustration of edge offloading. Edge offloading is located at the bottom layer in edge intelligence, which provides computing services for edge caching, edge training, and edge inference. The computing architecture includes D2C, D2E, D2D, and hybrid computing.&#34; srcset=&#34;
               /post/edge-intelligence-architectures-challenges-and-applications/fig6_hucedd142a5989158d9527b49ee7b96351_77004_01ca173e612a9bb564eb326e7c400b40.webp 400w,
               /post/edge-intelligence-architectures-challenges-and-applications/fig6_hucedd142a5989158d9527b49ee7b96351_77004_190ee33570bacc854795199675ec2210.webp 760w,
               /post/edge-intelligence-architectures-challenges-and-applications/fig6_hucedd142a5989158d9527b49ee7b96351_77004_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://bowenei.gitee.io/post/edge-intelligence-architectures-challenges-and-applications/fig6_hucedd142a5989158d9527b49ee7b96351_77004_01ca173e612a9bb564eb326e7c400b40.webp&#34;
               width=&#34;760&#34;
               height=&#34;384&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Fig. 6. The illustration of edge offloading. Edge offloading is located at the bottom layer in edge intelligence, which provides computing services for edge caching, edge training, and edge inference. The computing architecture includes D2C, D2E, D2D, and hybrid computing.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;blockquote&gt;
&lt;p&gt;As a necessary component of edge intelligence, edge offloading refers to a distributed computing paradigm, which provides computing service for edge caching, edge training, and edge inference. If a single edge device does not have enough resource for a specific edge intelligence application, it could offload application tasks to edge servers or other edge devices.&lt;/p&gt;
&lt;p&gt;Edge offloading layer transparently provides computing services for the other three components of edge intelligence. In edge offloading, Offloading strategy is of utmost importance, which should give full play to the available resources in edge environment.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;作为边缘智能的必要组成部分，边缘卸载是指一种分布式计算模式，它为边缘缓存、边缘训练和边缘推理提供计算服务。如果单个边缘设备没有足够的资源用于特定的边缘智能应用程序，它可能会将应用程序任务转移到边缘服务器或其他边缘设备。&lt;/p&gt;
&lt;p&gt;边缘卸载层透明地为边缘智能的其他三个组件提供计算服务。在边缘卸载中，卸载策略至关重要，它应该充分发挥边缘环境中的可用资源。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Available computing resources are distributed in cloud servers, edge servers, and edge devices. Correspondingly, existing literature mainly focuses on four strategies: device-to-cloud (D2C) offloading, device-to-edge server (D2E) offloading, device-to-device (D2D) offloading, and hybrid offloading. Works on the D2C offloading strategy prefer to leave pre-processing tasks on edge devices and offload the rest of the tasks to a cloud server, which could significantly reduce the amount of uploaded data and latency. Works on D2E offloading strategy, also adopt such operation, which could further reduce latency and the dependency on cellular network. Most works on D2D offloading strategy focus on smart home scenarios, where IoT devices, smartwatches and smartphones collaboratively perform training/inference tasks. Hybrid offloading schemes have the strongest ability of adaptiveness, which makes the most of all the available resources.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;可用的计算资源分布在云服务器、边缘服务器和边缘设备中。相应地，现有文献主要关注四种策略：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;D2C&lt;/strong&gt;：边缘设备卸载到云服务器&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;D2E&lt;/strong&gt;：边缘设备卸载到边缘服务器&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;D2D&lt;/strong&gt;：边缘设备卸载到边缘设备&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;hybrid offloading&lt;/strong&gt;：混合卸载&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;e-summary&#34;&gt;E. Summary&lt;/h3&gt;
















&lt;figure  id=&#34;figure-fig-7-publication-volume-over-time-these-curves-show-the-trend-of-publication-volume-in-edge-caching-edge-training-edge-computing-edge-inference-and-edge-intelligence-respectively&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Fig. 7. Publication volume over time. These curves show the trend of publication volume in edge caching, edge training, edge computing, edge inference, and edge intelligence, respectively.&#34; srcset=&#34;
               /post/edge-intelligence-architectures-challenges-and-applications/fig7_hua19c2d52acf89ac2e81e1fc5855ec49a_51022_e7aa685e71569e05cbaf7f71f21213d8.webp 400w,
               /post/edge-intelligence-architectures-challenges-and-applications/fig7_hua19c2d52acf89ac2e81e1fc5855ec49a_51022_9aaa18ef23d33d3cc985fa91138aa29a.webp 760w,
               /post/edge-intelligence-architectures-challenges-and-applications/fig7_hua19c2d52acf89ac2e81e1fc5855ec49a_51022_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://bowenei.gitee.io/post/edge-intelligence-architectures-challenges-and-applications/fig7_hua19c2d52acf89ac2e81e1fc5855ec49a_51022_e7aa685e71569e05cbaf7f71f21213d8.webp&#34;
               width=&#34;627&#34;
               height=&#34;422&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Fig. 7. Publication volume over time. These curves show the trend of publication volume in edge caching, edge training, edge computing, edge inference, and edge intelligence, respectively.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;blockquote&gt;
&lt;p&gt;In our survey, we identify four key components of edge intelligence, i.e. edge caching, edge training, edge inference, and edge offloading. Edge intelligence shows an explosive developing trend with a huge amount of researcher have been carried out to investigate and realise edge intelligence over the past five years. We count the publication volume of edge intelligence.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;在我们的调研中，我们确定了边缘智能的四个关键组成部分，即边缘缓存、边缘训练、边缘推理和边缘卸载。边缘智能呈现出爆炸式的发展趋势，在过去的五年中，大量的研究者被用来研究和实现边缘智能。我们统计了边缘智能的发布量，如图7所示。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Such prosperity of this research filed owes to the following three reasons.&lt;/p&gt;
&lt;p&gt;First, it is the booming development of intelligent techniques, e.g., deep learning and machine learning techniques that provides a theoretical foundation for the implementation of edge intelligence.&lt;/p&gt;
&lt;p&gt;Second, the increasing big data distributed at the edge, which fuels the performance of edge intelligence.&lt;/p&gt;
&lt;p&gt;Third, the maturing of edge computing systems, and peoples’ increasing demand on smart life facilitate the implementation of edge intelligence.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;作者认为，这一研究领域的繁荣有以下三个原因：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;智能技术的蓬勃发展，例如深度学习和机器学习技术，为边缘智能的实现提供了理论基础。&lt;/li&gt;
&lt;li&gt;分布在边缘的大数据越来越多，这推动了边缘智能的性能。&lt;/li&gt;
&lt;li&gt;边缘计算系统的成熟，以及人们对智能生活需求的增加，促进了边缘智能的实现。&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    至此，本文的概述结束。后面的各大章节 &lt;code&gt;Session&lt;/code&gt; 则是对 &lt;code&gt;Overview&lt;/code&gt; 的扩充，因此我在这里只写每个 &lt;code&gt;Session&lt;/code&gt; 的标题。未来如有详细了解的需要，会继续进行补充。
  &lt;/div&gt;
&lt;/div&gt;

&lt;h2 id=&#34;iii-edge-caching&#34;&gt;III. Edge Caching&lt;/h2&gt;
&lt;h3 id=&#34;a-preliminary-of-caching&#34;&gt;A. Preliminary of Caching&lt;/h3&gt;
&lt;h3 id=&#34;b-cache-deployment&#34;&gt;B. Cache Deployment&lt;/h3&gt;
&lt;h3 id=&#34;c-cache-replacement&#34;&gt;C. Cache Replacement&lt;/h3&gt;
&lt;h2 id=&#34;iv-edge-training&#34;&gt;IV. Edge Training&lt;/h2&gt;
&lt;h3 id=&#34;a-training-architecture&#34;&gt;A. Training Architecture&lt;/h3&gt;
&lt;h3 id=&#34;b-training-acceleration&#34;&gt;B. Training Acceleration&lt;/h3&gt;
&lt;h3 id=&#34;c-training-optimisation&#34;&gt;C. Training Optimisation&lt;/h3&gt;
&lt;h3 id=&#34;d-uncertainty-estimates&#34;&gt;D. Uncertainty Estimates&lt;/h3&gt;
&lt;h3 id=&#34;e-applications&#34;&gt;E. Applications&lt;/h3&gt;
&lt;h2 id=&#34;v-edge-inference&#34;&gt;V. Edge Inference&lt;/h2&gt;
&lt;h3 id=&#34;a-model-design&#34;&gt;A. Model Design&lt;/h3&gt;
&lt;h3 id=&#34;b-model-compression&#34;&gt;B. Model Compression&lt;/h3&gt;
&lt;h3 id=&#34;c-inference-acceleration&#34;&gt;C. Inference Acceleration&lt;/h3&gt;
&lt;h2 id=&#34;vi-edge-offloading&#34;&gt;VI. Edge Offloading&lt;/h2&gt;
&lt;h3 id=&#34;a-d2c-offloading-strategy&#34;&gt;A. D2C Offloading Strategy&lt;/h3&gt;
&lt;h3 id=&#34;b-d2e-offloading-strategy&#34;&gt;B. D2E Offloading Strategy&lt;/h3&gt;
&lt;h3 id=&#34;c-d2d-offloading-strategy&#34;&gt;C. D2D Offloading Strategy&lt;/h3&gt;
&lt;h3 id=&#34;d-hybrid-offloading&#34;&gt;D. Hybrid Offloading&lt;/h3&gt;
&lt;h3 id=&#34;e-applications-1&#34;&gt;E. Applications&lt;/h3&gt;
&lt;h2 id=&#34;vii-future-directions-and-open-challenges&#34;&gt;VII. Future Directions and Open Challenges&lt;/h2&gt;
&lt;h3 id=&#34;a-data-scarcity-at-edge&#34;&gt;A. Data Scarcity at Edge&lt;/h3&gt;
&lt;h3 id=&#34;b-data-consistency-on-edge-devices&#34;&gt;B. Data Consistency on Edge Devices&lt;/h3&gt;
&lt;h3 id=&#34;c-bad-adaptability-of-statically-trained-model&#34;&gt;C. Bad Adaptability of Statically Trained Model&lt;/h3&gt;
&lt;h3 id=&#34;d-privacy-and-security-issues&#34;&gt;D. Privacy and Security Issues&lt;/h3&gt;
&lt;h3 id=&#34;e-incentive-mechanism&#34;&gt;E. Incentive Mechanism&lt;/h3&gt;
&lt;h2 id=&#34;viii-conclusions&#34;&gt;VIII. Conclusions&lt;/h2&gt;</description>
    </item>
    
    <item>
      <title>Classification of Computation Offloading</title>
      <link>https://bowenei.gitee.io/post/classification-of-computation-offloading/</link>
      <pubDate>Mon, 05 Jul 2021 16:59:27 +0800</pubDate>
      <guid>https://bowenei.gitee.io/post/classification-of-computation-offloading/</guid>
      <description>&lt;p&gt;2021年6月23日上午8:30，湖南大学信息科学与工程学院博士生导师&lt;a href=&#34;http://csee.hnu.edu.cn/people/likeqin&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;李克勤&lt;/a&gt;教授在线上做题为《移动边缘计算中任务卸载的博弈论方法》的报告。&lt;/p&gt;
&lt;p&gt;本文将李教授报告中关于边缘计算领域研究的十个维度进行整理。对这十个维度熟悉到一定程度后，任何关于边缘计算的工作我们都可以进行定位。&lt;/p&gt;
&lt;h2 id=&#34;number-of-ues&#34;&gt;Number of UEs&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Single&lt;/li&gt;
&lt;li&gt;Multiple (homogeneous, heterogeneous)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;UEs，即 User Equipments，用户的设备。在论文的场景中，究竟是单用户 &lt;code&gt;signle&lt;/code&gt; 还是多用户 &lt;code&gt;multiple&lt;/code&gt;？如果是多用户，那么用户设备是同构的 &lt;code&gt;homogeneous&lt;/code&gt; 还是异构的 &lt;code&gt;heterogeneous&lt;/code&gt;？&lt;/p&gt;
&lt;h2 id=&#34;number-of-tasks-per-ue&#34;&gt;Number of tasks per UE&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Single/multiple, Finite/infinite&lt;/li&gt;
&lt;li&gt;Independent/precedence constrained&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在论文的场景中，每个用户产生的任务数量是多少？最简单的情况是每个用户只产生一个任务 &lt;code&gt;single&lt;/code&gt;，稍微复杂一些的就是多任务 &lt;code&gt;multiple&lt;/code&gt;。而多任务又可以分为有限 &lt;code&gt;finite&lt;/code&gt; 个任务和无限 &lt;code&gt;infinite&lt;/code&gt; 个任务。而无限个任务就是一个任务流 &lt;code&gt;task flow&lt;/code&gt;，我们就需要用到排队论的知识。&lt;/p&gt;
&lt;p&gt;任务之间可能没有任何依赖关系，或者说是独立的 &lt;code&gt;independent&lt;/code&gt;；但也有可能彼此之间是有先后次序的，或者说具有优先级约束 &lt;code&gt;precedence constrained&lt;/code&gt;。&lt;/p&gt;
&lt;h2 id=&#34;number-of-mecs&#34;&gt;Number of MECs&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Single&lt;/li&gt;
&lt;li&gt;Multiple (homogeneous, heterogeneous)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;MECs，即 Mobile Edge Clouds，移动边缘云，简单来说就是边缘服务器。同理，它也可以分为单个边缘服务器 &lt;code&gt;single&lt;/code&gt; 和多个边缘服务器 &lt;code&gt;multiple&lt;/code&gt;。而多个边缘服务器同样也涉及到同构 &lt;code&gt;homogeneous&lt;/code&gt; 和异构 &lt;code&gt;heterogeneous&lt;/code&gt; 的问题。&lt;/p&gt;
&lt;h2 id=&#34;type-of-ue-and-mec&#34;&gt;Type of UE and MEC&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Uni-server (M/M/1, M/G/1, G/G/1)&lt;/li&gt;
&lt;li&gt;Multi-server (M/M/m, M/G/m, G/G/m)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;所谓的用户设备并不是一个被动设备，它其实是有处理能力的。因此，从某种意义上说，用户设备也是一个服务器。排队论已经告诉我们如何对服务器进行建模。针对单核服务器 &lt;code&gt;uni-server&lt;/code&gt;，我们可以建模成 M/M/1、M/G/1 或者 G/G/1 问题；针对多核服务器（边缘服务器通常都是多核服务器），我们可以建模成 M/M/m、M/G/m 或者 G/G/m 问题。&lt;/p&gt;
&lt;h2 id=&#34;modeling-of-ue-and-mec&#34;&gt;Modeling of UE and MEC&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Deterministic&lt;/li&gt;
&lt;li&gt;Probabilistic&lt;/li&gt;
&lt;li&gt;Stochastic (queuing model)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;针对用户设备和边缘服务器的数学建模主要有三种：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;确定型。例如组合优化，要求每个任务的执行时间是一个已知的量。&lt;/li&gt;
&lt;li&gt;概率型。任务执行时间是一个随机变量&lt;/li&gt;
&lt;li&gt;统计型。例如排队论模型。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;variables-to-control&#34;&gt;Variables to control&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Offloading strategy (load distribution)&lt;/li&gt;
&lt;li&gt;Computation speed (CPU frequency)&lt;/li&gt;
&lt;li&gt;Communication speed (transmission power)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;可控变量，即哪些变量是可以调节的。&lt;/p&gt;
&lt;p&gt;首先就是任务卸载策略 &lt;code&gt;offloading strategy&lt;/code&gt;。任务到底卸不卸载？如果卸载，卸载到哪里去？如果有多个服务器，还涉及到负载均衡 &lt;code&gt;load distribution&lt;/code&gt; 的问题。&lt;/p&gt;
&lt;p&gt;其次是设备本身的计算速度 &lt;code&gt;computation speed&lt;/code&gt;，或者说 CPU 的主频 &lt;code&gt;frequency&lt;/code&gt;。计算速度如果快，那么能耗就会大。因此，计算速度和能耗需要进行平衡。不过，边缘服务器的计算机速度是不可调的，每个用户只能调节他自己设备的计算速度。&lt;/p&gt;
&lt;p&gt;最后是通讯速度 &lt;code&gt;communication speed&lt;/code&gt;，这个也可以调节。通讯速度主要取决于发射功率。发射功率越大，能耗也越大，这也需要进行平衡。&lt;/p&gt;
&lt;h2 id=&#34;metric&#34;&gt;Metric&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Performance (execution delay, response time)&lt;/li&gt;
&lt;li&gt;Cost (power consumption, energy consumption)&lt;/li&gt;
&lt;li&gt;Other (number of tasks completed)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;度量方法主要分为性能和开销两大类，也有其他的一些方法。&lt;/p&gt;
&lt;p&gt;具体来说，从性能角度看，主要有任务执行时延 &lt;code&gt;execution delay&lt;/code&gt; 和任务响应时延 &lt;code&gt;response time&lt;/code&gt; 两个指标。&lt;/p&gt;
&lt;p&gt;从开销角度看，主要有功耗 &lt;code&gt;power consumption&lt;/code&gt; 和能耗 &lt;code&gt;energy consumption&lt;/code&gt; 两个指标。&lt;/p&gt;
&lt;p&gt;性能和开销是两大最重要的度量方法，当然还有一些其他的度量方式。例如，已完成的任务数 &lt;code&gt;number of tasks completed&lt;/code&gt; 等。&lt;/p&gt;
&lt;h2 id=&#34;performance-cost-tradeoff&#34;&gt;Performance-cost tradeoff&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Cost constrained performance optimization&lt;/li&gt;
&lt;li&gt;Performance constrained cost optimization&lt;/li&gt;
&lt;li&gt;Joint performance and cost (multi-objective) optimization&lt;/li&gt;
&lt;li&gt;Combined performance and cost (weighted sum, cost-performance ratio) optimization&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;李教授认为，性能和开销的平衡是所有的服务计算（网格计算、分布式计算、集群计算、云计算、雾计算、边缘计算等）里面的重要问题，而且是鱼和熊掌不可兼得的。&lt;/p&gt;
&lt;p&gt;我们应该怎样去研究呢？例如，在一定开销的约束下优化性能 &lt;code&gt;cost constrained performance optimization&lt;/code&gt;，或者倒过来，在一定性能的约束下优化开销 &lt;code&gt;performance constrained cost optimization&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;还有一种方法，就是综合考虑这两种指标，这就涉及到多目标 &lt;code&gt;multi-objective&lt;/code&gt; 优化。也可以把这两种指标结合 &lt;code&gt;combined&lt;/code&gt; 起来，转化成单目标优化。例如加权求和 &lt;code&gt;weighted sum&lt;/code&gt;，或者求性价比 &lt;code&gt; cost-performance ratio&lt;/code&gt;。&lt;/p&gt;
&lt;h2 id=&#34;optimization&#34;&gt;Optimization&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Globalized, collective, and centralized optimization for all UEs&lt;/li&gt;
&lt;li&gt;Localized, individualized, and distributed optimization for each UE (non-cooperative game)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;优化方法主要分为两大类：一种是整体的、中心式的优化，它是针对所有用户的优化；还有一种是局部的、个性化的、分布式的优化，它是为每个用户量身定制的优化。李教授认为，这和非合作博弈 &lt;code&gt;non-cooperative game&lt;/code&gt; 非常类似。&lt;/p&gt;
&lt;h2 id=&#34;technique&#34;&gt;Technique&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Discrete and combinatorial (NP-hard, heuristics)&lt;/li&gt;
&lt;li&gt;Continuous and probabilistic (Lyapunov optimization)&lt;/li&gt;
&lt;li&gt;Continuous and stochastic (multi-variable optimization)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;优化的具体的技术和方法主要有以下几种：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;离散和组合型变量优化。这种方法一般适用于解决 NP 难问题，启发式 &lt;code&gt;heuristics&lt;/code&gt; 算法非常适合解决这种 NP 难问题。&lt;/li&gt;
&lt;li&gt;连续和概率型变量优化。李亚普诺夫优化是近几年来比较热门的方法之一。&lt;/li&gt;
&lt;li&gt;连续和统计型变量优化。即通过排队论将问题建模成传统的多变量优化问题。&lt;/li&gt;
&lt;/ol&gt;</description>
    </item>
    
    <item>
      <title>How to Read a Paper</title>
      <link>https://bowenei.gitee.io/post/how-to-read-a-paper/</link>
      <pubDate>Tue, 29 Jun 2021 15:28:16 +0800</pubDate>
      <guid>https://bowenei.gitee.io/post/how-to-read-a-paper/</guid>
      <description>&lt;p&gt;这是 2007 年发表在 SIGCOMM 上的一篇文章，作者提出了文献的三遍阅读法，并且介绍了如何利用这种方法做文献调研。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://dl.acm.org/doi/abs/10.1145/1273445.1273458&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;原文链接&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;摘要&#34;&gt;摘要&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;Researchers spend a great deal of time reading research papers. However, this skill is rarely taught, leading to much wasted effort. This article outlines a practical and efficient three-pass method for reading research papers. I also describe how to use this method to do a literature survey.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;作者认为研究人员花了很多时间阅读文献，但是缺少文献阅读方法的指导，很多时候都是在白白努力。作者在本文中概述了一种阅读科研论文实用而有效的三遍 &lt;code&gt;three-pass&lt;/code&gt; 方法，还描述了如何使用这种方法进行文献调研。&lt;/p&gt;
&lt;h2 id=&#34;介绍&#34;&gt;介绍&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;Researchers must read papers for several reasons: to review them for a conference or a class, to keep current in their field, or for a literature survey of a new field. A typical researcher will likely spend hundreds of hours every year reading papers.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;这段话作者主要讲了研究人员阅读文献的目的，作者认为典型的研究人员每年都会花费数百小时阅读论文。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Learning to efficiently read a paper is a critical but rarely taught skill. Beginning graduate students, therefore, must learn on their own using trial and error. Students waste much effort in the process and are frequently driven to rustration.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;作者认为学会有效阅读文献是一个关键的技能，但是很少会有人来教这些技能。因此，研究生在刚刚开始科研时必须通过试错的方式来学习，浪费了很多精力。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;For many years I have used a simple approach to efficiently read papers. This paper describes the ‘three-pass’ approach and its use in doing a literature survey.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;于是作者引出本文的工作：文献的三遍阅读法，以及如何使用这种方法进行文献调研。&lt;/p&gt;
&lt;h2 id=&#34;文献的三遍阅读法&#34;&gt;文献的三遍阅读法&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;The key idea is that you should read the paper in up to three passes, instead of starting at the beginning and plowing our way to the end. Each pass accomplishes specific goals and builds upon the previous pass: The first pass gives you a general idea about the paper. The second pass lets you grasp the paper’s content, but not its details. The third pass helps you understand the paper in depth.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;作者认为，不能简单从头到尾阅读文献。文献的三遍阅读法的关键在于，每一遍阅读都会完成特定的目标，并且建立在上一遍阅读收获的基础之上。第一遍阅读需要了解论文的大致想法 &lt;code&gt;general idea&lt;/code&gt;；第二遍阅读需要掌握论文的内容 &lt;code&gt;content&lt;/code&gt;，但不是细枝末节；第三遍阅读需要深入了解论文。&lt;/p&gt;
&lt;h3 id=&#34;第一遍阅读&#34;&gt;第一遍阅读&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;The first pass is a quick scan to get a bird’s-eye view of the paper. You can also decide whether you need to do any more passes. This pass should take about five to ten minutes and consists of the following steps:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Carefully read the title, abstract, and introduction&lt;/li&gt;
&lt;li&gt;Read the section and sub-section headings, but ignore everything else&lt;/li&gt;
&lt;li&gt;Read the conclusions&lt;/li&gt;
&lt;li&gt;Glance over the references, mentally ticking off the ones you’ve already read&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;p&gt;作者认为第一遍阅读文献需要快速扫描，以对论文有一个全局的把控（作者打了一个形象的比喻：鸟瞰图 &lt;code&gt;bird’s-eye view&lt;/code&gt;）。然后我们就可以决定是否还需要继续进行下一遍的阅读。这大概只需要 5 到 10 分钟，包括以下步骤：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;仔细阅读标题，摘要和介绍&lt;/li&gt;
&lt;li&gt;阅读每个部分 &lt;code&gt;section&lt;/code&gt; 的标题和子标题，但忽略其他所有内容&lt;/li&gt;
&lt;li&gt;阅读结论&lt;/li&gt;
&lt;li&gt;浏览参考文献，在大脑中勾结 &lt;code&gt;ticking off&lt;/code&gt; 你已经读过的那些文献&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;At the end of the first pass, you should be able to answer the five Cs:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Category: What type of paper is this? A measurement paper? An analysis of an existing system? A description of a research prototype?&lt;/li&gt;
&lt;li&gt;Context: Which other papers is it related to? Which theoretical bases were used to analyze the problem?&lt;/li&gt;
&lt;li&gt;Correctness: Do the assumptions appear to be valid?&lt;/li&gt;
&lt;li&gt;Contributions: What are the paper’s main contributions?&lt;/li&gt;
&lt;li&gt;Clarity: Is the paper well written?&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;p&gt;文献阅读的第一遍阅读完成后，你必须能够回答下面的 5 个问题：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;类别&lt;/strong&gt;：这是什么类型的论文？测量方法的论文？对现有系统的分析？研究原型的描述？&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;背景&lt;/strong&gt;：它与其他哪些文献有关？它是基于哪些理论去分析问题的？&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;正确性&lt;/strong&gt;：论文的假设合理吗？&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;贡献&lt;/strong&gt;：论文的主要贡献是什么？&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;清晰度&lt;/strong&gt;：论文写得好吗？&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;Using this information, you may choose not to read further. This could be because the paper doesn’t interest you, or you don’t know enough about the area to understand the paper, or that the authors make invalid assumptions. The first pass is adequate for papers that aren’t in your research area, but may someday prove relevant.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;有了这些信息，我们可以选择不再继续阅读。这主要有三个原因：对这篇论文不感兴趣，对涉及到的研究领域不了解，作者作出无效假设。对于不了解的研究领域，只读一遍足够了，但是可能有一天你会发现它和你的研究领域相关。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Incidentally, when you write a paper, you can expect most reviewers (and readers) to make only one pass over it. Take care to choose coherent section and subsection titles and to write concise and comprehensive abstracts. If a reviewer cannot understand the gist after one pass, the paper will likely be rejected; if a reader cannot understand the highlights of the paper after five minutes, the paper will likely never be read.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;作者还建议，当您撰写论文时，您可以期待大多数审阅者（和读者）只需要阅读一遍就能掌握上述信息。因此，注意每个部分的标题和子标题的相关性，并且摘要要简洁而全面。如果审阅者在阅读一遍后无法理解论文的要点，那么该论文可能会被拒绝; 如果读者在五分钟后无法理解论文的亮点，则可能永远不会再读这篇论文。&lt;/p&gt;
&lt;h3 id=&#34;第二遍阅读&#34;&gt;第二遍阅读&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;In the second pass, read the paper with greater care, but ignore details such as proofs. It helps to jot down the key points, or to make comments in the margins, as you read.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Look carefully at the figures, diagrams and other illustrations in the paper. Pay special attention to graphs. Are the axes properly labeled? Are results shown with error bars, so that conclusions are statistically significant? Common mistakes like these will separate rushed, shoddy work from the truly excellent.&lt;/li&gt;
&lt;li&gt;Remember to mark relevant unread references for further reading (this is a good way to learn more about the background of the paper).&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;p&gt;作者认为第二遍阅读文献需要仔细阅读，但是应该忽略掉细节部分，例如证明。在阅读时记下要点或在页边空白处作注释会有所帮助。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;仔细看文章中的图形、图表和其他插图。特别注意图表。坐标轴标记正确了吗？结果是否以误差条显示，从而使结论具有统计学意义？类似这样的常见错误会将匆忙的粗制滥造的工作与真正优秀的工作区分开来。&lt;/li&gt;
&lt;li&gt;记住标记相关的未读参考文献以供进一步阅读（这是了解更多关于论文背景的好方法）。&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;The second pass should take up to an hour. After this pass, you should be able to grasp the content of the paper. You should be able to summarize the main thrust of the paper, with supporting evidence, to someone else. This level of detail is appropriate for a paper in which you are interested, but does not lie in your research speciality.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;作者认为，第二遍阅读要花一个小时。经过这样一遍阅读，你应该能够掌握论文的内容。你应该能够将论文的主旨和支持性证据总结给其他人。这个层次的细节适合你感兴趣的论文，但不属于你的研究专业。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Sometimes you won’t understand a paper even at the end of the second pass. This may be because the subject matter is new to you, with unfamiliar terminology and acronyms. Or the authors may use a proof or experimental technique that you don’t understand, so that the bulk of the paper is incomprehensible. The paper may be poorly written with unsubstantiated assertions and numerous forward references. Or it could just be that it’s late at night and you’re tired. You can now choose to: (a) set the paper aside, hoping you don’t need to understand the material to be successful in your career, (b) return to the paper later, perhaps after reading background material or (c) persevere and go on to the third pass.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;有时你甚至在第二遍结束时也看不懂一篇论文。这可能是因为主题 &lt;code&gt;subject matter&lt;/code&gt; 对您来说是新的，具有不熟悉的术语和首字母缩写。或者，作者可能会使用你不理解的证明或实验技术，所以论文的大部分内容是无法理解的。论文可能写得很差，没有证据的断言和大量的前向参考文献。也可能是深夜，你很累。现在你可以选择:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;把论文放在一边，希望你不需要理解这些材料就能在学术生涯中取得成功；&lt;/li&gt;
&lt;li&gt;在阅读背景材料后再重新阅读论文；&lt;/li&gt;
&lt;li&gt;坚持下去，继续第三遍阅读。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;第三遍阅读&#34;&gt;第三遍阅读&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;To fully understand a paper, particularly if you are reviewer, requires a third pass. The key to the third pass is to attempt to virtually re-implement the paper: that is, making the same assumptions as the authors, re-create the work. By comparing this re-creation with the actual paper, you can easily identify not only a paper’s innovations, but also its hidden failings and assumptions.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;作者认为，要完全理解一篇论文，尤其是当你是审稿人的时候，需要第三遍阅读。第三遍阅读的关键是尝试重新实现 &lt;code&gt;virtually re-implement&lt;/code&gt; 论文：即，做出与作者相同的假设，复现 &lt;code&gt;re-create&lt;/code&gt; 论文工作（这里作者用副词 &lt;code&gt;virtually&lt;/code&gt; 修饰，是想表达这个复现是你头脑的想法，可能与作者本人的想法有出入）。通过将复现的工作 &lt;code&gt;re-creation&lt;/code&gt; 与实际论文进行比较，你可以很容易地识别出论文的创新之处，以及它隐藏的缺点和假设。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;This pass requires great attention to detail. You should identify and challenge every assumption in every statement. Moreover, you should think about how you yourself would present a particular idea. This comparison of the actual with the virtual lends a sharp insight into the proof and presentation techniques in the paper and you can very likely add this to your repertoire of tools. During this pass, you should also jot down ideas for future work.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;这一遍阅读需要非常注意细节。你应该识别并挑战每句话中的每一个假设。此外，你应该考虑自己将如何表达一个特定的想法。这种实际 &lt;code&gt;actual&lt;/code&gt;（这里作者的意思是论文的实际表述）与虚拟 &lt;code&gt;virtual&lt;/code&gt;（这里作者的意思是你头脑里所想的表达的方式）的比较有助于深入了解本文中的证明和表示技术，您很可能将其添加到您的工具库中。在此期间，你还应该记下未来工作的想法。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;This pass can take about four or five hours for beginners, and about an hour for an experienced reader. At the end of this pass, you should be able to reconstruct the entire structure of the paper from memory, as well as be able to identify its strong and weak points. In particular, you should be able to pinpoint implicit assumptions, missing citations to relevant work, and potential issues with experimental or analytical techniques.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;对于初学者来说，这一遍阅读大约需要 4 到 5 个小时，而对于有经验的读者来说，大约需要 1 个小时。在这一段的最后，你应该能够根据记忆重建整个论文结构，以及能够识别它的优点和缺点。特别是，您应该能够精确地指出隐含的假设、相关工作的遗漏引用，以及与实验或分析技术有关的潜在问题。&lt;/p&gt;
&lt;h2 id=&#34;做文献调研&#34;&gt;做文献调研&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;Paper reading skills are put to the test in doing a literature survey. This will require you to read tens of papers, perhaps in an unfamiliar field. What papers should you read? Here is how you can use the three-pass approach to help.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;做文献调研时非常考验一个人的文献阅读技巧。这一般需要你阅读几十篇论文，而且也许是一个不熟悉的领域。那么，你应该读哪些文献？作者就指出如何使用他在本文提出的文献的三遍阅读法来帮助我们进行文献调研。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;First, use an academic search engine such as Google Scholar or CiteSeer and some well-chosen keywords to find three to five recent papers in the area. Do one pass on each paper to get a sense of the work, then read their related work sections. You will find a thumbnail summary of the recent work, and perhaps, if you are lucky, a pointer to a recent survey paper. If you can find such a survey, you are done. Read the survey, congratulating yourself on your good luck.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;首先，使用学术搜索引擎（如谷歌学术或 CiteSeer）和一些精心挑选的关键词，找到该领域的三到五篇最新论文。每一篇论文都进行一遍阅读，了解一下这篇论文的工作，然后阅读相关工作部分。你会找到最近工作的缩略摘要，如果你幸运的话，可能还会找到最近调研的论文。如果你能找到这样的论文，应该为自己的好运气而庆幸。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Otherwise, in the second step, find shared citations and repeated author names in the bibliography. These are the key papers and researchers in that area. Download the key papers and set them aside. Then go to the websites of the key researchers and see where they’ve published recently. That will help you identify the top conferences in that field because the best researchers usually publish in the top conferences.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;如果找不到，在第二步中，我们可以在参考书目中找到共享的引文 &lt;code&gt;shared citations&lt;/code&gt; 和重复的作者名称。这些是该领域的关键论文和研究人员。下载关键的论文并把它们放在一边。然后访问主要研究人员的网站，看看他们最近在哪里发表的文章。这将帮助你确定该领域的顶级会议，因为最优秀的研究人员通常在顶级会议上发表文章。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The third step is to go to the website for these top conferences and look through their recent proceedings. A quick scan will usually identify recent high-quality related work. These papers, along with the ones you set aside earlier, constitute the first version of your survey. Make two passes through these papers. If they all cite a key paper that you did not find earlier, obtain and read it, iterating as necessary.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;第三步是访问这些顶级会议 &lt;code&gt;top conferences&lt;/code&gt; 的网站，查看它们最近的会议记录。快速扫描通常可以识别出近期高质量的相关工作。这些论文，连同你之前搁置的那些，构成了你调查的第一个版本。把这些论文翻两遍。如果他们都引用了一篇你之前没有找到的关键论文，获取并阅读它，必要时进行迭代。&lt;/p&gt;
&lt;h2 id=&#34;经验&#34;&gt;经验&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;I’ve used this approach for the last 15 years to read conference proceedings, write reviews, do background research, and to quickly review papers before a discussion. This disciplined approach prevents me from drowning in the details before getting a bird’s-eye-view. It allows me to estimate the amount of time required to review a set of papers. Moreover, I can adjust the depth of paper evaluation depending on my needs and how much time I have.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;作者在过去的 15 年里，一直使用这种方法来阅读会议记录、撰写评论、做背景研究，以及在讨论前快速审阅论文。这种有规律的方法能够防止在把握全文之前就被细节淹没。它可以估算出回顾一系列论文所需的时间。此外，作者可以根据自己的需要和时间来调整论文评估的深度。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>“不忘初心 一生一誓”——毕业生党员交流会</title>
      <link>https://bowenei.gitee.io/post/a-lifetime-a-oath/</link>
      <pubDate>Thu, 24 Jun 2021 20:05:06 +0800</pubDate>
      <guid>https://bowenei.gitee.io/post/a-lifetime-a-oath/</guid>
      <description>&lt;p&gt;2021年6月24日，安徽大学计算机科学与技术学院本科生党支部开展了以“不忘初心 一生一誓”为主题的毕业生党员交流会活动。&lt;/p&gt;
&lt;p&gt;交流会上，每位党员重温入党誓词，面对党旗庄严宣誓。各位学生党员积极发言，感悟四年来的学习与收获。辅导员老师给予同学们祝福和寄语，葛大圣老师即兴作诗一首。蒋伟书记最后做了总结，给全体党员寄语。&lt;/p&gt;
&lt;p&gt;尊敬的各位领导、老师、党员同志们：&lt;/p&gt;
&lt;p&gt;大家下午好！在这个收获满满的六月，很荣幸我能够作为计算机科学与技术学院2017级毕业生党员的一员在此发言。&lt;/p&gt;
&lt;p&gt;四年的大学时光如白驹过隙，转瞬即逝。四年前的那个暑假一次偶然的机会，我接触到计算机编程和软件开发，产生了浓厚的兴趣。大一开学后，我比过去任何一个阶段都更加注重基础知识的学习，尤其是《高等数学》，因为我知道，数学是包括计算机在内的所有理工科的基础。&lt;/p&gt;
&lt;p&gt;开学后不久，我听说了学校关于转专业的政策。从那时起，我将转入计算机专业作为我的首要目标，自学《C语言程序设计》、《数据结构》等专业核心课程。大一下学期，我终于如愿以偿，成功通过了转专业考试。随后不久，我向党组织递交了入党申请书。&lt;/p&gt;
&lt;p&gt;新学年伊始，我进入安徽大学智能软件与边缘计算实验室，从此正式踏上了科研生涯的第一步。时任计算机科学与技术学院副院长李学俊老师作为我的导师，在科研方面给了我许多耐心的指导，并且安排一位研究生和我一起合作开展科研。在科研工作的初期，我们在实验室刚刚涉足的领域开展了大量的文献调研，我的师兄形成了很多自己的见解与我分享，这使我受益良多。我运用自己的代码能力将师兄的想法变成现实。在实验结果与设想有所出入的情况下，我认真分析并寻找原因。最终，我们小组的科研论文被CCF A类会议ASE 2020录用。&lt;/p&gt;
&lt;p&gt;大学四年我不仅在科研成果上收获颇丰，在学业上也没有丝毫放松。我在大二一个学年快速补上了大一落下的公共基础课和专业核心课，大二大三学年度平均学分绩点一直在班级名列前茅。在思想方面，我积极向党组织靠拢。被列入入党积极分子后，我积极参加党课学习，抄写党章，对党的理论有了基本了解。我还十分关心国家大事，关注国际局势，就中美贸易战、香港修例风波、台海局势等以书面形式向党组织做了思想汇报。在保研夏令营中，我积极推荐自己，最终被东南大学计算机科学与工程学院录取为直博生。&lt;/p&gt;
&lt;p&gt;在两年多的考察期中，我用实际行动和积极表现向党组织证明，我达到了加入中国共产党的要求。成为预备党员以后，我没有辜负党组织对我的教育和培养，继续以更高的标准严格要求自己。保研拟录取之后，我按照实验室的规章制度每个工作日依然坚持来到理工D楼学习和科研，与师兄师姐们一同交流心得与收获，和东南大学那边的课题组线上交流。在学习和科研之余，我还在网络上系统地学习了马克思主义哲学、马克思主义政治经济学、科学社会主义理论，用辩证唯物主义和历史唯物主义树立共产主义世界观。我还用毛泽东思想武装头脑，阅读《毛泽东选集》中脍炙人口的名篇，例如《矛盾论》、《实践论》、《论持久战》等。我积极向我的同学和朋友甚至包括家人宣传马克思主义，并且将我的学习笔记放在我搭建的个人博客上。&lt;/p&gt;
&lt;p&gt;百年大党正青春，风华正茂再启航。一周之后的今天，我们就要迎来庆祝中国共产党成立100周年的盛大纪念日。可谁曾想到，100年前她还是只是南湖上漂泊的一艘小船。从南昌起义到秋收起义，中国共产党在万里长征中走出来的是中华民族的信仰；从中华民族的抗日战争到解放战争，中国共产党在抗美援朝中打出来的是中华民族的尊严；从一五计划到改革开放，中国共产党在全面小康中建设出来的是中华民族的富强；从两弹一星到航空航天，中国共产党在中国空间站中创造出来的是中华民族的智慧；从和平共处五项原则到人类命运共同体，中国共产党在中国特色大国外交中展现的是中华民族的包容。这艘小船现如今已经发展成拥有9000多万名党员的百年大党，作为中国人，特别是作为中国共产党预备党员，我无比自豪！&lt;/p&gt;
&lt;p&gt;习近平总书记指出，当今世界正面临百年未有之大变局。2016年，美帝国主义炮制的所谓“南海仲裁案”侵犯中国主权，严重损害中国利益。2018年，美帝国主义单方面对华挑起贸易战，进而发动对中兴、华为的科技战。2019年，美帝国主义与台独、港独分子狼狈为奸，挑起香港修例风波，对华舆论战愈演愈烈。2020年，印度军队在中印边界发起了蓄谋已久的挑衅，悍然越过边界侵犯中国主权。美帝国主义对我国发动大规模的金融战的可能性依然存在，新冠肺炎疫情使得全球经济危机、金融危机爆发的可能性正在变大。毛主席曾经说过，在战略上要藐视敌人，在战术上要重视敌人。作为新时代的青年，我们要明白美帝国主义是纸老虎这一深刻道理，但同时也不要忘记周总理伟大理想——为中华之崛起而读书。实现中华民族伟大复兴的中国梦，建设社会主义现代化强国的光荣使命落在我们身上。&lt;/p&gt;
&lt;p&gt;邓小平同志曾经指出，科学技术是第一生产力。作为即将入学的博士生，我深知自己更应该挑起科技创新的重担，在计算机网络与分布式计算领域贡献属于自己的一份力量。&lt;/p&gt;
&lt;p&gt;最后，我想引用无产阶级伟大导师马克思中学毕业论文当中的一段话作为结尾，与各位同志共勉：&lt;/p&gt;
&lt;p&gt;如果我们选择了最能为人类而工作的职业，那么，重担就不能把我们压倒，因为这是为大家作出的牺牲；那时我们所享受的就不是可怜的、有限的、自私的乐趣，我们的幸福将属于千百万人，我们的事业将悄然无声地存在下去，但是它会永远发挥作用，而面对我们的骨灰，高尚的人们将洒下热泪。&lt;/p&gt;
&lt;p&gt;谢谢大家！&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>挑战2021年高考数学全国Ⅰ卷压轴大题</title>
      <link>https://bowenei.gitee.io/post/college-entrance-examination-2021-mathematics/</link>
      <pubDate>Wed, 09 Jun 2021 12:29:21 +0800</pubDate>
      <guid>https://bowenei.gitee.io/post/college-entrance-examination-2021-mathematics/</guid>
      <description>&lt;p&gt;2021年高考已落下帷幕，转眼间大学即将毕业。回想当年高考解析几何和导数两个压轴大题没能拿到满分，内心感到非常遗憾。因此，今天我将重新来到高考的古战场，再战解几导数大题。&lt;/p&gt;
&lt;p&gt;每年高考全国Ⅰ卷数学的题型分布都会有小幅变化。过去，一般解析几何是第20题（倒数第二题，不含选做题），导数是第21题（压轴大题）。今年，解析几何成为压轴大题，导数则是倒数第二题。这究竟会带来怎样的变化？下面我们逐一来看这两题。&lt;/p&gt;
&lt;h2 id=&#34;导数&#34;&gt;导数&lt;/h2&gt;
&lt;p&gt;设函数 $f(x) = \ln (a-x)$，已知 $x = 0$ 是函数 $y = xf(x)$ 的极值点。&lt;/p&gt;
&lt;p&gt;(1) 求 $a$；&lt;/p&gt;
&lt;p&gt;(2) 设函数 $g(x) = \frac{x+f(x)}{xf(x)} $，证明 $g(x) &amp;lt; 1$。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;解&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;第(1)小题，我们可以根据题干当中的已知条件，通过极值点的性质列关于 $a$ 的方程，即可反解出 $a$。首先，我们对 $y$ 求导：&lt;/p&gt;

$$
\begin{align}
y&#39; &amp;= f(x) + xf&#39;(x) \\\\
&amp;= \ln (a-x)-\frac{x}{a-x}
\end{align}
$$

&lt;p&gt;然后，我们令 $x = 0$，$y&amp;rsquo; = 0$，即可反解出 $a$：&lt;/p&gt;

$$
\begin{align}
\ln a = 0\\\\
\Rightarrow a = 1
\end{align}
$$

&lt;p&gt;第(2)小题，如果直接对 $g(x)$ 求导，分母是幂函数和对数函数的复合函数，而且求导后在分子上会出现二次，计算量极其巨大。因此，去分母是本题的关键。&lt;/p&gt;
&lt;p&gt;历年来的全国卷导数题都有这样一个特点：第(1)小题的结论可以在第(2)小题当中使用。我们做完第(1)小题后，其实只是求出了一个未知参数，没有得到某一个具体函数的性质。这个时候，我们来观察第(2)小题当中的目标函数 $g(x)$。我们发现，$g(x)$ 的分母恰好是函数 $y$。因此，研究函数 $y$ 是非常有必要的。&lt;/p&gt;
&lt;p&gt;另一方面，第(2)小题让我们证明一个不等式，而不是等式。因此，我们要想直接去掉分母比较困难。如果分母是恒正或恒负，能够大大降低我们的计算量，方便我们解题。所以，我们期望函数 $y$ 的值域应当恒正或恒负。即使不是，我们也可以在不同的区间上讨论。&lt;/p&gt;
&lt;p&gt;由(1)可知：$f(x) = \ln (1-x)$，那么 $y = x\ln (1-x)$。显然，它们的定义域都是 $(-\infty, 1)$。根据(1)的求导结果，我们可以很容易写出 $y&amp;rsquo;$ 的解析式：&lt;/p&gt;

$$
y&#39; = \ln (1-x)+\frac{x}{x-1}
$$

&lt;p&gt;解析式还存在对数函数，很难一眼看出单调性。但是对数函数求导一次就能变成分式，因此我们对函数 $y$ 求二阶导数：&lt;/p&gt;

$$
\begin{align}
y&#39;&#39; &amp;= \frac{1}{x-1} - \frac{1}{(x-1)^2} \\\\
&amp;= \frac{x-2}{(x-1)^2}
\end{align}
$$

&lt;p&gt;由于函数 $y$ 的定义域是 $(-\infty, 1)$，显然 $y&amp;rsquo;&amp;rsquo; &amp;lt; 0$，$y&amp;rsquo;$ 在定义域内单调递减。而 $x = 0$ 是 $y$ 的极值点，也就是 $y&amp;rsquo;$ 的零点。故 $y$ 在 $(-\infty, 0)$ 上单调递增，在$(0, 1)$ 上单调递减。因此我们可以判断：&lt;/p&gt;

$$
y &lt; y(0) = 0
$$

&lt;p&gt;这是一个非常漂亮的结论：$g(x)$ 的分母是恒负的。因此，要证 $g(x) &amp;lt; 1$，只需证 $x + f(x) &amp;gt; xf(x)$。于是我们令 $h(x) = x + f(x) - xf(x)$，并对其求导：&lt;/p&gt;

$$
h&#39;(x) = 1 - \frac{1}{1-x} - \ln (1-x) + \frac{x}{1-x}
$$

&lt;p&gt;解析式当中还含有对数函数，我们需要求二阶导数，才能把对数消掉：&lt;/p&gt;

$$
\begin{align}
h&#39;&#39;(x) &amp;= - \frac{1}{(x-1)^2} + \frac{1}{1-x} + \frac{1}{(x-1)^2} \\\\
&amp;= \frac{1}{1-x} &gt; 0
\end{align}
$$

&lt;p&gt;因此，$h&amp;rsquo;(x)$ 在定义域内单调递增。而 $h&amp;rsquo;(0) = 0$，故 $h(x)$ 在 $(-\infty, 0)$ 上单调递减，在 $(0, 1)$ 上单调递增。因此，我们可以判断：&lt;/p&gt;

$$
h(x) &gt; h(0) = 0
$$

&lt;p&gt;证毕。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;总结&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;作为倒数第二题，本题难度适中。本题的关键就在于去分母，而去分母的思路来源于第(1)小题。如果不去分母，计算量极其巨大。本题没有涉及到分类讨论，与过去全国Ⅰ卷的导数题相比难度较小。&lt;/p&gt;
&lt;h2 id=&#34;解析几何&#34;&gt;解析几何&lt;/h2&gt;
&lt;p&gt;已知抛物线 $C$: $x^2 = 2py (p&amp;gt;0)$ 的焦点为 $F$，且 $F$ 与圆 $M$: $x^2 + (y+4)^2 = 1$ 上点的距离最小值为 $4$。&lt;/p&gt;
&lt;p&gt;(1) 求 $p$；&lt;/p&gt;
&lt;p&gt;(2) 若点 $P$ 在圆 $M$ 上，$PA$、$PB$ 是抛物线 $C$ 的两条切线，$A$、$B$ 为切点，求 $\triangle PAB$ 面积的最大值。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;解&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;第(1)小问需要求解焦准距 $p$，依题意，抛物线开口向上，小圆圆心在 $y$ 负半轴上。显然，抛物线焦点到圆顶部 $(0, -3)$ 的距离最小。我们可以列出下面这个简单方程求解：&lt;/p&gt;

$$
\begin{align}
\frac{p}{2} - (-4+1) &amp;= 4 \\\\
\Rightarrow p &amp;= 2
\end{align}
$$

&lt;p&gt;重点来看第(2)小问。题型很常规，题目也非常易懂，就是求解三角形面积的最值问题。我们首先来梳理一下，三角形面积求解的主要方法：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;$S = \frac{1}{2}ah$。在解析几何中，我们通常需要先求出一条直线的方程，然后才能求直线上的线段长以及点到直线的距离。&lt;/li&gt;
&lt;li&gt;$S = \frac{1}{2}ab\sin\theta$。常见于平面几何解三角形，但是在解析几何中，该方法较少使用。原因在于，在解析几何中，一个角的正切值相对好求，可以用斜率的几何意义加上三角恒等变换中的两角正切差公式求出，但是由正切求正弦非常困难。余弦定理虽然可以求出余弦，但是计算量特别大，而正弦定理并不能求出一个角的正弦。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;经过上述分析，我们明确，本题求解三角形面积应当采用第1种方法。那么，谁作底边，谁作顶点？很明显，动点 $P$ 是一定要作为顶点的，因为它是主动点。切点 $A$、$B$ 是从动点，它们是随着 $P$ 点的运动而运动的。这样，直线 $AB$ 就成了三角形底边所在直线。至此，我们的思路已基本明确。&lt;/p&gt;
&lt;p&gt;解析几何有两种起手式：&lt;strong&gt;设点与设线&lt;/strong&gt;。关于动点 $P$，这是一定要设的，毋庸置疑。难道我们希望联立两条切线以及圆的方程来确定 $P$ 点？这是绝对不可能的。我们应该如何设呢？我一开始想，可以尝试用参数方程，即设 $P$ 点坐标为 $(\cos\theta, \sin\theta - 4)$。但是，使用参数方程涉及到三角函数的计算，相较于有理代数运算困难。而且，抛物线的参数方程不含三角函数。因此，我们就设 $P$ 点坐标为 $(x_0, y_0)$。&lt;/p&gt;
&lt;p&gt;现在，大难题出现了：究竟是设直线 $AB$ 的方程，还是设 $A$、$B$ 两个端点的坐标？我们下面逐一尝试一下：&lt;/p&gt;
&lt;p&gt;&lt;em&gt;设线&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;目前来看，直线 $AB$ 不过任何定点。因此，我们只能设直线 $AB$ 的斜截式方程，并与抛物线方程联立：&lt;/p&gt;

$$
\begin{cases}
y = kx + b \\\\
x^2 = 4y
\end{cases}
$$

&lt;p&gt;消去 $y$，得到：&lt;/p&gt;

$$
x^2 - 4kx -4b = 0
$$

&lt;p&gt;弦长很容易就能计算。为了方便，我们计算弦长的平方：&lt;/p&gt;

$$
\begin{align}
|AB|^2 &amp;= (x_1 - x_2)^2 + (y_1 - y_2)^2 \\\\
&amp;= (1 + k^2)[(x_1 + x_2)^2 - 4 x_1 x_2] \\\\
&amp;= 16(1 + k^2)(k^2 + b)
\end{align}
$$

&lt;p&gt;相切的条件该怎么用呢？我们可以把抛物线改写成二次函数求导：&lt;/p&gt;

$$
\begin{align}
y &amp;= \frac{1}{4}x^2  \\\\
\Rightarrow y&#39; &amp;= \frac{1}{2}x
\end{align}
$$

&lt;p&gt;然后利用导数和切线斜率的关系列方程：&lt;/p&gt;

$$
\begin{cases}
\frac{1}{2}x_1 = \frac{y_1 - y_0}{x_1 - x_0}  \\\\
\frac{1}{2}x_2 = \frac{y_2 - y_0}{x_2 - x_0}
\end{cases}
$$

&lt;p&gt;计算量正在变大，但是还是可以算下去。我们去分母然后两式相加：&lt;/p&gt;

$$
\begin{align}
\frac{1}{2}(x_1^2 + x_2^2) - \frac{1}{2}x_0(x_1 + x_2) &amp;= y_1 + y_2 - 2 y_0 \\\\
\frac{1}{2}[(x_1 + x_2)^2 - 2 x_1 x_2] - 2kx_0 &amp;= k(x_1 + x_2) + 2b - 2y_0 \\\\
\frac{1}{2}(16k^2 + 8b) - 2kx_0 &amp;= 4k^2 + 2b - 2y_0 \\\\
2k^2 + y_0 + b &amp;= kx_0
\end{align}
$$

&lt;p&gt;下面我们来计算点 $P$ 到 $AB$ 的距离。同样为了方便，我们来算距离的平方：&lt;/p&gt;

$$
\begin{align}
d_{P \rightarrow AB}^2 &amp;= \frac{(kx_0 + b - y_0)^2}{1 + k^2} 
\end{align}
$$

&lt;p&gt;这样，我们就可以来算三角形的面积了。同样是算面积的平方，要注意这里可以将 $kx_0$ 代入，将 $x_0$ 和 $y_0$ 一并消去：&lt;/p&gt;

$$
\begin{align}
S_{\triangle PAB}^2 &amp;= \frac{1}{4} |AB|^2 d_{P \rightarrow AB}^2 \\\\
&amp;= 4 (1 + k^2) (k^2 + b) \frac{(kx_0 + b - y_0)^2}{1 + k^2} \\\\
&amp;= 4 (k^2 + b) (2k^2 + 2b)^2 \\\\
&amp;= 16 (k^2 + b)^3
\end{align}
$$

&lt;p&gt;显然，这里我们可以将 $k^2 + b$ 看成是一个整体。但是，$k^2 + b$ 一定是有取值范围的，我们需要确定这个取值范围。不过不要忘记，点 $P$ 在圆 $M$ 上的条件还没有使用：&lt;/p&gt;

$$
\begin{align}
x_0^2 + (y_0 + 4)^2 = 1
\end{align}
$$

&lt;p&gt;然而，我已经感觉很不妙了，怎样才能通过 $x_0$ 和 $y_0$ 的关系确定 $k$ 和 $b$ 的关系呢？我发现了之前计算得到的一个式子：&lt;/p&gt;

$$
\begin{align}
2k^2 + y_0 + b &amp;= kx_0
\end{align}
$$

&lt;p&gt;我们将这个式子两边平方，然后将 $x_0^2$ 整体代入得：&lt;/p&gt;

$$
\begin{align}
(2k^2 + y_0 + b)^2 &amp;= k^2 [1 - (y_0 + 4)^2]
\end{align}
$$

&lt;p&gt;然而这个式子根本无法消掉 $y_0$。设线的方法宣告失败！&lt;/p&gt;
&lt;p&gt;&lt;em&gt;设点&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;我们设 $A$ 点坐标为 $(x_1, y_1)$，$B$ 点坐标为 $(x_2, y_2)$。关键来了，下一步应该干什么？是直接写出直线 $AB$ 的两点式方程吗？&lt;/p&gt;
&lt;p&gt;显然不是的，因为我们有一个非常好的条件还没用——相切。因为我们有 $A$、$B$ 两点坐标，得到切线斜率非常容易，可以直接写出切线的点斜式方程：&lt;/p&gt;

$$
\begin{align}
l_{PA}: y - y_1 = \frac{1}{2}x_1(x-x_1) \\\\
l_{PB}: y - y_2 = \frac{1}{2}x_2(x-x_2)
\end{align}
$$

&lt;p&gt;由于 $A$、$B$ 两点都在抛物线上，满足抛物线方程，我们可以把上面的直线方程简化一下：&lt;/p&gt;

$$
\begin{align}
l_{PA}: y = \frac{1}{2}x_1x-y_1 \\\\
l_{PB}: y = \frac{1}{2}x_2x-y_2
\end{align}
$$

&lt;p&gt;这两条切线都经过 $P$ 点，我们将 $P$ 点坐标代入：&lt;/p&gt;

$$
\begin{cases}
y_0 = \frac{1}{2}x_1x_0-y_1 \\\\
y_0 = \frac{1}{2}x_2x_0-y_2
\end{cases}
$$

&lt;p&gt;本题的破题点来了。你是否能看出直线 $AB$ 的方程？&lt;/p&gt;

$$
\begin{align}
l_{AB}: y_0 = \frac{1}{2}x_0x-y
\end{align}
$$

&lt;p&gt;$A$、$B$ 两点都满足上面的方程，而两点确定一条直线，那么上面的方程就表示直线 $AB$。&lt;/p&gt;
&lt;p&gt;有了直线 $AB$ 的方程，一切都好办了。先把直线方程与抛物线方程联立：&lt;/p&gt;

$$
\begin{cases}
y_0 = \frac{1}{2}x_0x-y \\\\
x^2 = 4y
\end{cases}
$$

&lt;p&gt;得到：&lt;/p&gt;

$$
\begin{align}
x^2 - 2x_0x + 4y_0 = 0
\end{align}
$$

&lt;p&gt;先算弦长：&lt;/p&gt;

$$
\begin{align}
|AB|^2 &amp;= (x_1 - x_2)^2 + (y_1 - y_2)^2 \\\\
&amp;= (1 + \frac{1}{4} x_0^2)[(x_1 + x_2)^2 - 4 x_1 x_2] \\\\
&amp;= (1 + \frac{1}{4} x_0^2)(4x_0^2 - 16y_0)
\end{align}
$$

&lt;p&gt;再算距离：&lt;/p&gt;

$$
\begin{align}
d_{P \rightarrow AB}^2 &amp;= \frac{(\frac{1}{2}x_0^2 - 2y_0)^2}{1 + \frac{1}{4}x_0^2}
\end{align}
$$

&lt;p&gt;最后算三角形的面积。要注意，这里我们再用点 $P$ 在圆 $M$ 上的条件来消参就可以成功：&lt;/p&gt;

$$
\begin{align}
S_{\triangle PAB}^2 &amp;= \frac{1}{4} |AB|^2 d_{P \rightarrow AB}^2 \\\\
&amp;= (x_0^2 - 4y_0) (\frac{1}{2}x_0^2 - 2y_0)^2 \\\\
&amp;= 2(\frac{1}{2}x_0^2 - 2y_0)^3 \\\\
&amp;= 2[\frac{1}{2}(1 - (y_0 + 4)^2) - 2y_0]^3 \\\\
&amp;= 2[\frac{1}{2} - \frac{1}{2}(y_0^2 + 8y_0 + 16) - 2y_0]^3 \\\\
&amp;= 2[-\frac{1}{2}y_0^2 - 6y_0 - \frac{15}{2}]^3 \\\\
&amp;= 2[-\frac{1}{2}(y_0 + 6)^2 + \frac{21}{2}]^3 \\\\
\end{align}
$$

&lt;p&gt;配方后，转化为二次函数在闭区间上的最值问题。而 $y_0 \in [-5, -3]$，故 $y_0 = -5$ 时，$S_{\triangle PAB}$ 取最大值，最大值为：&lt;/p&gt;

$$
\begin{align}
S_{\triangle PAB} &amp;= \sqrt[]{2[-\frac{1}{2}(-5 + 6)^2 + \frac{21}{2}]^3} \\\\
&amp;= 20 \sqrt[]{5} 
\end{align}
$$

&lt;p&gt;&lt;strong&gt;总结&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;解析几何作为全国卷压轴大题的情况较为罕见，但实际上这道题目非常常规，计算量其实不算特别大，但是有一定的技巧性。&lt;/p&gt;
&lt;p&gt;首先，要明确计算三角形面积的思路。然后，要选择设点作为起手式。这里面的原因在于，设点可以更好地利用相切的已知条件，可以非常方便地写出切线方程。再加上对直线方程的理解，可以不用计算就可以得到弦所在直线方程。虽然设线在一开始就可以得到弦所在直线方程，但是相切的条件就不是那么方便使用，而且计算到最后，利用 $P$ 点在圆上的条件很难消参。&lt;/p&gt;
&lt;p&gt;另外，本题不适合设线还有一个原因就是，本题的 $P$ 点是主动点，而切点是从动点。设线相当于是把切点当成主动点了，这样就会产生一个问题，需要反过来表示 $P$ 点的时候就会困难，体现在解题步骤当中就是无法消参。&lt;/p&gt;
&lt;p&gt;在考场上，最大的困难就在于理清思路。如果没有理清思路，就是直接设完就算，最终自己都不知道自己在算什么了。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>沉痛悼念杂交水稻之父袁隆平院士</title>
      <link>https://bowenei.gitee.io/post/deeply-mourns-the-father-of-hybrid-rice-yuan-longping/</link>
      <pubDate>Sat, 22 May 2021 19:21:28 +0800</pubDate>
      <guid>https://bowenei.gitee.io/post/deeply-mourns-the-father-of-hybrid-rice-yuan-longping/</guid>
      <description>&lt;p&gt;5月22日13时07分，当代最伟大的科学家停止科研了。今天上午我才听说有关袁隆平院士逝世的消息系谣言，当我下午打开手机看看新闻时，便发现他真的与世长辞了。&lt;/p&gt;
&lt;p&gt;这位巨人的逝世，对于中国人民，对于世界人民，对于农学和遗传学，都是不可估量的损失。这位巨人逝世以后所形成的空白，不久就会使人感觉到。&lt;/p&gt;
&lt;p&gt;不像马克思发现人类历史的发展规律，袁隆平院士只是发现了杂交水稻高产的规律。我们知道，历来为繁芜丛杂的意识形态所掩盖着的一个简单事实：人们首先必须吃、喝、住、穿，然后才能从事政治、科学、艺术、宗教等等。袁隆平院士的伟大之处在于，他的籼型杂交水稻解决了当时中国亿万人口的吃饭问题。在华夏文明的传说中，神农氏尝百草，制耒耜，种五谷，奠定了农工基础，使“民以食为天”的观念深入每一位华夏儿女的心。华夏文明5000多年来，袁隆平院士是当代当之无愧的神农氏！&lt;/p&gt;
&lt;p&gt;不仅如此，袁隆平院士还研究和培育出了超级杂交水稻。2020年11月2日，在湖南省衡阳市衡南县清竹村进行的袁隆平领衔的杂交水稻双季测产达到了亩产1530.76公斤，其中早稻619.06公斤、第三代杂交水稻晚稻品种“叁优一号”911.7公斤，超过了1500公斤的预期目标。比数字更重要的意义在于：这次测产充分展示了第三代杂交水稻更加契合实际生产的特点，从而有利于进一步保障国家粮食安全。&lt;/p&gt;
&lt;p&gt;他作为科学家就是这样。但是这在他身上远不是主要的。在袁隆平院士看来，杂交水稻只是一种高产、抗病、抗寒、抗倒的水稻。任何一门理论科学中的每一个新发现——它的实际应用也许还根本无法预见——都使袁隆平院士感到衷心喜悦，而当他看到他的杂交水稻亩产比过去翻番时候，他的喜悦就非同寻常了。&lt;/p&gt;
&lt;p&gt;因为袁隆平院士首先是一个普通的知识分子。他毕生的真正使命，就是战胜饥饿。科研是他的生命要素。很少有人像他那样满腔热情、坚韧不拔和卓有成效地进行科研。50多年来，袁隆平院士始终在农业科研第一线辛勤耕耘、不懈探索，为人类运用科技手段战胜饥饿带来绿色的希望和金色的收获。不仅为解决中国人民的温饱和保障国家粮食安全做出了贡献，更为世界和平和社会进步树立了丰碑。&lt;/p&gt;
&lt;p&gt;如今，成长在物质生活丰富的现代社会的我们，难以体会和想象到上个世纪60年代的大饥荒。可是，我看到现在的食堂剩饭剩菜现象屡见不鲜，酒桌饭局的浪费大张旗鼓，婚宴酒席的奢靡之风已成常态。今天，我们真的有颜面在网络上发文，悼念这位伟大的科学家吗？吃水不忘挖井人，我们今天的幸福生活来之不易，珍惜眼前的每一粒粮食！&lt;/p&gt;
&lt;p&gt;可即使如此，袁隆平院士还是被一些小人忌恨和诬蔑。2018年4月14日，袁隆平院士在接受凤凰财经采访时发表了对转基因的看法。对于转基因大豆，袁隆平院士指出，只要是通过安全检测的转基因作物，都是没有问题的。袁隆平院士表示，“美国转基因大豆加入的是除草基因，这个对人体无害，中国每年从美国进口几千万吨大豆，这个完全没问题。”网络上各路牛鬼蛇神开始竞相歪曲、否定袁隆平院士，对他的言论断章取义和包装，到处散布谣言。现在他逝世了，举国上下，各行各业，14亿中国人民无不对他表示尊敬、爱戴和悼念。而我敢大胆地说：他可能有过许多敌人，但未必有一个私敌。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;他的英名和事业将永垂不朽！&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;本文改编自恩格斯《在马克思墓前的讲话》，转载请注明出处，谢谢！&lt;/p&gt;
&lt;/blockquote&gt;</description>
    </item>
    
    <item>
      <title>Writing technical content in Academic</title>
      <link>https://bowenei.gitee.io/post/writing-technical-content/</link>
      <pubDate>Fri, 12 Jul 2019 00:00:00 +0000</pubDate>
      <guid>https://bowenei.gitee.io/post/writing-technical-content/</guid>
      <description>&lt;p&gt;Academic is designed to give technical content creators a seamless experience. You can focus on the content and Academic handles the rest.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Highlight your code snippets, take notes on math classes, and draw diagrams from textual representation.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;On this page, you&amp;rsquo;ll find some examples of the types of technical content that can be rendered with Academic.&lt;/p&gt;
&lt;h2 id=&#34;examples&#34;&gt;Examples&lt;/h2&gt;
&lt;h3 id=&#34;code&#34;&gt;Code&lt;/h3&gt;
&lt;p&gt;Academic supports a Markdown extension for highlighting code syntax. You can enable this feature by toggling the &lt;code&gt;highlight&lt;/code&gt; option in your &lt;code&gt;config/_default/params.toml&lt;/code&gt; file.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;```python
import pandas as pd
data = pd.read_csv(&amp;quot;data.csv&amp;quot;)
data.head()
```
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;renders as&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pandas&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pd&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;data&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read_csv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;data.csv&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;data&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;head&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;charts&#34;&gt;Charts&lt;/h3&gt;
&lt;p&gt;Academic supports the popular &lt;a href=&#34;https://plot.ly/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Plotly&lt;/a&gt; chart format.&lt;/p&gt;
&lt;p&gt;Save your Plotly JSON in your page folder, for example &lt;code&gt;chart.json&lt;/code&gt;, and then add the &lt;code&gt;{{&amp;lt; chart data=&amp;quot;chart&amp;quot; &amp;gt;}}&lt;/code&gt; shortcode where you would like the chart to appear.&lt;/p&gt;
&lt;p&gt;Demo:&lt;/p&gt;


&lt;div id=&#34;chart-962351874&#34; class=&#34;chart&#34;&gt;&lt;/div&gt;
&lt;script&gt;
  (function() {
    let a = setInterval( function() {
      if ( typeof window.Plotly === &#39;undefined&#39; ) {
        return;
      }
      clearInterval( a );

      Plotly.d3.json(&#34;./line-chart.json&#34;, function(chart) {
        Plotly.plot(&#39;chart-962351874&#39;, chart.data, chart.layout, {responsive: true});
      });
    }, 500 );
  })();
&lt;/script&gt;
&lt;p&gt;You might also find the &lt;a href=&#34;http://plotly-json-editor.getforge.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Plotly JSON Editor&lt;/a&gt; useful.&lt;/p&gt;
&lt;h3 id=&#34;math&#34;&gt;Math&lt;/h3&gt;
&lt;p&gt;Academic supports a Markdown extension for $\LaTeX$ math. You can enable this feature by toggling the &lt;code&gt;math&lt;/code&gt; option in your &lt;code&gt;config/_default/params.toml&lt;/code&gt; file.&lt;/p&gt;
&lt;p&gt;To render &lt;em&gt;inline&lt;/em&gt; or &lt;em&gt;block&lt;/em&gt; math, wrap your LaTeX math with &lt;code&gt;$...$&lt;/code&gt; or &lt;code&gt;$$...$$&lt;/code&gt;, respectively.&lt;/p&gt;
&lt;p&gt;Example &lt;strong&gt;math block&lt;/strong&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-latex&#34; data-lang=&#34;latex&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;sb&#34;&gt;$$&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\gamma&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;_{n} &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\frac&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;{ 
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\left&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; | &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\left&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\mathbf&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; x_{n} &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\mathbf&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; x_{n&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;} &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\right&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;^T 
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\left&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\nabla&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; F &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\mathbf&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; x_{n}&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\nabla&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; F &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\mathbf&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; x_{n&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\right&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\right&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; |}
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\left&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\|\nabla&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; F&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\mathbf&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;{x}_{n}&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\nabla&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; F&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\mathbf&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;{x}_{n&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\right&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\|&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;^&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;$$&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;renders as&lt;/p&gt;
&lt;p&gt;$$\gamma_{n} = \frac{ \left | \left (\mathbf x_{n} - \mathbf x_{n-1} \right )^T \left [\nabla F (\mathbf x_{n}) - \nabla F (\mathbf x_{n-1}) \right ] \right |}{\left |\nabla F(\mathbf{x}&lt;em&gt;{n}) - \nabla F(\mathbf{x}&lt;/em&gt;{n-1}) \right |^2}$$&lt;/p&gt;
&lt;p&gt;Example &lt;strong&gt;inline math&lt;/strong&gt; &lt;code&gt;$\nabla F(\mathbf{x}_{n})$&lt;/code&gt; renders as $\nabla F(\mathbf{x}_{n})$.&lt;/p&gt;
&lt;p&gt;Example &lt;strong&gt;multi-line math&lt;/strong&gt; using the &lt;code&gt;\\\\&lt;/code&gt; math linebreak:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-latex&#34; data-lang=&#34;latex&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;sb&#34;&gt;$$&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;k;p_{&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;}^{&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\begin&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;{cases}p_{&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;}^{&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;} &amp;amp; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\text&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;{if }k&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;, &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\\\\&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;p_{&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;}^{&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;} &amp;amp; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\text&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;{if }k&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\end&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;{cases}&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;$$&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;renders as&lt;/p&gt;
&lt;p&gt;$$f(k;p_{0}^{&lt;em&gt;}) = \begin{cases}p_{0}^{&lt;/em&gt;} &amp;amp; \text{if }k=1, \\
1-p_{0}^{*} &amp;amp; \text{if }k=0.\end{cases}$$&lt;/p&gt;
&lt;h3 id=&#34;diagrams&#34;&gt;Diagrams&lt;/h3&gt;
&lt;p&gt;Academic supports a Markdown extension for diagrams. You can enable this feature by toggling the &lt;code&gt;diagram&lt;/code&gt; option in your &lt;code&gt;config/_default/params.toml&lt;/code&gt; file or by adding &lt;code&gt;diagram: true&lt;/code&gt; to your page front matter.&lt;/p&gt;
&lt;p&gt;An example &lt;strong&gt;flowchart&lt;/strong&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;```mermaid
graph TD
A[Hard] --&amp;gt;|Text| B(Round)
B --&amp;gt; C{Decision}
C --&amp;gt;|One| D[Result 1]
C --&amp;gt;|Two| E[Result 2]
```
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;renders as&lt;/p&gt;
&lt;div class=&#34;mermaid&#34;&gt;graph TD
A[Hard] --&gt;|Text| B(Round)
B --&gt; C{Decision}
C --&gt;|One| D[Result 1]
C --&gt;|Two| E[Result 2]
&lt;/div&gt;
&lt;p&gt;An example &lt;strong&gt;sequence diagram&lt;/strong&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;```mermaid
sequenceDiagram
Alice-&amp;gt;&amp;gt;John: Hello John, how are you?
loop Healthcheck
    John-&amp;gt;&amp;gt;John: Fight against hypochondria
end
Note right of John: Rational thoughts!
John--&amp;gt;&amp;gt;Alice: Great!
John-&amp;gt;&amp;gt;Bob: How about you?
Bob--&amp;gt;&amp;gt;John: Jolly good!
```
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;renders as&lt;/p&gt;
&lt;div class=&#34;mermaid&#34;&gt;sequenceDiagram
Alice-&gt;&gt;John: Hello John, how are you?
loop Healthcheck
    John-&gt;&gt;John: Fight against hypochondria
end
Note right of John: Rational thoughts!
John--&gt;&gt;Alice: Great!
John-&gt;&gt;Bob: How about you?
Bob--&gt;&gt;John: Jolly good!
&lt;/div&gt;
&lt;p&gt;An example &lt;strong&gt;Gantt diagram&lt;/strong&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;```mermaid
gantt
section Section
Completed :done,    des1, 2014-01-06,2014-01-08
Active        :active,  des2, 2014-01-07, 3d
Parallel 1   :         des3, after des1, 1d
Parallel 2   :         des4, after des1, 1d
Parallel 3   :         des5, after des3, 1d
Parallel 4   :         des6, after des4, 1d
```
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;renders as&lt;/p&gt;
&lt;div class=&#34;mermaid&#34;&gt;gantt
section Section
Completed :done,    des1, 2014-01-06,2014-01-08
Active        :active,  des2, 2014-01-07, 3d
Parallel 1   :         des3, after des1, 1d
Parallel 2   :         des4, after des1, 1d
Parallel 3   :         des5, after des3, 1d
Parallel 4   :         des6, after des4, 1d
&lt;/div&gt;
&lt;p&gt;An example &lt;strong&gt;class diagram&lt;/strong&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;```mermaid
classDiagram
Class01 &amp;lt;|-- AveryLongClass : Cool
&amp;lt;&amp;lt;interface&amp;gt;&amp;gt; Class01
Class09 --&amp;gt; C2 : Where am i?
Class09 --* C3
Class09 --|&amp;gt; Class07
Class07 : equals()
Class07 : Object[] elementData
Class01 : size()
Class01 : int chimp
Class01 : int gorilla
class Class10 {
  &amp;lt;&amp;lt;service&amp;gt;&amp;gt;
  int id
  size()
}
```
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;renders as&lt;/p&gt;
&lt;div class=&#34;mermaid&#34;&gt;classDiagram
Class01 &lt;|-- AveryLongClass : Cool
&lt;&lt;interface&gt;&gt; Class01
Class09 --&gt; C2 : Where am i?
Class09 --* C3
Class09 --|&gt; Class07
Class07 : equals()
Class07 : Object[] elementData
Class01 : size()
Class01 : int chimp
Class01 : int gorilla
class Class10 {
  &lt;&lt;service&gt;&gt;
  int id
  size()
}
&lt;/div&gt;
&lt;p&gt;An example &lt;strong&gt;state diagram&lt;/strong&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;```mermaid
stateDiagram
[*] --&amp;gt; Still
Still --&amp;gt; [*]
Still --&amp;gt; Moving
Moving --&amp;gt; Still
Moving --&amp;gt; Crash
Crash --&amp;gt; [*]
```
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;renders as&lt;/p&gt;
&lt;div class=&#34;mermaid&#34;&gt;stateDiagram
[*] --&gt; Still
Still --&gt; [*]
Still --&gt; Moving
Moving --&gt; Still
Moving --&gt; Crash
Crash --&gt; [*]
&lt;/div&gt;
&lt;h3 id=&#34;todo-lists&#34;&gt;Todo lists&lt;/h3&gt;
&lt;p&gt;You can even write your todo lists in Academic too:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-markdown&#34; data-lang=&#34;markdown&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;- [x]&lt;/span&gt; Write math example
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;- [x]&lt;/span&gt; Write diagram example
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;- [ ]&lt;/span&gt; Do something else
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;renders as&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; Write math example&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; Write diagram example&lt;/li&gt;
&lt;li&gt;&lt;input disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; Do something else&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;tables&#34;&gt;Tables&lt;/h3&gt;
&lt;p&gt;Represent your data in tables:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-markdown&#34; data-lang=&#34;markdown&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;| First Header  | Second Header |
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;| ------------- | ------------- |
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;| Content Cell  | Content Cell  |
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;| Content Cell  | Content Cell  |
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;renders as&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;First Header&lt;/th&gt;
&lt;th&gt;Second Header&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Content Cell&lt;/td&gt;
&lt;td&gt;Content Cell&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Content Cell&lt;/td&gt;
&lt;td&gt;Content Cell&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;callouts&#34;&gt;Callouts&lt;/h3&gt;
&lt;p&gt;Academic supports a &lt;a href=&#34;https://wowchemy.com/docs/content/writing-markdown-latex/#callouts&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;shortcode for callouts&lt;/a&gt;, also referred to as &lt;em&gt;asides&lt;/em&gt;, &lt;em&gt;hints&lt;/em&gt;, or &lt;em&gt;alerts&lt;/em&gt;. By wrapping a paragraph in &lt;code&gt;{{% callout note %}} ... {{% /callout %}}&lt;/code&gt;, it will render as an aside.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-markdown&#34; data-lang=&#34;markdown&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{{% callout note %}}
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;A Markdown aside is useful for displaying notices, hints, or definitions to your readers.
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{{% /callout %}}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;renders as&lt;/p&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    A Markdown aside is useful for displaying notices, hints, or definitions to your readers.
  &lt;/div&gt;
&lt;/div&gt;
&lt;h3 id=&#34;spoilers&#34;&gt;Spoilers&lt;/h3&gt;
&lt;p&gt;Add a spoiler to a page to reveal text, such as an answer to a question, after a button is clicked.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-markdown&#34; data-lang=&#34;markdown&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{{&lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;spoiler&lt;/span&gt; &lt;span class=&#34;na&#34;&gt;text&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;Click to view the spoiler&amp;#34;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;}}
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;You found me!
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{{&lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spoiler&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;}}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;renders as&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-2&#34;&gt;
  &lt;summary&gt;Click to view the spoiler&lt;/summary&gt;
  &lt;p&gt;You found me!&lt;/p&gt;
&lt;/details&gt;
&lt;h3 id=&#34;icons&#34;&gt;Icons&lt;/h3&gt;
&lt;p&gt;Academic enables you to use a wide range of &lt;a href=&#34;https://sourcethemes.com/academic/docs/page-builder/#icons&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;icons from &lt;em&gt;Font Awesome&lt;/em&gt; and &lt;em&gt;Academicons&lt;/em&gt;&lt;/a&gt; in addition to &lt;a href=&#34;https://sourcethemes.com/academic/docs/writing-markdown-latex/#emojis&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;emojis&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Here are some examples using the &lt;code&gt;icon&lt;/code&gt; shortcode to render icons:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-markdown&#34; data-lang=&#34;markdown&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{{&lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;icon&lt;/span&gt; &lt;span class=&#34;na&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;terminal&amp;#34;&lt;/span&gt; &lt;span class=&#34;na&#34;&gt;pack&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;fas&amp;#34;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;}} Terminal  
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{{&lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;icon&lt;/span&gt; &lt;span class=&#34;na&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;python&amp;#34;&lt;/span&gt; &lt;span class=&#34;na&#34;&gt;pack&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;fab&amp;#34;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;}} Python  
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{{&lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;icon&lt;/span&gt; &lt;span class=&#34;na&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;r-project&amp;#34;&lt;/span&gt; &lt;span class=&#34;na&#34;&gt;pack&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;fab&amp;#34;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;}} R
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;renders as&lt;/p&gt;
&lt;p&gt;
  &lt;i class=&#34;fas fa-terminal  pr-1 fa-fw&#34;&gt;&lt;/i&gt; Terminal&lt;br&gt;

  &lt;i class=&#34;fab fa-python  pr-1 fa-fw&#34;&gt;&lt;/i&gt; Python&lt;br&gt;

  &lt;i class=&#34;fab fa-r-project  pr-1 fa-fw&#34;&gt;&lt;/i&gt; R&lt;/p&gt;
&lt;h3 id=&#34;did-you-find-this-page-helpful-consider-sharing-it-&#34;&gt;Did you find this page helpful? Consider sharing it 🙌&lt;/h3&gt;
&lt;div class=&#34;highlight&#34; height=&#34;200px&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;- Hugo Modules
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  - wowchemy
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  - wowchemy-plugins-netlify
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  - wowchemy-plugins-netlify-cms
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  - wowchemy-plugins-reveal
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</description>
    </item>
    
  </channel>
</rss>
