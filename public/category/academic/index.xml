<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Academic | Bowen&#39;s Academic Home</title>
    <link>https://bowenei.gitee.io/category/academic/</link>
      <atom:link href="https://bowenei.gitee.io/category/academic/index.xml" rel="self" type="application/rss+xml" />
    <description>Academic</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Tue, 30 Nov 2021 13:37:38 +0800</lastBuildDate>
    <image>
      <url>https://bowenei.gitee.io/media/icon_huc813daf5dbf7d2b27f0daba22fe1e0fb_68056_512x512_fill_lanczos_center_3.png</url>
      <title>Academic</title>
      <link>https://bowenei.gitee.io/category/academic/</link>
    </image>
    
    <item>
      <title>An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale</title>
      <link>https://bowenei.gitee.io/post/an-image-is-worth-16x16-words-transformers-for-image-recognition-at-scale/</link>
      <pubDate>Tue, 30 Nov 2021 13:37:38 +0800</pubDate>
      <guid>https://bowenei.gitee.io/post/an-image-is-worth-16x16-words-transformers-for-image-recognition-at-scale/</guid>
      <description>&lt;p&gt;&lt;strong&gt;Vision Transformer (ViT)&lt;/strong&gt; 是目前计算机视觉 (CV) 领域影响力最大的一项工作，因为他挑战了自从 2012 年 AlexNet 提出以来的 CNN 模型在 CV 领域的绝对统治地位。实验表明，如果能够在足够多的数据集上做预训练，那么即使不使用 CNN 也能达到同等甚至更高的精度。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ViT&lt;/strong&gt; 不仅在 CV 领域挖了一个大坑，而且还打破了 CV 和 NLP 在模型上的壁垒，所以在多模态领域也挖了一个大坑。于是，在 2020 年 10 月本文在 arXiv 上公开以后，基于 &lt;strong&gt;ViT&lt;/strong&gt; 的工作层出不穷。毫无疑问，&lt;strong&gt;ViT&lt;/strong&gt; 标志着 Transformer 模型正式杀入 CV 界，也标志着 Transformer 模型正式成为继 MLP、CNN、RNN 之后的一种新的模型范式。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/2010.11929&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;原文链接&lt;/a&gt;&lt;/p&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    &lt;p&gt;&lt;strong&gt;特别鸣谢&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;本文结合亚马逊首席科学家&lt;a href=&#34;https://github.com/mli&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;李沐&lt;/a&gt;的&lt;a href=&#34;https://www.bilibili.com/video/BV15P4y137jb&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;深度学习论文精读系列视频&lt;/a&gt;进行整理。视频的主讲人是&lt;a href=&#34;https://bryanyzhu.github.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;朱毅&lt;/a&gt;研究员。&lt;/p&gt;

  &lt;/div&gt;
&lt;/div&gt;

&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;While the Transformer architecture has become the de-facto standard for natural language processing tasks, its applications to computer vision remain limited. In vision, attention is either applied in conjunction with convolutional networks, or used to replace certain components of convolutional networks while keeping their overall structure in place. We show that this reliance on CNNs is not necessary and a pure transformer applied directly to sequences of image patches can perform very well on image classification tasks. When pre-trained on large amounts of data and transferred to multiple mid-sized or small image recognition benchmarks (ImageNet, CIFAR-100, VTAB, etc.), Vision Transformer (ViT) attains excellent results compared to state-of-the-art convolutional networks while requiring substantially fewer computational resources to train.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;作者认为，Transformer 在 NLP 领域应用广泛并且成为标准，但在 CV 领域的应用仍然有限。注意力 &lt;code&gt;attention&lt;/code&gt; 机制要么与 CNN 结合使用，要么用于替换 CNN 中的某些部分而整体结构不变。作者通过实验证明，这种对 CNN 的依赖是不必要的，直接将序列化的图像块 &lt;code&gt;patches&lt;/code&gt; 输入进 Transformer 可以取得非常好的效果。尤其是在大规模的数据集上做预训练之后，再迁移到中小型数据上能够获得和最好的 CNN 相媲美的结果。&lt;/p&gt;
&lt;p&gt;朱老师提醒大家特别注意，这里作者说的花费更少的资源训练是指 TPU v3 训练 2500 天所花费的资源！&lt;/p&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;Self-attention-based architectures, in particular Transformers (Vaswani et al., 2017), have become the model of choice in natural language processing (NLP). The dominant approach is to pre-train on a large text corpus and then fine-tune on a smaller task-specific dataset (Devlin et al., 2019). Thanks to Transformers’ computational efficiency and scalability, it has become possible to train models of unprecedented size, with over 100B parameters (Brown et al., 2020; Lepikhin et al., 2020). With the models and datasets growing, there is still no sign of saturating performance.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;在 NLP 领域，目前主流的方式是先在一个大规模数据集上做预训练 &lt;code&gt;pre-train&lt;/code&gt;，然后在特定领域的小数据集上做微调 &lt;code&gt;fine-tune&lt;/code&gt;。（这实际上是 BERT 这篇论文里提出来的。）Transformer 的计算具有高效性 &lt;code&gt;efficiency&lt;/code&gt; 和可扩展性 &lt;code&gt;scalability&lt;/code&gt;，并且随着模型和数据集的增长，还没有看到出现性能饱和 &lt;code&gt;saturating&lt;/code&gt; 的现象。&lt;/p&gt;
&lt;div class=&#34;alert alert-warning&#34;&gt;
  &lt;div&gt;
    &lt;p&gt;&lt;strong&gt;Transformer 直接用于 CV 领域的困难&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;朱老师认为，在过去的工作中，Transformer 一直没能用于 CV 领域的原因是因为计算的复杂性。&lt;/p&gt;
&lt;p&gt;我们试想，如果我们偏要把图片当成序列送入 Transformer 里面训练该怎么做？我们很容易想到的是将二维的图片拉直成序列，然后就可以输入到 Transformer 里面了。然而这样的计算复杂度就达到 $O(n^2)$。如果输入图片为 224x224x3，即使不考虑通道，序列长度就高达 50176，这远远大于一句话甚至是一段话的长度。&lt;/p&gt;

  &lt;/div&gt;
&lt;/div&gt;

&lt;blockquote&gt;
&lt;p&gt;In computer vision, however, convolutional architectures remain dominant (LeCun et al., 1989; Krizhevsky et al., 2012; He et al., 2016). Inspired by NLP successes, multiple works try combining CNN-like architectures with self-attention (Wang et al., 2018; Carion et al., 2020), some replacing the convolutions entirely (Ramachandran et al., 2019; Wang et al., 2020a). The latter models, while theoretically efficient, have not yet been scaled effectively on modern hardware accelerators due to the use of specialized attention patterns. Therefore, in large-scale image recognition, classic ResNet-like architectures are still state of the art (Mahajan et al., 2018; Xie et al., 2020; Kolesnikov et al., 2020).&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;目前 CNN 在 CV 仍占主导地位。既然 Transformer 在 NLP 领域又特别火，注意力机制又那么香，为什么不可以在 CV 领域使用 Transformer 呢？其实是有相关工作的，一些工作将 CNN 和 self-attention 结合使用。例如，可以将网络中间的特征图当作是 Transformer 的输入。Ramachandran 等人认为可以添加一个小窗口以降低 Transformer 的计算复杂度，Wang 等人认为可以分别在图片的两个维度（宽和高）做自注意力。&lt;/p&gt;
&lt;p&gt;作者认为，上述优化理论上都是可行的，但是都是比较特殊的自注意力操作，很难在硬件上加速，训练更大的模型。个人认为，这种优化缺乏普适性。因此，传统的残差网络依然是最好的。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Inspired by the Transformer scaling successes in NLP, we experiment with applying a standard Transformer directly to images, with the fewest possible modifications. To do so, we split an image into patches and provide the sequence of linear embeddings of these patches as an input to a Transformer. Image patches are treated the same way as tokens (words) in an NLP application. We train the model on image classification in supervised fashion.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;作者是被 Transformer 在 NLP 领域应用的可扩展性所启发，所以他们希望将 Transformer 直接作用于图片而尽量做少的修改。作者将图片打成了很多个 &lt;code&gt;patch&lt;/code&gt;，每一个 &lt;code&gt;patch&lt;/code&gt; 的大小是 16x16。然后我们就可以将每一个 &lt;code&gt;patch&lt;/code&gt; 当成是 NLP 领域里的单词，这也就是本文标题 An Image is Worth 16x16 Words 的含义。这里作者还补充说明了训练方式是有监督训练，因为 NLP 领域绝大多数都是无监督训练。&lt;/p&gt;
&lt;p&gt;朱老师认为，读到这里可以认为作者真的是完全把 CV 任务当成是 NLP 任务去做。朱老师觉得本文其实是换了个角度讲故事，但是总而言之本文的作者只想说明一件事——Transformer在视觉领域也能取得很好的效果。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;When trained on mid-sized datasets such as ImageNet without strong regularization, these models yield modest accuracies of a few percentage points below ResNets of comparable size. This seemingly discouraging outcome may be expected: Transformers lack some of the inductive biases inherent to CNNs, such as translation equivariance and locality, and therefore do not generalize well when trained on insufficient amounts of data.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;如果在中等大小的数据集（ImageNet）上不加以强约束，&lt;strong&gt;ViT&lt;/strong&gt; 其实是比传统的残差网络更弱的。作者于是就解释到，看起来不太好的结果其实是可以预知的。因为 Transformer 和 CNN 相比它缺少 CNN 有的归纳偏置 &lt;code&gt;inductive biases&lt;/code&gt;，它指的是一种先验知识，或者是我们提前做好的假设。&lt;/p&gt;
&lt;p&gt;CNN 其实是有两个归纳偏置。一个是 &lt;code&gt;locality&lt;/code&gt;，因为卷积运算是一个滑动窗口一点一点在图片上做的，所以就可以假设图片中相邻的区域有相似的特征。另一个是平移同变性 &lt;code&gt;translation equivariance&lt;/code&gt;，用公式表示就是 $f(g(x)) = g(f(x))$。（这里将 $f$ 理解为卷积，$g$ 理解为平移。）&lt;/p&gt;
&lt;p&gt;正因为 CNN 有这两个归纳偏置，所以 CNN 在卷积之后只需要相对更少的数据就能够学到更多的特征，得到一个更好的模型。但是对于 Transformer 来说，它其实没有这些先验信息，所以 Transformer 里的所有参数都需要从数据里面自己学习。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;However, the picture changes if the models are trained on larger datasets (14M-300M images). We find that large scale training trumps inductive bias. Our Vision Transformer (ViT) attains excellent results when pre-trained at sufficient scale and transferred to tasks with fewer datapoints.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;果然，上了大数据以后没有归纳偏置的 Transformer 的效果要优于 CNN。&lt;/p&gt;
&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;按照沐神读论文的方式，先来看看结论。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;We have explored the direct application of Transformers to image recognition. Unlike prior works using self-attention in computer vision, we do not introduce image-specific inductive biases into the architecture apart from the initial patch extraction step. Instead, we interpret an image as a sequence of patches and process it by a standard Transformer encoder as used in NLP. This simple, yet scalable, strategy works surprisingly well when coupled with pre-training on large datasets. Thus, Vision Transformer matches or exceeds the state of the art on many image classification datasets, whilst being relatively cheap to pre-train.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;本文工作最大的特点是几乎不需要任何对 CV 领域有特别深的了解，只需要把图片当成是 NLP 领域当中的序列，即序列化的图像块，就可以用 Transformer 来做了。这种方法简单、可扩展性高，并且和大规模预训练结合起来的时候效果出奇地好。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;While these initial results are encouraging, many challenges remain. One is to apply ViT to other computer vision tasks, such as detection and segmentation. Our results, coupled with those in Carion et al. (2020), indicate the promise of this approach. Another challenge is to continue exploring self-supervised pre-training methods. Our initial experiments show improvement from self-supervised pre-training, but there is still large gap between self-supervised and large-scale supervised pre-training. Finally, further scaling of ViT would likely lead to improved performance.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;ViT&lt;/strong&gt; 属于挖坑型论文，这篇论文其实是挖了一个新模型的坑，即如何将 Transformer 应用到 CV。因此，很自然可以想到的第一个问题是，&lt;strong&gt;ViT&lt;/strong&gt; 能否在除了图像分类任务以外的任务上也达到很好的效果？例如语义分割 &lt;code&gt;segmentation&lt;/code&gt; 和目标检测 &lt;code&gt;detection&lt;/code&gt;。事实也的确如此，短短两个月不到，目标检测领域就出来了一个新的工作 ViT-FRCNN&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;，这就已经把 &lt;strong&gt;ViT&lt;/strong&gt; 用到目标检测上了。同年 12 月，语义分割也有一篇 SETR&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;。&lt;/p&gt;
&lt;p&gt;朱老师在这里不得不吐槽一波，大家的手速实在是太快了，CV 圈卷的程度已经不能用月来计算了！而且紧接着三个月后，Swin Transformer&lt;sup id=&#34;fnref:3&#34;&gt;&lt;a href=&#34;#fn:3&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;3&lt;/a&gt;&lt;/sup&gt; 横空出世，把多尺度设计融合到 Transformer 里面，真正让 Transformer 更适合来做 CV。&lt;/p&gt;
&lt;p&gt;另外一个可以探索的方向是自监督的训练方式，因为在 NLP 领域几乎所有基于 Transformer 的模型全都采用自监督的方式训练。本文也做了一些自监督训练的实验，但发现和有监督的训练比起来效果有明显差距。&lt;/p&gt;
&lt;p&gt;毕竟作者是 Google Brain，反正也没有谁有足够的计算资源能够填本文挖的大坑，那就自己来填吧！结果半年以后作者又提出了 Scaling Vision Transformer (ViT-G)&lt;sup id=&#34;fnref:4&#34;&gt;&lt;a href=&#34;#fn:4&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;4&lt;/a&gt;&lt;/sup&gt;，其实就是更大的 &lt;strong&gt;ViT&lt;/strong&gt;，然后就把 ImageNet 数据集的准确率刷到 $90\%$ 以上了。&lt;/p&gt;
&lt;p&gt;这篇论文不光是挖了一个 CV 大坑，更是待到 CV 和 NLP 大一统之后，挖了一个多模态的大坑。多模态深度学习领域的工作最近也呈井喷式增长，由此可见 &lt;strong&gt;ViT&lt;/strong&gt; 这篇论文的影响力是多么巨大。&lt;/p&gt;
&lt;h2 id=&#34;related-work&#34;&gt;Related Work&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;Transformers were proposed by Vaswani et al. (2017) for machine translation, and have since become the state of the art method in many NLP tasks. Large Transformer-based models are often pre-trained on large corpora and then fine-tuned for the task at hand: BERT (Devlin et al., 2019) uses a denoising self-supervised pre-training task, while the GPT line of workuses language modeling as its pre-training task (Radford et al., 2018; 2019; Brown et al., 2020).&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Transformer 模型目前一般都是先在一个大规模语料库上做预训练，然后在目标任务上做一些细小的微调。这里面有两大著名的工作：BERT&lt;sup id=&#34;fnref:5&#34;&gt;&lt;a href=&#34;#fn:5&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;5&lt;/a&gt;&lt;/sup&gt; 和 GPT&lt;sup id=&#34;fnref:6&#34;&gt;&lt;a href=&#34;#fn:6&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;6&lt;/a&gt;&lt;/sup&gt;。BERT 用的是一个被称为 &lt;code&gt;denoising&lt;/code&gt; 的自监督方式，其实就是完形填空。而 GPT 则使用 &lt;code&gt;language modeling&lt;/code&gt; 做自监督，它是指已经有一个句子，预测下一个词是什么。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Naive application of self-attention to images would require that each pixel attends to every other pixel. With quadratic cost in the number of pixels, this does not scale to realistic input sizes. Thus, to apply Transformers in the context of image processing, several approximations have been tried in the past.&lt;/p&gt;
&lt;p&gt;Many of these specialized attention architectures demonstrate promising results on computer vision tasks, but require complex engineering to be implemented efficiently on hardware accelerators.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;将自注意力简单地应用到图像的每个像素上会导致很大的计算开销，所以自注意力很难直接用到 CV。因此，想要用自注意力来处理图像就必须做一些近似 &lt;code&gt;approximation&lt;/code&gt;。下面作者列举了很多自注意力在 CV 领域的应用。例如只对邻近的像素做自注意力，或者只对一些稀疏的点做自注意力。但这些工作从本质上讲都是减少处理的数据大小，以求近似。许多这些专门的注意力架构在计算机视觉任务上展示了有希望的结果，但需要复杂的工程才能在硬件加速器上有效实施。&lt;/p&gt;
&lt;p&gt;本文这么简单的 idea 难道就没有人想到吗？其实是有类似的，作者在相关工作里面这样描述：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Most related to ours is the model of Cordonnier et al. (2020), which extracts patches of size 2 ×2 from the input image and applies full self-attention on top. This model is very similar to ViT, but our work goes further to demonstrate that large scale pre-training makes vanilla transformers competitive with (or even better than) state-of-the-art CNNs. Moreover, Cordonnier et al. (2020) use a small patch size of 2×2 pixels, which makes the model applicable only to small-resolution images, while we handle medium-resolution images as well.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;ICLR 2020 有一个工作是在 CIFAR-10 数据集上切 2x2 的 &lt;code&gt;patch&lt;/code&gt;，然后在上面做 self-attention。作者认为他们的工作和这项工作的区别是在大规模数据集上做预训练，不需要任何改动就能取得比目前最好的 CNN 还好的效果。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;There has also been a lot of interest in combining convolutional neural networks (CNNs) with forms of self-attention, e.g. by augmenting feature maps for image classification (Bello et al., 2019) or by further processing the output of a CNN using self-attention, e.g. for object detection (Hu et al., 2018; Carion et al., 2020), video processing (Wang et al., 2018; Sun et al., 2019), image classification (Wu et al., 2020), unsupervised objectdiscovery (Locatello et al., 2020), or unified text-vision tasks (Chen et al., 2020c; Lu et al., 2019; Li et al., 2019).&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;还有很多将 CNN 和自注意力结合起来的工作，而且基本涵盖了 CV 领域的很多任务。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Another recent related model is image GPT (iGPT) (Chen et al., 2020a), which applies Transformers to image pixels after reducing image resolution and color space. The model is trained in an unsupervised fashion as a generative model, and the resulting representation can then be fine-tuned or probed linearly for classification performance, achieving a maximal accuracy of 72% on ImageNet.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;一个特别新的工作是 image GPT (iGPT)。我们知道 GPT 是 NLP 领域的代表工作，iGPT 类似，它是一个生成式模型，用无监督的方式取训练的。但是这项工作的准确率最高仅仅只有 $72\%$，而本文的准确率已经达到 $88.5\%$ 了。但是另一个之后的工作 MAE&lt;sup id=&#34;fnref:7&#34;&gt;&lt;a href=&#34;#fn:7&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;7&lt;/a&gt;&lt;/sup&gt; 却反而让生成式模型比之前的判别式模型效果更好，随后爆火。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Our work adds to the increasing collection of papers that explore image recognition at larger scales than the standard ImageNet dataset.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;最后作者提到了比 ImageNet 还大的数据集上各个模型的效果。&lt;/p&gt;
&lt;p&gt;总结一下，本文的相关工作列举得非常彻底，基本上和本文工作相近的工作都涵盖到了。朱老师认为，在写相关工作章节时，就是要让读者知道在你的工作之前，别人做了哪些工作，你和他们的区别在哪里。这个只要写清楚了，其实是对你非常有利的，并不会因此降低论文的创新性，反而会让这个文章变得更加简单易懂。&lt;/p&gt;
&lt;h2 id=&#34;method&#34;&gt;Method&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;In model design we follow the original Transformer (Vaswani et al., 2017) as closely as possible. An advantage of this intentionally simple setup is that scalable NLP Transformer architectures – and their efficient implementations – can be used almost out of the box.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;作者强调，&lt;strong&gt;ViT&lt;/strong&gt; 在模型设计上是尽可能按照最原始的 Transformer 来做的。这样做的最大好处就是可以直接把 NLP 领域成功的 Transformer 架构直接拿过来使用，不需要再魔改模型了。&lt;/p&gt;
&lt;h3 id=&#34;vision-transformer-vit&#34;&gt;Vision Transformer (ViT)&lt;/h3&gt;
















&lt;figure  id=&#34;figure-figure-1-model-overview-we-split-an-image-into-fixed-size-patches-linearly-embed-each-of-them-add-position-embeddings-and-feed-the-resulting-sequence-of-vectors-to-a-standard-transformer-encoder-in-order-to-perform-classification-we-use-the-standard-approach-of-adding-an-extra-learnable-classification-token-to-the-sequence&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Figure 1: Model overview. We split an image into fixed-size patches, linearly embed each of them, add position embeddings, and feed the resulting sequence of vectors to a standard Transformer encoder. In order to perform classification, we use the standard approach of adding an extra learnable “classification token” to the sequence.&#34; srcset=&#34;
               /post/an-image-is-worth-16x16-words-transformers-for-image-recognition-at-scale/featured_hu64a7806ed9e97cb55f87b27af1c0aac1_126427_008558f1b5b4c64ea128a71be8e1da2f.webp 400w,
               /post/an-image-is-worth-16x16-words-transformers-for-image-recognition-at-scale/featured_hu64a7806ed9e97cb55f87b27af1c0aac1_126427_34ce1b785e7793a75231026b8d859947.webp 760w,
               /post/an-image-is-worth-16x16-words-transformers-for-image-recognition-at-scale/featured_hu64a7806ed9e97cb55f87b27af1c0aac1_126427_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://bowenei.gitee.io/post/an-image-is-worth-16x16-words-transformers-for-image-recognition-at-scale/featured_hu64a7806ed9e97cb55f87b27af1c0aac1_126427_008558f1b5b4c64ea128a71be8e1da2f.webp&#34;
               width=&#34;760&#34;
               height=&#34;392&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Figure 1: Model overview. We split an image into fixed-size patches, linearly embed each of them, add position embeddings, and feed the resulting sequence of vectors to a standard Transformer encoder. In order to perform classification, we use the standard approach of adding an extra learnable “classification token” to the sequence.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;朱老师认为，论文的总览图非常重要。总览图画得好，别人在不读整篇文章的情况下光看图就能够大致了解这篇文章在讲什么。&lt;strong&gt;ViT&lt;/strong&gt; 这篇文章的总览图画得非常好，以至于其他人在引用或者讲解 &lt;strong&gt;ViT&lt;/strong&gt; 的时候都是直接把图贴上去而不做任何修改。&lt;/p&gt;
&lt;p&gt;给定一张图片，首先将这张图打成了很多 &lt;code&gt;patch&lt;/code&gt;。然后他把这些 &lt;code&gt;patch&lt;/code&gt; 转化成一个序列，每个 &lt;code&gt;patch&lt;/code&gt; 会通过一个被称为线性投射层的操作得到一个特征，即图中的 &lt;code&gt;Patch + Position Embedding&lt;/code&gt;。我们知道，自注意力机制是所有的元素之间两两去做交互，所以说 attention 本身不存在顺序问题。但是对于图片来说它是一个整体，这个九宫格是有自己的顺序的。如果顺序颠倒了，就不是原来那张图片了，所以就需要 &lt;code&gt;Position Embedding&lt;/code&gt;。加上了位置编码的信息以后，每个 &lt;code&gt;token&lt;/code&gt; 既包括了原本的图像 &lt;code&gt;patch&lt;/code&gt; 信息，又包括了图像 &lt;code&gt;patch&lt;/code&gt; 所在的位置信息。&lt;/p&gt;
&lt;p&gt;接下来实际上就和 NLP 那边是完全一样了。经过 Transformer Encoder 之后，它会给我们很多输出。那么问题来了，应该用哪个输出去做最后的分类呢？这里还需要再次借鉴 BERT&lt;sup id=&#34;fnref:5&#34;&gt;&lt;a href=&#34;#fn:5&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;5&lt;/a&gt;&lt;/sup&gt; 当中的 extra learnable [class] embedding，即特殊字符 &lt;code&gt;cls&lt;/code&gt;。在 &lt;strong&gt;ViT&lt;/strong&gt; 中也加入了一个特殊字符，用 &lt;code&gt;*&lt;/code&gt; 代替，它的位置信息永远是 &lt;code&gt;0&lt;/code&gt;。因为自注意力机制使得每个 &lt;code&gt;token&lt;/code&gt; 之间都在互相学习，用一个空的 &lt;code&gt;token&lt;/code&gt; 就可以和图片的每个 &lt;code&gt;patch&lt;/code&gt; 交互学到完整的图片信息，所以只需要根据 &lt;code&gt;cls&lt;/code&gt; 对应的输出来判断即可。MLP Head 就是一个通用的分类头了，最后再用交叉熵函数去进行模型的训练。&lt;/p&gt;
&lt;p&gt;至于这里的 Transformer Encoder 也是完全标准的，即图中右边的部分。所以说从整体结构上来看，&lt;strong&gt;ViT&lt;/strong&gt; 的结构非常简洁，它的特殊之处就在于如何将一个图片转化成一系列的 &lt;code&gt;token&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;那么下面结合下图 &lt;strong&gt;ViT&lt;/strong&gt; 的 Transformer 部分对 Transformer 模型再做一个回顾。&lt;/p&gt;
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34;
           src=&#34;https://bowenei.gitee.io/post/an-image-is-worth-16x16-words-transformers-for-image-recognition-at-scale/ViT.svg&#34;
           loading=&#34;lazy&#34; data-zoomable class=&#34; img-light&#34; /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;p&gt;首先将输入的图片打成若干 &lt;code&gt;patch&lt;/code&gt;，这里的图片输入大小为 224x224x3，表示宽和高为 224 像素，RGB 3 通道。&lt;code&gt;patch&lt;/code&gt; 的大小为 16x16x3，因此原图被划分为 $14 \times 14 = 196$ 个 &lt;code&gt;patch&lt;/code&gt;。再加上 &lt;code&gt;cls&lt;/code&gt;，序列的总长度为 197。&lt;/p&gt;
&lt;p&gt;经过 Embedding 和位置编码之后，得到维度为 197x768 的 &lt;code&gt;tokens&lt;/code&gt;，因为每个 16x16x3 的 &lt;code&gt;patch&lt;/code&gt; 拉直之后是 $16 \times 16 \times 3 = 768$ 维。&lt;/p&gt;
&lt;p&gt;接下来进行 Self-Attention，需要映射出 3 个矩阵 Query、Key 和 Value。由于 Transformer 的多头自注意力机制，并且 &lt;strong&gt;ViT&lt;/strong&gt; 设置了 $h = 12$ 个头，那么 3 个矩阵的维度均为 197x64，因为 $768 \div 12 = 64$。最后经过拼接 &lt;code&gt;Concat&lt;/code&gt; 得到 197x768 维的 Attention 矩阵。&lt;/p&gt;
&lt;p&gt;最后经过 MLP 全连接层，一般先把维度放大 4 倍，即 197x3012，再回到原来的维度上输出。这就是 Transformer 一层 Encoder 上的计算过程。&lt;/p&gt;
&lt;h4 id=&#34;inductive-bias&#34;&gt;Inductive bias&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;We note that Vision Transformer has much less image-specific inductive bias than CNNs. In CNNs, locality, two-dimensional neighborhood structure, and translation equivariance are baked into each layer throughout the whole model. In ViT, only MLP layers are local and translationally equivariant, while the self-attention layers are global. The two-dimensional neighborhood structure is used very sparingly: in the beginning of the model by cutting the image into patches and at fine-tuning time for adjusting the position embeddings for images of different resolution (as described below). Other than that, the position embeddings at initialization time carry no information about the 2D positions of the patches and all spatial relations between the patches have to be learned from scratch.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;作者还补充了归纳偏置的一些细节。&lt;strong&gt;ViT&lt;/strong&gt; 相较于 CNN 而言要少很多这种图像特有的归纳偏置，例如 CNN 当中有平移性和模型的局部等变性（详见前文）。但是对于 &lt;strong&gt;ViT&lt;/strong&gt; 来说，MLP 是有上述的这些归纳偏置的，但是自注意力层是全局的 &lt;code&gt;global&lt;/code&gt;，即图片的 2D 信息自注意力层没怎么用。（基本上仅仅只是 Position Embedding 的时候用到了。）另外，位置编码也是随机初始化的，并没有携带任何 2D 信息，所有的 &lt;code&gt;patch&lt;/code&gt; 之间的距离信息、场景信息都得重头学。&lt;/p&gt;
&lt;p&gt;作者补充这一段的目的是为了给后面在中小数据集上 &lt;strong&gt;ViT&lt;/strong&gt; 不如 CNN 的实验结果的解释做铺垫。那么既然如此，Transformer 在全局上表现如此优秀，CNN 又在中小数据集上快速收敛，是不是可以将它们结合起来？&lt;/p&gt;
&lt;h4 id=&#34;hybrid-architecture&#34;&gt;Hybrid Architecture&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;As an alternative to raw image patches, the input sequence can be formed from feature maps of a CNN (LeCun et al., 1989). In this hybrid model, the patch embedding projection E (Eq. 1) is applied to patches extracted from a CNN feature map. As a special case, the patches can have spatial size 1x1, which means that the input sequence is obtained by simply flattening the spatial dimensions of the feature map and projecting to the Transformer dimension. The classification input embedding and position embeddings are added as described above.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;其实将 Transformer 和 CNN 的想法是可行的。我们假设现在不把图片打成 &lt;code&gt;patch&lt;/code&gt; 了，而是用一个 16x16 的卷积核去对原始图片进行卷积（步长也为 16），得到的也是一个 14x14 的特征图。后续的操作和 &lt;strong&gt;ViT&lt;/strong&gt; 一样，将特征图的每个像素当成 NLP 任务送入 Transformer Encoder 中。&lt;/p&gt;
&lt;h3 id=&#34;fine-tuning-and-higher-resolution&#34;&gt;Fine-tuning and Higher Resolution&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;When feeding images of higher resolution, we keep the patch size the same, which results in a larger effective sequence length. The Vision Transformer can handle arbitrary sequence lengths (up to memory constraints), however, the pre-trained position embeddings may no longer be meaningful. We therefore perform 2D interpolation of the pre-trained position embeddings, according to their location in the original image. Note that this resolution adjustment and patch extraction are the only points at which an inductive bias about the 2D structure of the images is manually injected into the Vision Transformer.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;微调 &lt;code&gt;fine-tuning&lt;/code&gt; 是指预训练好的 &lt;strong&gt;ViT&lt;/strong&gt; 模型（输入图片为 224x224x3）在更大尺寸的图片（例如 320x320x3）上进行“刷脸”。但是，这对于预训练好的 &lt;strong&gt;ViT&lt;/strong&gt; 有些麻烦，因为如果 &lt;code&gt;patch&lt;/code&gt; 的大小不变，而图片变大了，于是序列变长了。从理论上说，Transformer 可以处理任意长度的序列。但是，提前训练好的位置编码可能就完全没用了，因为预训练好的位置编码具有明确的物理意义。那么预训练的位置编码还是否有用呢？作者发现，再做一个 2D 的差值就可以了。但这里的差值也仅仅只是一个临时的解决方案，应该说这算是 &lt;strong&gt;ViT&lt;/strong&gt; 在微调的时候的一个局限性。&lt;/p&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    至此，已经可以基本了解 &lt;strong&gt;ViT&lt;/strong&gt; 的基本架构了。后面实验部分以及附录的有关说明，如有需要再进行补充。
  &lt;/div&gt;
&lt;/div&gt;

&lt;h2 id=&#34;experiments&#34;&gt;Experiments&lt;/h2&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Beal J, Kim E, Tzeng E, et al. Toward transformer-based object detection[J]. arXiv preprint arXiv:2012.09958, 2020.&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Zheng S, Lu J, Zhao H, et al. Rethinking semantic segmentation from a sequence-to-sequence perspective with transformers[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2021: 6881-6890.&amp;#160;&lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:3&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Liu Z, Lin Y, Cao Y, et al. Swin transformer: Hierarchical vision transformer using shifted windows[J]. arXiv preprint arXiv:2103.14030, 2021.&amp;#160;&lt;a href=&#34;#fnref:3&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:4&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Zhai X, Kolesnikov A, Houlsby N, et al. Scaling vision transformers[J]. arXiv preprint arXiv:2106.04560, 2021.&amp;#160;&lt;a href=&#34;#fnref:4&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:5&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Devlin J, Chang M W, Lee K, et al. Bert: Pre-training of deep bidirectional transformers for language understanding[J]. arXiv preprint arXiv:1810.04805, 2018.&amp;#160;&lt;a href=&#34;#fnref:5&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:6&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Radford A, Narasimhan K, Salimans T, et al. Improving language understanding by generative pre-training[J]. 2018.&amp;#160;&lt;a href=&#34;#fnref:6&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:7&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;He K, Chen X, Xie S, et al. Masked autoencoders are scalable vision learners[J]. arXiv preprint arXiv:2111.06377, 2021.&amp;#160;&lt;a href=&#34;#fnref:7&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;</description>
    </item>
    
    <item>
      <title>Attention Is All You Need</title>
      <link>https://bowenei.gitee.io/post/attention-is-all-you-need/</link>
      <pubDate>Tue, 09 Nov 2021 22:59:13 +0800</pubDate>
      <guid>https://bowenei.gitee.io/post/attention-is-all-you-need/</guid>
      <description>&lt;p&gt;&lt;strong&gt;Transformer&lt;/strong&gt; 是目前人工智能和深度学习领域最著名的模型之一，由 Google 团队于 2017 年 6 月提出，发表在 NeuralPS（Conference on Neural Information Processing Systems）上。起初是为了解决自然语言处理（Natural Language Processing, NLP）领域中的机器翻译问题，没想到它的效果竟然超越了循环神经网络（Recurrent Neural Networks, RNN），只需要用 &lt;code&gt;encoder&lt;/code&gt; 和 &lt;code&gt;decoder&lt;/code&gt; 以及注意力 &lt;code&gt;attention&lt;/code&gt; 机制就可以达到很好的效果。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Transformer&lt;/strong&gt; 本身是专门为 NLP 领域量身定制的，但是后来人们将图像等数据编码和序列化之后同样可以放进 &lt;strong&gt;Transformer&lt;/strong&gt; 中进行训练，并且也能让模型达到和卷积神经网络（Convolutional Neural Networks, CNN）和深度神经网络（Deep Neural Networks, DNN）相比更加出其不意的效果。这才让 &lt;strong&gt;Transformer&lt;/strong&gt; 在计算机视觉领域大火了起来。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://dl.acm.org/doi/abs/10.5555/3295222.3295349&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;原文链接&lt;/a&gt;&lt;/p&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    &lt;p&gt;&lt;strong&gt;特别鸣谢&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;本文结合亚马逊首席科学家&lt;a href=&#34;https://github.com/mli&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;李沐&lt;/a&gt;的&lt;a href=&#34;https://www.bilibili.com/video/BV1pu411o7BE&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;深度学习论文精读系列视频&lt;/a&gt;进行整理。&lt;/p&gt;

  &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;这篇文章最具特色的就是标题 Attention Is All You Need，翻译成中文就是“你需要注意”。后来这个标题成为了一个梗，即 xxx Is All You Need。&lt;/p&gt;
&lt;p&gt;值得注意的是，这篇文章的每一位作者后面都打了 &lt;code&gt;*&lt;/code&gt; 号，这说明这几位作者的贡献是均等的，论文首先下的注释已经充分说明了这一点。通常我们会认为论文的第一作者是主要贡献者，但是这篇文章是个例外。&lt;/p&gt;
&lt;details class=&#34;toc-inpage d-print-none  &#34; open&gt;
  &lt;summary class=&#34;font-weight-bold&#34;&gt;Table of Contents&lt;/summary&gt;
  &lt;nav id=&#34;TableOfContents&#34;&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;a href=&#34;#abstract&#34;&gt;Abstract&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#7-conclusion&#34;&gt;7 Conclusion&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#1-introduction&#34;&gt;1 Introduction&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#2-background&#34;&gt;2 Background&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#3-model-architecture&#34;&gt;3 Model Architecture&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#31-encoder-and-decoder-stacks&#34;&gt;3.1 Encoder and Decoder Stacks&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#32-attention&#34;&gt;3.2 Attention&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#33-position-wise-feed-forward-networks&#34;&gt;3.3 Position-wise Feed-Forward Networks&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#34-embeddings-and-softmax&#34;&gt;3.4 Embeddings and Softmax&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#35-positional-encoding&#34;&gt;3.5 Positional Encoding&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#4-why-self-attention&#34;&gt;4 Why Self-Attention&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#5-training&#34;&gt;5 Training&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#51-training-data-and-batching&#34;&gt;5.1 Training Data and Batching&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#52-hardware-and-schedule&#34;&gt;5.2 Hardware and Schedule&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#53-optimizer&#34;&gt;5.3 Optimizer&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#54-regularization&#34;&gt;5.4 Regularization&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#6-results&#34;&gt;6 Results&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#61-machine-translation&#34;&gt;6.1 Machine Translation&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#62-model-variations&#34;&gt;6.2 Model Variations&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
  &lt;/ul&gt;
&lt;/nav&gt;
&lt;/details&gt;

&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;The dominant sequence transduction models are based on complex recurrent or convolutional neural networks that include an encoder and a decoder. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 Englishto-German translation task, improving over the existing best results, including ensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.0 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;所谓序列转录模型 &lt;code&gt;sequence transduction models&lt;/code&gt; 是指输入为一个序列，输出也为一个序列的模型。例如在机器翻译中，输入一段中文，然后输出其对应的英文翻译。当时（作者写这篇文章的时候），主流的序列转录模型主要基于复杂的 CNN 和 RNN，一般采用 &lt;code&gt;encoder&lt;/code&gt; 和 &lt;code&gt;decoder&lt;/code&gt; 架构。作者提出了一种基于注意力机制 &lt;code&gt;attention mechanisms&lt;/code&gt; 的网络结构 &lt;strong&gt;Transformer&lt;/strong&gt;。作者做了两个机器翻译的实验，证明了他们提出的模型效果非常好。&lt;/p&gt;
&lt;h2 id=&#34;7-conclusion&#34;&gt;7 Conclusion&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;In this work, we presented the Transformer, the first sequence transduction model based entirely on attention, replacing the recurrent layers most commonly used in encoder-decoder architectures with multi-headed self-attention.&lt;/p&gt;
&lt;p&gt;For translation tasks, the Transformer can be trained significantly faster than architectures based on recurrent or convolutional layers. On both WMT 2014 English-to-German and WMT 2014 English-to-French translation tasks, we achieve a new state of the art. In the former task our best model outperforms even all previously reported ensembles.&lt;/p&gt;
&lt;p&gt;We are excited about the future of attention-based models and plan to apply them to other tasks. We plan to extend the Transformer to problems involving input and output modalities other than text and to investigate local, restricted attention mechanisms to efficiently handle large inputs and outputs such as images, audio and video. Making generation less sequential is another research goals of ours.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;按照沐神读论文的习惯，摘要读完以后直接跳到结论。沐神总结的结论主要有如下几点：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Transformer&lt;/strong&gt; 是当时第一个完全基于注意力的序列转录模型，它把过去常用的循环层全部换成了 &lt;code&gt;multi-headed self-attention&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Transformer&lt;/strong&gt; 在机器翻译的任务中比基于循环层和卷积层的架构要快很多。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Transformer&lt;/strong&gt; 未来可以用在文本以外的数据类型上，例如图像、音频、视频等。现在看来，作者在当时多多少少是预测到未来的研究方向的，我十分佩服！&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/tensorflow/tensor2tensor&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;仓库链接&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;1-introduction&#34;&gt;1 Introduction&lt;/h2&gt;
&lt;p&gt;这篇文章的导言 &lt;code&gt;Introduction&lt;/code&gt; 相对来说比较短，基本上是摘要 &lt;code&gt;Abstract&lt;/code&gt; 的扩充。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Recurrent neural networks, long short-term memory&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt; and gated recurrent&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt; neural networks in particular, have been firmly established as state of the art approaches in sequence modeling and transduction problems such as language modeling and machine translation. Numerous efforts have since continued to push the boundaries of recurrent language models and encoder-decoder architectures.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;当时机器翻译最常用的模型是 RNN，主要包括如下两个著名的网络模型：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;LSTM&lt;/strong&gt; (Long Short-Term Memory): 长短期记忆网络。它是一种时间循环神经网络，是为了解决一般的 RNN 存在的长期依赖问题而专门设计出来的，所有的 RNN 都具有一种重复神经网络模块的链式形式。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;GRU&lt;/strong&gt; (Gate Recurrent Unit): 门控循环单元。是 LSTM 网络的一种效果很好的变体，它较 LSTM 网络的结构更加简单，而且效果也很好，因此也是当前非常流形的一种网络。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;后续的工作主要围绕着循环语言模型 &lt;code&gt;recurrent language models&lt;/code&gt; 和编码器/解码器 &lt;code&gt;encoder-decoder&lt;/code&gt; 架构展开。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Recurrent models typically factor computation along the symbol positions of the input and output sequences.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;RNN 的特点是序列从左向右移一步一步往前做。当前时刻 $t$ 的隐藏状态 &lt;code&gt;hidden states&lt;/code&gt; 记作 $h_t$，它由上一个隐藏状态 $h_{t-1}$ 和当前时刻 $t$ 的输入决定。这就是为什么 RNN 能够处理时序信息的原因。也正因为 RNN 的这一特点，导致 RNN 存在如下问题：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;计算难以并行，主流的多线程 GPU 只能按照时序一个一个计算。&lt;/li&gt;
&lt;li&gt;序列长度和 $h_t$ 的长度之间的矛盾。如果序列长度特别长而 $h_t$ 不够长的话，前面的信息很可能会丢掉；但如果 $h_t$ 也设计得很长的话，内存开销太大。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;针对 RNN 的这些问题，近年来的改进工作很多，但都没有从根本上解决问题。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Attention mechanisms have become an integral part of compelling sequence modeling and transduction models in various tasks, allowing modeling of dependencies without regard to their distance in the input or output sequences.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;注意力机制并不是本文的创新点。在现有的工作中，注意力机制已经被成功地用在编码器/解码器里面了。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;In this work we propose the Transformer, a model architecture eschewing recurrence and instead relying entirely on an attention mechanism to draw global dependencies between input and output. The Transformer allows for significantly more parallelization and can reach a new state of the art in translation quality after being trained for as little as twelve hours on eight P100 GPUs.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;作者在本文提出的 &lt;strong&gt;Transformer&lt;/strong&gt; 则与 RNN 不同，是完全依赖注意力机制的一种模型架构。作者特别强调了他们在训练时候的并行性 &lt;code&gt;parallelization&lt;/code&gt;。&lt;/p&gt;
&lt;h2 id=&#34;2-background&#34;&gt;2 Background&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;The goal of reducing sequential computation also forms the foundation of the Extended Neural GPU, ByteNet and ConvS2S, all of which use convolutional neural networks as basic building block, computing hidden representations in parallel for all input and output positions.&lt;/p&gt;
&lt;p&gt;In the Transformer this is reduced to a constant number of operations, albeit at the cost of reduced effective resolution due to averaging attention-weighted positions, an effect we counteract with Multi-Head Attention as described in section 3.2.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;为了解决 RNN 训练的并行性问题，有很多工作考虑采用 CNN 来代替 RNN 以增加并行性，但问题是 CNN 对长序列难以建模。例如相隔很远的两个像素块，需要多层卷积才能建立起联系。不过卷积计算的好处是可以做多个输出通道，基于此作者提出了多头注意力 &lt;code&gt;Multi-Head Attention&lt;/code&gt; 机制。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Self-attention, sometimes called intra-attention is an attention mechanism relating different positions of a single sequence in order to compute a representation of the sequence.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;接下来就是自注意力 &lt;code&gt;Self-attention&lt;/code&gt; 机制，这其实也是 &lt;strong&gt;Transformer&lt;/strong&gt; 中很重要的一点。不过该工作并不是 &lt;strong&gt;Transformer&lt;/strong&gt; 的创新点，已经有不少相关工作了。&lt;/p&gt;
&lt;h2 id=&#34;3-model-architecture&#34;&gt;3 Model Architecture&lt;/h2&gt;
&lt;p&gt;为了解释清楚 &lt;code&gt;encoder-decoder&lt;/code&gt;，作者首先给出如下 3 个非常重要的定义：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$\left(x_1, x_2, &amp;hellip;, x_n\right)$：表示一个序列。假设这个序列是一个英文句子，那么 $x_t$ 就表示第 $t$ 个单词。&lt;/li&gt;
&lt;li&gt;$\textbf{z} = \left(z_1, z_2, &amp;hellip;, z_n\right)$：编码器的输出。$z_t$ 是 $x_t$ 的一个向量表示。&lt;/li&gt;
&lt;li&gt;$\left(y_1, y_2, &amp;hellip;, y_m\right)$：编码器的输出，是一个长为 $m$ 的序列。和编码器不同的是，解码器的词是一个个生成的，这叫做自回归 &lt;code&gt;auto-regressive&lt;/code&gt;。自回归的意思是当前的输出也会作为输入参与下一轮的输出。换句话说就是，翻译的结果出来是一个个词往外蹦儿的。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这样也就弄清楚 &lt;strong&gt;Transformer&lt;/strong&gt; 的输入和输出了，后文则主要对这里面的每个块进行说明。&lt;/p&gt;
















&lt;figure  id=&#34;figure-the-transformer---model-architecture&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;The Transformer - model architecture.&#34; srcset=&#34;
               /post/attention-is-all-you-need/featured_hu8b54ce84adafe40779efe33571820b6c_96849_69939f503c2e2d5c874ab43c5d89ab3f.webp 400w,
               /post/attention-is-all-you-need/featured_hu8b54ce84adafe40779efe33571820b6c_96849_7401b658ad7641a955eec6102478b257.webp 760w,
               /post/attention-is-all-you-need/featured_hu8b54ce84adafe40779efe33571820b6c_96849_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://bowenei.gitee.io/post/attention-is-all-you-need/featured_hu8b54ce84adafe40779efe33571820b6c_96849_69939f503c2e2d5c874ab43c5d89ab3f.webp&#34;
               width=&#34;536&#34;
               height=&#34;760&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption data-pre=&#34;Figure&amp;nbsp;&#34; data-post=&#34;:&amp;nbsp;&#34; class=&#34;numbered&#34;&gt;
      The Transformer - model architecture.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;h3 id=&#34;31-encoder-and-decoder-stacks&#34;&gt;3.1 Encoder and Decoder Stacks&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Encoder&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;layers: $N=6$&lt;/li&gt;
&lt;li&gt;sub-layers:
&lt;ul&gt;
&lt;li&gt;multi-head self-attention mechanism: 多头自注意力机制&lt;/li&gt;
&lt;li&gt;position-wise fully connected feed-forward network: 本质上就是一个 MLP（多层感知机，Multilayer Perceptron）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;output: $\textrm{LayerNorm}(x + \textrm{Sublayer}(x))$&lt;/li&gt;
&lt;li&gt;dimension: $d_{model} = 512$&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    &lt;p&gt;&lt;strong&gt;BatchNorm 和 LayerNorm 的区别&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;沐神就 &lt;code&gt;BatchNorm&lt;/code&gt; 和 &lt;code&gt;LayerNorm&lt;/code&gt; 的区别作了详细讲解。我们知道，&lt;code&gt;Norm&lt;/code&gt; 即 &lt;code&gt;Normalization&lt;/code&gt;，对数据进行归一化处理。这和概率论中对随机变量进行标准化的操作类似，即把原向量化为均值为 $0$ 方差为 $1$ 的标准化向量。&lt;/p&gt;
&lt;p&gt;\begin{align}
Y = \frac{X - \mu}{\sigma}
\end{align}&lt;/p&gt;
&lt;p&gt;如图所示，&lt;code&gt;BatchNorm&lt;/code&gt; 和 &lt;code&gt;LayerNorm&lt;/code&gt; 的区别一目了然。&lt;code&gt;BatchNorm&lt;/code&gt; 是在每一个特征 &lt;code&gt;feature&lt;/code&gt; 上对 &lt;code&gt;batch&lt;/code&gt; 进行归一化，而 &lt;code&gt;LayerNorm&lt;/code&gt; 是在每一个样本 &lt;code&gt;batch&lt;/code&gt; 上对 &lt;code&gt;feature&lt;/code&gt; 进行归一化。&lt;/p&gt;
&lt;figure  id=&#34;figure-difference-between-batchnorm-and-layernorm&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Difference between BatchNorm and LayerNorm.&#34; srcset=&#34;
               /post/attention-is-all-you-need/layernorm-batchnorm_huf61da6cf384951cc94fe6d875380b93b_18215_3780baf8790d7bad91ed2224590b2089.webp 400w,
               /post/attention-is-all-you-need/layernorm-batchnorm_huf61da6cf384951cc94fe6d875380b93b_18215_190a222c2ad3ad97c203eeb42329026d.webp 760w,
               /post/attention-is-all-you-need/layernorm-batchnorm_huf61da6cf384951cc94fe6d875380b93b_18215_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://bowenei.gitee.io/post/attention-is-all-you-need/layernorm-batchnorm_huf61da6cf384951cc94fe6d875380b93b_18215_3780baf8790d7bad91ed2224590b2089.webp&#34;
               width=&#34;657&#34;
               height=&#34;276&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption data-pre=&#34;Figure&amp;nbsp;&#34; data-post=&#34;:&amp;nbsp;&#34; class=&#34;numbered&#34;&gt;
      Difference between BatchNorm and LayerNorm.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;为什么要使用 &lt;code&gt;LayerNorm&lt;/code&gt; 呢？一个原因是样本长度可能发生变化（即 &lt;code&gt;sequence&lt;/code&gt; 的长度 $n$），如果使用 &lt;code&gt;BatchNorm&lt;/code&gt; 的话，切片的结果可能长度参差不齐，会有很多零填充。而使用 &lt;code&gt;LayerNorm&lt;/code&gt; 则不会出现这样的问题，因为是同一个样本（即同一个序列）。由于序列长度不一有零填充，计算均值和方差的时候每个样本的计算方法不一样，不能把零算进去，因为零不是有效值。&lt;/p&gt;
&lt;p&gt;还有一点原因是，假如在做预测的时候，序列特别特别长以至于训练所得的均值和方差并不好用。而使用 &lt;code&gt;LayerNorm&lt;/code&gt; 则不会出现这样的问题，因为它是每个样本独立计算的，最后也并不像 &lt;code&gt;BatchNorm&lt;/code&gt; 那样需要算出一个全局的均值和方差。因此不管序列有多长，均值和方差都是在序列本身的基础上算的。&lt;/p&gt;

  &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Decoder&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;layers: $N=6$&lt;/li&gt;
&lt;li&gt;sub-layers:
&lt;ul&gt;
&lt;li&gt;multi-head self-attention mechanism: 和 &lt;code&gt;encoder&lt;/code&gt; 相同&lt;/li&gt;
&lt;li&gt;position-wise fully connected feed-forward network: 和 &lt;code&gt;encoder&lt;/code&gt; 相同&lt;/li&gt;
&lt;li&gt;masked multi-head attention: 带掩码的多头注意力机制&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;masking: 确保位置 $i$ 的预测只能依赖于小于 $i$ 位置的已知输出。因为训练时 &lt;code&gt;decoder&lt;/code&gt; 的输入是上面一些时刻在 &lt;code&gt;encoder&lt;/code&gt; 的输出，不应该看到后面时刻的输入。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;32-attention&#34;&gt;3.2 Attention&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;An attention function can be described as mapping a query and a set of key-value pairs to an output, where the query, keys, values, and output are all vectors. The output is computed as a weighted sum of the values, where the weight assigned to each value is computed by a compatibility function of the query with the corresponding key.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;注意力函数是将 &lt;code&gt;query&lt;/code&gt; 和一些键值对 &lt;code&gt;key-value pairs&lt;/code&gt; 映射成一个输出 &lt;code&gt;output&lt;/code&gt; 的函数，这里面的 &lt;code&gt;query&lt;/code&gt;、&lt;code&gt;keys&lt;/code&gt;、&lt;code&gt;values&lt;/code&gt;、&lt;code&gt;output&lt;/code&gt; 都是向量 &lt;code&gt;vectors&lt;/code&gt;。具体来说，&lt;code&gt;output&lt;/code&gt; 是 &lt;code&gt;values&lt;/code&gt; 的加权，其输出维度和 &lt;code&gt;value&lt;/code&gt; 的维度是一样的。权重是通过每个 &lt;code&gt;value&lt;/code&gt; 对应的 &lt;code&gt;key&lt;/code&gt; 和 &lt;code&gt;query&lt;/code&gt; 计算相似度 &lt;code&gt;compatibility function&lt;/code&gt; 得来的。这里的相似度针对不同的注意力机制有不同的算法。&lt;/p&gt;
&lt;h4 id=&#34;321-scaled-dot-product-attention&#34;&gt;3.2.1 Scaled Dot-Product Attention&lt;/h4&gt;
&lt;p&gt;作者在本小节主要说明了 &lt;strong&gt;Transformer&lt;/strong&gt; 采用的注意力机制。作者将之命名为 &lt;code&gt;Scaled Dot-Product Attention&lt;/code&gt;，如图所示。&lt;/p&gt;
















&lt;figure  id=&#34;figure-scaled-dot-product-attention&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Scaled Dot-Product Attention.&#34; srcset=&#34;
               /post/attention-is-all-you-need/Scaled%20Dot-Product%20Attention_hu70c1dc728f23523ace7510001a2e738b_44270_c58055229fb3f7179931f9e847824dec.webp 400w,
               /post/attention-is-all-you-need/Scaled%20Dot-Product%20Attention_hu70c1dc728f23523ace7510001a2e738b_44270_e6cb6d0f00c311b886504a93a84edf8a.webp 760w,
               /post/attention-is-all-you-need/Scaled%20Dot-Product%20Attention_hu70c1dc728f23523ace7510001a2e738b_44270_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://bowenei.gitee.io/post/attention-is-all-you-need/Scaled%20Dot-Product%20Attention_hu70c1dc728f23523ace7510001a2e738b_44270_c58055229fb3f7179931f9e847824dec.webp&#34;
               width=&#34;415&#34;
               height=&#34;681&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption data-pre=&#34;Figure&amp;nbsp;&#34; data-post=&#34;:&amp;nbsp;&#34; class=&#34;numbered&#34;&gt;
      Scaled Dot-Product Attention.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;注意力函数的计算公式如下：&lt;/p&gt;
&lt;p&gt;\begin{align}
\textrm{Attention}\left(Q, K, V\right) = \textrm{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V
\end{align}&lt;/p&gt;
&lt;p&gt;$Q$ 即 &lt;code&gt;query&lt;/code&gt;，$K$ 即 &lt;code&gt;key&lt;/code&gt;，$QK^T$ 即 &lt;code&gt;query&lt;/code&gt; 和 &lt;code&gt;key&lt;/code&gt; 做内积。作者认为，两个向量的内积值越大，说明相似度越高。除以 $\sqrt{d_k}$ 则表示单位化，然后再用 softmax 得到权重。这里的道理其实就是机器学习中的余弦相似度（余弦距离）：&lt;/p&gt;
&lt;p&gt;\begin{align}
\textrm{similarity} = \cos{\theta} = \frac{\alpha \cdot \beta}{||\alpha|| \cdot ||\beta||}
\end{align}&lt;/p&gt;
&lt;p&gt;注意这里 &lt;code&gt;Mask&lt;/code&gt; 的作用是为了避免 $t$ 时刻看到后面的输入。在数学上的具体实现方式是以一个绝对值非常大的负数（$-\infty$）作为指数，计算出来的幂趋向于零，这样就实现了掩盖 $t$ 时刻后面的输入的效果。&lt;/p&gt;
&lt;h4 id=&#34;322-multi-head-attention&#34;&gt;3.2.2 Multi-Head Attention&lt;/h4&gt;
&lt;p&gt;作者认为，与其计算单个的注意力函数，不如把 &lt;code&gt;query&lt;/code&gt;、&lt;code&gt;key&lt;/code&gt;、&lt;code&gt;value&lt;/code&gt; 投影到一个更低的维度上，投影 $h$ 次，然后再计算 $h$ 次注意力函数，最后每一个函数的输出合并再投影得到最终的输出。如图所示。&lt;/p&gt;
















&lt;figure  id=&#34;figure-multi-head-attention&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Multi-Head Attention.&#34; srcset=&#34;
               /post/attention-is-all-you-need/Multi-Head%20Attention_hua1dcc6ec3dc6caf1927d2a8edcfb7688_72171_b0ffdf9e71d8f398d7da638889de4d27.webp 400w,
               /post/attention-is-all-you-need/Multi-Head%20Attention_hua1dcc6ec3dc6caf1927d2a8edcfb7688_72171_5b175683df723a45c4ed255077096fd1.webp 760w,
               /post/attention-is-all-you-need/Multi-Head%20Attention_hua1dcc6ec3dc6caf1927d2a8edcfb7688_72171_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://bowenei.gitee.io/post/attention-is-all-you-need/Multi-Head%20Attention_hua1dcc6ec3dc6caf1927d2a8edcfb7688_72171_b0ffdf9e71d8f398d7da638889de4d27.webp&#34;
               width=&#34;551&#34;
               height=&#34;685&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption data-pre=&#34;Figure&amp;nbsp;&#34; data-post=&#34;:&amp;nbsp;&#34; class=&#34;numbered&#34;&gt;
      Multi-Head Attention.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;多头注意力函数的计算公式如下：&lt;/p&gt;
&lt;p&gt;\begin{align}
\textrm{MultiHead}\left(Q, K, V\right) &amp;amp;= \textrm{Concat}\left(\textrm{head}_1, &amp;hellip;, \textrm{head}_h\right)W^O \\
\textbf{where}\quad\textrm{head}_i &amp;amp;= \textrm{Attention}\left(QW^Q_i, KW^K_i, VW^V_i\right)
\end{align}&lt;/p&gt;
&lt;p&gt;在本文中作者定义 $h=8$，于是 $d_k = d_v = d_{model}/h = 64$，也就是输出维度。&lt;/p&gt;
&lt;h4 id=&#34;323-applications-of-attention-in-our-model&#34;&gt;3.2.3 Applications of Attention in our Model&lt;/h4&gt;
&lt;p&gt;这一小节作者主要介绍 &lt;strong&gt;Transformer&lt;/strong&gt; 是如何使用注意力的，归结起来一共有如下 3 种情况：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;In &amp;ldquo;encoder-decoder attention&amp;rdquo; layers, the queries come from the previous decoder layer, and the memory keys and values come from the output of the encoder. This allows every position in the decoder to attend over all positions in the input sequence.&lt;/p&gt;
&lt;p&gt;The encoder contains self-attention layers. In a self-attention layer all of the keys, values and queries come from the same place, in this case, the output of the previous layer in the encoder. Each position in the encoder can attend to all positions in the previous layer of the encoder.&lt;/p&gt;
&lt;p&gt;Similarly, self-attention layers in the decoder allow each position in the decoder to attend to all positions in the decoder up to and including that position. We need to prevent leftward information flow in the decoder to preserve the auto-regressive property. We implement this inside of scaled dot-product attention by masking out (setting to $-\infty$) all values in the input of the softmax which correspond to illegal connections.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;encoder&lt;/code&gt; 的 &lt;code&gt;Multi-Head Attention&lt;/code&gt; 以 &lt;code&gt;key&lt;/code&gt;、&lt;code&gt;value&lt;/code&gt;、&lt;code&gt;query&lt;/code&gt; 作为输入。图中的箭头一分为三，表示同一数据复制三次，这就叫做自注意力机制。输出的维度和输入一致。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;decoder&lt;/code&gt; 的 &lt;code&gt;Masked Multi-Head Attention&lt;/code&gt; 和 &lt;code&gt;encoder&lt;/code&gt; 的 &lt;code&gt;Multi-Head Attention&lt;/code&gt; 类似，只不过需要掩盖后面的输入，前文已详述。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;decoder&lt;/code&gt; 的 &lt;code&gt;Multi-Head Attention&lt;/code&gt; 则不再像 &lt;code&gt;encoder&lt;/code&gt; 那样是自注意力了，而是 &lt;code&gt;key&lt;/code&gt; 和 &lt;code&gt;value&lt;/code&gt; 来自于编码器的输出，&lt;code&gt;query&lt;/code&gt; 来自于解码器下一个 &lt;code&gt;attention&lt;/code&gt; 的输入。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;为了更便于大家理解，沐神举了一个非常简单的机器翻译的例子：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Hello world&lt;/p&gt;
&lt;p&gt;你好世界&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;显然，输入的英文序列 $n=2$，输出的中文序列 $m=4$。当 &lt;strong&gt;Transformer&lt;/strong&gt; 在计算“好”字时，把“好”字对应的向量作为 &lt;code&gt;query&lt;/code&gt; 时，计算和 &lt;code&gt;Hello&lt;/code&gt; 对应的向量的相似度会更高一些，就会赋一个较大的权重。这就是注意力机制给我们最直观的感受！&lt;/p&gt;
&lt;h3 id=&#34;33-position-wise-feed-forward-networks&#34;&gt;3.3 Position-wise Feed-Forward Networks&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;In addition to attention sub-layers, each of the layers in our encoder and decoder contains a fully connected feed-forward network, which is applied to each position separately and identically. This consists of two linear transformations with a ReLU activation in between.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;\begin{align}
\textrm{FFN}\left(x\right) = \max \left(0, xW_1 + b_1\right)W_2 + b_2
\end{align}&lt;/p&gt;
&lt;p&gt;在注意力层之后，&lt;code&gt;encoder&lt;/code&gt; 和 &lt;code&gt;decoder&lt;/code&gt; 都会有一个前馈网络层，首先是一个全连接层，然后是 ReLU 激活函数，最后再过一个全连接层。&lt;/p&gt;
&lt;h3 id=&#34;34-embeddings-and-softmax&#34;&gt;3.4 Embeddings and Softmax&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;Similarly to other sequence transduction models, we use learned embeddings to convert the input tokens and output tokens to vectors of dimension $d_{model}$. We also use the usual learned linear transformation and softmax function to convert the decoder output to predicted next-token probabilities.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;code&gt;Embeddings&lt;/code&gt; 将输入的每一个词 &lt;code&gt;token&lt;/code&gt; 映射成维度为 $d_{model}$ 的向量。&lt;code&gt;Softmax&lt;/code&gt; 的作用是归一化。&lt;/p&gt;
&lt;h3 id=&#34;35-positional-encoding&#34;&gt;3.5 Positional Encoding&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;Since our model contains no recurrence and no convolution, in order for the model to make use of the order of the sequence, we must inject some information about the relative or absolute position of the tokens in the sequence. To this end, we add &amp;ldquo;positional encodings&amp;rdquo; to the input embeddings at the bottoms of the encoder and decoder stacks. The positional encodings have the same dimension $d_{model}$ as the embeddings, so that the two can be summed.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;为什么需要位置编码呢？因为 &lt;code&gt;attention&lt;/code&gt; 本身并没有时序信息，它只是计算了 &lt;code&gt;key&lt;/code&gt; 和 &lt;code&gt;query&lt;/code&gt; 之间的余弦距离，它与序列的时序性无关。例如我们阅读下面这句话：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;序语倒颠不响影读阅。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;我们会觉得有些别扭，因为语义发生变化了。但其实 &lt;code&gt;attention&lt;/code&gt; 在计算的时候根本处理不了这种情况，这个时候就需要把时序信息加进来。与 RNN 不同的是，&lt;strong&gt;Transformer&lt;/strong&gt; 在输入里面加入时序信息，而 RNN 则是以上一时刻的输出作为部分输入。&lt;/p&gt;
&lt;h2 id=&#34;4-why-self-attention&#34;&gt;4 Why Self-Attention&lt;/h2&gt;
&lt;p&gt;本节作者介绍了为什么要采用自注意力机制。沐神认为，作者并没有把这个原因讲得特别清楚。不过，我们可以首先来看看下表：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;Layer Type&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;Complexity per Layer&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;Sequential Operations&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;Maximum Path Length&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Self-Attention&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;$O(n^2 \cdot d)$&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;$O(1)$&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;$O(1)$&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Recurrent&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;$O(n \cdot d^2)$&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;$O(n)$&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;$O(n)$&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Convolutional&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;$O(k \cdot n \cdot d^2)$&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;$O(1)$&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;$O(\log_k{n})$&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Self-Attention (restricted)&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;$O(r \cdot n \cdot d)$&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;$O(1)$&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;$O(n/r)$&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;作者对比了自注意力机制、RNN、CNN 和受限制的 &lt;code&gt;restricted&lt;/code&gt; 自注意力机制的三个方面：计算复杂度、顺序计算、最大路径长度。显然计算复杂度越低越好；顺序计算是指下一步计算必须等前面几步计算完成才能计算，当然越低越好，并行度越高；最大路径长度是指一个序列信息从一个数据点走到另一个数据点需要走多远，当然越短越好。&lt;/p&gt;
&lt;p&gt;这里需要额外解释的是受限制的自注意力机制。为什么相比与自注意力机制，其计算复杂度会有所降低？是因为 &lt;code&gt;query&lt;/code&gt; 只跟最近的 $r$ 个邻居做运算。但带来的问题是最大路径长度的增加。&lt;/p&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    至此，已经可以基本了解 &lt;strong&gt;Transformer&lt;/strong&gt; 的基本架构了。后面的章节是训练和模型效果，如有需要再进行补充。
  &lt;/div&gt;
&lt;/div&gt;

&lt;h2 id=&#34;5-training&#34;&gt;5 Training&lt;/h2&gt;
&lt;h3 id=&#34;51-training-data-and-batching&#34;&gt;5.1 Training Data and Batching&lt;/h3&gt;
&lt;h3 id=&#34;52-hardware-and-schedule&#34;&gt;5.2 Hardware and Schedule&lt;/h3&gt;
&lt;h3 id=&#34;53-optimizer&#34;&gt;5.3 Optimizer&lt;/h3&gt;
&lt;h3 id=&#34;54-regularization&#34;&gt;5.4 Regularization&lt;/h3&gt;
&lt;h2 id=&#34;6-results&#34;&gt;6 Results&lt;/h2&gt;
&lt;h3 id=&#34;61-machine-translation&#34;&gt;6.1 Machine Translation&lt;/h3&gt;
&lt;h3 id=&#34;62-model-variations&#34;&gt;6.2 Model Variations&lt;/h3&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Hochreiter S, Schmidhuber J. Long short-term memory[J]. Neural computation, 1997, 9(8): 1735-1780.&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Chung J, Gulcehre C, Cho K H, et al. Empirical evaluation of gated recurrent neural networks on sequence modeling[J]. arXiv preprint arXiv:1412.3555, 2014.&amp;#160;&lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;</description>
    </item>
    
    <item>
      <title>Edge Intelligence: Architectures, Challenges, and Applications</title>
      <link>https://bowenei.gitee.io/post/edge-intelligence-architectures-challenges-and-applications/</link>
      <pubDate>Thu, 08 Jul 2021 11:53:13 +0800</pubDate>
      <guid>https://bowenei.gitee.io/post/edge-intelligence-architectures-challenges-and-applications/</guid>
      <description>&lt;p&gt;这篇关于边缘智能的综述文章最近一次修订时间为2020年12月。这篇文章的作者将边缘智能的相关工作分为四大部分：边缘缓存、边缘训练、边缘推断、边缘卸载，并且针对每部分研究工作进行了深入的文献调研和阐述分析。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/2003.12172&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;原文链接&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;Edge intelligence refers to a set of connected systems and devices for data collection, caching, processing, and analysis proximity to where data is captured based on artificial intelligence. Edge intelligence aims at enhancing data processing and protect the privacy and security of the data and users. Although recently emerged, spanning the period from 2011 to now, this field of research has shown explosive growth over the past five years. In this paper, we present a thorough and comprehensive survey on the literature surrounding edge intelligence. We first identify four fundamental components of edge intelligence, i.e. edge caching, edge training, edge inference, and edge offloading based on theoretical and practical results pertaining to proposed and deployed systems. We then aim for a systematic classification of the state of the solutions by examining research results and observations for each of the four components and present a taxonomy that includes practical problems, adopted techniques, and application goals. For each category, we elaborate, compare and analyse the literature from the perspectives of adopted techniques, objectives, performance, advantages and drawbacks, etc. This article provides a comprehensive survey to edge intelligence and its application areas. In addition, we summarise the development of the emerging research fields and the current stateof-the-art and discuss the important open issues and possible theoretical and technical directions.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;作者在摘要中首先指出了边缘智能的四个基本组成部分：边缘缓存、边缘训练、边缘推断、边缘卸载；然后对这四部分的研究成果进行系统分类，从采用的技术、目标、性能、优点和缺点等角度对文献进行阐述、比较和分析；最后总结了新兴研究领域的发展和当前的技术水平，并讨论了重要的开放问题和可能的理论和技术方向。&lt;/p&gt;
&lt;h2 id=&#34;i-introduction&#34;&gt;I. Introduction&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;With the breakthrough of Artificial Intelligence (AI), we are witnessing a booming increase in AI-based applications and services.&lt;/p&gt;
&lt;p&gt;However, existing intelligent applications are computationintensive, which present strict requirements on resources, e.g., CPU, GPU, memory, and network, which makes it impossible to be available anytime and anywhere for end users. Although current end devices are increasingly powerful, it is still insufficient to support some deep learning models.&lt;/p&gt;
&lt;p&gt;Moreover, existing intelligent applications generally adopt centralised data management, which requires users to upload their data to central cloud based data-centre.&lt;/p&gt;
&lt;p&gt;However, there is giant volume of data which has been generated and collected by billions of mobile users and Internet of Thing (IoT) devices distributed at the network edge. Uploading such volume of data to the cloud consumes significant bandwidth resources, which would also result in unacceptable latency for users.&lt;/p&gt;
&lt;p&gt;On the other hand, users increasingly concern their privacy. If mobile users upload their personal data to the cloud for a specific intelligent application, they would take the risk of privacy leakage, i.e., the personal data might be extracted by malicious hackers or companies for illegal purposes.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;作者首先指出了研究的背景：人工智能应用和服务的飞速发展。但是，这些智能应用和服务存在一些问题，归结起来主要是以下三点：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;终端计算资源不足&lt;/strong&gt;：现有的智能应用程序是计算密集型的，对资源提出了严格的要求。虽然目前的终端设备越来越强大，但仍然不足以支持一些深度学习模型。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;集中式云计算架构高时延&lt;/strong&gt;：现有的智能应用程序通常采用集中式数据管理，这要求用户将其数据上传到基于云的中央数据中心。然而，网络边缘的用户数量十分庞大，将如此大量的数据上传到云中会消耗大量的带宽资源，这也将导致用户无法接受的延迟。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;用户隐私安全问题&lt;/strong&gt;：如果移动用户将他们的个人数据上传到云上用于特定的智能应用，他们将承担隐私泄露的风险。&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;The main advantages of the edge computing paradigm could be summarised into three aspects. (i) Ultra-low latency: computation usually takes place in the proximity of the source data, which saves substantial amounts of time on data transmission. Edge servers provides nearly real-time responses to end devices. (ii) Saving energy for end devices: since end devices could offload computing tasks to edge servers, the energy consumption on end devices would significantly shrink. Consequently, the battery life of end devices would be extended. (iii) Scalability: cloud computing is still available if there are no enough resource on edge devices or edge servers. In such a case, the cloud server would help to perform tasks. In addition, end devices with idle resources could communicate amongst themselves to collaboratively finish a task. The capability of the edge computing paradigm is flexible to accommodate different application scenarios.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;因此，接下来作者顺理成章地提出了边缘计算的概念。作者首先阐述了边缘计算范式的三点优势：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;超低延迟&lt;/strong&gt;：计算通常在源数据附近进行，这节省了大量数据传输时间。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;为终端设备节省能源&lt;/strong&gt;：由于终端设备可以将计算任务卸载到边缘服务器，终端设备上的能耗将大幅减少。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;可扩展性&lt;/strong&gt;：如果边缘设备或边缘服务器上没有足够的资源，云计算仍然可用。在这种情况下，云服务器将有助于执行任务。此外，拥有空闲资源的终端设备可以相互通信，以协作方式完成任务。边缘计算范式的能力是灵活的，以适应不同的应用场景。&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;Edge computing addresses the critical challenges of AI based applications and the combination of edge computing and AI provides a promising solution. This new paradigm of intelligence is called edge intelligence, also named mobile intelligence.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;边缘计算解决了基于人工智能的应用程序的关键挑战，边缘计算和人工智能的结合提供了一个有前途的解决方案。这种新的智能范式被称为&lt;strong&gt;边缘智能&lt;/strong&gt;，也称为移动智能。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;It is also worth noting that AI could also be a powerful assistance for edge computing. This paradigm is called intelligent edge, which is different from edge intelligence. The emphasis of edge intelligence is to realize intelligent applications in edge environment with the assistance of edge computing and protect users’ privacy, while intelligent edge focuses on solving problems of edge computing with AI solutions, e.g., resource allocation optimization. Intelligent edge is out of our scope in this survey.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;同样值得注意的是，人工智能也可以成为边缘计算的有力辅助。这种范式称为智能边缘，不同于边缘智能。边缘智能的重点是借助边缘计算在边缘环境中实现智能应用，保护用户隐私，而智能边缘则侧重于用AI解决方案解决边缘计算的问题，例如资源分配优化。智能边缘并不在作者的调研范围内。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;This paper aims at providing a comprehensive survey to the development and the state-of-the-art of edge intelligence.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;本文旨在对边缘智能的发展和现状进行全面综述。这方面已有很多相关工作，作者在介绍中主要提到了以下几个方面：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;（边缘环境下的）联邦学习&lt;/li&gt;
&lt;li&gt;边缘智能深度学习模型训练与推理（包括模型设计、模型压缩和模型加速等角度）&lt;/li&gt;
&lt;li&gt;卸载策略和缓存策略&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;Our survey focuses on how to realise edge intelligence in a systematic way. There exist three key components in AI, i.e. data, model/algorithm, and computation. A complete process of implementing AI applications involves data collection and management, model training, and model inference. Computation plays an essential role throughout the whole process. Hence, we limit the scope of our survey on four aspects, including how to cache data to fuel intelligent applications (i.e., edge caching), how to train intelligent applications at the edge (i.e., edge training), how to infer intelligent applications at the edge (edge inference), and how to provide sufficient computing power for intelligent applications at the edge (edge offloading).&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;本文的调研侧重于如何以系统的方式实现边缘智能。人工智能有三个关键组成部分，即数据、模型/算法和计算。实现人工智能应用程序的完整过程包括数据收集和管理、模型训练和模型推理。计算在整个过程中起着重要的作用。因此，作者将调研范围限制在四个方面，包括如何缓存数据以支持智能应用（即边缘缓存），如何在边缘训练智能应用（即边缘训练），如何在边缘推断智能应用（边缘推断），以及如何在边缘为智能应用提供足够的计算能力（边缘卸载）。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Our contributions are summarized as following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;We survey recent research achievements on edge intelligence and identify four key components: edge caching, edge training, edge inference, and edge offloading. For each component, we outline a systematical and comprehensive classification from a multi-dimensional view, e.g., practical challenges, solutions, optimisation goals, etc.&lt;/li&gt;
&lt;li&gt;We present thorough discussion and analysis on relevant papers in the field of edge intelligence from multiple views, e.g., applicable scenarios, methodology, performance, etc. and summarise their advantages and shortcomings.&lt;/li&gt;
&lt;li&gt;We discuss and summarise open issues and challenges in the implementation of edge intelligence, and outline five important future research directions and development trends, i.e., data scarcity, data consistency, adaptability of model/algorithms, privacy and security, and incentive mechanisms.&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;p&gt;本文的贡献总结如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;作者调研了边缘智能的最新研究成果，并确定了四个关键的组成部分：边缘缓存、边缘训练、边缘推理和边缘卸载。对于每个部分，作者从多个维度概述了一个系统和全面的分类，例如，实际挑战、解决方案、优化目标等。&lt;/li&gt;
&lt;li&gt;作者从应用场景、方法论、性能等多个角度对边缘智能领域的相关论文进行了深入的讨论和分析。并总结它们的优点和缺点。&lt;/li&gt;
&lt;li&gt;作者讨论和总结了边缘智能实现中的开放问题和挑战，并概述了五个重要的未来研究方向和发展趋势，即数据稀缺性、数据一致性、模型/算法的适应性、隐私和安全以及激励机制。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;ii-overview&#34;&gt;II. Overview&lt;/h2&gt;
















&lt;figure  id=&#34;figure-fig-1-the-comparison-of-traditional-intelligence-and-edge-intelligence-from-the-perspective-of-implementation-in-traditional-intelligence-all-data-must-be-uploaded-to-a-central-cloud-server-whilst-in-edge-intelligence-intelligent-application-tasks-are-done-at-the-edge-with-locally-generated-data-in-a-distributed-manner&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Fig. 1. The comparison of traditional intelligence and edge intelligence from the perspective of implementation. In traditional intelligence, all data must be uploaded to a central cloud server, whilst in edge intelligence, intelligent application tasks are done at the edge with locally-generated data in a distributed manner.&#34; srcset=&#34;
               /post/edge-intelligence-architectures-challenges-and-applications/fig1_hu665fd517c4c5fb8d44d6086cebe5faec_1257683_951bce64514f827732989c6e679a190e.webp 400w,
               /post/edge-intelligence-architectures-challenges-and-applications/fig1_hu665fd517c4c5fb8d44d6086cebe5faec_1257683_eee8624ef4c5156511f9dd00a2d261d9.webp 760w,
               /post/edge-intelligence-architectures-challenges-and-applications/fig1_hu665fd517c4c5fb8d44d6086cebe5faec_1257683_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://bowenei.gitee.io/post/edge-intelligence-architectures-challenges-and-applications/fig1_hu665fd517c4c5fb8d44d6086cebe5faec_1257683_951bce64514f827732989c6e679a190e.webp&#34;
               width=&#34;760&#34;
               height=&#34;388&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Fig. 1. The comparison of traditional intelligence and edge intelligence from the perspective of implementation. In traditional intelligence, all data must be uploaded to a central cloud server, whilst in edge intelligence, intelligent application tasks are done at the edge with locally-generated data in a distributed manner.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;blockquote&gt;
&lt;p&gt;The comparison of traditional intelligence and edge intelligence from the perspective of implementation. In traditional intelligence, all data must be uploaded to a central cloud server, whilst in edge intelligence, intelligent application tasks are done at the edge with locally-generated data in a distributed manner.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;作者从实现的角度比较了传统智能和边缘智能。在传统智能中，所有数据都必须上传到中央云服务器，而在边缘智能中，智能应用任务是在边缘以分布式方式使用本地生成的数据完成的。&lt;/p&gt;
















&lt;figure  id=&#34;figure-fig-2-the-classification-of-edge-intelligence-literature&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Fig. 2. The classification of edge intelligence literature.&#34; srcset=&#34;
               /post/edge-intelligence-architectures-challenges-and-applications/fig2_huebe64dc92fa1caf2b3134795d72fd7d7_287466_7e0ed7359a71814facde3a539262362a.webp 400w,
               /post/edge-intelligence-architectures-challenges-and-applications/fig2_huebe64dc92fa1caf2b3134795d72fd7d7_287466_c177eff801eb08096dfc7476627274dd.webp 760w,
               /post/edge-intelligence-architectures-challenges-and-applications/fig2_huebe64dc92fa1caf2b3134795d72fd7d7_287466_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://bowenei.gitee.io/post/edge-intelligence-architectures-challenges-and-applications/fig2_huebe64dc92fa1caf2b3134795d72fd7d7_287466_7e0ed7359a71814facde3a539262362a.webp&#34;
               width=&#34;760&#34;
               height=&#34;365&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Fig. 2. The classification of edge intelligence literature.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;作者将边缘智能的文献分类绘制成上面的图，下面作者将给出这些模块的概述：&lt;/p&gt;
&lt;h3 id=&#34;a-edge-caching&#34;&gt;A. Edge Caching&lt;/h3&gt;
















&lt;figure  id=&#34;figure-fig-3-the-illustration-of-edge-caching-data-generated-by-mobile-users-and-collected-from-surrounding-environments-is-collected-and-stored-on-edge-devices-micro-bss-and-macro-bss-such-data-is-processed-and-analysed-by-intelligent-algorithms-to-provide-services-for-end-users&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Fig. 3. The illustration of edge caching. Data generated by mobile users and collected from surrounding environments is collected and stored on edge devices, micro BSs, and macro BSs. Such data is processed and analysed by intelligent algorithms to provide services for end users.&#34; srcset=&#34;
               /post/edge-intelligence-architectures-challenges-and-applications/fig3_hu0256fc95866280af08a469ae8c381815_117422_bc05fe2df8bae3d068fcb98f5a6016d0.webp 400w,
               /post/edge-intelligence-architectures-challenges-and-applications/fig3_hu0256fc95866280af08a469ae8c381815_117422_e9cb8cdd3cc9e296fae99764bfeb8d8f.webp 760w,
               /post/edge-intelligence-architectures-challenges-and-applications/fig3_hu0256fc95866280af08a469ae8c381815_117422_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://bowenei.gitee.io/post/edge-intelligence-architectures-challenges-and-applications/fig3_hu0256fc95866280af08a469ae8c381815_117422_bc05fe2df8bae3d068fcb98f5a6016d0.webp&#34;
               width=&#34;760&#34;
               height=&#34;386&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Fig. 3. The illustration of edge caching. Data generated by mobile users and collected from surrounding environments is collected and stored on edge devices, micro BSs, and macro BSs. Such data is processed and analysed by intelligent algorithms to provide services for end users.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;blockquote&gt;
&lt;p&gt;In edge intelligence, edge caching refers to a distributed data system proximity to end users, which collects and stores the data generated by edge devices and surrounding environments, and the data received from the Internet to support intelligent applications for users at the edge.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;在边缘智能中，边缘缓存是指接近终端用户的分布式数据系统，它收集和存储边缘设备和周围环境生成的数据，以及从互联网接收的数据，以支持边缘用户的智能应用。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;To implement edge caching, we answer three questions: (i) what to cache, (ii) where to cache, and (iii) how to cache.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;为了实现边缘缓存，我们需要回答三个问题：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;缓存什么&lt;/li&gt;
&lt;li&gt;缓存到哪里&lt;/li&gt;
&lt;li&gt;如何缓存&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;For the first problem, what to cache, we know that caching is based on the redundancy of requests. In edge caching, the collected data is inputted into intelligent applications and results are sent back to where data is cached. Hence, there are two kinds of redundancy: data redundancy and computation redundancy.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;作者认为，在边缘缓存中，收集的数据被输入到智能应用程序中，结果被发送回缓存数据的地方。因此，有两种冗余：数据冗余和计算冗余。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Data redundancy, also named communication redundancy, means that the inputs of an intelligent application may be the same or partially the same. For example, in continuous mobile vision analysis, there are large amounts of similar pixels between consecutive frames. Some resourceconstrained edge devices need to upload collected videos to edge servers or the cloud for further processing. With cache, edge devices only needs to upload different pixels or frames. For the repeated part, edge devices could reuse the results to avoid unnecessary computation.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;数据冗余，也称为通信冗余，意味着智能应用程序的输入可能相同或部分相同。例如，在连续移动视觉分析中，连续帧之间存在大量相似像素。一些资源受限的边缘设备需要将收集到的视频上传到边缘服务器或云端进行进一步处理。有了缓存，边缘设备只需要上传不同的像素或帧。对于重复的部分，边缘设备可以重用结果，以避免不必要的计算。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Caching based on such redundancy could effectively reduce computation and accelerate the inference. Computation redundancy means that the requested computing tasks of intelligent applications may be the same. For example, an edge server provides image recognition services for edge devices. The recognition tasks from the same context may be the same, e.g., the same tasks of flower recognition from different users of the same area. Edge servers could directly send the recognition results achieved previously back to users. Such kind of caching could significantly decrease computation and execution time.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;基于这种冗余的缓存可以有效减少计算量，加快推理速度。计算冗余意味着智能应用程序所请求的计算任务可能是相同的。例如，边缘服务器为边缘设备提供图像识别服务。来自相同上下文的识别任务可以是相同的，例如来自相同区域的不同用户的花识别的相同任务。边缘服务器可以直接将之前获得的识别结果发送回用户。这种缓存可以显著减少计算和执行时间。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;For the second problem, where to cache, existing works mainly focus on three places to deploy caches: macro BSs, micro BSs, and edge devices.&lt;/p&gt;
&lt;p&gt;Since the storage capacity of macro BSs, micro BSs, and edge devices is limited, the content replacement must be considered. Works on this problem focus on designing replacement policies to maximise the service quality.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;现有的工作主要集中在三个地方部署缓存：宏基站、微基站和边缘设备。由于宏基站、微基站和边缘设备的存储容量有限，因此必须考虑内容替换。关于这个问题的工作集中在设计替换策略以最大化服务质量。&lt;/p&gt;
&lt;h3 id=&#34;b-edge-training&#34;&gt;B. Edge Training&lt;/h3&gt;
















&lt;figure  id=&#34;figure-fig-4-the-illustration-of-edge-training-the-modelalgorithm-is-trained-either-on-a-single-device-solo-training-or-by-the-collaboration-of-edge-devices-collaborative-training-with-training-sets-cached-at-the-edge-acceleration-module-speeds-up-the-training-whilst-the-optimisation-module-solves-problems-in-training-eg-update-frequency-update-cost-and-privacy-and-security-issues-uncertainty-estimates-module-controls-the-uncertainty-in-training&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Fig. 4. The illustration of edge training. The model/algorithm is trained either on a single device (solo training), or by the collaboration of edge devices (collaborative training) with training sets cached at the edge. Acceleration module speeds up the training, whilst the optimisation module solves problems in training, e.g., update frequency, update cost, and privacy and security issues. Uncertainty estimates module controls the uncertainty in training.&#34; srcset=&#34;
               /post/edge-intelligence-architectures-challenges-and-applications/fig4_hu7ec90193ca0acb0c2a451cc39a7eb52f_137068_1263036f0886f1db066486065918a93d.webp 400w,
               /post/edge-intelligence-architectures-challenges-and-applications/fig4_hu7ec90193ca0acb0c2a451cc39a7eb52f_137068_59ad8d9fdb19facbfe41eaab4d4f40cf.webp 760w,
               /post/edge-intelligence-architectures-challenges-and-applications/fig4_hu7ec90193ca0acb0c2a451cc39a7eb52f_137068_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://bowenei.gitee.io/post/edge-intelligence-architectures-challenges-and-applications/fig4_hu7ec90193ca0acb0c2a451cc39a7eb52f_137068_1263036f0886f1db066486065918a93d.webp&#34;
               width=&#34;760&#34;
               height=&#34;596&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Fig. 4. The illustration of edge training. The model/algorithm is trained either on a single device (solo training), or by the collaboration of edge devices (collaborative training) with training sets cached at the edge. Acceleration module speeds up the training, whilst the optimisation module solves problems in training, e.g., update frequency, update cost, and privacy and security issues. Uncertainty estimates module controls the uncertainty in training.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;blockquote&gt;
&lt;p&gt;Edge training refers to a distributed learning procedure that learns the optimal values for all the weights and bias, or the hidden patterns based on the training set cached at the edge.&lt;/p&gt;
&lt;p&gt;Different from traditional centralised training procedures on powerful servers or computing clusters, edge training usually occurs on edge servers or edge devices, which are usually not as powerful as centralised servers or computing clusters.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;作者认为，边缘训练指的是一种分布式学习过程，它基于缓存在边缘的训练集来学习所有权重和偏差的最优值或隐藏模式。与传统的在功能强大的服务器或计算集群上的集中式训练过程不同，边缘训练通常发生在边缘服务器或边缘设备上，它们通常不如集中式服务器或计算集群强大。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Hence, in addition to the problem of training set (caching), four key problems should be considered for edge training: (i) how to train (the training architecture), (ii) how to make the training faster (acceleration), (iii) how to optimise the training procedure (optimisation), and (iv) how to estimate the uncertainty of the model output (uncertainty estimates).&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;因此，除了训练集（缓存）的问题之外，边缘训练还应考虑四个关键问题：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;如何训练（训练架构）&lt;/li&gt;
&lt;li&gt;如何使训练更快（加速）&lt;/li&gt;
&lt;li&gt;如何优化训练过程（优化）&lt;/li&gt;
&lt;li&gt;如何估计模型输出的不确定性（不确定性估计）&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;For the first problem, researchers design two training architectures: solo training and collaborative training. Solo training means training tasks are performed on a single device, without assistance from others, whilst collaborative training means that multiple devices cooperate to train a common model/algorithm. Since solo training has a higher requirement on the hardware, which is usually unavailable, most existing literature focuses on collaborative training architectures.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;对于第一个问题，研究人员设计了两种训练架构：单独训练和协同训练。单独训练意味着在单个设备上执行训练任务，无需其他设备的帮助，而协同训练意味着多个设备协同训练一个公共模型/算法。由于单独训练对硬件有更高的要求，而这通常是不可用的，大多数现有的文献集中在协同训练体系结构上。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Different from centralised training paradigms, in which powerful CPUs and GPUs could guarantee a good result with a limited training time, edge training is much slower. Some researchers pay attention to the acceleration of edge training. Corresponding to training architecture, works on training acceleration are divided into two categories: acceleration for solo training, and collaborative training.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;与集中式训练模式不同，在集中式训练模式中，强大的中央处理器和图形处理器可以在有限的训练时间内保证良好的结果，边缘训练要慢得多。一些研究者关注边缘训练的加速。与训练架构相对应，关于训练加速的工作分为两类：针对单独训练的加速，以及协同训练。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Solo training is a closed system, in which only iterative computation on single devices is needed to get the optimal parameters or patterns. In contrast, collaborative training is based on the cooperation of multiple devices, which requires periodic communication for updating. Update frequency and update cost are two factors which affect the performance of communication efficiency and training result. Researchers on this area mainly focus on how to maintain the performance of the model/algorithm with lower update frequency, and update cost. In addition, the public nature of collaborative training is vulnerable to malicious users. There is also some literature which focuses on the privacy and security issues.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;单独训练是一个封闭的系统，只需要在单个设备上进行迭代计算就可以获得最佳的参数或模式。相比之下，协同训练是基于多个设备的协作，需要定期沟通进行更新。更新频率和更新成本是影响通信效率和训练效果的两个因素。该领域的研究人员主要关注如何在较低的更新频率下保持模型/算法的性能，以及更新成本。此外，协作培训的公共性容易受到恶意用户的攻击。还有一些文献关注隐私和安全问题。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;In DL training, the output results may be erroneously interpreted as model confidence. Estimating uncertainty is easy on traditional intelligence, whilst it is resource-consuming for edge training. Some literature pays attention to this problem and proposes various kinds of solutions to reduce computation and energy consumption.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;在深度学习训练中，输出结果可能会被错误地解释为模型置信度。对传统智能来说，估计不确定性是容易的，而对边缘训练来说则是耗费资源的。一些文献关注了这个问题，并提出了各种解决方案来减少计算和能耗。&lt;/p&gt;
&lt;h3 id=&#34;c-edge-inference&#34;&gt;C. Edge Inference&lt;/h3&gt;
















&lt;figure  id=&#34;figure-fig-5-the-illustration-of-edge-inference-ai-modelsalgorithms-are-designed-either-by-machines-or-humans-models-could-be-further-compressed-through-compression-technologies-low-rank-approximation-network-pruning-compact-layer-design-parameter-quantisation-and-knowledge-distillation-hardware-and-software-solutions-are-used-to-accelerate-the-inference-with-input-data&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Fig. 5. The illustration of edge inference. AI models/algorithms are designed either by machines or humans. Models could be further compressed through compression technologies: low-rank approximation, network pruning, compact layer design, parameter quantisation, and knowledge distillation. Hardware and software solutions are used to accelerate the inference with input data.&#34; srcset=&#34;
               /post/edge-intelligence-architectures-challenges-and-applications/fig5_hu110700a7e9772abec25a80ee1df09d52_150363_f3157c1b1fd8fca4f8413c4ccc537795.webp 400w,
               /post/edge-intelligence-architectures-challenges-and-applications/fig5_hu110700a7e9772abec25a80ee1df09d52_150363_3d5d7f8d157f9b7e849b0299e4641b9c.webp 760w,
               /post/edge-intelligence-architectures-challenges-and-applications/fig5_hu110700a7e9772abec25a80ee1df09d52_150363_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://bowenei.gitee.io/post/edge-intelligence-architectures-challenges-and-applications/fig5_hu110700a7e9772abec25a80ee1df09d52_150363_f3157c1b1fd8fca4f8413c4ccc537795.webp&#34;
               width=&#34;760&#34;
               height=&#34;735&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Fig. 5. The illustration of edge inference. AI models/algorithms are designed either by machines or humans. Models could be further compressed through compression technologies: low-rank approximation, network pruning, compact layer design, parameter quantisation, and knowledge distillation. Hardware and software solutions are used to accelerate the inference with input data.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;blockquote&gt;
&lt;p&gt;Edge inference is the stage where a trained model/algorithm is used to infer the testing instance by a forward pass to compute the output on edge devices and servers.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;边缘推断是使用训练好的模型/算法通过向前传递来推断测试实例以计算边缘设备和服务器上的输出的阶段。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Most existing AI models are designed to be implemented on devices which have powerful CPUs and GPUs, this is not applicable in an edge environment. Hence, the critical problems of employing edge inference are: (i) how to make models applicable for their deployment on edge devices or servers (design new models, or compress existing models), and (ii) how to accelerate edge inference to provide real-time responses.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;大多数现有的人工智能模型被设计成在具有强大的中央处理器和图形处理器的设备上实现，这不适用于边缘环境。因此，采用边缘推断的关键问题是：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;如何使模型适用于它们在边缘设备或服务器上的部署（设计新模型，或压缩现有模型）&lt;/li&gt;
&lt;li&gt;如何加速边缘推断以提供实时响应&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;For the problem of how to make models applicable for the edge environment, researchers mainly focus on two research directions: design new models/algorithms that have less requirements on the hardware, naturally suitable for edge environments, and compress existing models to reduce unnecessary operation during inference. For the first direction, there are two ways to design new models: let machines themselves design optimal models, i.e., architecture search; and human-invented architectures with the application of depth-wise separable convolution and group convolution.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;对于如何使模型适用于边缘环境的问题，研究者主要集中在两个研究方向：设计对硬件要求较少、自然适用于边缘环境的新模型/算法，压缩现有模型以减少推理时不必要的操作。对于第一个方向，设计新模型有两种方式：让机器自己设计最优模型，即架构搜索；和群卷积的人类发明的体系结构。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;For the second direction, i.e., model compression, researchers focus on compressing existing models to obtain thinner and smaller models, which are more computation- and energy-efficient with negligible or even no loss on accuracy. There are five commonly used approaches on model compression: low-rank approximation, knowledge distillation, compact layer design, network pruning, and parameter quantisation.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;对于第二个方向，即模型压缩，研究人员专注于压缩现有模型，以获得更薄、更小的模型，这些模型更具计算和能源效率，精度损失可以忽略甚至没有。有五种常用的模型压缩方法：低秩近似，知识蒸馏，紧凑层设计，网络剪枝，以及参数量化。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Similar to edge training, edge devices and servers are not as powerful as centralised servers or computing clusters. Hence, edge inference is much slower. Some literature focuses on solving this problem by accelerating edge inference. There are two commonly used acceleration approaches: hardware acceleration and software acceleration. Literature on hardware acceleration mainly focuses on the parallel computing which is available as hardware on devices, e.g., CPU, GPU, and DSP. Literature on software acceleration focus on optimising resource management, pipeline design, and compilers, based on compressed models.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;与边缘训练类似，边缘设备和服务器不如集中式服务器或计算集群强大。因此，边缘推断要慢得多。一些文献集中于通过加速边缘推断来解决这个问题。有两种常用的加速方法：硬件加速和软件加速。关于硬件加速的文献主要集中在并行计算上，并行计算可作为设备上的硬件，例如中央处理器、图形处理器和数字信号处理器。关于软件加速的文献侧重于基于压缩模型优化资源管理、流水线设计和编译器。&lt;/p&gt;
&lt;h3 id=&#34;d-edge-offloading&#34;&gt;D. Edge Offloading&lt;/h3&gt;
















&lt;figure  id=&#34;figure-fig-6-the-illustration-of-edge-offloading-edge-offloading-is-located-at-the-bottom-layer-in-edge-intelligence-which-provides-computing-services-for-edge-caching-edge-training-and-edge-inference-the-computing-architecture-includes-d2c-d2e-d2d-and-hybrid-computing&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Fig. 6. The illustration of edge offloading. Edge offloading is located at the bottom layer in edge intelligence, which provides computing services for edge caching, edge training, and edge inference. The computing architecture includes D2C, D2E, D2D, and hybrid computing.&#34; srcset=&#34;
               /post/edge-intelligence-architectures-challenges-and-applications/fig6_hucedd142a5989158d9527b49ee7b96351_77004_01ca173e612a9bb564eb326e7c400b40.webp 400w,
               /post/edge-intelligence-architectures-challenges-and-applications/fig6_hucedd142a5989158d9527b49ee7b96351_77004_190ee33570bacc854795199675ec2210.webp 760w,
               /post/edge-intelligence-architectures-challenges-and-applications/fig6_hucedd142a5989158d9527b49ee7b96351_77004_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://bowenei.gitee.io/post/edge-intelligence-architectures-challenges-and-applications/fig6_hucedd142a5989158d9527b49ee7b96351_77004_01ca173e612a9bb564eb326e7c400b40.webp&#34;
               width=&#34;760&#34;
               height=&#34;384&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Fig. 6. The illustration of edge offloading. Edge offloading is located at the bottom layer in edge intelligence, which provides computing services for edge caching, edge training, and edge inference. The computing architecture includes D2C, D2E, D2D, and hybrid computing.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;blockquote&gt;
&lt;p&gt;As a necessary component of edge intelligence, edge offloading refers to a distributed computing paradigm, which provides computing service for edge caching, edge training, and edge inference. If a single edge device does not have enough resource for a specific edge intelligence application, it could offload application tasks to edge servers or other edge devices.&lt;/p&gt;
&lt;p&gt;Edge offloading layer transparently provides computing services for the other three components of edge intelligence. In edge offloading, Offloading strategy is of utmost importance, which should give full play to the available resources in edge environment.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;作为边缘智能的必要组成部分，边缘卸载是指一种分布式计算模式，它为边缘缓存、边缘训练和边缘推理提供计算服务。如果单个边缘设备没有足够的资源用于特定的边缘智能应用程序，它可能会将应用程序任务转移到边缘服务器或其他边缘设备。&lt;/p&gt;
&lt;p&gt;边缘卸载层透明地为边缘智能的其他三个组件提供计算服务。在边缘卸载中，卸载策略至关重要，它应该充分发挥边缘环境中的可用资源。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Available computing resources are distributed in cloud servers, edge servers, and edge devices. Correspondingly, existing literature mainly focuses on four strategies: device-to-cloud (D2C) offloading, device-to-edge server (D2E) offloading, device-to-device (D2D) offloading, and hybrid offloading. Works on the D2C offloading strategy prefer to leave pre-processing tasks on edge devices and offload the rest of the tasks to a cloud server, which could significantly reduce the amount of uploaded data and latency. Works on D2E offloading strategy, also adopt such operation, which could further reduce latency and the dependency on cellular network. Most works on D2D offloading strategy focus on smart home scenarios, where IoT devices, smartwatches and smartphones collaboratively perform training/inference tasks. Hybrid offloading schemes have the strongest ability of adaptiveness, which makes the most of all the available resources.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;可用的计算资源分布在云服务器、边缘服务器和边缘设备中。相应地，现有文献主要关注四种策略：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;D2C&lt;/strong&gt;：边缘设备卸载到云服务器&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;D2E&lt;/strong&gt;：边缘设备卸载到边缘服务器&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;D2D&lt;/strong&gt;：边缘设备卸载到边缘设备&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;hybrid offloading&lt;/strong&gt;：混合卸载&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;e-summary&#34;&gt;E. Summary&lt;/h3&gt;
















&lt;figure  id=&#34;figure-fig-7-publication-volume-over-time-these-curves-show-the-trend-of-publication-volume-in-edge-caching-edge-training-edge-computing-edge-inference-and-edge-intelligence-respectively&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Fig. 7. Publication volume over time. These curves show the trend of publication volume in edge caching, edge training, edge computing, edge inference, and edge intelligence, respectively.&#34; srcset=&#34;
               /post/edge-intelligence-architectures-challenges-and-applications/fig7_hua19c2d52acf89ac2e81e1fc5855ec49a_51022_e7aa685e71569e05cbaf7f71f21213d8.webp 400w,
               /post/edge-intelligence-architectures-challenges-and-applications/fig7_hua19c2d52acf89ac2e81e1fc5855ec49a_51022_9aaa18ef23d33d3cc985fa91138aa29a.webp 760w,
               /post/edge-intelligence-architectures-challenges-and-applications/fig7_hua19c2d52acf89ac2e81e1fc5855ec49a_51022_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://bowenei.gitee.io/post/edge-intelligence-architectures-challenges-and-applications/fig7_hua19c2d52acf89ac2e81e1fc5855ec49a_51022_e7aa685e71569e05cbaf7f71f21213d8.webp&#34;
               width=&#34;627&#34;
               height=&#34;422&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Fig. 7. Publication volume over time. These curves show the trend of publication volume in edge caching, edge training, edge computing, edge inference, and edge intelligence, respectively.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;blockquote&gt;
&lt;p&gt;In our survey, we identify four key components of edge intelligence, i.e. edge caching, edge training, edge inference, and edge offloading. Edge intelligence shows an explosive developing trend with a huge amount of researcher have been carried out to investigate and realise edge intelligence over the past five years. We count the publication volume of edge intelligence.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;在我们的调研中，我们确定了边缘智能的四个关键组成部分，即边缘缓存、边缘训练、边缘推理和边缘卸载。边缘智能呈现出爆炸式的发展趋势，在过去的五年中，大量的研究者被用来研究和实现边缘智能。我们统计了边缘智能的发布量，如图7所示。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Such prosperity of this research filed owes to the following three reasons.&lt;/p&gt;
&lt;p&gt;First, it is the booming development of intelligent techniques, e.g., deep learning and machine learning techniques that provides a theoretical foundation for the implementation of edge intelligence.&lt;/p&gt;
&lt;p&gt;Second, the increasing big data distributed at the edge, which fuels the performance of edge intelligence.&lt;/p&gt;
&lt;p&gt;Third, the maturing of edge computing systems, and peoples’ increasing demand on smart life facilitate the implementation of edge intelligence.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;作者认为，这一研究领域的繁荣有以下三个原因：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;智能技术的蓬勃发展，例如深度学习和机器学习技术，为边缘智能的实现提供了理论基础。&lt;/li&gt;
&lt;li&gt;分布在边缘的大数据越来越多，这推动了边缘智能的性能。&lt;/li&gt;
&lt;li&gt;边缘计算系统的成熟，以及人们对智能生活需求的增加，促进了边缘智能的实现。&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    至此，本文的概述结束。后面的各大章节 &lt;code&gt;Session&lt;/code&gt; 则是对 &lt;code&gt;Overview&lt;/code&gt; 的扩充，因此我在这里只写每个 &lt;code&gt;Session&lt;/code&gt; 的标题。未来如有详细了解的需要，会继续进行补充。
  &lt;/div&gt;
&lt;/div&gt;

&lt;h2 id=&#34;iii-edge-caching&#34;&gt;III. Edge Caching&lt;/h2&gt;
&lt;h3 id=&#34;a-preliminary-of-caching&#34;&gt;A. Preliminary of Caching&lt;/h3&gt;
&lt;h3 id=&#34;b-cache-deployment&#34;&gt;B. Cache Deployment&lt;/h3&gt;
&lt;h3 id=&#34;c-cache-replacement&#34;&gt;C. Cache Replacement&lt;/h3&gt;
&lt;h2 id=&#34;iv-edge-training&#34;&gt;IV. Edge Training&lt;/h2&gt;
&lt;h3 id=&#34;a-training-architecture&#34;&gt;A. Training Architecture&lt;/h3&gt;
&lt;h3 id=&#34;b-training-acceleration&#34;&gt;B. Training Acceleration&lt;/h3&gt;
&lt;h3 id=&#34;c-training-optimisation&#34;&gt;C. Training Optimisation&lt;/h3&gt;
&lt;h3 id=&#34;d-uncertainty-estimates&#34;&gt;D. Uncertainty Estimates&lt;/h3&gt;
&lt;h3 id=&#34;e-applications&#34;&gt;E. Applications&lt;/h3&gt;
&lt;h2 id=&#34;v-edge-inference&#34;&gt;V. Edge Inference&lt;/h2&gt;
&lt;h3 id=&#34;a-model-design&#34;&gt;A. Model Design&lt;/h3&gt;
&lt;h3 id=&#34;b-model-compression&#34;&gt;B. Model Compression&lt;/h3&gt;
&lt;h3 id=&#34;c-inference-acceleration&#34;&gt;C. Inference Acceleration&lt;/h3&gt;
&lt;h2 id=&#34;vi-edge-offloading&#34;&gt;VI. Edge Offloading&lt;/h2&gt;
&lt;h3 id=&#34;a-d2c-offloading-strategy&#34;&gt;A. D2C Offloading Strategy&lt;/h3&gt;
&lt;h3 id=&#34;b-d2e-offloading-strategy&#34;&gt;B. D2E Offloading Strategy&lt;/h3&gt;
&lt;h3 id=&#34;c-d2d-offloading-strategy&#34;&gt;C. D2D Offloading Strategy&lt;/h3&gt;
&lt;h3 id=&#34;d-hybrid-offloading&#34;&gt;D. Hybrid Offloading&lt;/h3&gt;
&lt;h3 id=&#34;e-applications-1&#34;&gt;E. Applications&lt;/h3&gt;
&lt;h2 id=&#34;vii-future-directions-and-open-challenges&#34;&gt;VII. Future Directions and Open Challenges&lt;/h2&gt;
&lt;h3 id=&#34;a-data-scarcity-at-edge&#34;&gt;A. Data Scarcity at Edge&lt;/h3&gt;
&lt;h3 id=&#34;b-data-consistency-on-edge-devices&#34;&gt;B. Data Consistency on Edge Devices&lt;/h3&gt;
&lt;h3 id=&#34;c-bad-adaptability-of-statically-trained-model&#34;&gt;C. Bad Adaptability of Statically Trained Model&lt;/h3&gt;
&lt;h3 id=&#34;d-privacy-and-security-issues&#34;&gt;D. Privacy and Security Issues&lt;/h3&gt;
&lt;h3 id=&#34;e-incentive-mechanism&#34;&gt;E. Incentive Mechanism&lt;/h3&gt;
&lt;h2 id=&#34;viii-conclusions&#34;&gt;VIII. Conclusions&lt;/h2&gt;</description>
    </item>
    
    <item>
      <title>Classification of Computation Offloading</title>
      <link>https://bowenei.gitee.io/post/classification-of-computation-offloading/</link>
      <pubDate>Mon, 05 Jul 2021 16:59:27 +0800</pubDate>
      <guid>https://bowenei.gitee.io/post/classification-of-computation-offloading/</guid>
      <description>&lt;p&gt;2021年6月23日上午8:30，湖南大学信息科学与工程学院博士生导师&lt;a href=&#34;http://csee.hnu.edu.cn/people/likeqin&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;李克勤&lt;/a&gt;教授在线上做题为《移动边缘计算中任务卸载的博弈论方法》的报告。&lt;/p&gt;
&lt;p&gt;本文将李教授报告中关于边缘计算领域研究的十个维度进行整理。对这十个维度熟悉到一定程度后，任何关于边缘计算的工作我们都可以进行定位。&lt;/p&gt;
&lt;h2 id=&#34;number-of-ues&#34;&gt;Number of UEs&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Single&lt;/li&gt;
&lt;li&gt;Multiple (homogeneous, heterogeneous)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;UEs，即 User Equipments，用户的设备。在论文的场景中，究竟是单用户 &lt;code&gt;signle&lt;/code&gt; 还是多用户 &lt;code&gt;multiple&lt;/code&gt;？如果是多用户，那么用户设备是同构的 &lt;code&gt;homogeneous&lt;/code&gt; 还是异构的 &lt;code&gt;heterogeneous&lt;/code&gt;？&lt;/p&gt;
&lt;h2 id=&#34;number-of-tasks-per-ue&#34;&gt;Number of tasks per UE&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Single/multiple, Finite/infinite&lt;/li&gt;
&lt;li&gt;Independent/precedence constrained&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在论文的场景中，每个用户产生的任务数量是多少？最简单的情况是每个用户只产生一个任务 &lt;code&gt;single&lt;/code&gt;，稍微复杂一些的就是多任务 &lt;code&gt;multiple&lt;/code&gt;。而多任务又可以分为有限 &lt;code&gt;finite&lt;/code&gt; 个任务和无限 &lt;code&gt;infinite&lt;/code&gt; 个任务。而无限个任务就是一个任务流 &lt;code&gt;task flow&lt;/code&gt;，我们就需要用到排队论的知识。&lt;/p&gt;
&lt;p&gt;任务之间可能没有任何依赖关系，或者说是独立的 &lt;code&gt;independent&lt;/code&gt;；但也有可能彼此之间是有先后次序的，或者说具有优先级约束 &lt;code&gt;precedence constrained&lt;/code&gt;。&lt;/p&gt;
&lt;h2 id=&#34;number-of-mecs&#34;&gt;Number of MECs&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Single&lt;/li&gt;
&lt;li&gt;Multiple (homogeneous, heterogeneous)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;MECs，即 Mobile Edge Clouds，移动边缘云，简单来说就是边缘服务器。同理，它也可以分为单个边缘服务器 &lt;code&gt;single&lt;/code&gt; 和多个边缘服务器 &lt;code&gt;multiple&lt;/code&gt;。而多个边缘服务器同样也涉及到同构 &lt;code&gt;homogeneous&lt;/code&gt; 和异构 &lt;code&gt;heterogeneous&lt;/code&gt; 的问题。&lt;/p&gt;
&lt;h2 id=&#34;type-of-ue-and-mec&#34;&gt;Type of UE and MEC&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Uni-server (M/M/1, M/G/1, G/G/1)&lt;/li&gt;
&lt;li&gt;Multi-server (M/M/m, M/G/m, G/G/m)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;所谓的用户设备并不是一个被动设备，它其实是有处理能力的。因此，从某种意义上说，用户设备也是一个服务器。排队论已经告诉我们如何对服务器进行建模。针对单核服务器 &lt;code&gt;uni-server&lt;/code&gt;，我们可以建模成 M/M/1、M/G/1 或者 G/G/1 问题；针对多核服务器（边缘服务器通常都是多核服务器），我们可以建模成 M/M/m、M/G/m 或者 G/G/m 问题。&lt;/p&gt;
&lt;h2 id=&#34;modeling-of-ue-and-mec&#34;&gt;Modeling of UE and MEC&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Deterministic&lt;/li&gt;
&lt;li&gt;Probabilistic&lt;/li&gt;
&lt;li&gt;Stochastic (queuing model)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;针对用户设备和边缘服务器的数学建模主要有三种：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;确定型。例如组合优化，要求每个任务的执行时间是一个已知的量。&lt;/li&gt;
&lt;li&gt;概率型。任务执行时间是一个随机变量&lt;/li&gt;
&lt;li&gt;统计型。例如排队论模型。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;variables-to-control&#34;&gt;Variables to control&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Offloading strategy (load distribution)&lt;/li&gt;
&lt;li&gt;Computation speed (CPU frequency)&lt;/li&gt;
&lt;li&gt;Communication speed (transmission power)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;可控变量，即哪些变量是可以调节的。&lt;/p&gt;
&lt;p&gt;首先就是任务卸载策略 &lt;code&gt;offloading strategy&lt;/code&gt;。任务到底卸不卸载？如果卸载，卸载到哪里去？如果有多个服务器，还涉及到负载均衡 &lt;code&gt;load distribution&lt;/code&gt; 的问题。&lt;/p&gt;
&lt;p&gt;其次是设备本身的计算速度 &lt;code&gt;computation speed&lt;/code&gt;，或者说 CPU 的主频 &lt;code&gt;frequency&lt;/code&gt;。计算速度如果快，那么能耗就会大。因此，计算速度和能耗需要进行平衡。不过，边缘服务器的计算机速度是不可调的，每个用户只能调节他自己设备的计算速度。&lt;/p&gt;
&lt;p&gt;最后是通讯速度 &lt;code&gt;communication speed&lt;/code&gt;，这个也可以调节。通讯速度主要取决于发射功率。发射功率越大，能耗也越大，这也需要进行平衡。&lt;/p&gt;
&lt;h2 id=&#34;metric&#34;&gt;Metric&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Performance (execution delay, response time)&lt;/li&gt;
&lt;li&gt;Cost (power consumption, energy consumption)&lt;/li&gt;
&lt;li&gt;Other (number of tasks completed)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;度量方法主要分为性能和开销两大类，也有其他的一些方法。&lt;/p&gt;
&lt;p&gt;具体来说，从性能角度看，主要有任务执行时延 &lt;code&gt;execution delay&lt;/code&gt; 和任务响应时延 &lt;code&gt;response time&lt;/code&gt; 两个指标。&lt;/p&gt;
&lt;p&gt;从开销角度看，主要有功耗 &lt;code&gt;power consumption&lt;/code&gt; 和能耗 &lt;code&gt;energy consumption&lt;/code&gt; 两个指标。&lt;/p&gt;
&lt;p&gt;性能和开销是两大最重要的度量方法，当然还有一些其他的度量方式。例如，已完成的任务数 &lt;code&gt;number of tasks completed&lt;/code&gt; 等。&lt;/p&gt;
&lt;h2 id=&#34;performance-cost-tradeoff&#34;&gt;Performance-cost tradeoff&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Cost constrained performance optimization&lt;/li&gt;
&lt;li&gt;Performance constrained cost optimization&lt;/li&gt;
&lt;li&gt;Joint performance and cost (multi-objective) optimization&lt;/li&gt;
&lt;li&gt;Combined performance and cost (weighted sum, cost-performance ratio) optimization&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;李教授认为，性能和开销的平衡是所有的服务计算（网格计算、分布式计算、集群计算、云计算、雾计算、边缘计算等）里面的重要问题，而且是鱼和熊掌不可兼得的。&lt;/p&gt;
&lt;p&gt;我们应该怎样去研究呢？例如，在一定开销的约束下优化性能 &lt;code&gt;cost constrained performance optimization&lt;/code&gt;，或者倒过来，在一定性能的约束下优化开销 &lt;code&gt;performance constrained cost optimization&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;还有一种方法，就是综合考虑这两种指标，这就涉及到多目标 &lt;code&gt;multi-objective&lt;/code&gt; 优化。也可以把这两种指标结合 &lt;code&gt;combined&lt;/code&gt; 起来，转化成单目标优化。例如加权求和 &lt;code&gt;weighted sum&lt;/code&gt;，或者求性价比 &lt;code&gt; cost-performance ratio&lt;/code&gt;。&lt;/p&gt;
&lt;h2 id=&#34;optimization&#34;&gt;Optimization&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Globalized, collective, and centralized optimization for all UEs&lt;/li&gt;
&lt;li&gt;Localized, individualized, and distributed optimization for each UE (non-cooperative game)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;优化方法主要分为两大类：一种是整体的、中心式的优化，它是针对所有用户的优化；还有一种是局部的、个性化的、分布式的优化，它是为每个用户量身定制的优化。李教授认为，这和非合作博弈 &lt;code&gt;non-cooperative game&lt;/code&gt; 非常类似。&lt;/p&gt;
&lt;h2 id=&#34;technique&#34;&gt;Technique&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Discrete and combinatorial (NP-hard, heuristics)&lt;/li&gt;
&lt;li&gt;Continuous and probabilistic (Lyapunov optimization)&lt;/li&gt;
&lt;li&gt;Continuous and stochastic (multi-variable optimization)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;优化的具体的技术和方法主要有以下几种：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;离散和组合型变量优化。这种方法一般适用于解决 NP 难问题，启发式 &lt;code&gt;heuristics&lt;/code&gt; 算法非常适合解决这种 NP 难问题。&lt;/li&gt;
&lt;li&gt;连续和概率型变量优化。李亚普诺夫优化是近几年来比较热门的方法之一。&lt;/li&gt;
&lt;li&gt;连续和统计型变量优化。即通过排队论将问题建模成传统的多变量优化问题。&lt;/li&gt;
&lt;/ol&gt;</description>
    </item>
    
    <item>
      <title>How to Read a Paper</title>
      <link>https://bowenei.gitee.io/post/how-to-read-a-paper/</link>
      <pubDate>Tue, 29 Jun 2021 15:28:16 +0800</pubDate>
      <guid>https://bowenei.gitee.io/post/how-to-read-a-paper/</guid>
      <description>&lt;p&gt;这是 2007 年发表在 SIGCOMM 上的一篇文章，作者提出了文献的三遍阅读法，并且介绍了如何利用这种方法做文献调研。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://dl.acm.org/doi/abs/10.1145/1273445.1273458&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;原文链接&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;摘要&#34;&gt;摘要&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;Researchers spend a great deal of time reading research papers. However, this skill is rarely taught, leading to much wasted effort. This article outlines a practical and efficient three-pass method for reading research papers. I also describe how to use this method to do a literature survey.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;作者认为研究人员花了很多时间阅读文献，但是缺少文献阅读方法的指导，很多时候都是在白白努力。作者在本文中概述了一种阅读科研论文实用而有效的三遍 &lt;code&gt;three-pass&lt;/code&gt; 方法，还描述了如何使用这种方法进行文献调研。&lt;/p&gt;
&lt;h2 id=&#34;介绍&#34;&gt;介绍&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;Researchers must read papers for several reasons: to review them for a conference or a class, to keep current in their field, or for a literature survey of a new field. A typical researcher will likely spend hundreds of hours every year reading papers.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;这段话作者主要讲了研究人员阅读文献的目的，作者认为典型的研究人员每年都会花费数百小时阅读论文。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Learning to efficiently read a paper is a critical but rarely taught skill. Beginning graduate students, therefore, must learn on their own using trial and error. Students waste much effort in the process and are frequently driven to rustration.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;作者认为学会有效阅读文献是一个关键的技能，但是很少会有人来教这些技能。因此，研究生在刚刚开始科研时必须通过试错的方式来学习，浪费了很多精力。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;For many years I have used a simple approach to efficiently read papers. This paper describes the ‘three-pass’ approach and its use in doing a literature survey.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;于是作者引出本文的工作：文献的三遍阅读法，以及如何使用这种方法进行文献调研。&lt;/p&gt;
&lt;h2 id=&#34;文献的三遍阅读法&#34;&gt;文献的三遍阅读法&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;The key idea is that you should read the paper in up to three passes, instead of starting at the beginning and plowing our way to the end. Each pass accomplishes specific goals and builds upon the previous pass: The first pass gives you a general idea about the paper. The second pass lets you grasp the paper’s content, but not its details. The third pass helps you understand the paper in depth.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;作者认为，不能简单从头到尾阅读文献。文献的三遍阅读法的关键在于，每一遍阅读都会完成特定的目标，并且建立在上一遍阅读收获的基础之上。第一遍阅读需要了解论文的大致想法 &lt;code&gt;general idea&lt;/code&gt;；第二遍阅读需要掌握论文的内容 &lt;code&gt;content&lt;/code&gt;，但不是细枝末节；第三遍阅读需要深入了解论文。&lt;/p&gt;
&lt;h3 id=&#34;第一遍阅读&#34;&gt;第一遍阅读&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;The first pass is a quick scan to get a bird’s-eye view of the paper. You can also decide whether you need to do any more passes. This pass should take about five to ten minutes and consists of the following steps:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Carefully read the title, abstract, and introduction&lt;/li&gt;
&lt;li&gt;Read the section and sub-section headings, but ignore everything else&lt;/li&gt;
&lt;li&gt;Read the conclusions&lt;/li&gt;
&lt;li&gt;Glance over the references, mentally ticking off the ones you’ve already read&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;p&gt;作者认为第一遍阅读文献需要快速扫描，以对论文有一个全局的把控（作者打了一个形象的比喻：鸟瞰图 &lt;code&gt;bird’s-eye view&lt;/code&gt;）。然后我们就可以决定是否还需要继续进行下一遍的阅读。这大概只需要 5 到 10 分钟，包括以下步骤：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;仔细阅读标题，摘要和介绍&lt;/li&gt;
&lt;li&gt;阅读每个部分 &lt;code&gt;section&lt;/code&gt; 的标题和子标题，但忽略其他所有内容&lt;/li&gt;
&lt;li&gt;阅读结论&lt;/li&gt;
&lt;li&gt;浏览参考文献，在大脑中勾结 &lt;code&gt;ticking off&lt;/code&gt; 你已经读过的那些文献&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;At the end of the first pass, you should be able to answer the five Cs:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Category: What type of paper is this? A measurement paper? An analysis of an existing system? A description of a research prototype?&lt;/li&gt;
&lt;li&gt;Context: Which other papers is it related to? Which theoretical bases were used to analyze the problem?&lt;/li&gt;
&lt;li&gt;Correctness: Do the assumptions appear to be valid?&lt;/li&gt;
&lt;li&gt;Contributions: What are the paper’s main contributions?&lt;/li&gt;
&lt;li&gt;Clarity: Is the paper well written?&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;p&gt;文献阅读的第一遍阅读完成后，你必须能够回答下面的 5 个问题：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;类别&lt;/strong&gt;：这是什么类型的论文？测量方法的论文？对现有系统的分析？研究原型的描述？&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;背景&lt;/strong&gt;：它与其他哪些文献有关？它是基于哪些理论去分析问题的？&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;正确性&lt;/strong&gt;：论文的假设合理吗？&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;贡献&lt;/strong&gt;：论文的主要贡献是什么？&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;清晰度&lt;/strong&gt;：论文写得好吗？&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;Using this information, you may choose not to read further. This could be because the paper doesn’t interest you, or you don’t know enough about the area to understand the paper, or that the authors make invalid assumptions. The first pass is adequate for papers that aren’t in your research area, but may someday prove relevant.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;有了这些信息，我们可以选择不再继续阅读。这主要有三个原因：对这篇论文不感兴趣，对涉及到的研究领域不了解，作者作出无效假设。对于不了解的研究领域，只读一遍足够了，但是可能有一天你会发现它和你的研究领域相关。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Incidentally, when you write a paper, you can expect most reviewers (and readers) to make only one pass over it. Take care to choose coherent section and subsection titles and to write concise and comprehensive abstracts. If a reviewer cannot understand the gist after one pass, the paper will likely be rejected; if a reader cannot understand the highlights of the paper after five minutes, the paper will likely never be read.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;作者还建议，当您撰写论文时，您可以期待大多数审阅者（和读者）只需要阅读一遍就能掌握上述信息。因此，注意每个部分的标题和子标题的相关性，并且摘要要简洁而全面。如果审阅者在阅读一遍后无法理解论文的要点，那么该论文可能会被拒绝; 如果读者在五分钟后无法理解论文的亮点，则可能永远不会再读这篇论文。&lt;/p&gt;
&lt;h3 id=&#34;第二遍阅读&#34;&gt;第二遍阅读&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;In the second pass, read the paper with greater care, but ignore details such as proofs. It helps to jot down the key points, or to make comments in the margins, as you read.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Look carefully at the figures, diagrams and other illustrations in the paper. Pay special attention to graphs. Are the axes properly labeled? Are results shown with error bars, so that conclusions are statistically significant? Common mistakes like these will separate rushed, shoddy work from the truly excellent.&lt;/li&gt;
&lt;li&gt;Remember to mark relevant unread references for further reading (this is a good way to learn more about the background of the paper).&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;p&gt;作者认为第二遍阅读文献需要仔细阅读，但是应该忽略掉细节部分，例如证明。在阅读时记下要点或在页边空白处作注释会有所帮助。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;仔细看文章中的图形、图表和其他插图。特别注意图表。坐标轴标记正确了吗？结果是否以误差条显示，从而使结论具有统计学意义？类似这样的常见错误会将匆忙的粗制滥造的工作与真正优秀的工作区分开来。&lt;/li&gt;
&lt;li&gt;记住标记相关的未读参考文献以供进一步阅读（这是了解更多关于论文背景的好方法）。&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;The second pass should take up to an hour. After this pass, you should be able to grasp the content of the paper. You should be able to summarize the main thrust of the paper, with supporting evidence, to someone else. This level of detail is appropriate for a paper in which you are interested, but does not lie in your research speciality.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;作者认为，第二遍阅读要花一个小时。经过这样一遍阅读，你应该能够掌握论文的内容。你应该能够将论文的主旨和支持性证据总结给其他人。这个层次的细节适合你感兴趣的论文，但不属于你的研究专业。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Sometimes you won’t understand a paper even at the end of the second pass. This may be because the subject matter is new to you, with unfamiliar terminology and acronyms. Or the authors may use a proof or experimental technique that you don’t understand, so that the bulk of the paper is incomprehensible. The paper may be poorly written with unsubstantiated assertions and numerous forward references. Or it could just be that it’s late at night and you’re tired. You can now choose to: (a) set the paper aside, hoping you don’t need to understand the material to be successful in your career, (b) return to the paper later, perhaps after reading background material or (c) persevere and go on to the third pass.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;有时你甚至在第二遍结束时也看不懂一篇论文。这可能是因为主题 &lt;code&gt;subject matter&lt;/code&gt; 对您来说是新的，具有不熟悉的术语和首字母缩写。或者，作者可能会使用你不理解的证明或实验技术，所以论文的大部分内容是无法理解的。论文可能写得很差，没有证据的断言和大量的前向参考文献。也可能是深夜，你很累。现在你可以选择:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;把论文放在一边，希望你不需要理解这些材料就能在学术生涯中取得成功；&lt;/li&gt;
&lt;li&gt;在阅读背景材料后再重新阅读论文；&lt;/li&gt;
&lt;li&gt;坚持下去，继续第三遍阅读。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;第三遍阅读&#34;&gt;第三遍阅读&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;To fully understand a paper, particularly if you are reviewer, requires a third pass. The key to the third pass is to attempt to virtually re-implement the paper: that is, making the same assumptions as the authors, re-create the work. By comparing this re-creation with the actual paper, you can easily identify not only a paper’s innovations, but also its hidden failings and assumptions.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;作者认为，要完全理解一篇论文，尤其是当你是审稿人的时候，需要第三遍阅读。第三遍阅读的关键是尝试重新实现 &lt;code&gt;virtually re-implement&lt;/code&gt; 论文：即，做出与作者相同的假设，复现 &lt;code&gt;re-create&lt;/code&gt; 论文工作（这里作者用副词 &lt;code&gt;virtually&lt;/code&gt; 修饰，是想表达这个复现是你头脑的想法，可能与作者本人的想法有出入）。通过将复现的工作 &lt;code&gt;re-creation&lt;/code&gt; 与实际论文进行比较，你可以很容易地识别出论文的创新之处，以及它隐藏的缺点和假设。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;This pass requires great attention to detail. You should identify and challenge every assumption in every statement. Moreover, you should think about how you yourself would present a particular idea. This comparison of the actual with the virtual lends a sharp insight into the proof and presentation techniques in the paper and you can very likely add this to your repertoire of tools. During this pass, you should also jot down ideas for future work.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;这一遍阅读需要非常注意细节。你应该识别并挑战每句话中的每一个假设。此外，你应该考虑自己将如何表达一个特定的想法。这种实际 &lt;code&gt;actual&lt;/code&gt;（这里作者的意思是论文的实际表述）与虚拟 &lt;code&gt;virtual&lt;/code&gt;（这里作者的意思是你头脑里所想的表达的方式）的比较有助于深入了解本文中的证明和表示技术，您很可能将其添加到您的工具库中。在此期间，你还应该记下未来工作的想法。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;This pass can take about four or five hours for beginners, and about an hour for an experienced reader. At the end of this pass, you should be able to reconstruct the entire structure of the paper from memory, as well as be able to identify its strong and weak points. In particular, you should be able to pinpoint implicit assumptions, missing citations to relevant work, and potential issues with experimental or analytical techniques.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;对于初学者来说，这一遍阅读大约需要 4 到 5 个小时，而对于有经验的读者来说，大约需要 1 个小时。在这一段的最后，你应该能够根据记忆重建整个论文结构，以及能够识别它的优点和缺点。特别是，您应该能够精确地指出隐含的假设、相关工作的遗漏引用，以及与实验或分析技术有关的潜在问题。&lt;/p&gt;
&lt;h2 id=&#34;做文献调研&#34;&gt;做文献调研&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;Paper reading skills are put to the test in doing a literature survey. This will require you to read tens of papers, perhaps in an unfamiliar field. What papers should you read? Here is how you can use the three-pass approach to help.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;做文献调研时非常考验一个人的文献阅读技巧。这一般需要你阅读几十篇论文，而且也许是一个不熟悉的领域。那么，你应该读哪些文献？作者就指出如何使用他在本文提出的文献的三遍阅读法来帮助我们进行文献调研。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;First, use an academic search engine such as Google Scholar or CiteSeer and some well-chosen keywords to find three to five recent papers in the area. Do one pass on each paper to get a sense of the work, then read their related work sections. You will find a thumbnail summary of the recent work, and perhaps, if you are lucky, a pointer to a recent survey paper. If you can find such a survey, you are done. Read the survey, congratulating yourself on your good luck.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;首先，使用学术搜索引擎（如谷歌学术或 CiteSeer）和一些精心挑选的关键词，找到该领域的三到五篇最新论文。每一篇论文都进行一遍阅读，了解一下这篇论文的工作，然后阅读相关工作部分。你会找到最近工作的缩略摘要，如果你幸运的话，可能还会找到最近调研的论文。如果你能找到这样的论文，应该为自己的好运气而庆幸。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Otherwise, in the second step, find shared citations and repeated author names in the bibliography. These are the key papers and researchers in that area. Download the key papers and set them aside. Then go to the websites of the key researchers and see where they’ve published recently. That will help you identify the top conferences in that field because the best researchers usually publish in the top conferences.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;如果找不到，在第二步中，我们可以在参考书目中找到共享的引文 &lt;code&gt;shared citations&lt;/code&gt; 和重复的作者名称。这些是该领域的关键论文和研究人员。下载关键的论文并把它们放在一边。然后访问主要研究人员的网站，看看他们最近在哪里发表的文章。这将帮助你确定该领域的顶级会议，因为最优秀的研究人员通常在顶级会议上发表文章。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The third step is to go to the website for these top conferences and look through their recent proceedings. A quick scan will usually identify recent high-quality related work. These papers, along with the ones you set aside earlier, constitute the first version of your survey. Make two passes through these papers. If they all cite a key paper that you did not find earlier, obtain and read it, iterating as necessary.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;第三步是访问这些顶级会议 &lt;code&gt;top conferences&lt;/code&gt; 的网站，查看它们最近的会议记录。快速扫描通常可以识别出近期高质量的相关工作。这些论文，连同你之前搁置的那些，构成了你调查的第一个版本。把这些论文翻两遍。如果他们都引用了一篇你之前没有找到的关键论文，获取并阅读它，必要时进行迭代。&lt;/p&gt;
&lt;h2 id=&#34;经验&#34;&gt;经验&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;I’ve used this approach for the last 15 years to read conference proceedings, write reviews, do background research, and to quickly review papers before a discussion. This disciplined approach prevents me from drowning in the details before getting a bird’s-eye-view. It allows me to estimate the amount of time required to review a set of papers. Moreover, I can adjust the depth of paper evaluation depending on my needs and how much time I have.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;作者在过去的 15 年里，一直使用这种方法来阅读会议记录、撰写评论、做背景研究，以及在讨论前快速审阅论文。这种有规律的方法能够防止在把握全文之前就被细节淹没。它可以估算出回顾一系列论文所需的时间。此外，作者可以根据自己的需要和时间来调整论文评估的深度。&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>
