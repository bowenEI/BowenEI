<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>数学基础 | Bowen&#39;s Academic Home</title>
    <link>https://bowenei.gitee.io/learn/convex-optimization/mathematical-background/</link>
      <atom:link href="https://bowenei.gitee.io/learn/convex-optimization/mathematical-background/index.xml" rel="self" type="application/rss+xml" />
    <description>数学基础</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Sun, 07 Nov 2021 17:18:56 +0800</lastBuildDate>
    <image>
      <url>https://bowenei.gitee.io/media/icon_huc813daf5dbf7d2b27f0daba22fe1e0fb_68056_512x512_fill_lanczos_center_3.png</url>
      <title>数学基础</title>
      <link>https://bowenei.gitee.io/learn/convex-optimization/mathematical-background/</link>
    </image>
    
    <item>
      <title>范数</title>
      <link>https://bowenei.gitee.io/learn/convex-optimization/mathematical-background/norms/</link>
      <pubDate>Fri, 26 Nov 2021 19:57:40 +0800</pubDate>
      <guid>https://bowenei.gitee.io/learn/convex-optimization/mathematical-background/norms/</guid>
      <description>&lt;h2 id=&#34;euclid-范数&#34;&gt;Euclid 范数&lt;/h2&gt;
&lt;h3 id=&#34;内积&#34;&gt;内积&lt;/h3&gt;
&lt;p&gt;\begin{align}
\langle x, y\rangle=x^{T} y=\sum_{i=1}^{n} x_{i} y_{i}
\end{align}&lt;/p&gt;
&lt;h3 id=&#34;ell_2-范数&#34;&gt;$\ell_2$-范数&lt;/h3&gt;
&lt;p&gt;\begin{align}
\|x\| _2 = \left ( x^Tx \right ) ^{1/2} = \left ( x_1^2 + \dots + x_n^2 \right ) ^{1/2}
\end{align}&lt;/p&gt;
&lt;h3 id=&#34;夹角&#34;&gt;夹角&lt;/h3&gt;
&lt;p&gt;\begin{align}
\cos \left ( x,y \right ) = \frac{x^Ty}{\|x\|_2\|y\|_2} 
\end{align}&lt;/p&gt;
&lt;p&gt;若 $x^Ty=0$，称 $x$ 和 $y$ &lt;strong&gt;正交&lt;/strong&gt;。&lt;/p&gt;
&lt;h2 id=&#34;frobenius-范数&#34;&gt;Frobenius 范数&lt;/h2&gt;
&lt;h3 id=&#34;矩阵的标准内积&#34;&gt;矩阵的标准内积&lt;/h3&gt;
&lt;p&gt;对于 $m \times n$ 的实矩阵 $X,Y \in \mathbf{R}^{m \times n}$，其标准内积为：&lt;/p&gt;
&lt;p&gt;\begin{align}
\langle X, Y\rangle = \operatorname{tr}\left(X^{T} Y\right) = \sum_{i = 1}^{m} \sum_{j = 1}^{n} X_{i j} Y_{i j}
\end{align}&lt;/p&gt;
&lt;p&gt;特别地，若 $X,Y \in \mathbf{R}^{n \times n}$，则标准内积为：&lt;/p&gt;
&lt;p&gt;\begin{align}
\langle X, Y\rangle=\operatorname{tr}(X Y)=\sum_{i=1}^{n} \sum_{j=1}^{n} X_{i j} Y_{i j}=\sum_{i=1}^{n} X_{i i} Y_{i i}+2 \sum_{i&amp;lt;j} X_{i j} Y_{i j}
\end{align}&lt;/p&gt;
&lt;h3 id=&#34;矩阵的-frobenius-范数&#34;&gt;矩阵的 Frobenius 范数&lt;/h3&gt;
&lt;p&gt;\begin{align}
\|X\| _F = \left( \operatorname{tr} \left( X^T X \right) \right) ^{1/2} = \left( \sum _{i=1} ^{m} \sum _{j=1} ^{n} X _{i j} ^{2} \right) ^{1/2}
\end{align}&lt;/p&gt;
&lt;p&gt;Frobenius 范数实际上就是将矩阵的系数按一定顺序排列后所生成的相应向量的 $\ell_2$-范数。&lt;/p&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    向量的 Euclid 范数和 $\ell_2$-范数是一回事，但是矩阵的 Frobenius 范数和 $\ell_2$-范数不是一回事。后文详述。
  &lt;/div&gt;
&lt;/div&gt;

&lt;h2 id=&#34;范数&#34;&gt;范数&lt;/h2&gt;
&lt;p&gt;满足以下条件的函数 $f: \mathbf{R}^{n} \rightarrow \mathbf{R}$ 称为&lt;strong&gt;范数&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$f$ 是非负的：对所有的 $x \in \mathbf{R}^{n}$，$f(x) \geqslant 0$ 成立；&lt;/li&gt;
&lt;li&gt;$f$ 是正定的：$f(x)=0$ 仅对 $x=0$ 成立；&lt;/li&gt;
&lt;li&gt;$f$ 是齐次的：对所有的 $x \in \mathbf{R}^{n}$ 和 $t \in \mathbf{R} $，$f(t x)=|t| f(x)$ 成立；&lt;/li&gt;
&lt;li&gt;$f$ 满足三角不等式：对所有的 $x, y \in \mathbf{R}^{n}$，$f(x+y) \leqslant f(x)+f(y)$ 成立。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;范数是 $\mathbf{R}$ 上绝对值函数的推广。&lt;/p&gt;
&lt;h3 id=&#34;距离&#34;&gt;距离&lt;/h3&gt;
&lt;p&gt;范数是对向量长度的度量，可以用两个向量 $x$ 和 $y$ 差的长度来度量它们之间的距离。&lt;/p&gt;
&lt;p&gt;\begin{align}
\operatorname{dist}(x, y)=\|x-y\|
\end{align}&lt;/p&gt;
&lt;h3 id=&#34;单位球&#34;&gt;单位球&lt;/h3&gt;
&lt;p&gt;范数小于或等于 $1$ 的所有向量的集合称为单位球。&lt;/p&gt;
&lt;p&gt;\begin{align}
\mathcal{B}=\left\{x \in \mathbf{R}^{n} \mid\|x\| \leqslant 1\right\}
\end{align}&lt;/p&gt;
&lt;h2 id=&#34;其他范数&#34;&gt;其他范数&lt;/h2&gt;
&lt;h3 id=&#34;ell_1-范数绝对值之和&#34;&gt;$\ell_1$-范数（绝对值之和）&lt;/h3&gt;
&lt;p&gt;\begin{align}
\|x\| _1 = \left| x_1 \right| + \cdots + \left| x_n \right|
\end{align}&lt;/p&gt;
&lt;h3 id=&#34;ell_infty-范数chebyshev-范数&#34;&gt;$\ell_{\infty}$-范数（Chebyshev 范数）&lt;/h3&gt;
&lt;p&gt;\begin{align}
\|x\| _{\infty} = \max \{ \left| x_1 \right|, \cdots, \left| x_n \right| \}
\end{align}&lt;/p&gt;
&lt;h3 id=&#34;ell_p-范数&#34;&gt;$\ell_p$-范数&lt;/h3&gt;
&lt;p&gt;\begin{align}
\|x\| _p = \left( \left| x_1 \right| ^p + \cdots + \left| x_n \right| ^p \right) ^{1/p}
\end{align}&lt;/p&gt;
&lt;p&gt;取 $p=1$ 就得到 $\ell_1$-范数，取 $p=2$ 就得到 $\ell_2$-范数。$p \rightarrow \infty$ 时的极限就是 $\ell_{\infty}$-范数。&lt;/p&gt;
&lt;h3 id=&#34;p--二次范数&#34;&gt;$P$- 二次范数&lt;/h3&gt;
&lt;p&gt;\begin{align}
\|x\| _{P}=\left(x^{T} P x\right)^{1 / 2}=\left\|P^{1 / 2} x\right\| _{2}
\end{align}&lt;/p&gt;
&lt;p&gt;二次范数的单位球是椭圆（反之, 如果一个范数的单位球是椭圆, 该范数就是二次范数）。&lt;/p&gt;
&lt;h2 id=&#34;范数的等价性&#34;&gt;范数的等价性&lt;/h2&gt;
&lt;p&gt;对所有的 $x \in \mathbf{R}^{n}$，存在正常数 $\alpha$ 和 $\beta$，使得：&lt;/p&gt;
&lt;p&gt;\begin{align}
\alpha\|x\| _{\mathrm{a}} \leqslant \|x\| _{\mathrm{b}} \leqslant \beta \|x\| _{\mathrm{a}}
\end{align}&lt;/p&gt;
&lt;p&gt;据此可以证明，$\mathbf{R}^{n}$ 上任何范数可以在 $\sqrt{n}$ 倍的范围内被二次范数一致逼近。&lt;/p&gt;
&lt;p&gt;\begin{align}
\|x\| _{P} \leqslant\|x\| \leqslant \sqrt{n}\|x\| _{P}
\end{align}&lt;/p&gt;
&lt;h2 id=&#34;算子范数&#34;&gt;算子范数&lt;/h2&gt;
&lt;p&gt;假设 $\| \cdot \| _{\mathrm{a}}$ 和 $\|\cdot\| _{\mathrm{b}}$ 分别是 $\mathbf{R}^{m}$ 和 $\mathbf{R}^{n}$ 上的范数。对于 $X \in \mathbf{R}^{m \times n}$，我们定义由范数 $\|\cdot\| _{\mathrm{a}}$ 和 $\|\cdot\| _{\mathrm{b}}$ 导出的&lt;strong&gt;算子范数&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;\begin{align}
\|X\| _{\mathrm{a}, \mathrm{b}}=\sup \{\|X u\| _{\mathrm{a}} \mid \|u\| _{\mathrm{b}} \leqslant 1\}
\end{align}&lt;/p&gt;
&lt;h3 id=&#34;矩阵的-ell_2-范数&#34;&gt;矩阵的 $\ell_2$-范数&lt;/h3&gt;
&lt;p&gt;当 $\|\cdot\| _{\mathrm{a}}$ 和 $\|\cdot\| _{\mathrm{b}}$ 都是 Euclid 范数时，$X$ 的算子范数是它的&lt;strong&gt;最大奇异值&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;\begin{align}
\|X\|_{2}=\sigma _{\max }(X)=\left(\lambda _{\max }\left(X^{T} X\right)\right)^{1 / 2}
\end{align}&lt;/p&gt;
&lt;h3 id=&#34;最大行和范数和最大列和范数&#34;&gt;最大行和范数和最大列和范数&lt;/h3&gt;
&lt;p&gt;由 $\mathbf{R}^{m}$ 和 $\mathbf{R}^{n}$ 上的 $\ell_{\infty}$-范数导出的范数，被称为最大行和范数：&lt;/p&gt;
&lt;p&gt;\begin{align}
\|X\| _{\infty}=\sup \{\|X u\| _{\infty} \mid\|u\| _{\infty} \leqslant 1\}=\max _{i=1, \cdots, m} \sum _{j=1}^{n}\left|X _{i j}\right|
\end{align}&lt;/p&gt;
&lt;p&gt;而由 $\mathbf{R}^{m}$ 和 $\mathbf{R}^{n}$ 上的 $\ell_{1}$-范数导出的范数，被称为最大列和范数：&lt;/p&gt;
&lt;p&gt;\begin{align}
\|X\| _{\infty}=\max _{j=1, \cdots, n} \sum _{i=1}^{m}\left|X _{i j}\right|
\end{align}&lt;/p&gt;
&lt;h2 id=&#34;对偶范数&#34;&gt;对偶范数&lt;/h2&gt;
&lt;p&gt;\begin{align}
\|z\|_{*}=\sup \{z^{T} x \mid \|x\| \leqslant 1\}
\end{align}&lt;/p&gt;
&lt;p&gt;关于对偶范数，有如下结论恒成立：&lt;/p&gt;
&lt;p&gt;\begin{align}
z^Tx \leqslant \|x\| \|z\|
\end{align}&lt;/p&gt;
&lt;p&gt;Euclid 范数的对偶还是 Euclid 范数，$\ell_1$-范数和 $\ell_{\infty}$-范数互为对偶。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>分析</title>
      <link>https://bowenei.gitee.io/learn/convex-optimization/mathematical-background/analysis/</link>
      <pubDate>Sat, 27 Nov 2021 19:59:12 +0800</pubDate>
      <guid>https://bowenei.gitee.io/learn/convex-optimization/mathematical-background/analysis/</guid>
      <description>&lt;h2 id=&#34;开集和闭集&#34;&gt;开集和闭集&lt;/h2&gt;
&lt;p&gt;对于 $x \in C \subseteq \mathbf{R}^n$，如果存在 $\epsilon &amp;gt; 0$ 使得&lt;/p&gt;
&lt;p&gt;\begin{align}
\{y \mid\|y-x\|_{2} \leqslant \epsilon\} \subseteq C
\end{align}&lt;/p&gt;
&lt;p&gt;即存在一个以 $x$ 为中心的完全包含于 $C$ 的球，则称 $x$ 为 $C$ 的&lt;strong&gt;内点&lt;/strong&gt;。$C$ 的所有内点组成的集合称为 $C$ 的内部，记作 $\operatorname{int}C$。若 $\operatorname{int}C = C$，则称集合 $C$ 为&lt;strong&gt;开集&lt;/strong&gt;。若集合 $C \subseteq \mathbf{R}^n$ 的补集 $\mathbf{R}^{n} \backslash C=\{x \in \mathbf{R}^{n} \mid x \notin C\}$ 是开集，则称集合 $C$ 为&lt;strong&gt;闭集&lt;/strong&gt;。&lt;/p&gt;
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /media/learn/convex-optimization/mathematical-background/1-2-1_huee4b216398525f3a5db517b1ae63af4c_61210_f7b47b0ab4fc52dbeee909d9ba5759b1.webp 400w,
               /media/learn/convex-optimization/mathematical-background/1-2-1_huee4b216398525f3a5db517b1ae63af4c_61210_8b41f91cdb19ca1b0bfb8a22c50f7769.webp 760w,
               /media/learn/convex-optimization/mathematical-background/1-2-1_huee4b216398525f3a5db517b1ae63af4c_61210_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://bowenei.gitee.io/media/learn/convex-optimization/mathematical-background/1-2-1_huee4b216398525f3a5db517b1ae63af4c_61210_f7b47b0ab4fc52dbeee909d9ba5759b1.webp&#34;
               width=&#34;760&#34;
               height=&#34;388&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;p&gt;如图所示，在二维平面中，不包含边界的圆是开集（左图所示），包含边界的圆是闭集（右图所示）。实际上，开集和闭集的概念可以看作是实数集上开区间和闭区间在 $n$ 维空间中的推广。&lt;/p&gt;
&lt;h3 id=&#34;闭包&#34;&gt;闭包&lt;/h3&gt;
&lt;p&gt;\begin{align}
\textbf{cl } C=\mathbf{R}^{n} \backslash \textbf{ int}(\mathbf{R}^{n} \backslash C)
\end{align}&lt;/p&gt;
&lt;p&gt;集合 $C$ 的闭包即为补集内部的补集。在上面的图中，左图不含边界的圆的闭包正好是右边包含边界的圆，而右边包含边界的圆的闭包正好是它本身。点 $x$ 属于 $C$ 的闭包的条件是：对于 $\forall \epsilon &amp;gt; 0$，$\exists y \in C$ 使得 $\|x-y\| _2 \leqslant \epsilon$。&lt;/p&gt;
&lt;h3 id=&#34;边界&#34;&gt;边界&lt;/h3&gt;
&lt;p&gt;\begin{align}
\textbf{bd } C=\textbf{cl } C \backslash \textbf{int } C
\end{align}&lt;/p&gt;
&lt;p&gt;显然，边界实际上就是集合的闭包去掉它所有的内点。我们可以用边界来刻画开集和闭集：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;开集：不含有边界点，即 $C \cap \textbf{bd } C = \emptyset$。&lt;/li&gt;
&lt;li&gt;闭集：包含边界，即 $\textbf{bd } C \in C$。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;上确界和下确界&#34;&gt;上确界和下确界&lt;/h2&gt;
&lt;p&gt;假定 $C \subseteq \mathbf{R}$。如果对 $\forall x \in C$，$\exists a \in \mathbf{R}$ 使得 $x \leqslant a$ 恒成立，则称 $a$ 为 $C$ 的&lt;strong&gt;上界&lt;/strong&gt;。其中，使得 $x \leqslant a$ 成立的最小的 $a$ 称为&lt;strong&gt;最小上界&lt;/strong&gt;或者&lt;strong&gt;上确界&lt;/strong&gt;，记作 $\sup C$。&lt;/p&gt;
&lt;p&gt;我们规定：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$\sup \emptyset = - \infty$&lt;/li&gt;
&lt;li&gt;当 $C$ 无上界时 $\sup C = \infty$&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;当 $\sup C \in C$ 时，我们说 $C$ 的上确界是&lt;strong&gt;可达&lt;/strong&gt;的。&lt;/p&gt;
&lt;p&gt;类似地，我们可以很容易给出下确界的定义。本文从略。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>函数</title>
      <link>https://bowenei.gitee.io/learn/convex-optimization/mathematical-background/functions/</link>
      <pubDate>Sun, 28 Nov 2021 14:26:49 +0800</pubDate>
      <guid>https://bowenei.gitee.io/learn/convex-optimization/mathematical-background/functions/</guid>
      <description>&lt;h2 id=&#34;连续&#34;&gt;连续&lt;/h2&gt;
&lt;p&gt;如果对 $\forall \epsilon &amp;gt; 0$，$\exists \delta$ 满足&lt;/p&gt;
&lt;p&gt;\begin{align}
y \in \operatorname{dom} f, \quad\|y-x\| _{2} \leqslant \delta \Longrightarrow\|f(y)-f(x)\| _{2} \leqslant \epsilon
\end{align}&lt;/p&gt;
&lt;p&gt;则称函数 $f: \mathbf{R}^n \rightarrow \mathbf{R}^m$ 在 $x \in \operatorname{dom} f$ 处&lt;strong&gt;连续&lt;/strong&gt;。&lt;/p&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    $\operatorname{dom} f$ 表示函数 $f: \mathbf{R}^n \rightarrow \mathbf{R}^m$ 的&lt;strong&gt;前域&lt;/strong&gt;。根据离散数学的相关知识，$f$ 是笛卡尔积 $\mathbf{R}^n \times \mathbf{R}^m$ 的子集，其前域（定义域）是 $\mathbf{R}^n$ 的子集。
  &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;可以用极限来描述函数的连续性：&lt;/p&gt;
&lt;p&gt;\begin{align}
\lim _{i \rightarrow \infty} f\left(x _{i}\right)=f\left(\lim _{i \rightarrow \infty} x _{i}\right)
\end{align}&lt;/p&gt;
&lt;p&gt;函数连续是指它在定义域上每个点都连续。&lt;/p&gt;
&lt;h2 id=&#34;闭函数&#34;&gt;闭函数&lt;/h2&gt;
&lt;p&gt;对于函数 $f: \mathbf{R}^n \rightarrow \mathbf{R}$，如果对 $\forall \alpha \in \mathbf{R}$，集合 $\{x \in \operatorname{dom} f \mid f(x) \leqslant \alpha\}$ 是闭集，则称函数 $f$ 是&lt;strong&gt;闭函数&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;对于连续函数 $f: \mathbf{R}^n \rightarrow \mathbf{R}$，如果 $\operatorname{dom} f$ 是闭集，那么 $f$ 是闭函数；如果 $\operatorname{dom} f$ 是开集，那么 $f$ 是闭函数的充要条件是 $f$ 将沿着任何收敛于 $\operatorname{dom} f$ 的边界点的序列趋于 $\infty$。&lt;/p&gt;
&lt;p&gt;来看 $\mathbf{R} \rightarrow \mathbf{R}$ 上的一些简单例子：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$f = x \log{x}$，$\operatorname{dom}f = (0, +\infty)$&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;而&lt;/p&gt;
&lt;p&gt;\begin{align}
\lim _{x \rightarrow 0^{+}} x \log{x} = 0 \neq \infty
\end{align}&lt;/p&gt;
&lt;p&gt;因此不是闭函数。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$f = \log{x}$，$\operatorname{dom}f = (0, +\infty)$&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;而&lt;/p&gt;
&lt;p&gt;\begin{align}
\lim _{x \rightarrow 0^{+}} \log{x} = -\infty
\end{align}&lt;/p&gt;
&lt;p&gt;且&lt;/p&gt;
&lt;p&gt;\begin{align}
\lim _{x \rightarrow +\infty} \log{x} = +\infty
\end{align}&lt;/p&gt;
&lt;p&gt;因此是闭函数。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>导数</title>
      <link>https://bowenei.gitee.io/learn/convex-optimization/mathematical-background/derivatives/</link>
      <pubDate>Sun, 28 Nov 2021 15:06:00 +0800</pubDate>
      <guid>https://bowenei.gitee.io/learn/convex-optimization/mathematical-background/derivatives/</guid>
      <description>&lt;h2 id=&#34;导数&#34;&gt;导数&lt;/h2&gt;
&lt;p&gt;设函数 $f: \mathbf{R}^{n} \rightarrow \mathbf{R}^{m}$，$x \in \operatorname{int} \operatorname{dom} f$。如果存在矩阵 $Df(x) \in \mathbf{R}^{m \times n}$，满足&lt;/p&gt;
&lt;p&gt;\begin{align}
\lim _{z \in \operatorname{dom} f, z \neq x, z \rightarrow x} \frac{\|f(z)-f(x)-D f(x)(z-x)\| _{2}}{\|z-x\| _{2}}=0
\end{align}&lt;/p&gt;
&lt;p&gt;则称函数 $f$ &lt;strong&gt;可微&lt;/strong&gt;，并称 $Df(x)$ 为 $f$ 在 $x$ 处的&lt;strong&gt;导数&lt;/strong&gt;（或 &lt;strong&gt;Jacobian&lt;/strong&gt; 矩阵）。&lt;/p&gt;
&lt;p&gt;我们将 $z$ 的仿射函数&lt;/p&gt;
&lt;p&gt;\begin{align}
f(x) + Df(x)(z-x)
\end{align}&lt;/p&gt;
&lt;p&gt;称为 $f$ 在 $x$ 处（或附近）的&lt;strong&gt;一次逼近&lt;/strong&gt;。当 $z$ 接近 $x$ 时，该仿射函数非常接近 $f$。&lt;/p&gt;
&lt;p&gt;$Df(x)$ 可以通过计算偏导数的方式求得：&lt;/p&gt;
&lt;p&gt;\begin{align}
D f(x) _{ij}=\frac{\partial f _{i}(x)}{\partial x _{j}}, \quad i=1, \cdots, m, \quad j=1, \cdots, n
\end{align}&lt;/p&gt;
&lt;h2 id=&#34;梯度&#34;&gt;梯度&lt;/h2&gt;
&lt;p&gt;\begin{align}
\nabla f(x)=D f(x)^{T}
\end{align}&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;梯度&lt;/strong&gt;是一个列向量，它的分量是 $f$ 的偏导数。&lt;/p&gt;
&lt;p&gt;\begin{align}
\nabla f(x) _{i}=\frac{\partial f(x)}{\partial x _{i}}, \quad i=1, \cdots, n
\end{align}&lt;/p&gt;
&lt;h2 id=&#34;链式规则&#34;&gt;链式规则&lt;/h2&gt;
&lt;p&gt;设复合函数 $h(x) = g(f(x))$，则&lt;/p&gt;
&lt;p&gt;\begin{align}
\nabla h(x) &amp;amp;= g&amp;rsquo;(f(x))f(x) \\
&amp;amp;= \nabla g(f(x))^T f(x)
\end{align}&lt;/p&gt;
&lt;h3 id=&#34;仿射函数&#34;&gt;仿射函数&lt;/h3&gt;
&lt;p&gt;设仿射函数 $g(x) = f(Ax+b)$，其中 $f: \mathbf{R}^{n} \rightarrow \mathbf{R}^{m}$，$A \in \mathbf{R}^{n \times p}$，$b \in \mathbf{R}^{n}$，则 $g: \mathbf{R}^{p} \rightarrow \mathbf{R}^{m}$。当 $f$ 是实函数时（即 $m=1$），仿射函数 $g$ 的梯度公式为：&lt;/p&gt;
&lt;p&gt;\begin{align}
\nabla g(x) = A^T \nabla f(Ax+b)
\end{align}&lt;/p&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    &lt;p&gt;&lt;strong&gt;仿射&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;从 $\mathbf{R}^{n}$ 到 $\mathbf{R}^{m}$ 的映射 $x \rightarrow Ax+b$ 称为&lt;strong&gt;仿射变换&lt;/strong&gt;。当 $m=1$ 时，称上述仿射变换为&lt;strong&gt;仿射函数&lt;/strong&gt;。若仿射函数的 $b=0$，则称之为&lt;strong&gt;线性函数&lt;/strong&gt;。&lt;/p&gt;

  &lt;/div&gt;
&lt;/div&gt;

&lt;h3 id=&#34;方向导数&#34;&gt;方向导数&lt;/h3&gt;
&lt;p&gt;设 $f: \mathbf{R}^{n} \rightarrow \mathbf{R}^{m}$，$x, v \in \mathbf{R}^{n}$。定义函数 $\tilde{f} = f(x+tv)$。（粗略地说，$\tilde{f}$ 是将 $f$ 限制在直线 $\{x+tv \mid t \in \mathbf{R}\}$ 上的函数。）则&lt;/p&gt;
&lt;p&gt;\begin{align}
D \tilde{f}(t)=\tilde{f}^{\prime}(t)=\nabla f(x+t v)^{T} v
\end{align}&lt;/p&gt;
&lt;p&gt;并称标量 $\tilde{f}^{\prime}(0)$ 为函数 $f$ 在 $x$ 处沿方向 $v$ 的&lt;strong&gt;方向导数&lt;/strong&gt;。&lt;/p&gt;
&lt;h2 id=&#34;二阶导数&#34;&gt;二阶导数&lt;/h2&gt;
&lt;p&gt;设函数 $f: \mathbf{R}^{n} \rightarrow \mathbf{R}$，$x \in \operatorname{int} \operatorname{dom} f$。那么 $f$ 在 $x$ 处的二阶导数（或 &lt;strong&gt;Hessian&lt;/strong&gt; 矩阵）为&lt;/p&gt;
&lt;p&gt;\begin{align}
\nabla^{2} f(x) _{ij}=\frac{\partial^{2} f(x)}{\partial x _{i} \partial x _{j}}, \quad i=1, \cdots, n, \quad j=1, \cdots, n
\end{align}&lt;/p&gt;
&lt;p&gt;函数 $f$ 在（或接近）$x$ 处以 $z$ 为变量的&lt;strong&gt;二次逼近&lt;/strong&gt;为&lt;/p&gt;
&lt;p&gt;\begin{align}
\widehat{f}(z)=f(x)+\nabla f(x)^{T}(z-x)+\frac{1}{2}(z-x)^{T} \nabla^{2} f(x)(z-x)
\end{align}&lt;/p&gt;
&lt;h2 id=&#34;二阶导数的链式规则&#34;&gt;二阶导数的链式规则&lt;/h2&gt;
&lt;h3 id=&#34;标量复合函数&#34;&gt;标量复合函数&lt;/h3&gt;
&lt;p&gt;设 $f: \mathbf{R}^{n} \rightarrow \mathbf{R}$，$g: \mathbf{R} \rightarrow \mathbf{R}$，$h(x)=g(f(x))$。我们有&lt;/p&gt;
&lt;p&gt;\begin{align}
\nabla^{2} h(x)=g^{\prime}(f(x)) \nabla^{2} f(x)+g^{\prime \prime}(f(x)) \nabla f(x) \nabla f(x)^{T}
\end{align}&lt;/p&gt;
&lt;h3 id=&#34;复合仿射函数&#34;&gt;复合仿射函数&lt;/h3&gt;
&lt;p&gt;设 $f: \mathbf{R}^{n} \rightarrow \mathbf{R}$，$A \in \mathbf{R}^{n \times m}$，$b \in \mathbf{R}^{n}$，定义 $g: \mathbf{R}^{m} \rightarrow \mathbf{R}$ 为 $g(x) = f(Ax+b)$。我们有&lt;/p&gt;
&lt;p&gt;\begin{align}
\nabla^{2} g(x)=A^T \nabla^{2} f(Ax+b) A
\end{align}&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>线性代数</title>
      <link>https://bowenei.gitee.io/learn/convex-optimization/mathematical-background/linear-algebra/</link>
      <pubDate>Sun, 28 Nov 2021 18:47:40 +0800</pubDate>
      <guid>https://bowenei.gitee.io/learn/convex-optimization/mathematical-background/linear-algebra/</guid>
      <description>&lt;h2 id=&#34;值域和零空间&#34;&gt;值域和零空间&lt;/h2&gt;
&lt;p&gt;设矩阵 $A \in \mathbf{R}^{m \times n}$，$A$ 的&lt;strong&gt;值域&lt;/strong&gt;是指 $\mathbf{R}^{m}$ 中能够写成 $A$ 的列向量的线性组合的所有向量的集合，即&lt;/p&gt;
&lt;p&gt;\begin{align}
\mathcal{R} (A) = \{Ax \mid x \in \mathbf{R}^{n} \}
\end{align}&lt;/p&gt;
&lt;p&gt;值域 $\mathcal{R} (A)$ 是 $\mathbf{R}^{m}$ 的子空间，它的维数是 $A$ 的&lt;strong&gt;秩&lt;/strong&gt;，记作 $\operatorname{rank} A$。$A$ 的秩一定不会大于 $m$ 和 $n$ 的较小值。当 $\operatorname{rank} A = \min \{m, n\}$ 时，称 $A$ 为&lt;strong&gt;满秩&lt;/strong&gt;矩阵。&lt;/p&gt;
&lt;p&gt;$A$ 的&lt;strong&gt;零空间&lt;/strong&gt;（或&lt;strong&gt;核&lt;/strong&gt;）是指被 $A$ 映射成零的所有向量 $x$ 的集合，即&lt;/p&gt;
&lt;p&gt;\begin{align}
\mathcal{N}(A) = \{x \mid Ax=0\}
\end{align}&lt;/p&gt;
&lt;h3 id=&#34;正交补&#34;&gt;正交补&lt;/h3&gt;
&lt;p&gt;\begin{align}
\mathcal{V}^{\bot} = \{x \mid \forall z \in \mathcal{V}, z^Tx=0\}
\end{align}&lt;/p&gt;
&lt;p&gt;有如下结论恒成立：&lt;/p&gt;
&lt;p&gt;\begin{align}
\mathcal{V}^{\bot\bot} = \mathcal{V}
\end{align}&lt;/p&gt;
&lt;h3 id=&#34;a-导出的正交分解&#34;&gt;$A$ 导出的正交分解&lt;/h3&gt;
&lt;p&gt;\begin{align}
\mathcal{N}(A) = \mathcal{R}(A^T)^{\bot}
\end{align}&lt;/p&gt;
&lt;h2 id=&#34;对称特征值分解&#34;&gt;对称特征值分解&lt;/h2&gt;
&lt;p&gt;设 $A$ 为 $n$ 阶实对称矩阵，则 $A$ 可以因式分解为&lt;/p&gt;
&lt;p&gt;\begin{align}
A = Q \Lambda Q^T
\end{align}&lt;/p&gt;
&lt;p&gt;其中 $Q \in \mathbf{R}^{n \times n}$ 是正交矩阵，满足 $Q^TQ = I$，而 $\Lambda = \operatorname{diag}(\lambda_1, \cdots, \lambda_n)$。实数 $\lambda_i$ 是 $A$ 的&lt;strong&gt;特征值&lt;/strong&gt;，是&lt;strong&gt;特征多项式&lt;/strong&gt; $\det(sI-A)$ 的根，$Q$ 的列向量构成 $A$ 的一组正交&lt;strong&gt;特征向量&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;通常我们将特征值按从大到小排序，用 $\lambda_{i}(A)$ 表示第 $i$ 大特征值。最大特征值记作 $\lambda_{1}(A) = \lambda_{max}(A)$，最小特征值记作 $\lambda_{n}(A) = \lambda_{min}(A)$。&lt;/p&gt;
&lt;p&gt;特征值具有如下性质：&lt;/p&gt;
&lt;p&gt;\begin{align}
\det A &amp;amp;= \prod_{i=1}^{n} \lambda_i \\
\operatorname{tr} A &amp;amp;= \sum_{i=1}^{n} \lambda_i
\end{align}&lt;/p&gt;
&lt;h3 id=&#34;矩阵不等式&#34;&gt;矩阵不等式&lt;/h3&gt;
&lt;p&gt;\begin{align}
\lambda_{\max}(A)=\sup_{x \neq 0} \frac{x^{T} A x}{x^{T} x}, \quad \lambda_{\min}(A)=\inf _{x \neq 0} \frac{x^{T} A x}{x^{T} x}
\end{align}&lt;/p&gt;
&lt;p&gt;特别地，对 $\forall x$，我们有&lt;/p&gt;
&lt;p&gt;\begin{align}
\lambda_{\min}(A)x^Tx \leqslant x^Tx \leqslant \lambda_{\max}(A)x^Tx
\end{align}&lt;/p&gt;
&lt;h3 id=&#34;正定矩阵&#34;&gt;正定矩阵&lt;/h3&gt;
&lt;p&gt;若矩阵 $A$ 对 $\forall x \ne 0$，有 $x^TAx &amp;gt; 0$ 成立，则称矩阵 $A$ &lt;strong&gt;正定&lt;/strong&gt;，记作 $A \succ 0$。显然，$A \succ 0$ 的充要条件是 $\lambda_{\min}(A) &amp;gt; 0$。&lt;/p&gt;
&lt;p&gt;同理，半正定（非负定）、负定、半负定（非正定）矩阵的定义类似。本文从略。&lt;/p&gt;
&lt;h3 id=&#34;对称平方根&#34;&gt;对称平方根&lt;/h3&gt;
&lt;p&gt;\begin{align}
A^{1 / 2}=Q \operatorname{diag}\left(\lambda_{1}^{1 / 2}, \cdots, \lambda_{n}^{1 / 2}\right) Q^{T}
\end{align}&lt;/p&gt;
&lt;p&gt;平方根 $A^{1/2}$ 是矩阵方程 $X^2 = A$ 的唯一的对称半正定的解。&lt;/p&gt;
&lt;h2 id=&#34;广义特征值分解&#34;&gt;广义特征值分解&lt;/h2&gt;
&lt;p&gt;两个对称矩阵 $\left(A, B\right) \in \mathbf{S}^{n} \times \mathbf{S}^{n}$ 的广义特征值定义为多项式 $\det (sB - A)$ 的根。&lt;/p&gt;
&lt;h2 id=&#34;奇异值分解&#34;&gt;奇异值分解&lt;/h2&gt;
&lt;p&gt;设 $A \in \mathbf{R}^{m \times n}$，$\operatorname{rank} A = r$，那么 $A$ 可以因式分解为&lt;/p&gt;
&lt;p&gt;\begin{align}
A = U \Sigma V^T
\end{align}&lt;/p&gt;
&lt;p&gt;其中 $U \in \mathbf{R}^{m \times r}$ 满足 $U^TU = I$，$V \in \mathbf{R}^{n \times r}$ 满足 $V^TV = I$，而 $\Sigma = \operatorname{diag}(\sigma_1, \cdots, \sigma_r)$ 满足&lt;/p&gt;
&lt;p&gt;\begin{align}
\sigma_1 \geqslant \sigma_2 \geqslant \cdots \geqslant \sigma_r &amp;gt; 0
\end{align}&lt;/p&gt;
&lt;p&gt;称为 $A$ 的&lt;strong&gt;奇异值分解&lt;/strong&gt;（SVD）。$U$ 的列向量称为 $A$ 的&lt;strong&gt;左奇异向量&lt;/strong&gt;，$V$ 的列向量称为 $A$ 的&lt;strong&gt;右奇异向量&lt;/strong&gt;，而 $\sigma_i$ 称为&lt;strong&gt;奇异值&lt;/strong&gt;。奇异值分解可以写成&lt;/p&gt;
&lt;p&gt;\begin{align}
A=\sum_{i=1}^{r} \sigma_{i} u_{i} v_{i}^{T}
\end{align}&lt;/p&gt;
&lt;h3 id=&#34;伪逆&#34;&gt;伪逆&lt;/h3&gt;
&lt;p&gt;设 $A = U \Sigma V^T$ 为 $A \in \mathbf{m \times n}$ 的奇异值分解，$\operatorname{rank} A = r$，则 $A$ 的&lt;strong&gt;伪逆&lt;/strong&gt;为&lt;/p&gt;
&lt;p&gt;\begin{align}
A^{\dagger}=V \Sigma^{-1} U^{T} \in \mathbf{R}^{n \times m}
\end{align}&lt;/p&gt;
&lt;p&gt;伪逆可以用于求解最小二乘、最小范数、二次规划以及（Euclid）投影这些问题。&lt;/p&gt;
&lt;h2 id=&#34;schur-补&#34;&gt;Schur 补&lt;/h2&gt;
&lt;p&gt;考虑进行以下划分的矩阵 $X \in \mathbf{S}^{n}$&lt;/p&gt;
&lt;p&gt;\begin{align}
X = \left [ \begin{matrix}
A &amp;amp; B \\
B^T &amp;amp; C
\end{matrix} \right ] 
\end{align}&lt;/p&gt;
&lt;p&gt;其中 $A \in \mathbf{S}^k$。如果 $\det A \ne 0$，矩阵&lt;/p&gt;
&lt;p&gt;\begin{align}
S = C - B^TA^{-1}B
\end{align}&lt;/p&gt;
&lt;p&gt;被称为 $A$ 在 $X$ 中的 &lt;strong&gt;Schur 补&lt;/strong&gt;。Schur 补出现于很多重要的公式和定理中，例如&lt;/p&gt;
&lt;p&gt;\begin{align}
\det X = \det A \det S
\end{align}&lt;/p&gt;
&lt;h3 id=&#34;分块矩阵求逆&#34;&gt;分块矩阵求逆&lt;/h3&gt;
&lt;p&gt;考虑如下分块矩阵方程：&lt;/p&gt;
&lt;p&gt;\begin{align}
\left[\begin{array}{cc}
A &amp;amp; B \\
B^{T} &amp;amp; C
\end{array}\right]\left[\begin{array}{l}
x \\
y
\end{array}\right]=\left[\begin{array}{l}
u \\
v
\end{array}\right]
\end{align}&lt;/p&gt;
&lt;p&gt;假设 $\det A \ne 0$。将方程中的 $x$ 消去，解得&lt;/p&gt;
&lt;p&gt;\begin{align}
y = S^{-1}\left(v - B^TA^{-1}u\right)
\end{align}&lt;/p&gt;
&lt;p&gt;将 $y$ 代入原方程，解得&lt;/p&gt;
&lt;p&gt;\begin{align}
x=\left(A^{-1}+A^{-1} B S^{-1} B^{T} A^{-1}\right) u-A^{-1} B S^{-1} v
\end{align}&lt;/p&gt;
&lt;p&gt;于是我们可以得到分块矩阵的求逆公式：&lt;/p&gt;
&lt;p&gt;\begin{align}
\left[\begin{array}{cc}
A &amp;amp; B \\
B^{T} &amp;amp; C
\end{array}\right]^{-1}=\left[\begin{array}{cc}
A^{-1}+A^{-1} B S^{-1} B^{T} A^{-1} &amp;amp; -A^{-1} B S^{-1} \\
-S^{-1} B^{T} A^{-1} &amp;amp; S^{-1}
\end{array}\right]
\end{align}&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>
